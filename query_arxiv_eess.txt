
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Can Domain Experts Rely on AI Appropriately? A Case Study on AI-Assisted Prostate Cancer MRI Diagnosis
Authors: Chacha Chen, Han Liu, Jiamin Yang, Benjamin M. Mervak, Bora Kalaycioglu, Grace Lee, Emre Cakmakli, Matteo Bonatti, Sridhar Pudu, Osman Kahraman, Gul Gizem Pamuk, Aytekin Oto, Aritrick Chatterjee, Chenhao Tan
Abstract: Despite the growing interest in human-AI decision making, experimental studies with domain experts remain rare, largely due to the complexity of working with domain experts and the challenges in setting up realistic experiments. In this work, we conduct an in-depth collaboration with radiologists in prostate cancer diagnosis based on MRI images. Building on existing tools for teaching prostate cancer diagnosis, we develop an interface and conduct two experiments to study how AI assistance and performance feedback shape the decision making of domain experts. In Study 1, clinicians were asked to provide an initial diagnosis (human), then view the AI's prediction, and subsequently finalize their decision (human-AI team). In Study 2 (after a memory wash-out period), the same participants first received aggregated performance statistics from Study 1, specifically their own performance, the AI's performance, and their human-AI team performance, and then directly viewed the AI's prediction before making their diagnosis (i.e., no independent initial diagnosis). These two workflows represent realistic ways that clinical AI tools might be used in practice, where the second study simulates a scenario where doctors can adjust their reliance and trust on AI based on prior performance feedback. Our findings show that, while human-AI teams consistently outperform humans alone, they still underperform the AI due to under-reliance, similar to prior studies with crowdworkers. Providing clinicians with performance feedback did not significantly improve the performance of human-AI teams, although showing AI decisions in advance nudges people to follow AI more. Meanwhile, we observe that the ensemble of human-AI teams can outperform AI alone, suggesting promising directions for human-AI collaboration.

Paper number 2:
Title: Dementia Classification Using Acoustic Speech and Feature Selection
Authors: Marko Niemelä, Mikaela von Bonsdorff, Sami Äyrämö, Tommi Kärkkäinen
Abstract: Dementia is a general term for a group of syndromes that affect cognitive functions such as memory, thinking, reasoning, and the ability to perform daily tasks. The number of dementia patients is increasing as the population ages, and it is estimated that over 10 million people develop dementia each year. Dementia progresses gradually, and the sooner a patient receives help and support, the better their chances of maintaining their functional abilities. For this reason, early diagnosis of dementia is important. In recent years, machine learning models based on naturally spoken language have been developed for the early diagnosis of dementia. These methods have proven to be user-friendly, cost-effective, scalable, and capable of providing extremely fast diagnoses. This study utilizes the well-known ADReSS challenge dataset for classifying healthy controls and Alzheimer's patients. The dataset contains speech recordings from a picture description task featuring a kitchen scene, collected from both healthy controls and dementia patients. Unlike most studies, this research does not segment the audio recordings into active speech segments; instead, acoustic features are extracted from entire recordings. The study employs Ridge linear regression, Extreme Minimal Learning Machine, and Linear Support Vector Machine machine learning models to compute feature importance scores based on model outputs. The Ridge model performed best in Leave-One-Subject-Out cross-validation, achieving a classification accuracy of 87.8%. The EMLM model, proved to be effective in both cross-validation and the classification of a separate test dataset, with accuracies of 85.3% and 79.2%, respectively. The study's results rank among the top compared to other studies using the same dataset and acoustic feature extraction for dementia diagnosis.

Paper number 3:
Title: Lanpaint: Training-Free Diffusion Inpainting with Exact and Fast Conditional Inference
Authors: Candi Zheng, Yuan Lan, Yang Wang
Abstract: Diffusion models generate high-quality images but often lack efficient and universally applicable inpainting capabilities, particularly in community-trained models. We introduce LanPaint, a training-free method tailored for widely adopted ODE-based samplers, which leverages Langevin dynamics to perform exact conditional inference, enabling precise and visually coherent inpainting. LanPaint addresses two key challenges in Langevin-based inpainting: (1) the risk of local likelihood maxima trapping and (2) slow convergence. By proposing a guided score function and a fast-converging Langevin framework, LanPaint achieves high-fidelity results in very few iterations. Experiments demonstrate that LanPaint outperforms existing training-free inpainting techniques, outperforming in challenging tasks such as outpainting with Stable Diffusion.

Paper number 4:
Title: MetaFE-DE: Learning Meta Feature Embedding for Depth Estimation from Monocular Endoscopic Images
Authors: Dawei Lu, Deqiang Xiao, Danni Ai, Jingfan Fan, Tianyu Fu, Yucong Lin, Hong Song, Xujiong Ye, Lei Zhang, Jian Yang
Abstract: Depth estimation from monocular endoscopic images presents significant challenges due to the complexity of endoscopic surgery, such as irregular shapes of human soft tissues, as well as variations in lighting conditions. Existing methods primarily estimate the depth information from RGB images directly, and often surffer the limited interpretability and accuracy. Given that RGB and depth images are two views of the same endoscopic surgery scene, in this paper, we introduce a novel concept referred as ``meta feature embedding (MetaFE)", in which the physical entities (e.g., tissues and surgical instruments) of endoscopic surgery are represented using the shared features that can be alternatively decoded into RGB or depth image. With this concept, we propose a two-stage self-supervised learning paradigm for the monocular endoscopic depth estimation. In the first stage, we propose a temporal representation learner using diffusion models, which are aligned with the spatial information through the cross normalization to construct the MetaFE. In the second stage, self-supervised monocular depth estimation with the brightness calibration is applied to decode the meta features into the depth image. Extensive evaluation on diverse endoscopic datasets demonstrates that our approach outperforms the state-of-the-art method in depth estimation, achieving superior accuracy and generalization. The source code will be publicly available.

Paper number 5:
Title: Integral Fast Fourier Color Constancy
Authors: Wenjun Wei, Yanlin Qian, Huaian Chen, Junkang Dai, Yi Jin
Abstract: Traditional auto white balance (AWB) algorithms typically assume a single global illuminant source, which leads to color distortions in multi-illuminant scenes. While recent neural network-based methods have shown excellent accuracy in such scenarios, their high parameter count and computational demands limit their practicality for real-time video applications. The Fast Fourier Color Constancy (FFCC) algorithm was proposed for single-illuminant-source scenes, predicting a global illuminant source with high efficiency. However, it cannot be directly applied to multi-illuminant scenarios unless specifically modified. To address this, we propose Integral Fast Fourier Color Constancy (IFFCC), an extension of FFCC tailored for multi-illuminant scenes. IFFCC leverages the proposed integral UV histogram to accelerate histogram computations across all possible regions in Cartesian space and parallelizes Fourier-based convolution operations, resulting in a spatially-smooth illumination map. This approach enables high-accuracy, real-time AWB in multi-illuminant scenes. Extensive experiments show that IFFCC achieves accuracy that is on par with or surpasses that of pixel-level neural networks, while reducing the parameter count by over $400\times$ and processing speed by 20 - $100\times$ faster than network-based approaches.

Paper number 6:
Title: FreqPrior: Improving Video Diffusion Models with Frequency Filtering Gaussian Noise
Authors: Yunlong Yuan, Yuanfan Guo, Chunwei Wang, Wei Zhang, Hang Xu, Li Zhang
Abstract: Text-driven video generation has advanced significantly due to developments in diffusion models. Beyond the training and sampling phases, recent studies have investigated noise priors of diffusion models, as improved noise priors yield better generation results. One recent approach employs the Fourier transform to manipulate noise, marking the initial exploration of frequency operations in this context. However, it often generates videos that lack motion dynamics and imaging details. In this work, we provide a comprehensive theoretical analysis of the variance decay issue present in existing methods, contributing to the loss of details and motion dynamics. Recognizing the critical impact of noise distribution on generation quality, we introduce FreqPrior, a novel noise initialization strategy that refines noise in the frequency domain. Our method features a novel filtering technique designed to address different frequency signals while maintaining the noise prior distribution that closely approximates a standard Gaussian distribution. Additionally, we propose a partial sampling process by perturbing the latent at an intermediate timestep during finding the noise prior, significantly reducing inference time without compromising quality. Extensive experiments on VBench demonstrate that our method achieves the highest scores in both quality and semantic assessments, resulting in the best overall total score. These results highlight the superiority of our proposed noise prior.

Paper number 7:
Title: SLCGC: A lightweight Self-supervised Low-pass Contrastive Graph Clustering Network for Hyperspectral Images
Authors: Yao Ding, Zhili Zhang, Aitao Yang, Yaoming Cai, Xiongwu Xiao, Danfeng Hong, Junsong Yuan
Abstract: Self-supervised hyperspectral image (HSI) clustering remains a fundamental yet challenging task due to the absence of labeled data and the inherent complexity of spatial-spectral interactions. While recent advancements have explored innovative approaches, existing methods face critical limitations in clustering accuracy, feature discriminability, computational efficiency, and robustness to noise, hindering their practical deployment. In this paper, a self-supervised efficient low-pass contrastive graph clustering (SLCGC) is introduced for HSIs. Our approach begins with homogeneous region generation, which aggregates pixels into spectrally consistent regions to preserve local spatial-spectral coherence while drastically reducing graph complexity. We then construct a structural graph using an adjacency matrix A and introduce a low-pass graph denoising mechanism to suppress high-frequency noise in the graph topology, ensuring stable feature propagation. A dual-branch graph contrastive learning module is developed, where Gaussian noise perturbations generate augmented views through two multilayer perceptrons (MLPs), and a cross-view contrastive loss enforces structural consistency between views to learn noise-invariant representations. Finally, latent embeddings optimized by this process are clustered via K-means. Extensive experiments and repeated comparative analysis have verified that our SLCGC contains high clustering accuracy, low computational complexity, and strong robustness. The code source will be available at this https URL.

Paper number 8:
Title: Controllable Satellite-to-Street-View Synthesis with Precise Pose Alignment and Zero-Shot Environmental Control
Authors: Xianghui Ze, Zhenbo Song, Qiwei Wang, Jianfeng Lu, Yujiao Shi
Abstract: Generating street-view images from satellite imagery is a challenging task, particularly in maintaining accurate pose alignment and incorporating diverse environmental conditions. While diffusion models have shown promise in generative tasks, their ability to maintain strict pose alignment throughout the diffusion process is limited. In this paper, we propose a novel Iterative Homography Adjustment (IHA) scheme applied during the denoising process, which effectively addresses pose misalignment and ensures spatial consistency in the generated street-view images. Additionally, currently, available datasets for satellite-to-street-view generation are limited in their diversity of illumination and weather conditions, thereby restricting the generalizability of the generated outputs. To mitigate this, we introduce a text-guided illumination and weather-controlled sampling strategy that enables fine-grained control over the environmental factors. Extensive quantitative and qualitative evaluations demonstrate that our approach significantly improves pose accuracy and enhances the diversity and realism of generated street-view images, setting a new benchmark for satellite-to-street-view generation tasks.

Paper number 9:
Title: Efficient Image Restoration via Latent Consistency Flow Matching
Authors: Elad Cohen, Idan Achituve, Idit Diamant, Arnon Netzer, Hai Victor Habi
Abstract: Recent advances in generative image restoration (IR) have demonstrated impressive results. However, these methods are hindered by their substantial size and computational demands, rendering them unsuitable for deployment on edge devices. This work introduces ELIR, an Efficient Latent Image Restoration method. ELIR operates in latent space by first predicting the latent representation of the minimum mean square error (MMSE) estimator and then transporting this estimate to high-quality images using a latent consistency flow-based model. Consequently, ELIR is more than 4x faster compared to the state-of-the-art diffusion and flow-based approaches. Moreover, ELIR is also more than 4x smaller, making it well-suited for deployment on resource-constrained edge devices. Comprehensive evaluations of various image restoration tasks show that ELIR achieves competitive results, effectively balancing distortion and perceptual quality metrics while offering improved efficiency in terms of memory and computation.

Paper number 10:
Title: Proxy Prompt: Endowing SAM and SAM 2 with Auto-Interactive-Prompt for Medical Segmentation
Authors: Wang Xinyi, Kang Hongyu, Wei Peishan, Shuai Li, Yu Sun, Sai Kit Lam, Yongping Zheng
Abstract: In this paper, we aim to address the unmet demand for automated prompting and enhanced human-model interactions of SAM and SAM2 for the sake of promoting their widespread clinical adoption. Specifically, we propose Proxy Prompt (PP), auto-generated by leveraging non-target data with a pre-annotated mask. We devise a novel 3-step context-selection strategy for adaptively selecting the most representative contextual information from non-target data via vision mamba and selective maps, empowering the guiding capability of non-target image-mask pairs for segmentation on target image/video data. To reinforce human-model interactions in PP, we further propose a contextual colorization module via a dual-reverse cross-attention to enhance interactions between target features and contextual-embedding with amplifying distinctive features of user-defined object(s). Via extensive evaluations, our method achieves state-of-the-art performance on four public datasets and yields comparable results with fully-trained models, even when trained with only 16 image masks.

Paper number 11:
Title: DC-VSR: Spatially and Temporally Consistent Video Super-Resolution with Video Diffusion Prior
Authors: Janghyeok Han, Gyujin Sim, Geonung Kim, Hyunseung Lee, Kyuha Choi, Youngseok Han, Sunghyun Cho
Abstract: Video super-resolution (VSR) aims to reconstruct a high-resolution (HR) video from a low-resolution (LR) counterpart. Achieving successful VSR requires producing realistic HR details and ensuring both spatial and temporal consistency. To restore realistic details, diffusion-based VSR approaches have recently been proposed. However, the inherent randomness of diffusion, combined with their tile-based approach, often leads to spatio-temporal inconsistencies. In this paper, we propose DC-VSR, a novel VSR approach to produce spatially and temporally consistent VSR results with realistic textures. To achieve spatial and temporal consistency, DC-VSR adopts a novel Spatial Attention Propagation (SAP) scheme and a Temporal Attention Propagation (TAP) scheme that propagate information across spatio-temporal tiles based on the self-attention mechanism. To enhance high-frequency details, we also introduce Detail-Suppression Self-Attention Guidance (DSSAG), a novel diffusion guidance scheme. Comprehensive experiments demonstrate that DC-VSR achieves spatially and temporally consistent, high-quality VSR results, outperforming previous approaches.

Paper number 12:
Title: Enhancing Free-hand 3D Photoacoustic and Ultrasound Reconstruction using Deep Learning
Authors: SiYeoul Lee, SeonHo Kim, Minkyung Seo, SeongKyu Park, Salehin Imrus, Kambaluru Ashok, DongEon Lee, Chunsu Park, SeonYeong Lee, Jiye Kim, Jae-Heung Yoo, MinWoo Kim
Abstract: This study introduces a motion-based learning network with a global-local self-attention module (MoGLo-Net) to enhance 3D reconstruction in handheld photoacoustic and ultrasound (PAUS) imaging. Standard PAUS imaging is often limited by a narrow field of view and the inability to effectively visualize complex 3D structures. The 3D freehand technique, which aligns sequential 2D images for 3D reconstruction, faces significant challenges in accurate motion estimation without relying on external positional sensors. MoGLo-Net addresses these limitations through an innovative adaptation of the self-attention mechanism, which effectively exploits the critical regions, such as fully-developed speckle area or high-echogenic tissue area within successive ultrasound images to accurately estimate motion parameters. This facilitates the extraction of intricate features from individual frames. Additionally, we designed a patch-wise correlation operation to generate a correlation volume that is highly correlated with the scanning motion. A custom loss function was also developed to ensure robust learning with minimized bias, leveraging the characteristics of the motion parameters. Experimental evaluations demonstrated that MoGLo-Net surpasses current state-of-the-art methods in both quantitative and qualitative performance metrics. Furthermore, we expanded the application of 3D reconstruction technology beyond simple B-mode ultrasound volumes to incorporate Doppler ultrasound and photoacoustic imaging, enabling 3D visualization of vasculature. The source code for this study is publicly available at: this https URL

Paper number 13:
Title: Comprehensive Layer-wise Analysis of SSL Models for Audio Deepfake Detection
Authors: Yassine El Kheir, Youness Samih, Suraj Maharjan, Tim Polzehl, Sebastian Möller
Abstract: This paper conducts a comprehensive layer-wise analysis of self-supervised learning (SSL) models for audio deepfake detection across diverse contexts, including multilingual datasets (English, Chinese, Spanish), partial, song, and scene-based deepfake scenarios. By systematically evaluating the contributions of different transformer layers, we uncover critical insights into model behavior and performance. Our findings reveal that lower layers consistently provide the most discriminative features, while higher layers capture less relevant information. Notably, all models achieve competitive equal error rate (EER) scores even when employing a reduced number of layers. This indicates that we can reduce computational costs and increase the inference speed of detecting deepfakes by utilizing only a few lower layers. This work enhances our understanding of SSL models in deepfake detection, offering valuable insights applicable across varied linguistic and contextual settings. Our trained models and code are publicly available: this https URL.

Paper number 14:
Title: On the effects of angular acceleration in orientation estimation using inertial measurement units
Authors: Felix Brändle, David Meister, Marc Seidel, Robin Strässer, Frank Allgöwer
Abstract: Determining the orientation of a rigid body using an inertial measurement unit is a common problem in many engineering applications. However, sensor fusion algorithms suffer from performance loss when other motions besides the gravitational acceleration affect the accelerometer. In this paper, we show that linear accelerations caused by rotational accelerations lead to additional zeros in the linearized transfer functions, which are strongly dependent on the operating point. These zeros lead to non-minimum phase systems, which are known to be challenging to control. In addition, we demonstrate how Mahony and Madgwick filters can mitigate the effects of the additional acceleration, but at the cost of reduced bandwidth. This generates insights into a fundamental problem in estimation, that are transferable to many practical applications.

Paper number 15:
Title: Decoding Human Attentive States from Spatial-temporal EEG Patches Using Transformers
Authors: Yi Ding, Joon Hei Lee, Shuailei Zhang, Tianze Luo, Cuntai Guan
Abstract: Learning the spatial topology of electroencephalogram (EEG) channels and their temporal dynamics is crucial for decoding attention states. This paper introduces EEG-PatchFormer, a transformer-based deep learning framework designed specifically for EEG attention classification in Brain-Computer Interface (BCI) applications. By integrating a Temporal CNN for frequency-based EEG feature extraction, a pointwise CNN for feature enhancement, and Spatial and Temporal Patching modules for organizing features into spatial-temporal patches, EEG-PatchFormer jointly learns spatial-temporal information from EEG data. Leveraging the global learning capabilities of the self-attention mechanism, it captures essential features across brain regions over time, thereby enhancing EEG data decoding performance. Demonstrating superior performance, EEG-PatchFormer surpasses existing benchmarks in accuracy, area under the ROC curve (AUC), and macro-F1 score on a public cognitive attention dataset. The code can be found via: this https URL .

Paper number 16:
Title: UAV Cognitive Semantic Communications Enabled by Knowledge Graph for Robust Object Detection
Authors: Xi Song, Fuhui Zhou, Rui Ding, Zhibo Qu, Yihao Li, Qihui Wu, Naofal Al-Dhahir
Abstract: Unmanned aerial vehicles (UAVs) are widely used for object detection. However, the existing UAV-based object detection systems are subject to severe challenges, namely, their limited computation, energy and communication resources, which limits the achievable detection performance. To overcome these challenges, a UAV cognitive semantic communication system is proposed by exploiting a knowledge graph. Moreover, we design a multi-scale codec for semantic compression to reduce data transmission volume while guaranteeing detection performance. Considering the complexity and dynamicity of UAV communication scenarios, a signal-to-noise ratio (SNR) adaptive module with robust channel adaptation capability is introduced. Furthermore, an object detection scheme is proposed by exploiting the knowledge graph to overcome channel noise interference and compression distortion. Simulation results conducted on the practical aerial image dataset demonstrate that our proposed semantic communication system outperforms benchmark systems in terms of detection accuracy, communication robustness, and computation efficiency, especially in dealing with low bandwidth compression ratios and low SNR regimes.

Paper number 17:
Title: Replacing K-infinity Function with Leaky ReLU in Barrier Function Design: A Union of Invariant Sets Approach for ReLU-Based Dynamical Systems
Authors: Pouya Samanipour, Hasan Poonawala
Abstract: In this paper, a systematic framework is presented for determining piecewise affine PWA barrier functions and their corresponding invariant sets for dynamical systems identified via Rectified Linear Unit (ReLU) neural networks or their equivalent PWA representations. A common approach to determining the invariant set is to use Nagumo's condition, or to utilize the barrier function with a class K-infinity function. It may be challenging to find a suitable class K-infinity function in some cases. We propose leaky ReLU as an efficient substitute for the complex nonlinear K-infinity function in our formulation. Moreover, we propose the Union of Invariant Sets (UIS) method, which combines information from multiple invariant sets in order to compute the largest possible PWA invariant set. The proposed framework is validated through multiple examples, showcasing its potential to enhance the analysis of invariant sets in ReLU-based dynamical systems. Our code is available at: this https URL.

Paper number 18:
Title: UltraBones100k: An Ultrasound Image Dataset with CT-Derived Labels for Lower Extremity Long Bone Surface Segmentation
Authors: Luohong Wu, Nicola A. Cavalcanti, Matthias Seibold, Giuseppe Loggia, Lisa Reissner, Jonas Hein, Silvan Beeler, Arnd Viehöfer, Stephan Wirth, Lilian Calvet, Philipp Fürnstahl
Abstract: Ultrasound-based bone surface segmentation is crucial in computer-assisted orthopedic surgery. However, ultrasound images have limitations, including a low signal-to-noise ratio, and acoustic shadowing, which make interpretation difficult. Existing deep learning models for bone segmentation rely primarily on costly manual labeling by experts, limiting dataset size and model generalizability. Additionally, the complexity of ultrasound physics and acoustic shadow makes the images difficult for humans to interpret, leading to incomplete labels in anechoic regions and limiting model performance. To advance ultrasound bone segmentation and establish effective model benchmarks, larger and higher-quality datasets are needed. We propose a methodology for collecting ex-vivo ultrasound datasets with automatically generated bone labels, including anechoic regions. The proposed labels are derived by accurately superimposing tracked bone CT models onto the tracked ultrasound images. These initial labels are refined to account for ultrasound physics. A clinical evaluation is conducted by an expert physician specialized on orthopedic sonography to assess the quality of the generated bone labels. A neural network for bone segmentation is trained on the collected dataset and its predictions are compared to expert manual labels, evaluating accuracy, completeness, and F1-score. We collected the largest known dataset of 100k ultrasound images of human lower limbs with bone labels, called UltraBones100k. A Wilcoxon signed-rank test with Bonferroni correction confirmed that the bone alignment after our method significantly improved the quality of bone labeling (p < 0.001). The model trained on UltraBones100k consistently outperforms manual labeling in all metrics, particularly in low-intensity regions (320% improvement in completeness at a distance threshold of 0.5 mm).

Paper number 19:
Title: Synthetic Poisoning Attacks: The Impact of Poisoned MRI Image on U-Net Brain Tumor Segmentation
Authors: Tianhao Li, Tianyu Zeng, Yujia Zheng, Chulong Zhang, Jingyu Lu, Haotian Huang, Chuangxin Chu, Fang-Fang Yin, Zhenyu Yang
Abstract: Deep learning-based medical image segmentation models, such as U-Net, rely on high-quality annotated datasets to achieve accurate predictions. However, the increasing use of generative models for synthetic data augmentation introduces potential risks, particularly in the absence of rigorous quality control. In this paper, we investigate the impact of synthetic MRI data on the robustness and segmentation accuracy of U-Net models for brain tumor segmentation. Specifically, we generate synthetic T1-contrast-enhanced (T1-Ce) MRI scans using a GAN-based model with a shared encoding-decoding framework and shortest-path regularization. To quantify the effect of synthetic data contamination, we train U-Net models on progressively "poisoned" datasets, where synthetic data proportions range from 16.67% to 83.33%. Experimental results on a real MRI validation set reveal a significant performance degradation as synthetic data increases, with Dice coefficients dropping from 0.8937 (33.33% synthetic) to 0.7474 (83.33% synthetic). Accuracy and sensitivity exhibit similar downward trends, demonstrating the detrimental effect of synthetic data on segmentation robustness. These findings underscore the importance of quality control in synthetic data integration and highlight the risks of unregulated synthetic augmentation in medical image analysis. Our study provides critical insights for the development of more reliable and trustworthy AI-driven medical imaging systems.

Paper number 20:
Title: On the Number of Control Nodes in Boolean Networks with Degree Constraints
Authors: Liangjie Sun, Wai-Ki Ching, Tatsuya Akutsu
Abstract: This paper studies the minimum control node set problem for Boolean networks (BNs) with degree constraints. The main contribution is to derive the nontrivial lower and upper bounds on the size of the minimum control node set through combinatorial analysis of four types of BNs (i.e., $k$-$k$-XOR-BNs, simple $k$-$k$-AND-BNs, $k$-$k$-AND-BNs with negation and $k$-$k$-NC-BNs, where the $k$-$k$-AND-BN with negation is an extension of the simple $k$-$k$-AND-BN that considers the occurrence of negation and NC means nested canalyzing). More specifically, four bounds for the size of the minimum control node set: general lower bound, best case upper bound, worst case lower bound, and general upper bound are studied, where the general lower bound is a value that is not less than the size of the control node set for any BN, the general upper bound is the maximum value of the size of the minimum control node set for any BN, while the best case upper bound (resp., the worst case lower bound) is the minimum (resp., maximum) value currently found, which is obtained from some BN. By dividing nodes into three disjoint sets, extending the time to reach the target state, and utilizing necessary conditions for controllability, these bounds are obtained, and further meaningful results and phenomena are discovered. Notably, all of the above results involving the AND function also apply to the OR function.

Paper number 21:
Title: Stabilizing scheduling logic for networked control systems under limited capacity and lossy communication networks
Authors: Anubhab Dasgupta
Abstract: In this paper we address the problem of designing scheduling logic for stabilizing Networked Control Systems (NCSs) with plants and controllers remotely-located over a limited capacity communication network subject to data losses. Our specific contributions include characterization of stability under worst case data loss using an inequality associated with a cycle on a graph. This is eventually formulated as a feasibility problem to solve for certain parameters (\(T\)-factors) used to design a periodic scheduling logic. We show that given a solution to the feasibility problem, the designed scheduling logic guarantees \emph{global asymptotic stability} for all plants of the network under all admissible data losses. We also derive sufficient conditions on the number of plants and the capacity of the network for the existence of a solution to the feasibility problem. Given that a sufficient condition is satisfied, we discuss the procedure to obtain the feasible \(T\)-factors. We use tools from switched systems theory and graph theory in this work. A numerical experiment is provided to verify our results.

Paper number 22:
Title: Compact Nested Hexagonal Metamaterial Sensor for High-Sensitivity Permittivity Characterization Across S and X-Band Frequencies
Authors: Md Mujahid Hossain, Saif Hannan
Abstract: This article presents a Compact Nested Hexagonal Metamaterial Sensor designed for microwave sensing to characterize material permittivity in S and X-band applications. The proposed sensor attained compact dimensions of merely 30 mm x 30 mm x 0.79 mm. This innovative design technique employs a distinctive and compact architecture with elevated electromagnetic (EM) field strength, enhancing the precision of the sensing mechanism in the microwave frequency spectrum. The design geometry and dimensions attained resonance frequencies of 3.98 GHz and 11.57 GHz, with notch depths of -13.16129 dB and -10.23024 dB, respectively. The design evolution, metamaterial properties, equivalent circuit model, and electric (E) is delineated to elucidate the stopband features at the resonant frequency. The suggested sensor attains a very high sensitivity of 9.55% in transmission mode (S21) for a permittivity range of 1 to 6. The reflection and transmission properties of the proposed CRR-based sensor are validated by simulations using the mathematical equations of the design. Furthermore, the sensor's performance is corroborated by utilizing several dielectric materials (Roger R04350B, Roger RT5880 and FR-4). The computed outcomes demonstrate alignment with the simulated results. The compact, low-profile sensor design and its excellent sensitivity for characterizing material permittivity render the suggested sensor appropriate for permittivity sensing applications.

Paper number 23:
Title: Blind Capon Beamformer Based on Independent Component Extraction: Single-Parameter Algorithm,
Authors: Zbyněk Koldovský, Jaroslav Čmejla, Stephen O'Regan
Abstract: We consider a phase-shift mixing model for linear sensor arrays in the context of blind source extraction. We derive a blind Capon beamformer that seeks the direction where the output is independent of the other signals in the mixture. The algorithm is based on Independent Component Extraction and imposes an orthogonal constraint, thanks to which it optimizes only one real-valued parameter related to the angle of arrival. The Cramér-Rao lower bound for the mean interference-to-signal ratio is derived. The algorithm and the bound are compared with conventional blind and direction-of-arrival estimation+beamforming methods, showing improvements in terms of extraction accuracy. An application is demonstrated in frequency-domain speaker extraction in a low-reverberation room.

Paper number 24:
Title: Geometric Stabilization of Virtual Nonlinear Nonholonomic Constraints
Authors: Efstratios Stratoglou, Alexandre Anahory Simoes, Anthony Bloch, Leonardo Colombo
Abstract: In this paper, we address the problem of stabilizing a system around a desired manifold determined by virtual nonlinear nonholonomic constraints. Virtual constraints are relationships imposed on a control system that are rendered invariant through feedback control. Virtual nonholonomic constraints represent a specific class of virtual constraints that depend on the system's velocities in addition to its configurations. We derive a control law under which a mechanical control system achieves exponential convergence to the virtual constraint submanifold, and rendering it control-invariant. The proposed controller's performance is validated through simulation results in two distinct applications: flocking motion in multi-agent systems and the control of an unmanned surface vehicle (USV) navigating a stream.

Paper number 25:
Title: On the existence of strong functional observer
Authors: Michael Di Loreto, Damien Eberard
Abstract: For arbitrary linear time-invariant systems, the existence of a strong functional observer is investigated. Such observer determines, from the available measurement on the plant, an estimate of a function of the state and the input. This estimate converges irrespective to initial state and input. This formulation encompass the cases of observer existence for known or unknown inputs and generalizes state-of-art. Necessary and sufficient conditions for such an existence are proposed, in the framework of state-space representation. These conditions are based on functional detectability property and its generalizations for arbitrary input, which include considerations on convergence of the estimation, irrespective to the initial state and the input. Known results on state detectability, input reconstruction or functional detectability are retrieved by particularizing the proposed conditions.

Paper number 26:
Title: Graph Neural Network Enabled Fluid Antenna Systems: A Two-Stage Approach
Authors: Changpeng He, Yang Lu, Wei Chen, Bo Ai, Kai-Kit Wong, Dusit Niyato
Abstract: An emerging fluid antenna system (FAS) brings a new dimension, i.e., the antenna positions, to deal with the deep fading, but simultaneously introduces challenges related to the transmit design. This paper proposes an ``unsupervised learning to optimize" paradigm to optimize the FAS. Particularly, we formulate the sum-rate and energy efficiency (EE) maximization problems for a multiple-user multiple-input single-output (MU-MISO) FAS and solved by a two-stage graph neural network (GNN) where the first stage and the second stage are for the inference of antenna positions and beamforming vectors, respectively. The outputs of the two stages are jointly input into a unsupervised loss function to train the two-stage GNN. The numerical results demonstrates that the advantages of the FAS for performance improvement and the two-stage GNN for real-time and scalable optimization. Besides, the two stages can function separately.

Paper number 27:
Title: SWIPTNet: A Unified Deep Learning Framework for SWIPT based on GNN and Transfer Learning
Authors: Hong Han, Yang Lu, Zihan Song, Ruichen Zhang, Wei Chen, Bo Ai, Dusit Niyato, Dong In Kim
Abstract: This paper investigates the deep learning based approaches for simultaneous wireless information and power transfer (SWIPT). The quality-of-service (QoS) constrained sum-rate maximization problems are, respectively, formulated for power-splitting (PS) receivers and time-switching (TS) receivers and solved by a unified graph neural network (GNN) based model termed SWIPT net (SWIPTNet). To improve the performance of SWIPTNet, we first propose a single-type output method to reduce the learning complexity and facilitate the satisfaction of QoS constraints, and then, utilize the Laplace transform to enhance input features with the structural information. Besides, we adopt the multi-head attention and layer connection to enhance feature extracting. Furthermore, we present the implementation of transfer learning to the SWIPTNet between PS and TS receivers. Ablation studies show the effectiveness of key components in the SWIPTNet. Numerical results also demonstrate the capability of SWIPTNet in achieving near-optimal performance with millisecond-level inference speed which is much faster than the traditional optimization algorithms. We also show the effectiveness of transfer learning via fast convergence and expressive capability improvement.

Paper number 28:
Title: DiTAR: Diffusion Transformer Autoregressive Modeling for Speech Generation
Authors: Dongya Jia, Zhuo Chen, Jiawei Chen, Chenpeng Du, Jian Wu, Jian Cong, Xiaobin Zhuang, Chumin Li, Zhen Wei, Yuping Wang, Yuxuan Wang
Abstract: Several recent studies have attempted to autoregressively generate continuous speech representations without discrete speech tokens by combining diffusion and autoregressive models, yet they often face challenges with excessive computational loads or suboptimal outcomes. In this work, we propose Diffusion Transformer Autoregressive Modeling (DiTAR), a patch-based autoregressive framework combining a language model with a diffusion transformer. This approach significantly enhances the efficacy of autoregressive models for continuous tokens and reduces computational demands. DiTAR utilizes a divide-and-conquer strategy for patch generation, where the language model processes aggregated patch embeddings and the diffusion transformer subsequently generates the next patch based on the output of the language model. For inference, we propose defining temperature as the time point of introducing noise during the reverse diffusion ODE to balance diversity and determinism. We also show in the extensive scaling analysis that DiTAR has superb scalability. In zero-shot speech generation, DiTAR achieves state-of-the-art performance in robustness, speaker similarity, and naturalness.

Paper number 29:
Title: ICGNN: Graph Neural Network Enabled Scalable Beamforming for MISO Interference Channels
Authors: Changpeng He, Yang Lu, Bo Ai, Octavia A. Dobre, Zhiguo Ding, Dusit Niyato
Abstract: This paper investigates the graph neural network (GNN)-enabled beamforming design for interference channels. We propose a model termed interference channel GNN (ICGNN) to solve a quality-of-service constrained energy efficiency maximization problem. The ICGNN is two-stage, where the direction and power parts of beamforming vectors are learned separately but trained jointly via unsupervised learning. By formulating the dimensionality of features independent of the transceiver pairs, the ICGNN is scalable with the number of transceiver pairs. Besides, to improve the performance of the ICGNN, the hybrid maximum ratio transmission and zero-forcing scheme reduces the output ports, the feature enhancement module unifies the two types of links into one type, the subgraph representation enhances the message passing efficiency, and the multi-head attention and residual connection facilitate the feature extracting. Furthermore, we present the over-the-air distributed implementation of the ICGNN. Ablation studies validate the effectiveness of key components in the ICGNN. Numerical results also demonstrate the capability of ICGNN in achieving near-optimal performance with an average inference time less than 0.1 ms. The scalability of ICGNN for unseen problem sizes is evaluated and enhanced by transfer learning with limited fine-tuning cost. The results of the centralized and distributed implementations of ICGNN are illustrated.

Paper number 30:
Title: Exact Covariance Characterization for Controlled Linear Systems subject to Stochastic Parametric and Additive Uncertainties
Authors: Kaouther Moussa, Mirko Fiacchini
Abstract: This work addresses the exact characterization of the covariance dynamics related to linear discrete-time systems subject to both additive and parametric stochastic uncertainties that are potentially unbounded. The derived exact representation allows to understand how the covariance of the multiplicative parametric uncertainties affects the stability of the state covariance dynamics through a transformation of the parameters covariance matrix, allowing therefore to address the problem of control design for state covariance dynamics in this context. Numerical results assess this new characterization by comparing it to the empirical covariance and illustrating the control design problem.

Paper number 31:
Title: Semantic Feature Division Multiple Access for Digital Semantic Broadcast Channels
Authors: Shuai Ma, Zhiye Sun, Bin Shen, Youlong Wu, Hang Li, Guangming Shi, Shiyin Li, Naofal Al-Dhahir
Abstract: In this paper, we propose a digital semantic feature division multiple access (SFDMA) paradigm in multi-user broadcast (BC) networks for the inference and the image reconstruction tasks. In this SFDMA scheme, the multi-user semantic information is encoded into discrete approximately orthogonal representations, and the encoded semantic features of multiple users can be simultaneously transmitted in the same time-frequency resource. Specifically, for inference tasks, we design a SFDMA digital BC network based on robust information bottleneck (RIB), which can achieve a tradeoff between inference performance, data compression and multi-user interference. Moreover, for image reconstruction tasks, we develop a SFDMA digital BC network by utilizing a Swin Transformer, which significantly reduces multi-user interference. More importantly, SFDMA can protect the privacy of users' semantic information, in which each receiver can only decode its own semantic information. Furthermore, we establish a relationship between performance and signal to interference plus noise ratio (SINR), which is fitted by an Alpha-Beta-Gamma (ABG) function. Furthermore, an optimal power allocation method is developed for the inference and reconstruction tasks. Extensive simulations verify the effectiveness and superiority of our proposed SFDMA scheme.

Paper number 32:
Title: Spatiotemporal Trajectory Tracking Method for Vehicles Incorporating Lead-Lag Judgement
Authors: Yuan Li, Xiang Dong, Tao Li, Junfeng Hao, Xiaoxue Xu, Sana Ullaha, Yincai Cai, Peng Wu, Ting Peng
Abstract: In the domain of intelligent transportation systems, especially within the context of autonomous vehicle control, the preemptive holistic collaborative system has been presented as a promising solution to bring a remarkable enhancement in traffic efficiency and a substantial reduction in the accident rate, demonstrating a great potential of development. In order to ensure this system operates as intended, accurate tracking of the spatiotemporal trajectory is of crucial significance. Moreover, minimizing the tracking error is a necessary step in this process. To this end, a novel lead-lag judgment mechanism is proposed. This mechanism precisely quantifies the longitudinal positional deviation between the vehicle and the target trajectory over time, then the deviation is corrected with a real - time acceleration compensation strategy, as a result, the accuracy and reliability of trajectory tracking are significantly enhanced. Real - vehicle experiments were conducted in a dedicated test field to validate the feasibility of this innovative approach empirically. Subsequently, the obtained tracking data was subsequent processed using the lead-lag judgment mechanism. In this step, we carefully analyzed the spatiotemporal error patterns between the vehicle and the target trajectory under different alignments and speeds. Finally, using real highway speed and alignment data, we conducted comprehensive spatiotemporal trajectory tracking simulations. Through experiments and simulations, tracking errors maintained in an acceptable range and reasonable spatiotemporal distance is given during the preemptive merging process on highway ramps. Overall, this study offers valuable insights for highway ramp emerging safety. Future work can expand on these findings.

Paper number 33:
Title: Small Signal Stability Analysis of Kurdistan Regional Power System
Authors: Ibrahim Ismael Hamarash
Abstract: This paper presents for the first time a mathematical model for evaluating the Planned Kurdistan Regional Power System (KRPS) for its ability to maintain stability under small disturbances and fluctuations during normal operating conditions. To achieve this objective, practical field data, manufacture's datasheets, related IEEE task force reports have been used to build a complete mathematical model in MATLAB/SIMULINK/SimPowerSystem environment. New modules have been established and added to the platform wherever it does not support special type of elements. The model represents accurately all the power system components involved in physical phenomena of system dynamic oscillations. The model consists of 53 transmission lines, 35 nodes and 6 generating stations. The system is simulated under different configurations and settings; the dynamic behaviors associated with each configuration are recorded and analyzed accordingly.

Paper number 34:
Title: Frequency Control and Power Sharing in Combined Heat and Power Networks
Authors: Xin Qin, Ioannis Lestas
Abstract: We consider the problem of using district heating systems as ancillary services for primary frequency control in power networks. We propose a novel power sharing scheme for heating systems based on the average temperature, which enables an optimal power allocation among the diverse heat sources without having a prior knowledge of the disturbances. We then discuss two approaches for heating systems to contribute to frequency regulation in power networks. We show that both approaches ensure stability in the combined heat and power network and facilitate optimal power allocation among the different energy sources.

Paper number 35:
Title: Pre-Optimized Irregular Arrays versus Moveable Antennas in Multi-User MIMO Systems
Authors: Amna Irshad, Alva Kosasih, Vitaly Petrov, Emil Björnson
Abstract: Massive multiple-input multiple-output (MIMO) systems exploit the spatial diversity achieved with an array of many antennas to perform spatial multiplexing of many users. Similar performance can be achieved using fewer antennas if movable antenna (MA) elements are used instead. MA-enabled arrays can dynamically change the antenna locations, mechanically or electrically, to achieve maximum spatial diversity for the current propagation conditions. However, optimizing the antenna locations for each channel realization is computationally excessive, requires channel knowledge for all conceivable locations, and requires rapid antenna movements, thus making real-time implementation cumbersome. To overcome these challenges, we propose a pre-optimized irregular array (PIA) concept, where the antenna locations at the base station are optimized a priori for a given coverage area. The objective is to maximize the average sum rate and we take a particle swarm optimization approach to solve it. Simulation results show that PIA achieves performance comparable to MA-enabled arrays while outperforming traditional uniform arrays. Hence, PIA offers a fixed yet efficient array deployment approach without the complexities associated with MA-enabled arrays.

Paper number 36:
Title: A Self-supervised Multimodal Deep Learning Approach to Differentiate Post-radiotherapy Progression from Pseudoprogression in Glioblastoma
Authors: Ahmed Gomaa, Yixing Huang, Pluvio Stephan, Katharina Breininger, Benjamin Frey, Arnd Dörfler, Oliver Schnell, Daniel Delev, Roland Coras, Charlotte Schmitter, Jenny Stritzelberger, Sabine Semrau, Andreas Maier, Siming Bayer, Stephan Schönecker, Dieter H Heiland, Peter Hau, Udo S. Gaipl, Christoph Bert, Rainer Fietkau, Manuel A. Schmidt, Florian Putz
Abstract: Accurate differentiation of pseudoprogression (PsP) from True Progression (TP) following radiotherapy (RT) in glioblastoma (GBM) patients is crucial for optimal treatment planning. However, this task remains challenging due to the overlapping imaging characteristics of PsP and TP. This study therefore proposes a multimodal deep-learning approach utilizing complementary information from routine anatomical MR images, clinical parameters, and RT treatment planning information for improved predictive accuracy. The approach utilizes a self-supervised Vision Transformer (ViT) to encode multi-sequence MR brain volumes to effectively capture both global and local context from the high dimensional input. The encoder is trained in a self-supervised upstream task on unlabeled glioma MRI datasets from the open BraTS2021, UPenn-GBM, and UCSF-PDGM datasets to generate compact, clinically relevant representations from FLAIR and T1 post-contrast sequences. These encoded MR inputs are then integrated with clinical data and RT treatment planning information through guided cross-modal attention, improving progression classification accuracy. This work was developed using two datasets from different centers: the Burdenko Glioblastoma Progression Dataset (n = 59) for training and validation, and the GlioCMV progression dataset from the University Hospital Erlangen (UKER) (n = 20) for testing. The proposed method achieved an AUC of 75.3%, outperforming the current state-of-the-art data-driven approaches. Importantly, the proposed approach relies on readily available anatomical MRI sequences, clinical data, and RT treatment planning information, enhancing its clinical feasibility. The proposed approach addresses the challenge of limited data availability for PsP and TP differentiation and could allow for improved clinical decision-making and optimized treatment plans for GBM patients.

Paper number 37:
Title: Performance Analysis of BEM-based Channel Estimation for OTFS with Hardware Impairments
Authors: Haowei Wu, Huanyu Chen, Qihao Peng, Qu Luo, Jinglan Ou
Abstract: This letter studies the low-complexity channel estimation for orthogonal time frequency space (OTFS) in the presence of hardware impairments. Firstly, to tackle the computational complexity of channel estimation, the basis expansion model (BEM) is utilized. Then, the mean square error (MSE) of the estimated channel is theoretically derived, revealing the effects of hardware impairments on channel estimation. Based on the estimated channel, the minimum mean square error (MMSE) detector is adopted to analyze the impacts of imperfect hardware on the bit error rate (BER). Finally, the numerical results validate the correctness of our theoretical analysis of the MSE for channel estimation and lower bound of the BER, and also demonstrate that even minor hardware impairments can significantly degrade the performance of the OTFS system.

Paper number 38:
Title: A Robust Optimization Model for Cost-Efficient and Fast Electric Vehicle Charging with L2-norm Uncertainty
Authors: Trung Duc Tran, Ngoc-Doanh Nguyen, Hong T.M. Chu, Laurent El Ghaoui, Luca Ambrosino, Giuseppe Calafiore
Abstract: In this paper, we propose a robust optimization model that addresses both the cost-efficiency and fast charging requirements for electric vehicles (EVs) at charging stations. By combining elements from traditional cost-minimization models and a fast charging objective, we construct an optimization model that balances user costs with rapid power allocation. Additionally, we incorporate L2-norm uncertainty into the charging cost, ensuring that the model remains resilient under cost fluctuations. The proposed model is tested under real-world scenarios and demonstrates its potential for efficient and flexible EV charging solutions.

Paper number 39:
Title: Adaptive Output Feedback MPC with Guaranteed Stability and Robustness
Authors: Anchita Dey, Shubhendu Bhasin
Abstract: This work proposes an adaptive output feedback model predictive control (MPC) framework for uncertain systems subject to external disturbances. In the absence of exact knowledge about the plant parameters and complete state measurements, the MPC optimization problem is reformulated in terms of their estimates derived from a suitably designed robust adaptive observer. The MPC routine returns a homothetic tube for the state estimate trajectory. Sets that characterize the state estimation errors are then added to the homothetic tube sections, resulting in a larger tube containing the true state trajectory. The two-tier tube architecture provides robustness to uncertainties due to imperfect parameter knowledge, external disturbances, and incomplete state information. Additionally, recursive feasibility and robust exponential stability are guaranteed and validated using a numerical example.

Paper number 40:
Title: Towards Explainable Spoofed Speech Attribution and Detection:a Probabilistic Approach for Characterizing Speech Synthesizer Components
Authors: Jagabandhu Mishraa, Manasi Chhibbera, Hye-jin Shimb, Tomi H. Kinnunena
Abstract: We propose an explainable probabilistic framework for characterizing spoofed speech by decomposing it into probabilistic attribute embeddings. Unlike raw high-dimensional countermeasure embeddings, which lack interpretability, the proposed probabilistic attribute embeddings aim to detect specific speech synthesizer components, represented through high-level attributes and their corresponding values. We use these probabilistic embeddings with four classifier back-ends to address two downstream tasks: spoofing detection and spoofing attack attribution. The former is the well-known bonafide-spoof detection task, whereas the latter seeks to identify the source method (generator) of a spoofed utterance. We additionally use Shapley values, a widely used technique in machine learning, to quantify the relative contribution of each attribute value to the decision-making process in each task. Results on the ASVspoof2019 dataset demonstrate the substantial role of duration and conversion modeling in spoofing detection; and waveform generation and speaker modeling in spoofing attack attribution. In the detection task, the probabilistic attribute embeddings achieve $99.7\%$ balanced accuracy and $0.22\%$ equal error rate (EER), closely matching the performance of raw embeddings ($99.9\%$ balanced accuracy and $0.22\%$ EER). Similarly, in the attribution task, our embeddings achieve $90.23\%$ balanced accuracy and $2.07\%$ EER, compared to $90.16\%$ and $2.11\%$ with raw embeddings. These results demonstrate that the proposed framework is both inherently explainable by design and capable of achieving performance comparable to raw CM embeddings.

Paper number 41:
Title: On Sufficient Richness for Linear Time-Invariant Systems
Authors: Marco Borghesi, Simone Baroncini, Guido Carnevale, Alessandro Bosso, Giuseppe Notarstefano
Abstract: Persistent excitation (PE) is a necessary and sufficient condition for uniform exponential parameter convergence in several adaptive, identification, and learning schemes. In this article, we consider, in the context of multi-input linear time-invariant (LTI) systems, the problem of guaranteeing PE of commonly-used regressors by applying a sufficiently rich (SR) input signal. Exploiting the analogies between time shifts and time derivatives, we state simple necessary and sufficient PE conditions for the discrete- and continuous-time frameworks. Moreover, we characterize the shape of the set of SR input signals for both single-input and multi-input systems. Finally, we show with a numerical example that the derived conditions are tight and cannot be improved without including additional knowledge of the considered LTI system.

Paper number 42:
Title: DEALing with Image Reconstruction: Deep Attentive Least Squares
Authors: Mehrsa Pourya, Erich Kobler, Michael Unser, Sebastian Neumayer
Abstract: State-of-the-art image reconstruction often relies on complex, highly parameterized deep architectures. We propose an alternative: a data-driven reconstruction method inspired by the classic Tikhonov regularization. Our approach iteratively refines intermediate reconstructions by solving a sequence of quadratic problems. These updates have two key components: (i) learned filters to extract salient image features, and (ii) an attention mechanism that locally adjusts the penalty of filter responses. Our method achieves performance on par with leading plug-and-play and learned regularizer approaches while offering interpretability, robustness, and convergent behavior. In effect, we bridge traditional regularization and deep learning with a principled reconstruction approach.

Paper number 43:
Title: A Neural Network-based Multi-timestep Command Governor for Nonlinear Systems with Constraints
Authors: Mostafaali Ayubirad, Hamid R. Ossareh
Abstract: The multi-timestep command governor (MCG) is an add-on algorithm that enforces constraints by modifying, at each timestep, the reference command to a pre-stabilized control system. The MCG can be interpreted as a Model-Predictive Control scheme operating on the reference command. The implementation of MCG on nonlinear systems carries a heavy computational burden as it requires solving a nonlinear program with multiple decision variables at each timestep. This paper proposes a less computationally demanding alternative, based on approximating the MCG control law using a neural network (NN) trained on offline data. However, since the NN output may not always be constraint-admissible due to training errors, its output is adjusted using a sensitivity-based method. We thus refer to the resulting control strategy as the neural network-based MCG (NN-MCG). As validation, the proposed controller is applied as a load governor for constraint management in an automotive fuel cell system. It is shown that the proposed strategy is significantly more computationally efficient than the traditional MCG, while achieving nearly identical performance if the NN is well-trained.

Paper number 44:
Title: RC Measurement Uncertainty Estimation Method for Directive Antennas and Turntable Stirring
Authors: Alejandro Antón Ruiz, John Kvarnstrand, Klas Arvidsson, Andrés Alayón Glazunov
Abstract: This paper investigates measurement uncertainty in a Reverberation Chamber (RC) within the lower FR2 bands (24.25-29.5 GHz). The study focuses on the impact of several factors contributing to RC measurement uncertainty, including finite sample size, polarization imbalance, and spatial non-uniformity. A series of 24 measurements were conducted using a horn antenna, known for its directivity in mmWave frequencies, varying antenna parameters such as height, orientation, position on the turntable, and polarization within a predefined chamber volume. The measurement uncertainty was evaluated by a method based on the standardized 3GPP and CTIA approaches, incorporating uncorrelated measurements and analyzing Pearson correlation coefficients between measurement pairs. An analysis of variance (ANOVA) was performed on the frequency-averaged power transfer function to identify the significance and impact of each variable on measurement variability. Additionally, the K-factor was estimated for each measurement set as part of the RC characterization, using an alternative approach to account for the turntable stirring effect. The findings highlight which variables most significantly influence measurement uncertainty, where the antenna orientation emerges as the most significant factor for the mmWave directive antenna setup.

Paper number 45:
Title: Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis
Authors: Zhen Ye, Xinfa Zhu, Chi-Min Chan, Xinsheng Wang, Xu Tan, Jiahe Lei, Yi Peng, Haohe Liu, Yizhu Jin, Zheqi DAI, Hongzhan Lin, Jianyi Chen, Xingjian Du, Liumeng Xue, Yunlin Chen, Zhifei Li, Lei Xie, Qiuqiang Kong, Yike Guo, Wei Xue
Abstract: Recent advances in text-based large language models (LLMs), particularly in the GPT series and the o1 model, have demonstrated the effectiveness of scaling both training-time and inference-time compute. However, current state-of-the-art TTS systems leveraging LLMs are often multi-stage, requiring separate models (e.g., diffusion models after LLM), complicating the decision of whether to scale a particular model during training or testing. This work makes the following contributions: First, we explore the scaling of train-time and inference-time compute for speech synthesis. Second, we propose a simple framework Llasa for speech synthesis that employs a single-layer vector quantizer (VQ) codec and a single Transformer architecture to fully align with standard LLMs such as Llama. Our experiments reveal that scaling train-time compute for Llasa consistently improves the naturalness of synthesized speech and enables the generation of more complex and accurate prosody patterns. Furthermore, from the perspective of scaling inference-time compute, we employ speech understanding models as verifiers during the search, finding that scaling inference-time compute shifts the sampling modes toward the preferences of specific verifiers, thereby improving emotional expressiveness, timbre consistency, and content accuracy. In addition, we released the checkpoint and training code for our TTS model (1B, 3B, 8B) and codec model publicly available.

Paper number 46:
Title: Terahertz Defect Detection in Multi-Layer Materials Using Echo Labeling
Authors: Dogus Can Sevdiren, Furkan H. Ilgac, Aydin Sezgin
Abstract: Non-destructive testing is an important technique for detecting defects in multi-layer materials, enabling the evaluation of structural integrity without causing damage on test materials. Terahertz time-domain spectroscopy (THz-TDS) offers unique capabilities for this purpose due to its sensitivity and resolution. Inspired by room geometry estimation methods in acoustic signal processing, this work proposes a novel approach for defect detection in multi-layer composite materials using THz-TDS, enhanced by high-power sources. The proposed method utilizes Euclidean distance matrices to reduce problem complexity compared to state-of-the-art approaches, and effectively distinguishes and maps higher-order reflections from sublayers, enabling precise defect localization in composite materials without artifacts.

Paper number 47:
Title: Integration of Prior Knowledge into Direct Learning for Safe Control of Linear Systems
Authors: Amir Modares, Bahare Kiumarsi, Hamidreza Modares
Abstract: This paper integrates prior knowledge into direct learning of safe controllers for linear uncertain systems under disturbances. To this end, we characterize the set of all closed-loop systems that can be explained by available prior knowledge of the system model and the disturbances. We leverage matrix zonotopes for data-based characterization of closed-loop systems and show that the explainability of closed-loop systems by prior knowledge can be formalized by adding an equality conformity constraint to the matrix zonotope. We then leverage the resulting constraint matrix zonotope and design safe controllers that conform with both data and prior knowledge. This is achieved by ensuring the inclusion of a constrained zonotope of all possible next states in a {\lambda}-scaled level set of the safe set. We consider both polytope and zonotope safe sets and provide set inclusion conditions using linear programming.

Paper number 48:
Title: Expanding Training Data for Endoscopic Phenotyping of Eosinophilic Esophagitis
Authors: Juming Xiong, Hou Xiong, Quan Liu, Ruining Deng, Regina N Tyree, Girish Hiremath, Yuankai Huo
Abstract: Eosinophilic esophagitis (EoE) is a chronic esophageal disorder marked by eosinophil-dominated inflammation. Diagnosing EoE usually involves endoscopic inspection of the esophageal mucosa and obtaining esophageal biopsies for histologic confirmation. Recent advances have seen AI-assisted endoscopic imaging, guided by the EREFS system, emerge as a potential alternative to reduce reliance on invasive histological assessments. Despite these advancements, significant challenges persist due to the limited availability of data for training AI models - a common issue even in the development of AI for more prevalent diseases. This study seeks to improve the performance of deep learning-based EoE phenotype classification by augmenting our training data with a diverse set of images from online platforms, public datasets, and electronic textbooks increasing our dataset from 435 to 7050 images. We utilized the Data-efficient Image Transformer for image classification and incorporated attention map visualizations to boost interpretability. The findings show that our expanded dataset and model enhancements improved diagnostic accuracy, robustness, and comprehensive analysis, enhancing patient outcomes.

Paper number 49:
Title: Memory-dependent abstractions of stochastic systems through the lens of transfer operators
Authors: Adrien Banse, Giannis Delimpaltadakis, Luca Laurenti, Manuel Mazo Jr., Raphaël M. Jungers
Abstract: With the increasing ubiquity of safety-critical autonomous systems operating in uncertain environments, there is a need for mathematical methods for formal verification of stochastic models. Towards formally verifying properties of stochastic systems, methods based on discrete, finite Markov approximations -- abstractions -- thereof have surged in recent years. These are found in contexts where: either a) one only has partial, discrete observations of the underlying continuous stochastic process, or b) the original system is too complex to analyze, so one partitions the continuous state-space of the original system to construct a handleable, finite-state model thereof. In both cases, the abstraction is an approximation of the discrete stochastic process that arises precisely from the discretization of the underlying continuous process. The fact that the abstraction is Markov and the discrete process is not (even though the original one is) leads to approximation errors. Towards accounting for non-Markovianity, we introduce memory-dependent abstractions for stochastic systems, capturing dynamics with memory effects. Our contribution is twofold. First, we provide a formalism for memory-dependent abstractions based on transfer operators. Second, we quantify the approximation error by upper bounding the total variation distance between the true continuous state distribution and its discrete approximation.

Paper number 50:
Title: Work in Progress: AI-Powered Engineering-Bridging Theory and Practice
Authors: Oz Levy, Ilya Dikman, Natan Levy, Michael Winokur
Abstract: This paper explores how generative AI can help automate and improve key steps in systems engineering. It examines AI's ability to analyze system requirements based on INCOSE's "good requirement" criteria, identifying well-formed and poorly written requirements. The AI does not just classify requirements but also explains why some do not meet the standards. By comparing AI assessments with those of experienced engineers, the study evaluates the accuracy and reliability of AI in identifying quality issues. Additionally, it explores AI's ability to classify functional and non-functional requirements and generate test specifications based on these classifications. Through both quantitative and qualitative analysis, the research aims to assess AI's potential to streamline engineering processes and improve learning outcomes. It also highlights the challenges and limitations of AI, ensuring its safe and ethical use in professional and academic settings.

Paper number 51:
Title: Beyond Diagonal RIS: A New Frontier for 6G Internet of Things Networks
Authors: Wali Ullah Khan, Chandan Kumar Sheemar, Eva Lagunas, Symeon Chatzinotas
Abstract: Reconfigurable intelligent surface (RIS) technology has emerged as a promising enabler for next-generation wireless networks, offering a paradigm shift from passive environments to programmable radio wave propagation. Despite the potential of diagonal RIS (D-RIS), its limited wave manipulation capability restricts performance gains. In this paper, we investigate the burgeoning concept of beyond-diagonal RIS (BD-RIS), which incorporates non-diagonal elements in its scattering matrix to deliver more fine-grained control of electromagnetic wavefronts. We begin by discussing the limitations of traditional D-RIS and introduce key BD-RIS architectures with different operating modes. We then highlight the features that make BD-RIS particularly advantageous for 6G IoT applications, including advanced beamforming, enhanced interference mitigation, and flexible coverage. A case study on BD-RIS-assisted vehicle-to-vehicle (V2V) communication in an underlay cellular network demonstrates considerable improvements in spectral efficiency when compared to D-RIS and conventional systems. Lastly, we present current challenges such as hardware design complexity, channel estimation, and non-ideal hardware effects, and propose future research directions involving AI-driven optimization, joint communication and sensing, and physical layer security. Our findings illustrate the transformative potential of BD-RIS in shaping high-performance, scalable, and reliable 6G IoT networks.

Paper number 52:
Title: Sample Motion for Structured Illumination Fluorescence Microscopy
Authors: Ruiming Cao, Guanghan Meng, Laura Waller
Abstract: Structured illumination microscopy (SIM) uses a set of images captured with different patterned illumination to computationally reconstruct resolution beyond the diffraction limit. Here, we propose an alternative approach using a static speckle illumination pattern and relying on inherent sample motion to encode the super-resolved information in multiple raw images, for the case of fluorescence microscopy. From a set of sequentially captured raw images, we jointly estimate the sample motion and the super-resolved image. We demonstrate the feasibility of the proposed method both in simulation and in experiment.

Paper number 53:
Title: Reduce Lap Time for Autonomous Racing with Curvature-Integrated MPCC Local Trajectory Planning Method
Authors: Zhouheng Li, Lei Xie, Cheng Hu, Hongye Su
Abstract: The widespread application of autonomous driving technology has significantly advanced the field of autonomous racing. Model Predictive Contouring Control (MPCC) is a highly effective local trajectory planning method for autonomous racing. However, the traditional MPCC method struggles with racetracks that have significant curvature changes, limiting the performance of the vehicle during autonomous racing. To address this issue, we propose a curvature-integrated MPCC (CiMPCC) local trajectory planning method for autonomous racing. This method optimizes the velocity of the local trajectory based on the curvature of the racetrack centerline. The specific implementation involves mapping the curvature of the racetrack centerline to a reference velocity profile, which is then incorporated into the cost function for optimizing the velocity of the local trajectory. This reference velocity profile is created by normalizing and mapping the curvature of the racetrack centerline, thereby ensuring efficient and performance-oriented local trajectory planning in racetracks with significant curvature. The proposed CiMPCC method has been experimented on a self-built 1:10 scale F1TENTH racing vehicle deployed with ROS platform. The experimental results demonstrate that the proposed method achieves outstanding results on a challenging racetrack with sharp curvature, improving the overall lap time by 11.4%-12.5% compared to other autonomous racing trajectory planning methods. Our code is available at this https URL.

Paper number 54:
Title: Gaze-Assisted Human-Centric Domain Adaptation for Cardiac Ultrasound Image Segmentation
Authors: Ruiyi Li, Yuting He, Rongjun Ge, Chong Wang, Daoqiang Zhang, Yang Chen, Shuo Li
Abstract: Domain adaptation (DA) for cardiac ultrasound image segmentation is clinically significant and valuable. However, previous domain adaptation methods are prone to be affected by the incomplete pseudo-label and low-quality target to source images. Human-centric domain adaptation has great advantages of human cognitive guidance to help model adapt to target domain and reduce reliance on labels. Doctor gaze trajectories contains a large amount of cross-domain human guidance. To leverage gaze information and human cognition for guiding domain adaptation, we propose gaze-assisted human-centric domain adaptation (GAHCDA), which reliably guides the domain adaptation of cardiac ultrasound images. GAHCDA includes following modules: (1) Gaze Augment Alignment (GAA): GAA enables the model to obtain human cognition general features to recognize segmentation target in different domain of cardiac ultrasound images like humans. (2) Gaze Balance Loss (GBL): GBL fused gaze heatmap with outputs which makes the segmentation result structurally closer to the target domain. The experimental results illustrate that our proposed framework is able to segment cardiac ultrasound images more effectively in the target domain than GAN-based methods and other self-train based methods, showing great potential in clinical application.

Paper number 55:
Title: Enhancing Hallucination Detection through Noise Injection
Authors: Litian Liu, Reza Pourreza, Sunny Panchal, Apratim Bhattacharyya, Yao Qin, Roland Memisevic
Abstract: Large Language Models (LLMs) are prone to generating plausible yet incorrect responses, known as hallucinations. Effectively detecting hallucinations is therefore crucial for the safe deployment of LLMs. Recent research has linked hallucinations to model uncertainty, suggesting that hallucinations can be detected by measuring dispersion over answer distributions obtained from a set of samples drawn from a model. While drawing from the distribution over tokens defined by the model is a natural way to obtain samples, in this work, we argue that it is sub-optimal for the purpose of detecting hallucinations. We show that detection can be improved significantly by taking into account model uncertainty in the Bayesian sense. To this end, we propose a very simple and efficient approach that perturbs an appropriate subset of model parameters, or equivalently hidden unit activations, during sampling. We demonstrate its effectiveness across a wide range of datasets and model architectures.

Paper number 56:
Title: Electromagnetic Channel Modeling and Capacity Analysis for HMIMO Communications
Authors: Li Wei, Shuai S. A. Yuan, Chongwen Huang, Jianhua Zhang, Faouzi Bader, Zhaoyang Zhang, Sami Muhaidat, Merouane Debbah, Chau Yuen
Abstract: Advancements in emerging technologies, e.g., reconfigurable intelligent surfaces and holographic MIMO (HMIMO), facilitate unprecedented manipulation of electromagnetic (EM) waves, significantly enhancing the performance of wireless communication systems. To accurately characterize the achievable performance limits of these systems, it is crucial to develop a universal EM-compliant channel model. This paper addresses this necessity by proposing a comprehensive EM channel model tailored for realistic multi-path environments, accounting for the combined effects of antenna array configurations and propagation conditions in HMIMO communications. Both polarization phenomena and spatial correlation are incorporated into this probabilistic channel model. Additionally, physical constraints of antenna configurations, such as mutual coupling effects and energy consumption, are integrated into the channel modeling framework. Simulation results validate the effectiveness of the proposed probabilistic channel model, indicating that traditional Rician and Rayleigh fading models cannot accurately depict the channel characteristics and underestimate the channel capacity. More importantly, the proposed channel model outperforms free-space Green's functions in accurately depicting both near-field gain and multi-path effects in radiative near-field regions. These gains are much more evident in tri-polarized systems, highlighting the necessity of polarization interference elimination techniques. Moreover, the theoretical analysis accurately verifies that capacity decreases with expanding communication regions of two-user communications.

Paper number 57:
Title: UniForm: A Unified Diffusion Transformer for Audio-Video Generation
Authors: Lei Zhao, Linfeng Feng, Dongxu Ge, Fangqiu Yi, Chi Zhang, Xiao-Lei Zhang, Xuelong Li
Abstract: As a natural multimodal content, audible video delivers an immersive sensory experience. Consequently, audio-video generation systems have substantial potential. However, existing diffusion-based studies mainly employ relatively independent modules for generating each modality, which lack exploration of shared-weight generative modules. This approach may under-use the intrinsic correlations between audio and visual modalities, potentially resulting in sub-optimal generation quality. To address this, we propose UniForm, a unified diffusion transformer designed to enhance cross-modal consistency. By concatenating auditory and visual information, UniForm learns to generate audio and video simultaneously within a unified latent space, facilitating the creation of high-quality and well-aligned audio-visual pairs. Extensive experiments demonstrate the superior performance of our method in joint audio-video generation, audio-guided video generation, and video-guided audio generation tasks. Our demos are available at this https URL.

Paper number 58:
Title: A Gaussian-Sinc Pulse Shaping Filter for Zak-OTFS
Authors: Arpan Das, Fathima Jesbin, Ananthanarayanan Chockalingam
Abstract: The choice of delay-Doppler domain (DD) pulse shaping filter plays an important role in determining the performance of Zak-OTFS. Sinc filter has good main lobe characteristics (with nulls at information grid points) which is good for equalization/detection, but has high side lobes which are detrimental for input-output (I/O) relation estimation. Whereas, Gaussian filter is highly localized with very low side lobes which is good for I/O relation estimation, but has poor main lobe characteristics which is not good for equalization/detection. In this paper, we propose a new filter, termed as {\em Gaussian-sinc (GS) filter}, which inherits the complementary strengths of both Gaussian and sinc filters. The proposed filter does not incur time or bandwidth expansion. We derive closed-form expressions for the I/O relation and noise covariance of Zak-OTFS with the proposed GS filter. We evaluate the Zak-OTFS performance for different pulse shaping filters with I/O relation estimated using exclusive and embedded pilots. Our results show that the proposed GS filter achieves better bit error rate (BER) performance compared to other filters reported in the literature. For example, with model-free I/O relation estimation using embedded pilot and 8-QAM, the proposed GS filter achieves an SNR gain of about 4 dB at $10^{-2}$ uncoded BER compared to Gaussian and sinc filters, and the SNR gain becomes more than 6 dB at a coded BER of $10^{-4}$ with rate-1/2 coding.

Paper number 59:
Title: A Flexible FBG-Based Contact Force Sensor for Robotic Gripping Systems
Authors: Wenjie Lai, Huu Duoc Nguyen, Jiajun Liu, Xingyu Chen, Soo Jay Phee
Abstract: Soft robotic grippers demonstrate great potential for gently and safely handling objects; however, their full potential for executing precise and secure grasping has been limited by the lack of integrated sensors, leading to problems such as slippage and excessive force exertion. To address this challenge, we present a small and highly sensitive Fiber Bragg Grating-based force sensor designed for accurate contact force measurement. The flexible force sensor comprises a 3D-printed TPU casing with a small bump and uvula structure, a dual FBG array, and a protective tube. A series of tests have been conducted to evaluate the effectiveness of the proposed force sensor, including force calibration, repeatability test, hysteresis study, force measurement comparison, and temperature calibration and compensation tests. The results demonstrated good repeatability, with a force measurement range of 4.69 N, a high sensitivity of approximately 1169.04 pm/N, a root mean square error (RMSE) of 0.12 N, and a maximum hysteresis of 4.83%. When compared to a commercial load cell, the sensor showed a percentage error of 2.56% and an RMSE of 0.14 N. Besides, the proposed sensor validated its temperature compensation effectiveness, with a force RMSE of 0.01 N over a temperature change of 11 Celsius degree. The sensor was integrated with a soft grow-and-twine gripper to monitor interaction forces between different objects and the robotic gripper. Closed-loop force control was applied during automated pick-and-place tasks and significantly improved gripping stability, as demonstrated in tests. This force sensor can be used across manufacturing, agriculture, healthcare (like prosthetic hands), logistics, and packaging, to provide situation awareness and higher operational efficiency.

Paper number 60:
Title: Towards Unified Music Emotion Recognition across Dimensional and Categorical Models
Authors: Jaeyong Kang, Dorien Herremans
Abstract: One of the most significant challenges in Music Emotion Recognition (MER) comes from the fact that emotion labels can be heterogeneous across datasets with regard to the emotion representation, including categorical (e.g., happy, sad) versus dimensional labels (e.g., valence-arousal). In this paper, we present a unified multitask learning framework that combines these two types of labels and is thus able to be trained on multiple datasets. This framework uses an effective input representation that combines musical features (i.e., key and chords) and MERT embeddings. Moreover, knowledge distillation is employed to transfer the knowledge of teacher models trained on individual datasets to a student model, enhancing its ability to generalize across multiple tasks. To validate our proposed framework, we conducted extensive experiments on a variety of datasets, including MTG-Jamendo, DEAM, PMEmo, and EmoMusic. According to our experimental results, the inclusion of musical features, multitask learning, and knowledge distillation significantly enhances performance. In particular, our model outperforms the state-of-the-art models, including the best-performing model from the MediaEval 2021 competition on the MTG-Jamendo dataset. Our work makes a significant contribution to MER by allowing the combination of categorical and dimensional emotion labels in one unified framework, thus enabling training across datasets.

Paper number 61:
Title: A Cloud-native Agile approach to cyber platform prototyping and integration for astronomy: the ENGAGE SKA case
Authors: Domingos Barbosa, Diogo Regateiro, João Paulo Barraca, Dzianis Bartashevich, Marco Bartolini, Matteo di Carlo, Piers Harding, Dalmiro Maia, Bruno Morgado, Domingos Nunes, Bruno Ribeiro, Bruno Coelho, Valério Ribeiro, Allan K. de Almeida Jr, Timothée Vaillant, Uğur Yilmaz
Abstract: The Square Kilometre Array (SKA) Observatory is gearing up the formal construction of its two radio interferometers in Australia and South Africa after the end of design and pre-construction phases. Agile methodologies, the Cloud native Computing technologies and the DevOps software ideas are influencing the design of compute infrastructures that will be key to reduce the operational costs of SKA while improving the control and monitoring of the SKA antennas and ancillary systems, Correlators, HPC facilities or related data centre tiered systems. These tools will likely include advanced power metering technologies and efficient distribution automation and Network Operation Centres (NOC). SKA will become the world's largest radio telescope and is expected to achieve its first science by 2026. To cope with this dimension and complexity, a key part of this distributed Observatory is the overall software control and monitoring system embodied in the Observatory Management and Control (OMC) and the Services Teams that requires specialized Agile Teams to assist in software and cyber infrastructure building using an Agile development environment that includes test automation, Continuous Integration, and Continuous Deployment. To manage such a large and distributed machine, the Agile approach was adopted for the core software package of the SKA Telescope aimed at scheduling observations, controlling their execution, monitoring the telescope status and ensuring scalability and reliability. Here, we report on the ENGAGE SKA ciberinfrastructure prototyping support to the SKA Agile Software Development Life Cycle (SDLC).

Paper number 62:
Title: TQ-DiT: Efficient Time-Aware Quantization for Diffusion Transformers
Authors: Younghye Hwang, Hyojin Lee, Joonhyuk Kang
Abstract: Diffusion transformers (DiTs) combine transformer architectures with diffusion models. However, their computational complexity imposes significant limitations on real-time applications and sustainability of AI systems. In this study, we aim to enhance the computational efficiency through model quantization, which represents the weights and activation values with lower precision. Multi-region quantization (MRQ) is introduced to address the asymmetric distribution of network values in DiT blocks by allocating two scaling parameters to sub-regions. Additionally, time-grouping quantization (TGQ) is proposed to reduce quantization error caused by temporal variation in activations. The experimental results show that the proposed algorithm achieves performance comparable to the original full-precision model with only a 0.29 increase in FID at W8A8. Furthermore, it outperforms other baselines at W6A6, thereby confirming its suitability for low-bit quantization. These results highlight the potential of our method to enable efficient real-time generative models.

Paper number 63:
Title: A data-driven two-microphone method for in-situ sound absorption measurements
Authors: Leon Emmerich, Patrik Aste, Eric Brandão, Mélanie Nolan, Jacques Cuenca, U. Peter Svensson, Marcus Maeder, Steffen Marburg, Elias Zea
Abstract: This work presents a data-driven approach to estimating the sound absorption coefficient of an infinite porous slab using a neural network and a two-microphone measurement on a finite porous sample. A 1D-convolutional network predicts the sound absorption coefficient from the complex-valued transfer function between the sound pressure measured at the two microphone positions. The network is trained and validated with numerical data generated by a boundary element model using the Delany-Bazley-Miki model, demonstrating accurate predictions for various numerical samples. The method is experimentally validated with baffled rectangular samples of a fibrous material, where sample size and source height are varied. The results show that the neural network offers the possibility to reliably predict the in-situ sound absorption of a porous material using the traditional two-microphone method as if the sample were infinite. The normal-incidence sound absorption coefficient obtained by the network compares well with that obtained theoretically and in an impedance tube. The proposed method has promising perspectives for estimating the sound absorption coefficient of acoustic materials after installation and in realistic operational conditions.

Paper number 64:
Title: Dense Fixed-Wing Swarming using Receding-Horizon NMPC
Authors: Varun Madabushi, Yocheved Kopel, Adam Polevoy, Joseph Moore
Abstract: In this paper, we present an approach for controlling a team of agile fixed-wing aerial vehicles in close proximity to one another. Our approach relies on receding-horizon nonlinear model predictive control (NMPC) to plan maneuvers across an expanded flight envelope to enable inter-agent collision avoidance. To facilitate robust collision avoidance and characterize the likelihood of inter-agent collisions, we compute a statistical bound on the probability of the system leaving a tube around the planned nominal trajectory. Finally, we propose a metric for evaluating highly dynamic swarms and use this metric to evaluate our approach. We successfully demonstrated our approach through both simulation and hardware experiments, and to our knowledge, this the first time close-quarters swarming has been achieved with physical aerobatic fixed-wing vehicles.

Paper number 65:
Title: XAttnMark: Learning Robust Audio Watermarking with Cross-Attention
Authors: Yixin Liu, Lie Lu, Jihui Jin, Lichao Sun, Andrea Fanelli
Abstract: The rapid proliferation of generative audio synthesis and editing technologies has raised significant concerns about copyright infringement, data provenance, and the spread of misinformation through deepfake audio. Watermarking offers a proactive solution by embedding imperceptible, identifiable, and traceable marks into audio content. While recent neural network-based watermarking methods like WavMark and AudioSeal have improved robustness and quality, they struggle to achieve both robust detection and accurate attribution simultaneously. This paper introduces Cross-Attention Robust Audio Watermark (XAttnMark), which bridges this gap by leveraging partial parameter sharing between the generator and the detector, a cross-attention mechanism for efficient message retrieval, and a temporal conditioning module for improved message distribution. Additionally, we propose a psychoacoustic-aligned temporal-frequency masking loss that captures fine-grained auditory masking effects, enhancing watermark imperceptibility. Our approach achieves state-of-the-art performance in both detection and attribution, demonstrating superior robustness against a wide range of audio transformations, including challenging generative editing with strong editing strength. The project webpage is available at this https URL.

Paper number 66:
Title: Every Call is Precious: Global Optimization of Black-Box Functions with Unknown Lipschitz Constants
Authors: Fares Fourati, Salma Kharrat, Vaneet Aggarwal, Mohamed-Slim Alouini
Abstract: Optimizing expensive, non-convex, black-box Lipschitz continuous functions presents significant challenges, particularly when the Lipschitz constant of the underlying function is unknown. Such problems often demand numerous function evaluations to approximate the global optimum, which can be prohibitive in terms of time, energy, or resources. In this work, we introduce Every Call is Precious (ECP), a novel global optimization algorithm that minimizes unpromising evaluations by strategically focusing on potentially optimal regions. Unlike previous approaches, ECP eliminates the need to estimate the Lipschitz constant, thereby avoiding additional function evaluations. ECP guarantees no-regret performance for infinite evaluation budgets and achieves minimax-optimal regret bounds within finite budgets. Extensive ablation studies validate the algorithm's robustness, while empirical evaluations show that ECP outperforms 10 benchmark algorithms including Lipschitz, Bayesian, bandits, and evolutionary methods across 30 multi-dimensional non-convex synthetic and real-world optimization problems, which positions ECP as a competitive approach for global optimization.

Paper number 67:
Title: DexterityGen: Foundation Controller for Unprecedented Dexterity
Authors: Zhao-Heng Yin, Changhao Wang, Luis Pineda, Francois Hogan, Krishna Bodduluri, Akash Sharma, Patrick Lancaster, Ishita Prasad, Mrinal Kalakrishnan, Jitendra Malik, Mike Lambeta, Tingfan Wu, Pieter Abbeel, Mustafa Mukadam
Abstract: Teaching robots dexterous manipulation skills, such as tool use, presents a significant challenge. Current approaches can be broadly categorized into two strategies: human teleoperation (for imitation learning) and sim-to-real reinforcement learning. The first approach is difficult as it is hard for humans to produce safe and dexterous motions on a different embodiment without touch feedback. The second RL-based approach struggles with the domain gap and involves highly task-specific reward engineering on complex tasks. Our key insight is that RL is effective at learning low-level motion primitives, while humans excel at providing coarse motion commands for complex, long-horizon tasks. Therefore, the optimal solution might be a combination of both approaches. In this paper, we introduce DexterityGen (DexGen), which uses RL to pretrain large-scale dexterous motion primitives, such as in-hand rotation or translation. We then leverage this learned dataset to train a dexterous foundational controller. In the real world, we use human teleoperation as a prompt to the controller to produce highly dexterous behavior. We evaluate the effectiveness of DexGen in both simulation and real world, demonstrating that it is a general-purpose controller that can realize input dexterous manipulation commands and significantly improves stability by 10-100x measured as duration of holding objects across diverse tasks. Notably, with DexGen we demonstrate unprecedented dexterous skills including diverse object reorientation and dexterous tool use such as pen, syringe, and screwdriver for the first time.

Paper number 68:
Title: Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment
Authors: Zuyan Liu, Yuhao Dong, Jiahui Wang, Ziwei Liu, Winston Hu, Jiwen Lu, Yongming Rao
Abstract: Recent advances in large language models, particularly following GPT-4o, have sparked increasing interest in developing omni-modal models capable of understanding more modalities. While some open-source alternatives have emerged, there is still a notable lag behind specialized single-modality models in performance. In this paper, we present Ola, an Omni-modal language model that achieves competitive performance across image, video, and audio understanding compared to specialized counterparts. The core design of Ola lies in its progressive modality alignment strategy that extends the supporting modality of the language model progressively. Our training pipeline begins with the most distinct modalities: image and text, then gradually expands the skill sets of the model using speech data that connects language and audio knowledge, and video data that connects all modalities. The progressive learning pipeline also enables us to maintain a relatively small size of the cross-modal alignment data, making developing omni-modal from existing vision-language models easy and less costly. Moreover, to unlock an advanced interactive experience like GPT-4o, we further design a sentence-wise decoding solution for streaming speech generation. Extensive experiments demonstrate that Ola surpasses existing open omni-modal LLMs across all modalities while achieving highly competitive performance compared to state-of-the-art specialized models of similar sizes. We aim to make Ola a fully open omni-modal understanding solution to advance future research in this emerging field. Model weights, code, and data are open-sourced at this https URL.

Paper number 69:
Title: A study of why we need to reassess full reference image quality assessment with medical images
Authors: Anna Breger, Ander Biguri, Malena Sabaté Landman, Ian Selby, Nicole Amberg, Elisabeth Brunner, Janek Gröhl, Sepideh Hatamikia, Clemens Karner, Lipeng Ning, Sören Dittmer, Michael Roberts, AIX-COVNET Collaboration, Carola-Bibiane Schönlieb
Abstract: Image quality assessment (IQA) is indispensable in clinical practice to ensure high standards, as well as in the development stage of machine learning algorithms that operate on medical images. The popular full reference (FR) IQA measures PSNR and SSIM are known and tested for working successfully in many natural imaging tasks, but discrepancies in medical scenarios have been reported in the literature, highlighting the gap between development and actual clinical application. Such inconsistencies are not surprising, as medical images have very different properties than natural images, and PSNR and SSIM have neither been targeted nor properly tested for medical images. This may cause unforeseen problems in clinical applications due to wrong judgment of novel methods. This paper provides a structured and comprehensive overview of examples where PSNR and SSIM prove to be unsuitable for the assessment of novel algorithms using different kinds of medical images, including real-world MRI, CT, OCT, X-Ray, digital pathology and photoacoustic imaging data. Therefore, improvement is urgently needed in particular in this era of AI to increase reliability and explainability in machine learning for medical imaging and beyond. Lastly, we will provide ideas for future research as well as suggesting guidelines for the usage of FR-IQA measures applied to medical images.

Paper number 70:
Title: A game-theoretic, market-based approach to extract flexibility from distributed energy resources
Authors: Vineet Jagadeesan Nair, Anuradha Annaswamy
Abstract: We propose a market designed using game theory to optimally utilize the flexibility of distributed energy resources (DERs) like solar, batteries, electric vehicles, and flexible loads. Market agents perform multiperiod optimization to determine their feasible flexibility limits for power injections while satisfying all constraints of their DERs. This is followed by a Stackelberg game between the market operator and agents. The market operator as the leader aims to regulate the aggregate power injection around a desired value by leveraging the flexibility of their agents, and computes optimal prices for both electricity and flexibility services. The agents follow by optimally bidding their desired flexible power injections in response to these prices. We show the existence and uniqueness of a Nash equilibrium among all the agents and a Stackelberg equilibrium between all agents and the operator. In addition to deriving analytical closed-form solutions, we provide simulation results for a small example system to illustrate our approach.

Paper number 71:
Title: Environmental Variation or Instrumental Drift? A Probabilistic Approach to Gas Sensor Drift Modeling and Evaluation
Authors: Cheng Yang, Gustav Bohlin, Tobias Oechtering
Abstract: Drift is a significant issue that undermines the reliability of gas sensors. This paper introduces a probabilistic model to distinguish between environmental variation and instrumental drift, using low-cost non-dispersive infrared (NDIR) CO2 sensors as a case study. Data from a long-term field experiment is analyzed to evaluate both sensor performance and environmental changes over time. Our approach employs importance sampling to isolate instrumental drift from environmental variation, providing a more accurate assessment of sensor performance. The results show that failing to account for environmental variation can significantly affect the evaluation of sensor drift, leading to improper calibration processes.

Paper number 72:
Title: Robust model predictive control exploiting monotonicity properties
Authors: Moritz Heinlein, Sankaranarayanan Subramanian, Sergio Lucia
Abstract: Robust model predictive control algorithms are essential for addressing unavoidable errors due to the uncertainty in predicting real-world systems. However, the formulation of such algorithms typically results in a trade-off between conservatism and computational complexity. Monotone systems facilitate the efficient computation of reachable sets and thus the straightforward formulation of a robust model predictive control approach optimizing over open-loop predictions. We present an approach based on the division of reachable sets to incorporate feedback in the predictions, resulting in less conservative strategies. The concept of mixed-monotonicity enables an extension of our methodology to non-monotone systems. The potential of the proposed approaches is demonstrated through a nonlinear high-dimensional chemical tank reactor cascade case study.

Paper number 73:
Title: Protecting residential electrical panels and service through model predictive control: A field study
Authors: Elias N. Pergantis, Levi D. Reyes Premer, Alex H. Lee, Priyadarshan, Haotian Liu, Eckhard A. Groll, Davide Ziviani, Kevin J. Kircher
Abstract: Residential electrification - replacing fossil-fueled appliances and vehicles with electric machines - can significantly reduce greenhouse gas emissions and air pollution. However, installing electric appliances or vehicle charging in a residential building can sharply increase its current draws. In older housing, high current draws can jeopardize electrical infrastructure, such as circuit breaker panels or electrical service (the wires that connect a building to the distribution grid). Upgrading electrical infrastructure can entail long delays and high costs, so poses a significant barrier to electrification. This paper develops and field-tests a control system that avoids the need for electrical upgrades by keeping an electrified home's total current draw within the safe limits of its panel and service. In the proposed control architecture, a high-level controller plans device set-points over a rolling prediction horizon. A low-level controller monitors real-time conditions and ramps down devices if necessary. The control system was tested in an occupied, electrified single-family house with code-minimum insulation, an air-to-air heat pump and backup resistance heat, a resistance water heater, and a plug-in hybrid electric vehicle with Level I charging. The field tests spanned 31 winter days with outdoor temperatures as low as -20 C. The control system maintained the whole-home current within the safe limits of electrical panels and service rated at 100 A, a common rating for older houses in North America, by adjusting only the temperature set-points of the heat pump and water heater. Simulations suggest that the same 100 A limit could accommodate a second electric vehicle with Level II charging. The proposed control system could allow older homes to safely electrify without upgrading electrical panels or service, saving a typical household on the order of $2,000 to $10,000.

Paper number 74:
Title: Moner: Motion Correction in Undersampled Radial MRI with Unsupervised Neural Representation
Authors: Qing Wu, Chenhe Du, Xuanyu Tian, Jingyi Yu, Yuyao Zhang, Hongjiang Wei
Abstract: Motion correction (MoCo) in radial MRI is a challenging problem due to the unpredictability of subject's motion. Current state-of-the-art (SOTA) MoCo algorithms often use extensive high-quality MR images to pre-train neural networks, obtaining excellent reconstructions. However, the need for large-scale datasets significantly increases costs and limits model generalization. In this work, we propose Moner, an unsupervised MoCo method that jointly solves artifact-free MR images and accurate motion from undersampled, rigid motion-corrupted k-space data, without requiring training data. Our core idea is to leverage the continuous prior of implicit neural representation (INR) to constrain this ill-posed inverse problem, enabling ideal solutions. Specifically, we incorporate a quasi-static motion model into the INR, granting its ability to correct subject's motion. To stabilize model optimization, we reformulate radial MRI as a back-projection problem using the Fourier-slice theorem. Additionally, we propose a novel coarse-to-fine hash encoding strategy, significantly enhancing MoCo accuracy. Experiments on multiple MRI datasets show our Moner achieves performance comparable to SOTA MoCo techniques on in-domain data, while demonstrating significant improvements on out-of-domain data. The code is available at: this https URL

Paper number 75:
Title: FetDTIAlign: A Deep Learning Framework for Affine and Deformable Registration of Fetal Brain dMRI
Authors: Bo Li, Qi Zeng, Simon K. Warfield, Davood Karimi
Abstract: Diffusion MRI (dMRI) provides unique insights into fetal brain microstructure in utero. Longitudinal and cross-sectional fetal dMRI studies can reveal crucial neurodevelopmental changes but require precise spatial alignment across scans and subjects. This is challenging due to low data quality, rapid brain development, and limited anatomical landmarks. Existing registration methods, designed for high-quality adult data, struggle with these complexities. To address this, we introduce FetDTIAlign, a deep learning approach for fetal brain dMRI registration, enabling accurate affine and deformable alignment. FetDTIAlign features a dual-encoder architecture and iterative feature-based inference, reducing the impact of noise and low resolution. It optimizes network configurations and domain-specific features at each registration stage, enhancing both robustness and accuracy. We validated FetDTIAlign on data from 23 to 36 weeks gestation, covering 60 white matter tracts. It consistently outperformed two classical optimization-based methods and a deep learning pipeline, achieving superior anatomical correspondence. Further validation on external data from the Developing Human Connectome Project confirmed its generalizability across acquisition protocols. Our results demonstrate the feasibility of deep learning for fetal brain dMRI registration, providing a more accurate and reliable alternative to classical techniques. By enabling precise cross-subject and tract-specific analyses, FetDTIAlign supports new discoveries in early brain development.

Paper number 76:
Title: Containment Control Approach for Steering Opinion in a Social Network
Authors: Hossein Rastgoftar
Abstract: The paper studies the problem of steering multi-dimensional opinion in a social network. Assuming the society of desire consists of stubborn and regular agents, stubborn agents are considered as leaders who specify the desired opinion distribution as a distributed reward or utility function. In this context, each regular agent is seen as a follower, updating its bias on the initial opinion and influence weights by averaging their observations of the rewards their influencers have received. Assuming random graphs with reducible and irreducible topology specify the influences on regular agents, opinion evolution is represented as a containment control problem in which stability and convergence to the final opinion are proven.

Paper number 77:
Title: Generalization analysis of an unfolding network for analysis-based Compressed Sensing
Authors: Vicky Kouni, Yannis Panagakis
Abstract: Unfolding networks have shown promising results in the Compressed Sensing (CS) field. Yet, the investigation of their generalization ability is still in its infancy. In this paper, we perform a generalization analysis of a state-of-the-art ADMM-based unfolding network, which jointly learns a decoder for CS and a sparsifying redundant analysis operator. To this end, we first impose a structural constraint on the learnable sparsifier, which parametrizes the network's hypothesis class. For the latter, we estimate its Rademacher complexity. With this estimate in hand, we deliver generalization error bounds -- which scale like the square root of the number of layers -- for the examined network. Finally, the validity of our theory is assessed and numerical comparisons to a state-of-the-art unfolding network are made, on synthetic and real-world datasets. Our experimental results demonstrate that our proposed framework complies with our theoretical findings and outperforms the baseline, consistently for all datasets.

Paper number 78:
Title: Rates of Convergence in the Central Limit Theorem for Markov Chains, with an Application to TD Learning
Authors: R. Srikant
Abstract: We prove a non-asymptotic central limit theorem for vector-valued martingale differences using Stein's method, and use Poisson's equation to extend the result to functions of Markov Chains. We then show that these results can be applied to establish a non-asymptotic central limit theorem for Temporal Difference (TD) learning with averaging.

Paper number 79:
Title: On Robust Reinforcement Learning with Lipschitz-Bounded Policy Networks
Authors: Nicholas H. Barbara, Ruigang Wang, Ian R. Manchester
Abstract: This paper presents a study of robust policy networks in deep reinforcement learning. We investigate the benefits of policy parameterizations that naturally satisfy constraints on their Lipschitz bound, analyzing their empirical performance and robustness on two representative problems: pendulum swing-up and Atari Pong. We illustrate that policy networks with smaller Lipschitz bounds are more robust to disturbances, random noise, and targeted adversarial attacks than unconstrained policies composed of vanilla multi-layer perceptrons or convolutional neural networks. However, the structure of the Lipschitz layer is important. We find that the widely-used method of spectral normalization is too conservative and severely impacts clean performance, whereas more expressive Lipschitz layers such as the recently-proposed Sandwich layer can achieve improved robustness without sacrificing clean performance.

Paper number 80:
Title: SoNIC: Safe Social Navigation with Adaptive Conformal Inference and Constrained Reinforcement Learning
Authors: Jianpeng Yao, Xiaopan Zhang, Yu Xia, Zejin Wang, Amit K. Roy-Chowdhury, Jiachen Li
Abstract: Reinforcement learning (RL) enables social robots to generate trajectories without relying on human-designed rules or interventions, making it generally more effective than rule-based systems in adapting to complex, dynamic real-world scenarios. However, social navigation is a safety-critical task that requires robots to avoid collisions with pedestrians, whereas existing RL-based solutions often fall short of ensuring safety in complex environments. In this paper, we propose SoNIC, which to the best of our knowledge is the first algorithm that integrates adaptive conformal inference (ACI) with constrained reinforcement learning (CRL) to enable safe policy learning for social navigation. Specifically, our method not only augments RL observations with ACI-generated nonconformity scores, which inform the agent of the quantified uncertainty but also employs these uncertainty estimates to effectively guide the behaviors of RL agents by using constrained reinforcement learning. This integration regulates the behaviors of RL agents and enables them to handle safety-critical situations. On the standard CrowdNav benchmark, our method achieves a success rate of 96.93%, which is 11.67% higher than the previous state-of-the-art RL method and results in 4.5 times fewer collisions and 2.8 times fewer intrusions to ground-truth human future trajectories as well as enhanced robustness in out-of-distribution scenarios. To further validate our approach, we deploy our algorithm on a real robot by developing a ROS2-based navigation system. Our experiments demonstrate that the system can generate robust and socially polite decision-making when interacting with both sparse and dense crowds. The video demos can be found on our project website: this https URL.

Paper number 81:
Title: Recent Advances in Speech Language Models: A Survey
Authors: Wenqian Cui, Dianzhi Yu, Xiaoqi Jiao, Ziqiao Meng, Guangyan Zhang, Qichao Wang, Yiwen Guo, Irwin King
Abstract: Large Language Models (LLMs) have recently garnered significant attention, primarily for their capabilities in text-based interactions. However, natural human interaction often relies on speech, necessitating a shift towards voice-based models. A straightforward approach to achieve this involves a pipeline of ``Automatic Speech Recognition (ASR) + LLM + Text-to-Speech (TTS)", where input speech is transcribed to text, processed by an LLM, and then converted back to speech. Despite being straightforward, this method suffers from inherent limitations, such as information loss during modality conversion, significant latency due to the complex pipeline, and error accumulation across the three stages. To address these issues, Speech Language Models (SpeechLMs) -- end-to-end models that generate speech without converting from text -- have emerged as a promising alternative. This survey paper provides the first comprehensive overview of recent methodologies for constructing SpeechLMs, detailing the key components of their architecture and the various training recipes integral to their development. Additionally, we systematically survey the various capabilities of SpeechLMs, categorize their evaluation metrics, and discuss the challenges and future research directions in this rapidly evolving field. The GitHub repository is available at this https URL

Paper number 82:
Title: Graph-Enhanced EEG Foundation Model
Authors: Limin Wang, Toyotaro Suzumura, Hiroki Kanezashi
Abstract: Electroencephalography (EEG) signals provide critical insights for applications in disease diagnosis and healthcare. However, the scarcity of labeled EEG data poses a significant challenge. Foundation models offer a promising solution by leveraging large-scale unlabeled data through pre-training, enabling strong performance across diverse tasks. While both temporal dynamics and inter-channel relationships are vital for understanding EEG signals, existing EEG foundation models primarily focus on the former, overlooking the latter. To address this limitation, we propose a novel foundation model for EEG that integrates both temporal and inter-channel information. Our architecture combines Graph Neural Networks (GNNs), which effectively capture relational structures, with a masked autoencoder to enable efficient pre-training. We evaluated our approach using three downstream tasks and experimented with various GNN architectures. The results demonstrate that our proposed model, particularly when employing the GCN architecture with optimized configurations, consistently outperformed baseline methods across all tasks. These findings suggest that our model serves as a robust foundation model for EEG analysis.

Paper number 83:
Title: M$^3$PC: Test-time Model Predictive Control for Pretrained Masked Trajectory Model
Authors: Kehan Wen, Yutong Hu, Yao Mu, Lei Ke
Abstract: Recent work in Offline Reinforcement Learning (RL) has shown that a unified Transformer trained under a masked auto-encoding objective can effectively capture the relationships between different modalities (e.g., states, actions, rewards) within given trajectory datasets. However, this information has not been fully exploited during the inference phase, where the agent needs to generate an optimal policy instead of just reconstructing masked components from unmasked ones. Given that a pretrained trajectory model can act as both a Policy Model and a World Model with appropriate mask patterns, we propose using Model Predictive Control (MPC) at test time to leverage the model's own predictive capability to guide its action selection. Empirical results on D4RL and RoboMimic show that our inference-phase MPC significantly improves the decision-making performance of a pretrained trajectory model without any additional parameter training. Furthermore, our framework can be adapted to Offline to Online (O2O) RL and Goal Reaching RL, resulting in more substantial performance gains when an additional online interaction budget is provided, and better generalization capabilities when different task targets are specified. Code is available: this https URL.

Paper number 84:
Title: Gravity Compensation of the dVRK-Si Patient Side Manipulator based on Dynamic Model Identification
Authors: Haoying Zhou, Hao Yang, Anton Deguet, Loris Fichera, Jie Ying Wu, Peter Kazanzides
Abstract: The da Vinci Research Kit (dVRK, also known as dVRK Classic) is an open-source teleoperated surgical robotic system whose hardware is obtained from the first generation da Vinci Surgical System (Intuitive, Sunnyvale, CA, USA). The dVRK has greatly facilitated research in robot-assisted surgery over the past decade and helped researchers address multiple major challenges in this domain. Recently, the dVRK-Si system, a new version of the dVRK which uses mechanical components from the da Vinci Si Surgical System, became available to the community. The major difference between the first generation da Vinci and the da Vinci Si is in the structural upgrade of the Patient Side Manipulator (PSM). Because of this upgrade, the gravity of the dVRK-Si PSM can no longer be ignored as in the dVRK Classic. The high gravity offset may lead to relatively low control accuracy and longer response time. In addition, although substantial progress has been made in addressing the dynamic model identification problem for the dVRK Classic, further research is required on model-based control for the dVRK-Si, due to differences in mechanical components and the demand for enhanced control performance. To address these problems, in this work, we present (1) a novel full kinematic model of the dVRK-Si PSM, and (2) a gravity compensation approach based on the dynamic model identification.
    