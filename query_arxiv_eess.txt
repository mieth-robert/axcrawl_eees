
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Sub-diffraction terahertz backpropagation compressive imaging
Authors: Yongsheng Zhu, Shaojing Liu, Ximiao Wang, Runli Li, Haili Yang, Jiali Wang, Hongjia Zhu, Yanlin Ke, Ningsheng Xu, Huanjun Chen, Shaozhi Deng
Abstract: Terahertz single-pixel imaging (TSPI) has garnered significant attention due to its simplicity and cost-effectiveness. However, the relatively long wavelength of THz waves limits sub-diffraction-scale imaging resolution. Although TSPI technique can achieve sub-wavelength resolution, it requires harsh experimental conditions and time-consuming processes. Here, we propose a sub-diffraction THz backpropagation compressive imaging technique. We illuminate the object with monochromatic continuous-wave THz radiation. The transmitted THz wave is modulated by prearranged patterns generated on the back surface of a 500-{\mu}m-thick silicon wafer, realized through photoexcited carriers using a 532-nm laser. The modulated THz wave is then recorded by a single-element detector. An untrained neural network is employed to iteratively reconstruct the object image with an ultralow compression ratio of 1.5625% under a physical model constraint, thus reducing the long sampling times. To further suppress the diffraction-field effects, embedded with the angular spectrum propagation (ASP) theory to model the diffraction of THz waves during propagation, the network retrieves near-field information from the object, enabling sub-diffraction imaging with a spatial resolution of ~{\lambda}0/7 ({\lambda}0 = 833.3 {\mu}m at 0.36 THz) and eliminating the need for ultrathin photomodulators. This approach provides an efficient solution for advancing THz microscopic imaging and addressing other inverse imaging challenges.

Paper number 2:
Title: Evaluation of UAV-Based RGB and Multispectral Vegetation Indices for Precision Agriculture in Palm Tree Cultivation
Authors: Alavikunhu Panthakkan, S M Anzar, K. Sherin, Saeed Al Mansoori, Hussain Al-Ahmad
Abstract: Precision farming relies on accurate vegetation monitoring to enhance crop productivity and promote sustainable agricultural practices. This study presents a comprehensive evaluation of UAV-based imaging for vegetation health assessment in a palm tree cultivation region in Dubai. By comparing multispectral and RGB image data, we demonstrate that RGBbased vegetation indices offer performance comparable to more expensive multispectral indices, providing a cost-effective alternative for large-scale agricultural monitoring. Using UAVs equipped with multispectral sensors, indices such as NDVI and SAVI were computed to categorize vegetation into healthy, moderate, and stressed conditions. Simultaneously, RGB-based indices like VARI and MGRVI delivered similar results in vegetation classification and stress detection. Our findings highlight the practical benefits of integrating RGB imagery into precision farming, reducing operational costs while maintaining accuracy in plant health monitoring. This research underscores the potential of UAVbased RGB imaging as a powerful tool for precision agriculture, enabling broader adoption of data-driven decision-making in crop management. By leveraging the strengths of both multispectral and RGB imaging, this work advances the state of UAV applications in agriculture, paving the way for more efficient and scalable farming solutions.

Paper number 3:
Title: Pose Estimation for Intra-cardiac Echocardiography Catheter via AI-Based Anatomical Understanding
Authors: Jaeyoung Huh, Ankur Kapoor, Young-Ho Kim
Abstract: Intra-cardiac Echocardiography (ICE) plays a crucial role in Electrophysiology (EP) and Structural Heart Disease (SHD) interventions by providing high-resolution, real-time imaging of cardiac structures. However, existing navigation methods rely on electromagnetic (EM) tracking, which is susceptible to interference and position drift, or require manual adjustments based on operator expertise. To overcome these limitations, we propose a novel anatomy-aware pose estimation system that determines the ICE catheter position and orientation solely from ICE images, eliminating the need for external tracking sensors. Our approach leverages a Vision Transformer (ViT)-based deep learning model, which captures spatial relationships between ICE images and anatomical structures. The model is trained on a clinically acquired dataset of 851 subjects, including ICE images paired with position and orientation labels normalized to the left atrium (LA) mesh. ICE images are patchified into 16x16 embeddings and processed through a transformer network, where a [CLS] token independently predicts position and orientation via separate linear layers. The model is optimized using a Mean Squared Error (MSE) loss function, balancing positional and orientational accuracy. Experimental results demonstrate an average positional error of 9.48 mm and orientation errors of (16.13 deg, 8.98 deg, 10.47 deg) across x, y, and z axes, confirming the model accuracy. Qualitative assessments further validate alignment between predicted and target views within 3D cardiac meshes. This AI-driven system enhances procedural efficiency, reduces operator workload, and enables real-time ICE catheter localization for tracking-free procedures. The proposed method can function independently or complement existing mapping systems like CARTO, offering a transformative approach to ICE-guided interventions.

Paper number 4:
Title: Computationally Efficient Diffusion Models in Medical Imaging: A Comprehensive Review
Authors: Abdullah, Tao Huang, Ickjai Lee, Euijoon Ahn
Abstract: The diffusion model has recently emerged as a potent approach in computer vision, demonstrating remarkable performances in the field of generative artificial intelligence. Capable of producing high-quality synthetic images, diffusion models have been successfully applied across a range of applications. However, a significant challenge remains with the high computational cost associated with training and generating these models. This study focuses on the efficiency and inference time of diffusion-based generative models, highlighting their applications in both natural and medical imaging. We present the most recent advances in diffusion models by categorizing them into three key models: the Denoising Diffusion Probabilistic Model (DDPM), the Latent Diffusion Model (LDM), and the Wavelet Diffusion Model (WDM). These models play a crucial role in medical imaging, where producing fast, reliable, and high-quality medical images is essential for accurate analysis of abnormalities and disease diagnosis. We first investigate the general framework of DDPM, LDM, and WDM and discuss the computational complexity gap filled by these models in natural and medical imaging. We then discuss the current limitations of these models as well as the opportunities and future research directions in medical imaging.

Paper number 5:
Title: MiniMax-Speech: Intrinsic Zero-Shot Text-to-Speech with a Learnable Speaker Encoder
Authors: Bowen Zhang, Congchao Guo, Geng Yang, Hang Yu, Haozhe Zhang, Heidi Lei, Jialong Mai, Junjie Yan, Kaiyue Yang, Mingqi Yang, Peikai Huang, Ruiyang Jin, Sitan Jiang, Weihua Cheng, Yawei Li, Yichen Xiao, Yiying Zhou, Yongmao Zhang, Yuan Lu, Yucen He
Abstract: We introduce MiniMax-Speech, an autoregressive Transformer-based Text-to-Speech (TTS) model that generates high-quality speech. A key innovation is our learnable speaker encoder, which extracts timbre features from a reference audio without requiring its transcription. This enables MiniMax-Speech to produce highly expressive speech with timbre consistent with the reference in a zero-shot manner, while also supporting one-shot voice cloning with exceptionally high similarity to the reference voice. In addition, the overall quality of the synthesized audio is enhanced through the proposed Flow-VAE. Our model supports 32 languages and demonstrates excellent performance across multiple objective and subjective evaluations metrics. Notably, it achieves state-of-the-art (SOTA) results on objective voice cloning metrics (Word Error Rate and Speaker Similarity) and has secured the top position on the public TTS Arena leaderboard. Another key strength of MiniMax-Speech, granted by the robust and disentangled representations from the speaker encoder, is its extensibility without modifying the base model, enabling various applications such as: arbitrary voice emotion control via LoRA; text to voice (T2V) by synthesizing timbre features directly from text description; and professional voice cloning (PVC) by fine-tuning timbre features with additional data. We encourage readers to visit this https URL for more examples.

Paper number 6:
Title: Near-Field Beamfocusing, Localization, and Channel Estimation with Modular Linear Arrays
Authors: Alva Kosasih, Özlem Tuğfe Demir, Emil Björnson
Abstract: This paper investigates how near-field beamfocusing can be achieved using a modular linear array (MLA), composed of multiple widely spaced uniform linear arrays (ULAs). The MLA architecture extends the aperture length of a standard ULA without adding additional antennas, thereby enabling near-field beamfocusing without increasing processing complexity. Unlike conventional far-field beamforming, near-field beamfocusing enables simultaneous data transmission to multiple users at different distances in the same angular interval, offering significant multiplexing gains. We present a detailed mathematical analysis of the beamwidth and beamdepth achievable with the MLA and show that by appropriately selecting the number of antennas in each constituent ULA, ideal near-field beamfocusing can be realized. In addition, we propose a computationally efficient localization method that fuses estimates from each ULA, enabling efficient parametric channel estimation. Simulation results confirm the accuracy of the analytical expressions and that MLAs achieve near-field beamfocusing with a limited number of antennas, making them a promising solution for next-generation wireless systems.

Paper number 7:
Title: Safety and optimality in learning-based control at low computational cost
Authors: Dominik Baumann, Krzysztof Kowalczyk, Cristian R. Rojas, Koen Tiels, Pawel Wachel
Abstract: Applying machine learning methods to physical systems that are supposed to act in the real world requires providing safety guarantees. However, methods that include such guarantees often come at a high computational cost, making them inapplicable to large datasets and embedded devices with low computational power. In this paper, we propose CoLSafe, a computationally lightweight safe learning algorithm whose computational complexity grows sublinearly with the number of data points. We derive both safety and optimality guarantees and showcase the effectiveness of our algorithm on a seven-degrees-of-freedom robot arm.

Paper number 8:
Title: Statistical CSI-Based Distributed Precoding Design for OFDM-Cooperative Multi-Satellite Systems
Authors: Yafei Wang, Vu Nguyen Ha, Konstantinos Ntontin, Hong Yan, Wenjin Wang, Symeon Chatzinotas, Björn Ottersten
Abstract: This paper investigates the design of distributed precoding for multi-satellite massive MIMO transmissions. We first conduct a detailed analysis of the transceiver model, in which delay and Doppler precompensation is introduced to ensure coherent transmission. In this analysis, we examine the impact of precompensation errors on the transmission model, emphasize the near-independence of inter-satellite interference, and ultimately derive the received signal model. Based on such signal model, we formulate an approximate expected rate maximization problem that considers both statistical channel state information (sCSI) and compensation errors. Unlike conventional approaches that recast such problems as weighted minimum mean square error (WMMSE) minimization, we demonstrate that this transformation fails to maintain equivalence in the considered scenario. To address this, we introduce an equivalent covariance decomposition-based WMMSE (CDWMMSE) formulation derived based on channel covariance matrix decomposition. Taking advantage of the channel characteristics, we develop a low-complexity decomposition method and propose an optimization algorithm. To further reduce computational complexity, we introduce a model-driven scalable deep learning (DL) approach that leverages the equivariance of the mapping from sCSI to the unknown variables in the optimal closed-form solution, enhancing performance through novel dense Transformer network and scaling-invariant loss function design. Simulation results validate the effectiveness and robustness of the proposed method in some practical scenarios. We also demonstrate that the DL approach can adapt to dynamic settings with varying numbers of users and satellites.

Paper number 9:
Title: Zak-OTFS for Spread Spectrum Communication
Authors: Nishant Mehrotra, Sandesh Rao Mattu, Robert Calderbank
Abstract: An attractive feature of spread spectrum technologies such as code division multiple access (CDMA) is that it is harder to intercept or jam signals, and this feature was lost when orthogonal frequency domain modulation prevailed over CDMA in wireless standards. Legacy spread carrier waveforms are not matched to delay and Doppler shifts characteristic of 6G wireless environments, and this makes equalization very challenging. Zak-OTFS modulation is a communication framework that parameterizes the wireless channel in the delay-Doppler (DD) domain, where the parameters map directly to physical attributes of the scatterers that comprise the scattering environment. Hence, the channel can be efficiently acquired and equalized. The Zak-OTFS carrier is a pulse in the DD domain, and the Zak transform converts it to a pulse train modulated by a tone (pulsone) in the time domain. The pulsone waveform is localized rather than spread, and it suffers from high PAPR. We describe how to transform Zak-OTFS into a spread spectrum communication system, where the spread carrier waveforms have low PAPR and are matched to the delay and Doppler characteristics of the wireless channel. This transformation is realized by a unitary transform that is a generalization of the discrete affine Fourier transform. The transform maps a pulsone to a time domain waveform which yields a CAZAC sequence after sampling. The family of CAZAC sequences includes the Zadoff-Chu sequences incorporated in LTE and 5G-NR standards. We describe the end-to-end time-domain transceiver signal processing, comprising channel estimation and data demodulation, for the proposed system. We quantify system performance through BER simulations using a six-path Veh-A channel model, showing that the proposed system achieves similar uncoded BER as pulsone-based Zak-OTFS, where the PAPR of each spread carrier waveform is only 3.58 dB.

Paper number 10:
Title: Leveraging Reinforcement Learning and Koopman Theory for Enhanced Model Predictive Control Performance
Authors: Md Nur-A-Adam Dony, Jing Yang
Abstract: This study presents an innovative approach to Model Predictive Control (MPC) by leveraging the powerful combination of Koopman theory and Deep Reinforcement Learning (DRL). By transforming nonlinear dynamical systems into a higher-dimensional linear regime, the Koopman operator facilitates the linear treatment of nonlinear behaviors, paving the way for more efficient control strategies. Our methodology harnesses the predictive prowess of Koopman-based models alongside the optimization capabilities of DRL, particularly using the Proximal Policy Optimization (PPO) algorithm, to enhance the controller's performance. The resulting end-to-end learning framework refines the predictive control policies to cater to specific operational tasks, optimizing both performance and economic efficiency. We validate our approach through rigorous NMPC and eNMPC case studies, demonstrating that the Koopman-RL controller outperforms traditional controllers by achieving higher stability, superior constraint satisfaction, and significant cost savings. The findings indicate that our model can be a robust tool for complex control tasks, offering valuable insights into future applications of RL in MPC.

Paper number 11:
Title: Integrating Koopman theory and Lyapunov stability for enhanced model predictive control in nonlinear systems
Authors: Md Nur-A-Adam Dony, Minghui Zhu
Abstract: This paper delves into the challenges posed by the increasing complexity of modern control systems, specifically focusing on bilinear systems, a prevalent subclass of non-linear systems characterized by state dynamics influenced by the interaction of state and control variables. Traditional control strategies, such as PID controllers, often fall short in adequately addressing the intricacies of such systems due to their predictive limitations. To bridge this gap, we introduce Model Predictive Control (MPC), a sophisticated technique that utilizes system models to forecast future behaviors, allowing for the computation of an optimal control sequence by minimizing deviations and control efforts. The Koopman operator emerges as a pivotal tool in this framework by providing a means to linearize the nonlinear dynamics of bilinear systems. By integrating the principles of Lyapunov theory with the linearizing capabilities of the Koopman operator into the MPC framework, we give rise to Koopman Lyapunov-based Model Predictive Control (Koopman LMPC). This approach not only retains MPC's predictive capabilities but also harnesses the Koopman operator's ability to transform complex nonlinear behaviors into a linear framework, thereby enhancing the robustness and applicability of LMPC. With the stability assurances from Lyapunov theory, Koopman LMPC presents a robust solution to effectively control and stabilize bilinear systems. The paper underscores the efficacy of Koopman LMPC, emphasizing its significance in achieving optimal performance and system stability, marking it as a promising approach for the future of advanced control systems.

Paper number 12:
Title: Highly Undersampled MRI Reconstruction via a Single Posterior Sampling of Diffusion Models
Authors: Jin Liu, Qing Lin, Zhuang Xiong, Shanshan Shan, Chunyi Liu, Min Li, Feng Liu, G. Bruce Pike, Hongfu Sun, Yang Gao
Abstract: Incoherent k-space under-sampling and deep learning-based reconstruction methods have shown great success in accelerating MRI. However, the performance of most previous methods will degrade dramatically under high acceleration factors, e.g., 8$\times$ or higher. Recently, denoising diffusion models (DM) have demonstrated promising results in solving this issue; however, one major drawback of the DM methods is the long inference time due to a dramatic number of iterative reverse posterior sampling steps. In this work, a Single Step Diffusion Model-based reconstruction framework, namely SSDM-MRI, is proposed for restoring MRI images from highly undersampled k-space. The proposed method achieves one-step reconstruction by first training a conditional DM and then iteratively distilling this model. Comprehensive experiments were conducted on both publicly available fastMRI images and an in-house multi-echo GRE (QSM) subject. Overall, the results showed that SSDM-MRI outperformed other methods in terms of numerical metrics (PSNR and SSIM), qualitative error maps, image fine details, and latent susceptibility information hidden in MRI phase images. In addition, the reconstruction time for a 320*320 brain slice of SSDM-MRI is only 0.45 second, which is only comparable to that of a simple U-net, making it a highly effective solution for MRI reconstruction tasks.

Paper number 13:
Title: Fault Detection Method for Power Conversion Circuits Using Thermal Image and Convolutional Autoencoder
Authors: Noboru Katayama, Rintaro Ishida
Abstract: A fault detection method for power conversion circuits using thermal images and a convolutional autoencoder is presented. The autoencoder is trained on thermal images captured from a commercial power module at randomly varied load currents and augmented image2 generated through image processing techniques such as resizing, rotation, perspective transformation, and bright and contrast adjustment. Since the autoencoder is trained to output images identical to input only for normal samples, it reconstructs images similar to normal ones even when the input images containing faults. A small heater is attached to the circuit board to simulate a fault on a power module, and then thermal images were captured from different angles and positions, as well as various load currents to test the trained autoencoder model. The areas under the curve (AUC) were obtained to evaluate the proposed method. The results show the autoencoder model can detect anomalies with 100% accuracy under given conditions. The influence of hyperparameters such as the number of convolutional layers and image augmentation conditions on anomaly detection accuracy was also investigated.

Paper number 14:
Title: Non-Blocking Robustness Analysis in Discrete Event Systems
Authors: Md Nur-A-Adam Dony, Satadru Dey
Abstract: This paper presents a mathematical framework for characterizing state blocking in discrete event systems (DES) under transition deletions. We introduce a path-based analysis approach that determines whether systems maintain non-blocking properties when transitions are removed. Through formal analysis and case studies, we establish three key contributions: a mathematical characterization of transition-induced blocking with necessary and sufficient conditions, a definition of robust deviations that preserve non-blocking properties, and an algorithm for identifying critical transitions and analyzing system behavior under deletions. Our algorithm reduces computational complexity by leveraging minimal blocking sets, achieving significant reduction in computational requirements. We demonstrate the framework's effectiveness through manufacturing system and autonomous vehicle case studies, showing substantial improvements in identifying critical transitions and predicting potential blocking scenarios across different application domains.

Paper number 15:
Title: Performance Analysis of Cooperative Integrated Sensing and Communications for 6G Networks
Authors: Dongsheng Sui, Cunhua Pan, Hong Ren, Jiahua Wan, Liuchang Zhuo, Jing Jin, Qixing Wang, Jiangzhou Wang
Abstract: In this work, we aim to effectively characterize the performance of cooperative integrated sensing and communication (ISAC) networks and to reveal how performance metrics relate to network parameters. To this end, we introduce a generalized stochastic geometry framework to model the cooperative ISAC networks, which approximates the spatial randomness of the network deployment. Based on this framework, we derive analytical expressions for key performance metrics in both communication and sensing domains, with a particular focus on communication coverage probability and radar information rate. The analytical expressions derived explicitly highlight how performance metrics depend on network parameters, thereby offering valuable insights into the deployment and design of cooperative ISAC networks. In the end, we validate the theoretical performance analysis through Monte Carlo simulation results. Our results demonstrate that increasing the number of cooperative base stations (BSs) significantly improves both metrics, while increasing the BS deployment density has a limited impact on communication coverage probability but substantially enhances the radar information rate. Additionally, increasing the number of transmit antennas is effective when the total number of transmit antennas is relatively small. The incremental performance gain reduces with the increase of the number of transmit antennas, suggesting that indiscriminately increasing antennas is not an efficient strategy to improve the performance of the system in cooperative ISAC networks.

Paper number 16:
Title: N$^2$LoS: Single-Tag mmWave Backscatter for Robust Non-Line-of-Sight Localization
Authors: Zhenguo Shi, Yihe Yan, Yanxiang Wang, Wen Hu, Chun Tung Chou
Abstract: The accuracy of traditional localization methods significantly degrades when the direct path between the wireless transmitter and the target is blocked or non-penetrable. This paper proposes N2LoS, a novel approach for precise non-line-of-sight (NLoS) localization using a single mmWave radar and a backscatter tag. N2LoS leverages multipath reflections from both the tag and surrounding reflectors to accurately estimate the targets position. N2LoS introduces several key innovations. First, we design HFD (Hybrid Frequency-Hopping and Direct Sequence Spread Spectrum) to detect and differentiate reflectors from the target. Second, we enhance signal-to-noise ratio (SNR) by exploiting the correlation properties of the designed signals, improving detection robustness in complex environments. Third, we propose FS-MUSIC (Frequency-Spatial Multiple Signal Classification), a super resolution algorithm that extends the traditional MUSIC method by constructing a higher-rank signal matrix, enabling the resolution of additional multipath components. We evaluate N2LoS using a 24 GHz mmWave radar with 250 MHz bandwidth in three diverse environments: a laboratory, an office, and an around-the-corner corridor. Experimental results demonstrate that N2LoS achieves median localization errors of 10.69 cm (X) and 11.98 cm (Y) at a 5 m range in the laboratory setting, showcasing its effectiveness for real-world NLoS localization.

Paper number 17:
Title: Skeleton-Guided Diffusion Model for Accurate Foot X-ray Synthesis in Hallux Valgus Diagnosis
Authors: Midi Wan, Pengfei Li, Yizhuo Liang, Di Wu, Yushan Pan, Guangzhen Zhu, Hao Wang
Abstract: Medical image synthesis plays a crucial role in providing anatomically accurate images for diagnosis and treatment. Hallux valgus, which affects approximately 19% of the global population, requires frequent weight-bearing X-rays for assessment, placing additional strain on both patients and healthcare providers. Existing X-ray models often struggle to balance image fidelity, skeletal consistency, and physical constraints, particularly in diffusion-based methods that lack skeletal guidance. We propose the Skeletal-Constrained Conditional Diffusion Model (SCCDM) and introduce KCC, a foot evaluation method utilizing skeletal landmarks. SCCDM incorporates multi-scale feature extraction and attention mechanisms, improving the Structural Similarity Index (SSIM) by 5.72% (0.794) and Peak Signal-to-Noise Ratio (PSNR) by 18.34% (21.40 dB). When combined with KCC, the model achieves an average score of 0.85, demonstrating strong clinical applicability. The code is available at this https URL.

Paper number 18:
Title: Sparsity-Aware Near-Field Beam Training via Multi-Beam Combination
Authors: Zijun Wang, Rama Kiran, Jinesh Nair, Chien-Hua Chen, Tzu-Han Chou, Shawn Tsai, Rui Zhang
Abstract: This paper proposes an adaptive near-field beam training method to enhance performance in multi-user and multipath environments. The approach identifies multiple strongest beams through beam sweeping and linearly combines their received signals - capturing both amplitude and phase - for improved channel estimation. Two codebooks are considered: the conventional DFT codebook and a near-field codebook that samples both angular and distance domains. As the near-field basis functions are generally non-orthogonal and often over-complete, we exploit sparsity in the solution using LASSO-based linear regression, which can also suppress noise. Simulation results show that the near-field codebook reduces feedback overhead by up to 95% compared to the DFT codebook. The proposed LASSO regression method also maintains robustness under varying noise levels, particularly in low SNR regions. Furthermore, an off-grid refinement scheme is introduced to enhance accuracy especially when the codebook sampling is coarse, improving reconstruction accuracy by 69.4%.

Paper number 19:
Title: Investigating self-supervised features for expressive, multilingual voice conversion
Authors: Álvaro Martín-Cortinas, Daniel Sáez-Trigueros, Grzegorz Beringer, Iván Vallés-Pérez, Roberto Barra-Chicote, Biel Tura-Vecino, Adam Gabryś, Piotr Bilinski, Thomas Merritt, Jaime Lorenzo-Trueba
Abstract: Voice conversion (VC) systems are widely used for several applications, from speaker anonymisation to personalised speech synthesis. Supervised approaches learn a mapping between different speakers using parallel data, which is expensive to produce. Unsupervised approaches are typically trained to reconstruct the input signal, which is composed of the content and the speaker information. Disentangling these components is a challenge and often leads to speaker leakage or prosodic information removal. In this paper, we explore voice conversion by leveraging the potential of self-supervised learning (SSL). A combination of the latent representations of SSL models, concatenated with speaker embeddings, is fed to a vocoder which is trained to reconstruct the input. Zero-shot voice conversion results show that this approach allows to keep the prosody and content of the source speaker while matching the speaker similarity of a VC system based on phonetic posteriorgrams (PPGs).

Paper number 20:
Title: Multi-Active RIS-Assisted THz Cell-Free Systems: Spectral and Energy Efficiency Tradeoff
Authors: Mario R. Camana, Zaid Abdullah, Carla E. Garcia, Chandan Kumar Sheemar, Eva Lagunas, Symeon Chatzinotas
Abstract: Reconfigurable intelligent surfaces (RISs) and cell-free massive multiple-input multiple-output (CF-mMIMO) are effective solutions for mitigating large path loss and inter-cell interference in terahertz (THz) systems. However, passive RISs are notably limited from double-fading attenuation, motivating the use of active RISs with power amplification to improve signal strength. In this paper, we investigate a multi-active RIS-aided wideband CF-mMIMO system for THz communications, considering low-resolution digital-to-analog converters (DACs) to optimize the spectral efficiency (SE)-energy efficiency (EE) tradeoff by adjusting precoding vectors and reflection coefficient response of the RISs, subject to power and minimum desirable per-user rate constraints. This leads to a highly complex and non-convex, multi-objective and fractional optimization problem. To solve it, we propose a tailored quadratic transformation to manage the fractional form. This allows decomposition into two subproblems, which are iteratively solved via a successive convex approximation algorithm to optimize the precoding vectors and active RIS reflection coefficients until convergence. Numerical results demonstrate that the proposed active RIS-aided CF-mMIMO system effectively addresses propagation loss and limited scattering in THz communication, achieving superior EE and SE compared to conventional passive RIS across diverse scenarios. Furthermore, the integration of low-resolution DACs shows significant improvement in EE while preserving satisfactory communication performance.

Paper number 21:
Title: SemCSINet: A Semantic-Aware CSI Feedback Network in Massive MIMO Systems
Authors: Ruonan Ren, Jianhua Mo, Meixia Tao
Abstract: Massive multiple-input multiple-output (MIMO) technology is a key enabler of modern wireless communication systems, which demand accurate downlink channel state information (CSI) for optimal performance. Although deep learning (DL) has shown great potential in improving CSI feedback, most existing approaches fail to exploit the semantic relationship between CSI and other related channel metrics. In this paper, we propose SemCSINet, a semantic-aware Transformer-based framework that incorporates Channel Quality Indicator (CQI) into the CSI feedback process. By embedding CQI information and leveraging a joint coding-modulation (JCM) scheme, SemCSINet enables efficient, digital-friendly CSI feedback under noisy feedback channels. Experimental results on DeepMIMO datasets show that SemCSINet significantly outperforms conventional methods, particularly in scenarios with low signal-to-noise ratio (SNR) and low compression ratios (CRs), highlighting the effectiveness of semantic embedding in enhancing CSI reconstruction accuracy and system robustness.

Paper number 22:
Title: A spherical amplitude-phase formulation for 3-D adaptive line-of-sight (ALOS) guidance with USGES stability guarantees
Authors: Erlend M. Coates, Thor I. Fossen
Abstract: A recently proposed 3-D adaptive line-of-sight (ALOS) path-following algorithm addressed coupled motion dynamics of marine craft, aircraft, and uncrewed vehicles under environmental disturbances such as wind, waves, and ocean currents. Stability analysis established uniform semiglobal exponential stability (USGES) of the cross- and vertical-track errors using a body-velocity-based amplitude-phase representation of the North-East-Down (NED) kinematic differential equations. In this brief paper, we revisit the ALOS framework and introduce a novel spherical amplitude-phase representation. This formulation yields a more geometrically intuitive and physically observable description of the guidance errors and enables a significantly simplified stability proof. Unlike the previous model, which relied on a vertical crab angle derived from body-frame velocities, the new representation uses an alternative vertical crab angle and retains the USGES property. It also removes restrictive assumptions such as constant altitude/depth or zero horizontal crab angle, and remains valid for general 3-D maneuvers with nonzero roll, pitch, and flight-path angles.

Paper number 23:
Title: Non-contact Vital Signs Detection in Dynamic Environments
Authors: Shuai Sun, Chong-Xi Liang, Chengwei Ye, Huanzhen Zhang, Kangsheng Wang
Abstract: Accurate phase demodulation is critical for vital sign detection using millimeter-wave radar. However, in complex environments, time-varying DC offsets and phase imbalances can severely degrade demodulation performance. To address this, we propose a novel DC offset calibration method alongside a Hilbert and Differential Cross-Multiply (HADCM) demodulation algorithm. The approach estimates time-varying DC offsets from neighboring signal peaks and valleys, then employs both differential forms and Hilbert transforms of the I/Q channel signals to extract vital sign information. Simulation and experimental results demonstrate that the proposed method maintains robust performance under low signal-to-noise ratios. Compared to existing demodulation techniques, it offers more accurate signal recovery in challenging scenarios and effectively suppresses noise interference.

Paper number 24:
Title: On the Average Secrecy Performance of Satellite Networks in Short Packet Communication Systems
Authors: Ramin Hashemi, Graciela Corral Briones, Risto Wichman
Abstract: This paper investigates the secrecy performance of satellite networks in short packet communication systems under shadowed Rician fading (SRF). We derive a lower bound on the average achievable secrecy rate in the finite blocklength regime (FBL) and provide analytical insights into the impact of key secrecy-related performance indicators (KPIs). Monte Carlo simulations validate the theoretical framework, and demonstrate that increasing the blocklength and improving the legitimate receiver's signal-to-noise ratio (SNR) enhance secrecy, while a stronger eavesdropper degrades it. Additionally, we show that directional antenna patterns can effectively reduce information leakage and provide secure satellite communications in the short packet regime. These findings offer valuable guidance for designing secure and efficient satellite-based communication systems, particularly in IoT and space-based networks.

Paper number 25:
Title: An integrated language-vision foundation model for conversational diagnostics and triaging in primary eye care
Authors: Zhi Da Soh, Yang Bai, Kai Yu, Yang Zhou, Xiaofeng Lei, Sahil Thakur, Zann Lee, Lee Ching Linette Phang, Qingsheng Peng, Can Can Xue, Rachel Shujuan Chong, Quan V. Hoang, Lavanya Raghavan, Yih Chung Tham, Charumathi Sabanayagam, Wei-Chi Wu, Ming-Chih Ho, Jiangnan He, Preeti Gupta, Ecosse Lamoureux, Seang Mei Saw, Vinay Nangia, Songhomitra Panda-Jonas, Jie Xu, Ya Xing Wang, Xinxing Xu, Jost B. Jonas, Tien Yin Wong, Rick Siow Mong Goh, Yong Liu, Ching-Yu Cheng
Abstract: Current deep learning models are mostly task specific and lack a user-friendly interface to operate. We present Meta-EyeFM, a multi-function foundation model that integrates a large language model (LLM) with vision foundation models (VFMs) for ocular disease assessment. Meta-EyeFM leverages a routing mechanism to enable accurate task-specific analysis based on text queries. Using Low Rank Adaptation, we fine-tuned our VFMs to detect ocular and systemic diseases, differentiate ocular disease severity, and identify common ocular signs. The model achieved 100% accuracy in routing fundus images to appropriate VFMs, which achieved $\ge$ 82.2% accuracy in disease detection, $\ge$ 89% in severity differentiation, $\ge$ 76% in sign identification. Meta-EyeFM was 11% to 43% more accurate than Gemini-1.5-flash and ChatGPT-4o LMMs in detecting various eye diseases and comparable to an ophthalmologist. This system offers enhanced usability and diagnostic performance, making it a valuable decision support tool for primary eye care or an online LLM for fundus evaluation.

Paper number 26:
Title: GNCAF: A GNN-based Neighboring Context Aggregation Framework for Tertiary Lymphoid Structures Semantic Segmentation in WSI
Authors: Lei Su
Abstract: Tertiary lymphoid structures (TLS) are organized clusters of immune cells, whose maturity and area can be quantified in whole slide image (WSI) for various prognostic tasks. Existing methods for assessing these characteristics typically rely on cell proxy tasks and require additional post-processing steps. In this work, We focus on a novel task-TLS Semantic Segmentation (TLS-SS)-which segments both the regions and maturation stages of TLS in WSI in an end-to-end manner. Due to the extensive scale of WSI and patch-based segmentation strategies, TLS-SS necessitates integrating from neighboring patches to guide target patch (target) segmentation. Previous techniques often employ on multi-resolution approaches, constraining the capacity to leverage the broader neighboring context while tend to preserve coarse-grained information. To address this, we propose a GNN-based Neighboring Context Aggregation Framework (GNCAF), which progressively aggregates multi-hop neighboring context from the target and employs a self-attention mechanism to guide the segmentation of the target. GNCAF can be integrated with various segmentation models to enhance their ability to perceive contextual information outside of the patch. We build two TLS-SS datasets, called TCGA-COAD and INHOUSE-PAAD, and make the former (comprising 225 WSIs and 5041 TLSs) publicly available. Experiments on these datasets demonstrate the superiority of GNCAF, achieving a maximum of 22.08% and 26.57% improvement in mF1 and mIoU, respectively. Additionally, we also validate the task scalability of GNCAF on segmentation of lymph node metastases.

Paper number 27:
Title: On the Use of CVRP to Diagnose Faulty Elements in Antenna Arrays
Authors: Alejandro Antón Ruiz, John Kvarnstrand, Klas Arvidsson, Andrés Alayón Glazunov
Abstract: This paper investigates the application of Constrained-View Radiated Power (CVRP) for diagnosing phased array element failures, specifically focusing on on-off element failure. CVRP, similar to Partial Radiated Power (PRP), considers a specific Field-of-View (FoV) but normalizes it by the FoV area. The study explores CVRP's effectiveness in detecting failures in a 2x8 cosine element array under beam-steering conditions, accounting for random and depointing errors, angular resolution, and pattern rotation. Results indicate that CVRP can detect on-off failures based on angular resolution and error severity, under the assumption of reduced Total Radiated Power (TRP) with element failures. Additionally, CVRP is effective with partial far-field patterns, making it suitable for near-field, indirect far-field, and far-field measurement systems without requiring phase acquisition in the latter two.

Paper number 28:
Title: A Practical Approach to Generating First-Order Rician Channel Statistics in a RC plus CATR Chamber at mmWave
Authors: Alejandro Antón Ruiz, Samar Hosseinzadegan, John Kvarnstrand, Klas Arvidsson, Andrés Alayón Glazunov
Abstract: This paper explores a novel hybrid configuration integrating a Reverberation Chamber (RC) with a Compact Antenna Test Range (CATR) to achieve a controllable Rician K-factor. The focus is testing directive antennas in the lower FR2 frequency bands (24.25-29.5 GHz) for 5G and beyond wireless applications. The study meticulously evaluates 39 unique configurations, using a stationary horn antenna for consistent reference K-factor characterization, and considers variables like absorbers and CATR polarization. Results demonstrate that the K-factor can be effectively adjusted within the hybrid setup, maintaining substantial margins above the noise level across all configurations. Sample independence is confirmed for at least 600 samples in all cases. The Bootstrap Anderson-Darling goodness-of-fit test verifies that the data align with Rician or Rayleigh distributions. Analysis of total received power, stirred and unstirred power and frequency-dependent modeling reveals that power variables are inversely related to frequency, while the K-factor remains frequency-independent. The hybrid RC-CATR system achieves a wide range of frequency-averaged K-factors from -9.2 dB to 40.8 dB, with an average granularity of 1.3 dB. Notably, configurations using co-polarized CATR signals yield large K-factors, reduced system losses, and improved frequency stability, underscoring the system's efficacy for millimeter-wave over-the-air testing. This research offers a cost-efficient and repeatable method for generating complex Rician fading channels at mmWave frequencies, crucial for the effective OTA testing of advanced wireless devices.

Paper number 29:
Title: The Quadrature Gaussian Sum Filter and Smoother for Wiener Systems
Authors: Angel L. Cedeño, Rodrigo A. González, Juan C. Agüero
Abstract: Block-Oriented Nonlinear (BONL) models, particularly Wiener models, are widely used for their computational efficiency and practicality in modeling nonlinear behaviors in physical systems. Filtering and smoothing methods for Wiener systems, such as particle filters and Kalman-based techniques, often struggle with computational feasibility or accuracy. This work addresses these challenges by introducing a novel Gaussian Sum Filter for Wiener system state estimation that is built on a Gauss-Legendre quadrature approximation of the likelihood function associated with the output signal. In addition to filtering, a two-filter smoothing strategy is proposed, enabling accurate computation of smoothed state distributions at single and consecutive time instants. Numerical examples demonstrate the superiority of the proposed method in balancing accuracy and computational efficiency compared to traditional approaches, highlighting its benefits in control, state estimation and system identification, for Wiener systems.

Paper number 30:
Title: Max-Min Fairness in Stacked Intelligent Metasurface-Aided Rate Splitting Networks
Authors: Abdullah Quran, Shimaa Naser, Maryam Tariq, Omar Alhussein, Sami Muhaidat
Abstract: This paper investigates a downlink multiuser multiple-input single-output system that integrates rate-splitting multiple access (RSMA) with a stacked intelligent metasurface (SIM) to enable wave-domain beamforming. Unlike conventional digital beamforming, the proposed system leverages the programmable phase shifts of the SIM to perform beamforming entirely in the wave domain. In contrast to existing literature, this work introduces a fairness-centric SIM-RSMA design that shifts the emphasis from maximizing sum-rate to ensuring fair allocation of resources. In particular, we formulate a max-min rate optimization problem that jointly optimizes transmit power coefficients at the base station and SIM phase shifts. Given the non-convex nature of this problem, we develop an alternating optimization framework, where the power allocation is optimized through successive convex approximation and SIM beamforming is optimized using the Riemannian conjugate gradient method. Simulation results indicate that combining SIM with RSMA yields superior max-min performance compared to its integration with space division multiple access or non-orthogonal multiple access.

Paper number 31:
Title: Diffusion-assisted Model Predictive Control Optimization for Power System Real-Time Operation
Authors: Linna Xu, Yongli Zhu
Abstract: This paper presents a modified model predictive control (MPC) framework for real-time power system operation. The framework incorporates a diffusion model tailored for time series generation to enhance the accuracy of the load forecasting module used in the system operation. In the absence of explicit state transition law, a model-identification procedure is leveraged to derive the system dynamics, thereby eliminating a barrier when applying MPC to a renewables-dominated power system. Case study results on an industry park system and the IEEE 30-bus system demonstrate that using the diffusion model to augment the training dataset significantly improves load-forecasting accuracy, and the inferred system dynamics are applicable to the real-time grid operation with solar and wind.

Paper number 32:
Title: Short Wins Long: Short Codes with Language Model Semantic Correction Outperform Long Codes
Authors: Jiafu Hao, Chentao Yue, Hao Chang, Branka Vucetic, Yonghui Li
Abstract: This paper presents a novel semantic-enhanced decoding scheme for transmitting natural language sentences with multiple short block codes over noisy wireless channels. After ASCII source coding, the natural language sentence message is divided into segments, where each is encoded with short block channel codes independently before transmission. At the receiver, each short block of codewords is decoded in parallel, followed by a semantic error correction (SEC) model to reconstruct corrupted segments semantically. We design and train the SEC model based on Bidirectional and Auto-Regressive Transformers (BART). Simulations demonstrate that the proposed scheme can significantly outperform encoding the sentence with one conventional long LDPC code, in terms of block error rate (BLER), semantic metrics, and decoding latency. Finally, we proposed a semantic hybrid automatic repeat request (HARQ) scheme to further enhance the error performance, which selectively requests retransmission depends on semantic uncertainty.

Paper number 33:
Title: SAR-GTR: Attributed Scattering Information Guided SAR Graph Transformer Recognition Algorithm
Authors: Xuying Xiong, Xinyu Zhang, Weidong Jiang, Li Liu, Yongxiang Liu, Tianpeng Liu
Abstract: Utilizing electromagnetic scattering information for SAR data interpretation is currently a prominent research focus in the SAR interpretation domain. Graph Neural Networks (GNNs) can effectively integrate domain-specific physical knowledge and human prior knowledge, thereby alleviating challenges such as limited sample availability and poor generalization in SAR interpretation. In this study, we thoroughly investigate the electromagnetic inverse scattering information of single-channel SAR and re-examine the limitations of applying GNNs to SAR interpretation. We propose the SAR Graph Transformer Recognition Algorithm (SAR-GTR). SAR-GTR carefully considers the attributes and characteristics of different electromagnetic scattering parameters by distinguishing the mapping methods for discrete and continuous parameters, thereby avoiding information confusion and loss. Furthermore, the GTR combines GNNs with the Transformer mechanism and introduces an edge information enhancement channel to facilitate interactive learning of node and edge features, enabling the capture of robust and global structural characteristics of targets. Additionally, the GTR constructs a hierarchical topology-aware system through global node encoding and edge position encoding, fully exploiting the hierarchical structural information of targets. Finally, the effectiveness of the algorithm is validated using the ATRNet-STAR large-scale vehicle dataset.

Paper number 34:
Title: Towards Digital Twin in Flood Forecasting with Data Assimilation Satellite Earth Observations -- A Proof-of-Concept in the Alzette Catchment
Authors: Thanh Huy Nguyen, Sukriti Bhattacharya, Jefferson S. Wong, Yoanne Didry, Duc Long Phan, Thomas Tamisier, Patrick Matgen
Abstract: Floods pose significant risks to human lives, infrastructure, and the environment. Timely and accurate flood forecasting plays a pivotal role in mitigating these risks. This study presents a proof-of-concept for a Digital Twin framework aimed at improving flood forecasting in the Alzette Catchment, Luxembourg. The approach integrates satellite-based Earth observations, specifically Sentinel-1 flood probability maps, into a particle filter-based data assimilation (DA) process to enhance flood predictions. By combining the GloFAS global flood monitoring and GloFAS streamflow forecasts products with DA using a high-resolution LISFLOOD-FP hydrodynamic model, the Digital Twin can provide daily flood forecasts for up to 30 days with reduced prediction uncertainties. Using the 2021 flood event as a case study, we evaluate the performance of the Digital Twin in assimilating EO data to refine hydraulic model simulations and issue accurate forecasts. While some limitations, such as uncertainties in GloFAS discharge forecasts, remain large, the approach successfully improves forecast accuracy compared to open-loop simulations. Future developments will focus on constructing more adaptively the hazard catalog, and reducing inherent uncertainties related to GloFAS streamflow forecasts and Sentinel-1 flood maps, to further enhance predictive capability. The framework demonstrates potential for advancing real-time flood forecasting and strengthening flood resilience.

Paper number 35:
Title: A High-Efficiency Reconfigurable Bidirectional Array Antenna Based on Transmit-Reflect Switchable Metasurface
Authors: Fan Qin, Jinyang Bi, Jiao Ma, Chao Gu, Hailin Zhang, Wenchi Cheng, Steven Gao
Abstract: This paper proposes a reconfigurable bidirectional array antenna with high-efficiency radiations and flexible beam-switching capability by employing a novel transmit-reflect switchable metasurface (TRSM). To realize the electromagnetic (EM) wave transmitted or reflected manipulation, a dedicated transmit-reflect switch layer (TRSL) with periodically soldered PIN diodes is introduced between two transmitted metasurfaces. By switching ON/OFF the embedded diodes, the TRSL performs as a mesh-type ground layer or polarization-grid layer, exhibiting a reflect or transmit property to the incident wave respectively. Further, utilizing the above TRSM configuration in conjunction with a microstrip feed antenna, bidirectional radiations are obtained at the same frequency and polarization. To further reduce the number of PIN diodes and control complexity, an enhanced TRSM using a single diode to control two unit cells is also investigated, resulting in half PIN diodes reduction. Since the bidirectional beam-switching is achieved by only controlling PIN diodes integrated in the ground plane instead of directly acting on the radiation element, which reduces insertion loss and avoids phase quantization errors, the proposed antenna can maintain a high aperture efficiency. To verify this concept, a prototype was designed, fabricated, and measured, demonstrating a successful realization of backward and forward patterns with peak gains of 22.3 and 22.1 dBi, and aperture efficiencies of 47.2% and 43.8%. The 3-dB gain bandwidths of reflected and transmitted modes are 13.7% and 12.3%. This antenna has the advantages of high gain, high aperture efficiency, simple configuration, cost-effectiveness, and flexible and digital beam control.

Paper number 36:
Title: Extract the Best, Discard the Rest: CSI Feedback with Offline Large AI Models
Authors: Jialin Zhuang, Yafei Wang, Hongwei Hou, Yu Han, Wenjin Wang, Shi Jin, Jiangzhou Wang
Abstract: Large AI models (LAMs) have shown strong potential in wireless communication tasks, but their practical deployment remains hindered by latency and computational constraints. In this work, we focus on the challenge of integrating LAMs into channel state information (CSI) feedback for frequency-division duplex (FDD) massive multiple-intput multiple-output (MIMO) systems. To this end, we propose two offline frameworks, namely site-specific LAM-enhanced CSI feedback (SSLCF) and multi-scenario LAM-enhanced CSI feedback (MSLCF), that incorporate LAMs into the codebook-based CSI feedback paradigm without requiring real-time inference. Specifically, SSLCF generates a site-specific enhanced codebook through fine-tuning on locally collected CSI data, while MSLCF improves generalization by pre-generating a set of environment-aware codebooks. Both of these frameworks build upon the LAM with vision-based backbone, which is pre-trained on large-scale image datasets and fine-tuned with CSI data to generate customized codebooks. This resulting network named LVM4CF captures the structural similarity between CSI and image, allowing the LAM to refine codewords tailored to the specific environments. To optimize the codebook refinement capability of LVM4CF under both single- and dual-side deployment modes, we further propose corresponding training and inference algorithms. Simulation results show that our frameworks significantly outperform existing schemes in both reconstruction accuracy and system throughput, without introducing additional inference latency or computational overhead. These results also support the core design methodology of our proposed frameworks, extracting the best and discarding the rest, as a promising pathway for integrating LAMs into future wireless systems.

Paper number 37:
Title: Joint Optimization of User Association and Resource Allocation for Load Balancing With Multi-Level Fairness
Authors: Jonggyu Jang, Hyeonsu Lyu, David J. Love, Hyun Jong Yang
Abstract: User association, the problem of assigning each user device to a suitable base station, is increasingly crucial as wireless networks become denser and serve more users with diverse service demands. The joint optimization of user association and resource allocation (UARA) is a fundamental issue for future wireless networks, as it plays a pivotal role in enhancing overall network performance, user fairness, and resource efficiency. Given the latency-sensitive nature of emerging network applications, network management favors algorithms that are simple and computationally efficient rather than complex centralized approaches. Thus, distributed pricing-based strategies have gained prominence in the UARA literature, demonstrating practicality and effectiveness across various objective functions, e.g., sum-rate, proportional fairness, max-min fairness, and alpha-fairness. While the alpha-fairness frameworks allow for flexible adjustments between efficiency and fairness via a single parameter $\alpha$, existing works predominantly assume a homogeneous fairness context, assigning an identical $\alpha$ value to all users. Real-world networks, however, frequently require differentiated user prioritization due to varying application requirements and latency. To bridge this gap, we propose a novel heterogeneous alpha-fairness (HAF) objective function, assigning distinct {\alpha} values to different users, thereby providing enhanced control over the balance between throughput, fairness, and latency across the network. We present a distributed, pricing-based optimization approach utilizing an auxiliary variable framework and provide analytical proof of its convergence to an $\epsilon$-optimal solution, where the optimality gap $\epsilon$ decreases with the number of iterations.

Paper number 38:
Title: A portable diagnosis model for Keratoconus using a smartphone
Authors: Yifan Li, Myeongjun Kim, Yanjing Jin, Peter Ho, Jo Woon Chong
Abstract: Keratoconus (KC) is a progressive corneal disorder characterized by localized thinning and protrusion, leading to visual distortion. While Placido disc-based topography remains a standard in clinical diagnostics, its dependence on specialized equipment limits accessibility. In this paper, we propose a portable, smartphone-based diagnostic framework that captures corneal reflections of a Placido disc displayed on a phone screen and applies a two-stage detection pipeline, then validate on 3D-printed emulated eyeball models that simulate normal, moderate, and severe KC stages based on anterior chamber depth (ACD). The first step of the two-stage detection pipeline is classifying different stages of KC with features including height and width of extracted reflections using weighted support vector machine (WSVM). It achieves a maximum accuracy of 92.93%, and maintains over 90% accuracy across multiple smartphone models, including the Galaxy Z Flip 3, iPhone 15 Pro, and iPhone 16 Pro. For the second step, we visualize the KC-affected protrusion regions on the corneas with color maps based on inter-disc distance, that provides an intuitive representation of disease severity and localization. Moreover, we validate the ability of the extracted features to differentiate between KC stages with ANOVA and Omega Squared, with significant p-values (e.g., $p < 10^{-6}$) and large effect sizes ($\\omega^2$ up to 0.8398) among classes.

Paper number 39:
Title: Robust Indoor Localization via Conformal Methods and Variational Bayesian Adaptive Filtering
Authors: Zhiyi Zhou, Dongzhuo Liu, Songtao Guo, Yuanyuan Yang
Abstract: Indoor localization is critical for IoT applications, yet challenges such as non-Gaussian noise, environmental interference, and measurement outliers hinder the robustness of traditional methods. Existing approaches, including Kalman filtering and its variants, often rely on Gaussian assumptions or static thresholds, limiting adaptability in dynamic environments. This paper proposes a hierarchical robust framework integrating Variational Bayesian (VB) parameter learning, Huber M-estimation, and Conformal Outlier Detection (COD) to address these limitations. First, VB inference jointly estimates state and noise parameters, adapting to time-varying uncertainties. Second, Huber-based robust filtering suppresses mild outliers while preserving Gaussian efficiency. Third, COD provides statistical guarantees for outlier detection via dynamically calibrated thresholds, ensuring a user-controlled false alarm rate. Theoretically, we prove the Semi-positive Definiteness of Huber-based Kalman filtering covariance and the coverage of sliding window conformal prediction. Experiments on geomagnetic fingerprint datasets demonstrate significant improvements: fingerprint matching accuracy increases from 81.25% to 93.75%, and positioning errors decrease from 0.62-6.87 m to 0.03-0.35 m. Comparative studies further validate the framework's robustness, showing consistent performance gains under non-Gaussian noise and outlier conditions.

Paper number 40:
Title: Robust Beamforming Design for STAR-RIS Aided RSMA Network with Hardware Impairments
Authors: Ziyue Wang, Xiaoyan Ma, Xingyu Peng, Zheao Li, Jinyuan Liu, Yongliang Guan, Chau Yuen
Abstract: In this article, we investigate the robust beamforming design for a simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) aided downlink rate-splitting multiple access (RSMA) communication system, where both transceivers and STAR-RIS suffer from the impact of hardware impairments (HWI). A base station (BS) is deployed to transmit messages concurrently to multiple users, utilizing a STAR-RIS to improve communication quality and expand user coverage. We aim to maximize the achievable sum rate of the users while ensuring the constraints of transmit power, STAR-RIS coefficients, and the actual rate of the common stream for all users. To solve this challenging high-coupling and non-convexity problem, we adopt a fractional programming (FP)-based alternating optimization (AO) approach, where each sub-problem is addressed via semidefinite relaxation (SDR) and successive convex approximation (SCA) methods. Numerical results demonstrate that the proposed scheme outperforms other multiple access schemes and conventional passive RIS in terms of the achievable sum rate. Additionally, considering the HWI of the transceiver and STAR-RIS makes our algorithm more robust than when such considerations are not included.

Paper number 41:
Title: Joint Communication Scheduling and Resource Allocation for Distributed Edge Learning: Seamless Integration in Next-Generation Wireless Networks
Authors: Paul Zheng, Navid Keshtiarast, Pradyumna Kumar Bishoyi, Yao Zhu, Yulin Hu, Marina Petrova, Anke Schmeink
Abstract: Distributed edge learning (DL) is considered a cornerstone of intelligence enablers, since it allows for collaborative training without the necessity for local clients to share raw data with other parties, thereby preserving privacy and security. Integrating DL into the 6G networks requires a coexistence design with existing services such as high-bandwidth (HB) traffic like eMBB. Current designs in the literature mainly focus on communication round-wise designs that assume a rigid resource allocation throughout each communication round (CR). However, rigid resource allocation within a CR is a highly inefficient and inaccurate representation of the system's realistic behavior. This is due to the heterogeneous nature of the system, as clients inherently may need to access the network at different times. This work zooms into one arbitrary CR, and demonstrates the importance of considering a time-dependent resource sharing design with HB traffic. We first formulate a time-step-wise optimization problem to minimize the consumed time by DL within the CR while constrained by a DL energy budget. Due to its intractability, a session-based optimization problem is formulated assuming a CR lasts less than a large-scale coherence time. Some scheduling properties of such multi-server joint communication scheduling and resource allocation framework have been established. An iterative algorithm has been designed to solve such non-convex and non-block-separable-constrained problems. Simulation results confirm the importance of the efficient and accurate integration design proposed in this work.

Paper number 42:
Title: VIViT: Variable-Input Vision Transformer Framework for 3D MR Image Segmentation
Authors: Badhan Kumar Das, Ajay Singh, Gengyan Zhao, Han Liu, Thomas J. Re, Dorin Comaniciu, Eli Gibson, Andreas Maier
Abstract: Self-supervised pretrain techniques have been widely used to improve the downstream tasks' performance. However, real-world magnetic resonance (MR) studies usually consist of different sets of contrasts due to different acquisition protocols, which poses challenges for the current deep learning methods on large-scale pretrain and different downstream tasks with different input requirements, since these methods typically require a fixed set of input modalities or, contrasts. To address this challenge, we propose variable-input ViT (VIViT), a transformer-based framework designed for self-supervised pretraining and segmentation finetuning for variable contrasts in each study. With this ability, our approach can maximize the data availability in pretrain, and can transfer the learned knowledge from pretrain to downstream tasks despite variations in input requirements. We validate our method on brain infarct and brain tumor segmentation, where our method outperforms current CNN and ViT-based models with a mean Dice score of 0.624 and 0.883 respectively. These results highlight the efficacy of our design for better adaptability and performance on tasks with real-world heterogeneous MR data.

Paper number 43:
Title: A Survey of Deep Learning for Complex Speech Spectrograms
Authors: Yuying Xie, Zheng-Hua Tan
Abstract: Recent advancements in deep learning have significantly impacted the field of speech signal processing, particularly in the analysis and manipulation of complex spectrograms. This survey provides a comprehensive overview of the state-of-the-art techniques leveraging deep neural networks for processing complex spectrograms, which encapsulate both magnitude and phase information. We begin by introducing complex spectrograms and their associated features for various speech processing tasks. Next, we explore the key components and architectures of complex-valued neural networks, which are specifically designed to handle complex-valued data and have been applied for complex spectrogram processing. We then discuss various training strategies and loss functions tailored for training neural networks to process and model complex spectrograms. The survey further examines key applications, including phase retrieval, speech enhancement, and speech separation, where deep learning has achieved significant progress by leveraging complex spectrograms or their derived feature representations. Additionally, we examine the intersection of complex spectrograms with generative models. This survey aims to serve as a valuable resource for researchers and practitioners in the field of speech signal processing and complex-valued neural networks.

Paper number 44:
Title: Granite-speech: open-source speech-aware LLMs with strong English ASR capabilities
Authors: George Saon, Avihu Dekel, Alexander Brooks, Tohru Nagano, Abraham Daniels, Aharon Satt, Ashish Mittal, Brian Kingsbury, David Haws, Edmilson Morais, Gakuto Kurata, Hagai Aronowitz, Ibrahim Ibrahim, Jeff Kuo, Kate Soule, Luis Lastras, Masayuki Suzuki, Ron Hoory, Samuel Thomas, Sashi Novitasari, Takashi Fukuda, Vishal Sunder, Xiaodong Cui, Zvi Kons
Abstract: Granite-speech LLMs are compact and efficient speech language models specifically designed for English ASR and automatic speech translation (AST). The models were trained by modality aligning the 2B and 8B parameter variants of granite-3.3-instruct to speech on publicly available open-source corpora containing audio inputs and text targets consisting of either human transcripts for ASR or automatically generated translations for AST. Comprehensive benchmarking shows that on English ASR, which was our primary focus, they outperform several competitors' models that were trained on orders of magnitude more proprietary data, and they keep pace on English-to-X AST for major European languages, Japanese, and Chinese. The speech-specific components are: a conformer acoustic encoder using block attention and self-conditioning trained with connectionist temporal classification, a windowed query-transformer speech modality adapter used to do temporal downsampling of the acoustic embeddings and map them to the LLM text embedding space, and LoRA adapters to further fine-tune the text LLM. Granite-speech-3.3 operates in two modes: in speech mode, it performs ASR and AST by activating the encoder, projector, and LoRA adapters; in text mode, it calls the underlying granite-3.3-instruct model directly (without LoRA), essentially preserving all the text LLM capabilities and safety. Both models are freely available on HuggingFace (this https URL and this https URL) and can be used for both research and commercial purposes under a permissive Apache 2.0 license.

Paper number 45:
Title: Optimal Trajectory Planning with Collision Avoidance for Autonomous Vehicle Maneuvering
Authors: Jason Zalev
Abstract: To perform autonomous driving maneuvers, such as parallel or perpendicular parking, a vehicle requires continual speed and steering adjustments to follow a generated path. In consequence, the path's quality is a limiting factor of the vehicle maneuver's performance. While most path planning approaches include finding a collision-free route, optimal trajectory planning involves solving the best transition from initial to final states, minimizing the action over all paths permitted by a kinematic model. Here we propose a novel method based on sequential convex optimization, which permits flexible and efficient optimal trajectory generation. The objective is to achieve the fastest time, shortest distance, and fewest number of path segments to satisfy motion requirements, while avoiding sensor blind-spots. In our approach, vehicle kinematics are represented by a discretized Dubins model. To avoid collisions, each waypoint is constrained by linear inequalities representing closest distance of obstacles to a polygon specifying the vehicle's extent. To promote smooth and valid trajectories, the solved kinematic state and control variables are constrained and regularized by penalty terms in the model's cost function, which enforces physical restrictions including limits for steering angle, acceleration and speed. In this paper, we analyze trajectories obtained for several parking scenarios. Results demonstrate efficient and collision-free motion generated by the proposed technique.

Paper number 46:
Title: Load-independent Metrics for Benchmarking Force Controllers
Authors: Victor Shime, Elisa G. Vergamini, Cícero Zanette, Leonardo F. dos Santos, Lucca Maitan, Andrea Calanca, Thiago Boaventura
Abstract: Torque-controlled actuators are critical components in mechatronic systems that closely interact with their environment, such as legged robots, collaborative manipulators, and exoskeletons. The performance and stability of these actuators depend not only on controller design and system dynamics but also significantly on load characteristics, which may include interactions with humans or unstructured environments. This load dependence highlights the need for frameworks that properly assess and compare torque controllers independent of specific loading conditions. In this short paper, we concisely present a modeling approach that captures the impact of load on the closed-loop dynamics of torque-controlled systems. Based on this model, we propose new methods and quantitative metrics, including the Passivity Index Interval, which blends passivity and small-gain theory to offer a less conservative measure of coupled stability than passivity alone. These metrics can be used alongside traditional control performance indicators, such as settling time and bandwidth, to provide a more comprehensive characterization of torque-controlled systems. We demonstrate the application of the proposed metrics through experimental comparisons of linear actuator force controllers.

Paper number 47:
Title: 3GPP-Compliant Radar Cross Section Characterization of Indoor Factory Targets
Authors: Ali Waqar Azim, Ahmad Bazzi, Roberto Bomfin, Marwa Chafii
Abstract: The following paper presents a systematic 3rd Generation Partnership Project (3GPP)-compliant characterization of radar cross section (RCS) for indoor factory (InF) objects, including small and mid-sized unmanned aerial vehicles (UAVs), robotic arms, and automated guided vehicles (AGVs). Through measurements in the 25-28 GHz range, we validate the 3GPP standardized log-normal distribution model for RCS for above-mentioned target objects. The 3GPP-complaint RCS parameters obtained for the small-sized UAV are in close agreement (<1 dB deviation) with 3GPP agreed values. The mid-sized UAVs exhibit higher reflectivity compared to the small-sized UAV due to enhanced specular components attributed to material and lithium-ion battery packs. The robotic arm exhibits dynamic RCS behavior due to mechanical articulation, whereas UAVs show clear size-dependent reflectivity patterns in AGVs. Our findings provide empirical validation for RCS characterization for integrated sensing and communication channel modeling in InF environments.

Paper number 48:
Title: GNN-based Precoder Design and Fine-tuning for Cell-free Massive MIMO with Real-world CSI
Authors: Tianzheng Miao, Thomas Feys, Gilles Callebaut, Jarne Van Mulders, Emanuele Peschiera, Md Arifur Rahman, François Rottenberg
Abstract: Cell-free massive MIMO (CF-mMIMO) has emerged as a promising paradigm for delivering uniformly high-quality coverage in future wireless networks. To address the inherent challenges of precoding in such distributed systems, recent studies have explored the use of graph neural network (GNN)-based methods, using their powerful representation capabilities. However, these approaches have predominantly been trained and validated on synthetic datasets, leaving their generalizability to real-world propagation environments largely unverified. In this work, we initially pre-train the GNN using simulated channel state information (CSI) data, which incorporates standard propagation models and small-scale Rayleigh fading. Subsequently, we finetune the model on real-world CSI measurements collected from a physical testbed equipped with distributed access points (APs). To balance the retention of pre-trained features with adaptation to real-world conditions, we adopt a layer-freezing strategy during fine-tuning, wherein several GNN layers are frozen and only the later layers remain trainable. Numerical results demonstrate that the fine-tuned GNN significantly outperforms the pre-trained model, achieving an approximate 8.2 bits per channel use gain at 20 dB signal-to-noise ratio (SNR), corresponding to a 15.7 % improvement. These findings highlight the critical role of transfer learning and underscore the potential of GNN-based precoding techniques to effectively generalize from synthetic to real-world wireless environments.

Paper number 49:
Title: A General Approach of Automated Environment Design for Learning the Optimal Power Flow
Authors: Thomas Wolgast, Astrid Nieße
Abstract: Reinforcement learning (RL) algorithms are increasingly used to solve the optimal power flow (OPF) problem. Yet, the question of how to design RL environments to maximize training performance remains unanswered, both for the OPF and the general case. We propose a general approach for automated RL environment design by utilizing multi-objective optimization. For that, we use the hyperparameter optimization (HPO) framework, which allows the reuse of existing HPO algorithms and methods. On five OPF benchmark problems, we demonstrate that our automated design approach consistently outperforms a manually created baseline environment design. Further, we use statistical analyses to determine which environment design decisions are especially important for performance, resulting in multiple novel insights on how RL-OPF environments should be designed. Finally, we discuss the risk of overfitting the environment to the utilized RL algorithm. To the best of our knowledge, this is the first general approach for automated RL environment design.

Paper number 50:
Title: Revenue Optimization in Video Caching Networks with Privacy-Preserving Demand Predictions
Authors: Yijing Zhang, Ferdous Pervej, Andreas F. Molisch
Abstract: Performance of video streaming, which accounts for most of the traffic in wireless communication, can be significantly improved by caching popular videos at the wireless edge. Determining the cache content that optimizes performance (defined via a revenue function) is thus an important task, and prediction of the future demands based on past history can make this process much more efficient. However, since practical video caching networks involve various parties (e.g., users, isp, and csp) that do not wish to reveal information such as past history to each other, privacy-preserving solutions are required. Motivated by this, we propose a proactive caching method based on users' privacy-preserving multi-slot future demand predictions -- obtained from a trained Transformer -- to optimize revenue. Specifically, we first use a privacy-preserving fl algorithm to train a Transformer to predict multi-slot future demands of the users. However, prediction accuracy is not perfect and decreases the farther into the future the prediction is done. We model the impact of prediction errors invoking the file popularities, based on which we formulate a long-term system revenue optimization to make the cache placement decisions. As the formulated problem is NP-hard, we use a greedy algorithm to efficiently obtain an approximate solution. Simulation results validate that (i) the fl solution achieves results close to the centralized (non-privacy-preserving) solution and (ii) optimization of revenue may provide different solutions than the classical chr criterion.

Paper number 51:
Title: TSLFormer: A Lightweight Transformer Model for Turkish Sign Language Recognition Using Skeletal Landmarks
Authors: Kutay Ertürk, Furkan Altınışık, İrem Sarıaltın, Ömer Nezih Gerek
Abstract: This study presents TSLFormer, a light and robust word-level Turkish Sign Language (TSL) recognition model that treats sign gestures as ordered, string-like language. Instead of using raw RGB or depth videos, our method only works with 3D joint positions - articulation points - extracted using Google's Mediapipe library, which focuses on the hand and torso skeletal locations. This creates efficient input dimensionality reduction while preserving important semantic gesture information. Our approach revisits sign language recognition as sequence-to-sequence translation, inspired by the linguistic nature of sign languages and the success of transformers in natural language processing. Since TSLFormer uses the self-attention mechanism, it effectively captures temporal co-occurrence within gesture sequences and highlights meaningful motion patterns as words unfold. Evaluated on the AUTSL dataset with over 36,000 samples and 227 different words, TSLFormer achieves competitive performance with minimal computational cost. These results show that joint-based input is sufficient for enabling real-time, mobile, and assistive communication systems for hearing-impaired individuals.

Paper number 52:
Title: VoI-Driven Joint Optimization of Control and Communication in Vehicular Digital Twin Network
Authors: Lei Lei, Kan Zheng, Jie Mei, Xuemin (Sherman)Shen
Abstract: The vision of sixth-generation (6G) wireless networks paves the way for the seamless integration of digital twins into vehicular networks, giving rise to a Vehicular Digital Twin Network (VDTN). The large amount of computing resources as well as the massive amount of spatial-temporal data in Digital Twin (DT) domain can be utilized to enhance the communication and control performance of Internet of Vehicle (IoV) systems. In this article, we first propose the architecture of VDTN, emphasizing key modules that center on functions related to the joint optimization of control and communication. We then delve into the intricacies of the multitimescale decision process inherent in joint optimization in VDTN, specifically investigating the dynamic interplay between control and communication. To facilitate the joint optimization, we define two Value of Information (VoI) concepts rooted in control performance. Subsequently, utilizing VoI as a bridge between control and communication, we introduce a novel joint optimization framework, which involves iterative processing of two Deep Reinforcement Learning (DRL) modules corresponding to control and communication to derive the optimal policy. Finally, we conduct simulations of the proposed framework applied to a platoon scenario to demonstrate its effectiveness in ensu

Paper number 53:
Title: Channel Fingerprint Construction for Massive MIMO: A Deep Conditional Generative Approach
Authors: Zhenzhou Jin, Li You, Xudong Li, Zhen Gao, Yuanwei Liu, Xiang-Gen Xia, Xiqi Gao
Abstract: Accurate channel state information (CSI) acquisition for massive multiple-input multiple-output (MIMO) systems is essential for future mobile communication networks. Channel fingerprint (CF), also referred to as channel knowledge map, is a key enabler for intelligent environment-aware communication and can facilitate CSI acquisition. However, due to the cost limitations of practical sensing nodes and test vehicles, the resulting CF is typically coarse-grained, making it insufficient for wireless transceiver design. In this work, we introduce the concept of CF twins and design a conditional generative diffusion model (CGDM) with strong implicit prior learning capabilities as the computational core of the CF twin to establish the connection between coarse- and fine-grained CFs. Specifically, we employ a variational inference technique to derive the evidence lower bound (ELBO) for the log-marginal distribution of the observed fine-grained CF conditioned on the coarse-grained CF, enabling the CGDM to learn the complicated distribution of the target data. During the denoising neural network optimization, the coarse-grained CF is introduced as side information to accurately guide the conditioned generation of the CGDM. To make the proposed CGDM lightweight, we further leverage the additivity of network layers and introduce a one-shot pruning approach along with a multi-objective knowledge distillation technique. Experimental results show that the proposed approach exhibits significant improvement in reconstruction performance compared to the baselines. Additionally, zero-shot testing on reconstruction tasks with different magnification factors further demonstrates the scalability and generalization ability of the proposed approach.

Paper number 54:
Title: EnvCDiff: Joint Refinement of Environmental Information and Channel Fingerprints via Conditional Generative Diffusion Model
Authors: Zhenzhou Jin, Li You, Xiang-Gen Xia, Xiqi Gao
Abstract: The paradigm shift from environment-unaware communication to intelligent environment-aware communication is expected to facilitate the acquisition of channel state information for future wireless communications. Channel Fingerprint (CF), as an emerging enabling technology for environment-aware communication, provides channel-related knowledge for potential locations within the target communication area. However, due to the limited availability of practical devices for sensing environmental information and measuring channel-related knowledge, most of the acquired environmental information and CF are coarse-grained, insufficient to guide the design of wireless transmissions. To address this, this paper proposes a deep conditional generative learning approach, namely a customized conditional generative diffusion model (CDiff). The proposed CDiff simultaneously refines environmental information and CF, reconstructing a fine-grained CF that incorporates environmental information, referred to as EnvCF, from its coarse-grained counterpart. Experimental results show that the proposed approach significantly improves the performance of EnvCF construction compared to the baselines.

Paper number 55:
Title: An Ultra-Sub-Wavelength Microwave Polarization Switch Implemented with Directed Surface Acoustic Waves in a Magnonic Crystal
Authors: Raisa Fabiha, Erdem Topsakal, Supriyo Bandyopadhyay
Abstract: The ability to switch the polarization of a transmitted electromagnetic wave from vertical to horizontal, or vice versa, is of great technological interest because of its many applications in long distance communication. Binary bits can be encoded in two orthogonal polarizations and transmitted securely from point to point. Polarization switches, however, are usually much larger than the wavelength of the electromagnetic wave. Consequently, most research in this area has focused on the optical regime where the wavelength is relatively short (~1 micron), so that the switch being much larger than the wavelength is not too inconvenient. However, this changes in the microwave regime where the wavelength is much larger (typically > 1 cm). That makes a microwave ultra-sub-wavelength polarization switch very attractive. Here, we report such a switch made of an array of magnetostrictive nanomagnets (~100 nm lateral dimension) deposited on a piezoelectric substrate to make an "artificial magnonic crystal". A surface acoustic wave (SAW) launched in the substrate with suitable electrodes excites spin waves in the nanomagnets via phonon-magnon coupling, resulting in radiation of electromagnetic waves via magnon-photon coupling. The polarization of the beam radiated in a given direction at a given frequency can be rotated through ~90 degrees by changing the direction of SAW propagation in the substrate to implement the polarization switch.

Paper number 56:
Title: Mobile Jamming Mitigation in 5G Networks: A MUSIC-Based Adaptive Beamforming Approach
Authors: Olivia Holguin, Rachel Donati, Seyed bagher Hashemi Natanzi, Bo Tang
Abstract: Mobile jammers pose a critical threat to 5G networks, particularly in military communications. We propose an intelligent anti-jamming framework that integrates Multiple Signal Classification (MUSIC) for high-resolution Direction-of-Arrival (DoA) estimation, Minimum Variance Distortionless Response (MVDR) beamforming for adaptive interference suppression, and machine learning (ML) to enhance DoA prediction for mobile jammers. Extensive simulations in a realistic highway scenario demonstrate that our hybrid approach achieves an average Signal-to-Noise Ratio (SNR) improvement of 9.58 dB (maximum 11.08 dB) and up to 99.8% DoA estimation accuracy. The framework's computational efficiency and adaptability to dynamic jammer mobility patterns outperform conventional anti-jamming techniques, making it a robust solution for securing 5G communications in contested environments.

Paper number 57:
Title: QubitLens: An Interactive Learning Tool for Quantum State Tomography
Authors: Mohammad Aamir Sohail, R. Ranga Sudharshan, S. Sandeep Pradhan, Arvind Rao
Abstract: Quantum state tomography is a fundamental task in quantum computing, involving the reconstruction of an unknown quantum state from measurement outcomes. Although essential, it is typically introduced at the graduate level due to its reliance on advanced concepts such as the density matrix formalism, tensor product structures, and partial trace operations. This complexity often creates a barrier for students and early learners. In this work, we introduce QubitLens, an interactive visualization tool designed to make quantum state tomography more accessible and intuitive. QubitLens leverages maximum likelihood estimation (MLE), a classical statistical method, to estimate pure quantum states from projective measurement outcomes in the X, Y, and Z bases. The tool emphasizes conceptual clarity through visual representations, including Bloch sphere plots of true and reconstructed qubit states, bar charts comparing parameter estimates, and fidelity gauges that quantify reconstruction accuracy. QubitLens offers a hands-on approach to learning quantum tomography without requiring deep prior knowledge of density matrices or optimization theory. The tool supports both single- and multi-qubit systems and is intended to bridge the gap between theory and practice in quantum computing education.

Paper number 58:
Title: Intelligent Polarforming Antenna Enhanced Sensing and Communication: Modeling and Optimization
Authors: Xiaodan Shao, Rui Zhang, Haibo Zhou, Qijun Jiang, Conghao Zhou, Weihua Zhuang, Xuemin Shen
Abstract: In this paper, we propose a novel intelligent polarforming antenna (IPA) to achieve cost-effective wireless sensing and communication. Specifically, the IPA can enable polarforming by adaptively controlling the antenna's polarization electrically as well as its position/rotation mechanically, so as to effectively exploit polarization and spatial diversity to reconfigure wireless channels for improving sensing and communication performance. We study an IPA-enhanced integrated sensing and communication (ISAC) system that utilizes user location sensing to facilitate communication between an IPA-equipped base station (BS) and IPA-equipped users. First, we model the IPA channel in terms of transceiver antenna polarforming vectors and antenna positions/rotations. We then propose a two-timescale ISAC protocol, where in the slow timescale, user localization is first performed, followed by the optimization of the BS antennas' positions and rotations based on the sensed user locations; subsequently, in the fast timescale, transceiver polarforming is adapted to cater to the instantaneous channel state information (CSI), with the optimized BS antennas' positions and rotations. We propose a new polarforming-based user localization method that uses a structured time-domain pattern of pilot-polarforming vectors to extract the common stable components in the IPA channel across different polarizations based on the parallel factor (PARAFAC) tensor model. Moreover, we maximize the achievable average sum-rate of users by jointly optimizing the fast-timescale transceiver polarforming, including phase shifts and amplitude variations, along with the slow-timescale antenna rotations and positions at the BS. Simulation results validate the effectiveness of polarforming-based localization algorithm and demonstrate the performance advantages of polarforming, antenna placement, and their joint design.

Paper number 59:
Title: Fréchet Power-Scenario Distance: A Metric for Evaluating Generative AI Models across Multiple Time-Scales in Smart Grids
Authors: Yuting Cai, Shaohuai Liu, Chao Tian, Le Xie
Abstract: Generative artificial intelligence (AI) models in smart grids have advanced significantly in recent years due to their ability to generate large amounts of synthetic data, which would otherwise be difficult to obtain in the real world due to confidentiality constraints. A key challenge in utilizing such synthetic data is how to assess the data quality produced from such generative models. Traditional Euclidean distance-based metrics only reflect pair-wise relations between two individual samples, and could fail in evaluating quality differences between groups of synthetic datasets. In this work, we propose a novel metric based on the Fréchet Distance (FD) estimated between two datasets in a learned feature space. The proposed method evaluates the quality of generation from a distributional perspective. Empirical results demonstrate the superiority of the proposed metric across timescales and models, enhancing the reliability of data-driven decision-making in smart grid operations.

Paper number 60:
Title: Fast Text-to-Audio Generation with Adversarial Post-Training
Authors: Zachary Novack, Zach Evans, Zack Zukowski, Josiah Taylor, CJ Carr, Julian Parker, Adnan Al-Sinan, Gian Marco Iodice, Julian McAuley, Taylor Berg-Kirkpatrick, Jordi Pons
Abstract: Text-to-audio systems, while increasingly performant, are slow at inference time, thus making their latency unpractical for many creative applications. We present Adversarial Relativistic-Contrastive (ARC) post-training, the first adversarial acceleration algorithm for diffusion/flow models not based on distillation. While past adversarial post-training methods have struggled to compare against their expensive distillation counterparts, ARC post-training is a simple procedure that (1) extends a recent relativistic adversarial formulation to diffusion/flow post-training and (2) combines it with a novel contrastive discriminator objective to encourage better prompt adherence. We pair ARC post-training with a number optimizations to Stable Audio Open and build a model capable of generating $\approx$12s of 44.1kHz stereo audio in $\approx$75ms on an H100, and $\approx$7s on a mobile edge-device, the fastest text-to-audio model to our knowledge.

Paper number 61:
Title: A Tightly Coupled IMU-Based Motion Capture Approach for Estimating Multibody Kinematics and Kinetics
Authors: Hassan Osman, Daan de Kanter, Jelle Boelens, Manon Kok, Ajay Seth
Abstract: Inertial Measurement Units (IMUs) enable portable, multibody motion capture (MoCap) in diverse environments beyond the laboratory, making them a practical choice for diagnosing mobility disorders and supporting rehabilitation in clinical or home settings. However, challenges associated with IMU measurements, including magnetic distortions and drift errors, complicate their broader use for MoCap. In this work, we propose a tightly coupled motion capture approach that directly integrates IMU measurements with multibody dynamic models via an Iterated Extended Kalman Filter (IEKF) to simultaneously estimate the system's kinematics and kinetics. By enforcing kinematic and kinetic properties and utilizing only accelerometer and gyroscope data, our method improves IMU-based state estimation accuracy. Our approach is designed to allow for incorporating additional sensor data, such as optical MoCap measurements and joint torque readings, to further enhance estimation accuracy. We validated our approach using highly accurate ground truth data from a 3 Degree of Freedom (DoF) pendulum and a 6 DoF Kuka robot. We demonstrate a maximum Root Mean Square Difference (RMSD) in the pendulum's computed joint angles of 3.75 degrees compared to optical MoCap Inverse Kinematics (IK), which serves as the gold standard in the absence of internal encoders. For the Kuka robot, we observe a maximum joint angle RMSD of 3.24 degrees compared to the Kuka's internal encoders, while the maximum joint angle RMSD of the optical MoCap IK compared to the encoders was 1.16 degrees. Additionally, we report a maximum joint torque RMSD of 2 Nm in the pendulum compared to optical MoCap Inverse Dynamics (ID), and 3.73 Nm in the Kuka robot relative to its internal torque sensors.

Paper number 62:
Title: Not that Groove: Zero-Shot Symbolic Music Editing
Authors: Li Zhang
Abstract: Most work in AI music generation focused on audio, which has seen limited use in the music production industry due to its rigidity. To maximize flexibility while assuming only textual instructions from producers, we are among the first to tackle symbolic music editing. We circumvent the known challenge of lack of labeled data by proving that LLMs with zero-shot prompting can effectively edit drum grooves. The recipe of success is a creatively designed format that interfaces LLMs and music, while we facilitate evaluation by providing an evaluation dataset with annotated unit tests that highly aligns with musicians' judgment.

Paper number 63:
Title: Unveiling the Best Practices for Applying Speech Foundation Models to Speech Intelligibility Prediction for Hearing-Impaired People
Authors: Haoshuai Zhou, Boxuan Cao, Changgeng Mo, Linkai Li, Shan Xiang Wang
Abstract: Speech foundation models (SFMs) have demonstrated strong performance across a variety of downstream tasks, including speech intelligibility prediction for hearing-impaired people (SIP-HI). However, optimizing SFMs for SIP-HI has been insufficiently explored. In this paper, we conduct a comprehensive study to identify key design factors affecting SIP-HI performance with 5 SFMs, focusing on encoder layer selection, prediction head architecture, and ensemble configurations. Our findings show that, contrary to traditional use-all-layers methods, selecting a single encoder layer yields better results. Additionally, temporal modeling is crucial for effective prediction heads. We also demonstrate that ensembling multiple SFMs improves performance, with stronger individual models providing greater benefit. Finally, we explore the relationship between key SFM attributes and their impact on SIP-HI performance. Our study offers practical insights into effectively adapting SFMs for speech intelligibility prediction for hearing-impaired populations.

Paper number 64:
Title: Rethink Repeatable Measures of Robot Performance with Statistical Query
Authors: Bowen Weng, Linda Capito, Guillermo A. Castillo, Dylan Khor
Abstract: For a general standardized testing algorithm designed to evaluate a specific aspect of a robot's performance, several key expectations are commonly imposed. Beyond accuracy (i.e., closeness to a typically unknown ground-truth reference) and efficiency (i.e., feasibility within acceptable testing costs and equipment constraints), one particularly important attribute is repeatability. Repeatability refers to the ability to consistently obtain the same testing outcome when similar testing algorithms are executed on the same subject robot by different stakeholders, across different times or locations. However, achieving repeatable testing has become increasingly challenging as the components involved grow more complex, intelligent, diverse, and, most importantly, stochastic. While related efforts have addressed repeatability at ethical, hardware, and procedural levels, this study focuses specifically on repeatable testing at the algorithmic level. Specifically, we target the well-adopted class of testing algorithms in standardized evaluation: statistical query (SQ) algorithms (i.e., algorithms that estimate the expected value of a bounded function over a distribution using sampled data). We propose a lightweight, parameterized, and adaptive modification applicable to any SQ routine, whether based on Monte Carlo sampling, importance sampling, or adaptive importance sampling, that makes it provably repeatable, with guaranteed bounds on both accuracy and efficiency. We demonstrate the effectiveness of the proposed approach across three representative scenarios: (i) established and widely adopted standardized testing of manipulators, (ii) emerging intelligent testing algorithms for operational risk assessment in automated vehicles, and (iii) developing use cases involving command tracking performance evaluation of humanoid robots in locomotion tasks.

Paper number 65:
Title: Constrained Factor Graph Optimization for Robust Networked Pedestrian Inertial Navigation
Authors: Yingjie Hu, Wang Hu
Abstract: This paper presents a novel constrained Factor Graph Optimization (FGO)-based approach for networked inertial navigation in pedestrian localization. To effectively mitigate the drift inherent in inertial navigation solutions, we incorporate kinematic constraints directly into the nonlinear optimization framework. Specifically, we utilize equality constraints, such as Zero-Velocity Updates (ZUPTs), and inequality constraints representing the maximum allowable distance between body-mounted Inertial Measurement Units (IMUs) based on human anatomical limitations. While equality constraints are straightforwardly integrated as error factors, inequality constraints cannot be explicitly represented in standard FGO formulations. To address this, we introduce a differentiable softmax-based penalty term in the FGO cost function to enforce inequality constraints smoothly and robustly. The proposed constrained FGO approach leverages temporal correlations across multiple epochs, resulting in optimal state trajectory estimates while consistently maintaining constraint satisfaction. Experimental results confirm that our method outperforms conventional Kalman filter approaches, demonstrating its effectiveness and robustness for pedestrian navigation.

Paper number 66:
Title: Ultra Lowrate Image Compression with Semantic Residual Coding and Compression-aware Diffusion
Authors: Anle Ke, Xu Zhang, Tong Chen, Ming Lu, Chao Zhou, Jiawen Gu, Zhan Ma
Abstract: Existing multimodal large model-based image compression frameworks often rely on a fragmented integration of semantic retrieval, latent compression, and generative models, resulting in suboptimal performance in both reconstruction fidelity and coding efficiency. To address these challenges, we propose a residual-guided ultra lowrate image compression named ResULIC, which incorporates residual signals into both semantic retrieval and the diffusion-based generation process. Specifically, we introduce Semantic Residual Coding (SRC) to capture the semantic disparity between the original image and its compressed latent representation. A perceptual fidelity optimizer is further applied for superior reconstruction quality. Additionally, we present the Compression-aware Diffusion Model (CDM), which establishes an optimal alignment between bitrates and diffusion time steps, improving compression-reconstruction synergy. Extensive experiments demonstrate the effectiveness of ResULIC, achieving superior objective and subjective performance compared to state-of-the-art diffusion-based methods with - 80.7%, -66.3% BD-rate saving in terms of LPIPS and FID. Project page is available at https: //njuvision.this http URL.

Paper number 67:
Title: M3G: Multi-Granular Gesture Generator for Audio-Driven Full-Body Human Motion Synthesis
Authors: Zhizhuo Yin, Yuk Hang Tsui, Pan Hui
Abstract: Generating full-body human gestures encompassing face, body, hands, and global movements from audio is a valuable yet challenging task in virtual avatar creation. Previous systems focused on tokenizing the human gestures framewisely and predicting the tokens of each frame from the input audio. However, one observation is that the number of frames required for a complete expressive human gesture, defined as granularity, varies among different human gesture patterns. Existing systems fail to model these gesture patterns due to the fixed granularity of their gesture tokens. To solve this problem, we propose a novel framework named Multi-Granular Gesture Generator (M3G) for audio-driven holistic gesture generation. In M3G, we propose a novel Multi-Granular VQ-VAE (MGVQ-VAE) to tokenize motion patterns and reconstruct motion sequences from different temporal granularities. Subsequently, we proposed a multi-granular token predictor that extracts multi-granular information from audio and predicts the corresponding motion tokens. Then M3G reconstructs the human gestures from the predicted tokens using the MGVQ-VAE. Both objective and subjective experiments demonstrate that our proposed M3G framework outperforms the state-of-the-art methods in terms of generating natural and expressive full-body human gestures.

Paper number 68:
Title: AI-Driven Digital Twins: Optimizing 5G/6G Network Slicing with NTNs
Authors: Afan Ali, Huseyin Arslan
Abstract: Network slicing in 5G/6G Non-Terrestrial Network (NTN) is confronted with mobility and traffic variability. An artificial intelligence (AI)-based digital twin (DT) architecture with deep reinforcement learning (DRL) using Deep deterministic policy gradient (DDPG) is proposed for dynamic optimization of resource allocation. DT virtualizes network states to enable predictive analysis, while DRL changes bandwidth for eMBB slice. Simulations show a 25\% latency reduction compared to static methods, with enhanced resource utilization. This scalable solution supports 5G/6G NTN applications like disaster recovery and urban blockage.

Paper number 69:
Title: Fast Contact Detection via Fusion of Joint and Inertial Sensors for Parallel Robots in Human-Robot Collaboration
Authors: Aran Mohammad, Jan Piosik, Dustin Lehmann, Thomas Seel, Moritz Schappler
Abstract: Fast contact detection is crucial for safe human-robot collaboration. Observers based on proprioceptive information can be used for contact detection but have first-order error dynamics, which results in delays. Sensor fusion based on inertial measurement units (IMUs) consisting of accelerometers and gyroscopes is advantageous for reducing delays. The acceleration estimation enables the direct calculation of external forces. For serial robots, the installation of multiple accelerometers and gyroscopes is required for dynamics modeling since the joint coordinates are the minimal coordinates. Alternatively, parallel robots (PRs) offer the potential to use only one IMU on the end-effector platform, which already presents the minimal coordinates of the PR. This work introduces a sensor-fusion method for contact detection using encoders and only one low-cost, consumer-grade IMU for a PR. The end-effector accelerations are estimated by an extended Kalman filter and incorporated into the dynamics to calculate external forces. In real-world experiments with a planar PR, we demonstrate that this approach reduces the detection duration by up to 50% compared to a momentum observer and enables the collision and clamping detection within 3-39ms.

Paper number 70:
Title: Lorentzian-Constrained Holographic Beamforming Optimization in Multi-user Networks with Dynamic Metasurface Antennas
Authors: Askin Altinoklu, Leila Musavian
Abstract: Dynamic metasurface antennas (DMAs) are promising alternatives to fully digital (FD) architectures, enabling hybrid beamforming via low-cost reconfigurable metasurfaces. In DMAs, holographic beamforming is achieved through tunable elements by Lorentzian-constrained holography (LCH), significantly reducing the need for radio-frequency (RF) chains and analog circuitry. However, the Lorentzian constraints and limited RF chains introduce a trade-off between reduced system complexity and beamforming performance, especially in dense network scenarios. This paper addresses resource allocation in multi-user multiple-input-single-output (MISO) networks under the Signal-to-Interference-plus-Noise Ratio (SINR) constraints, aiming to minimize total transmit power. We propose a holographic beamforming algorithm based on the Generalized Method of Lorentzian-Constrained Holography (GMLCH), which optimizes DMA weights, yielding flexibility for using various LCH techniques to tackle the aforementioned trade-offs. Building upon GMLCH, we further propose a new algorithm, Adaptive Radius Lorentzian Constrained Holography (ARLCH), which achieves optimization of DMA weights with additional degree of freedom in a greater optimization space, and provides lower transmitted power, while improving scalability for higher number of users. Numerical results show that ARLCH reduces power consumption by over 20% compared to benchmarks, with increasing effectiveness as the number of users grows.

Paper number 71:
Title: Distributionally Robust LQG with Kullback-Leibler Ambiguity Sets
Authors: Marta Fochesato, Lucia Falconi, Mattia Zorzi, Augusto Ferrante, John Lygeros
Abstract: The Linear Quadratic Gaussian (LQG) controller is known to be inherently fragile to model misspecifications often occurring in real-world situations. We consider discretetime partially observable stochastic linear systems and provide a robustification of the standard LQG against distributional uncertainties on the process and measurement noise. Our distributionally robust formulation specifies the admissible perturbations by defining a relative entropy based ambiguity set individually for each time step along a finite-horizon trajectory, and minimizes the worst-case cost across all admissible distributions. Notably, we prove that the optimal control policy is still linear, as in standard LQG, and we derive a computational scheme grounded on iterative best response that provably converges to the set of saddle points. Finally, we consider the case of endogenous uncertainty captured via decision-dependent ambiguity sets and we propose an approximation scheme based on dynamic programming.

Paper number 72:
Title: Continuous World Coverage Path Planning for Fixed-Wing UAVs using Deep Reinforcement Learning
Authors: Mirco Theile, Andres R. Zapata Rodriguez, Marco Caccamo, Alberto L. Sangiovanni-Vincentelli
Abstract: Unmanned Aerial Vehicle (UAV) Coverage Path Planning (CPP) is critical for applications such as precision agriculture and search and rescue. While traditional methods rely on discrete grid-based representations, real-world UAV operations require power-efficient continuous motion planning. We formulate the UAV CPP problem in a continuous environment, minimizing power consumption while ensuring complete coverage. Our approach models the environment with variable-size axis-aligned rectangles and UAV motion with curvature-constrained Bézier curves. We train a reinforcement learning agent using an action-mapping-based Soft Actor-Critic (AM-SAC) algorithm employing a self-adaptive curriculum. Experiments on both procedurally generated and hand-crafted scenarios demonstrate the effectiveness of our method in learning energy-efficient coverage strategies.

Paper number 73:
Title: Low-complexity Detection for Noncoherent Massive MIMO Communications
Authors: Marc Vilà-Insa, Jaume Riba
Abstract: This work studies a point-to-point MIMO uplink in which user equipment transmits data to a base station equipped with a massive array. Signal detection is noncoherent and fading is assumed to follow the Weichselberger model. By exploiting the spatial stationarity of fading at the base station, a cyclostationary structure emerges naturally in the space-time representation, which suggests formulating the statistical properties of the received signal in the Karhunen-Loève domain. This allows the derivation of a low-complexity receiver that approximates maximum likelihood detection even for a moderate array size. The spectral analysis of the problem provides valuable insights on the design of space-time codewords.

Paper number 74:
Title: Dual-UAV-Enabled Secure Communication and Sensing for A2G-ISAC Systems with Maneuverable Jamming
Authors: Libiao Lou, Yuan Liu, Fotis Foukalas, Hongjiang Lei, Gaofeng Pan, Theodoros A. Tsiftsis, Hongwu Liu
Abstract: In this paper, we propose a dual-unmanned aerial vehicle (UAV)-enabled secure communication and sensing (SCS) scheme for an air-to-ground integrated sensing and communication (ISAC) system, in which a dual-functional source UAV and jamming UAV collaborate to enhance both the secure communication and target sensing performance. From a perspective of hybrid monostatitc-bistatic radar, the jamming UAV maneuvers to aid the source UAV to detect multiple ground targets by emitting artificial noise, meanwhile interfering with the ground eavesdropper. Residual interference is considered to reflect the effects of imperfect successive interference cancellation (SIC) on the receive signal-plus-interference-to-noise ratios, which results in a degraded system performance. To maximize the average secrecy rate (ASR), the dual-UAV trajectory and dual-UAV beamforming are jointly optimized subject to the transmit power budget, UAV maneuvering constraint, and sensing requirements. To tackle the highly complicated non-convex ASR maximization problem, the dual-UAV trajectory and dual-UAV beamforming are optimized for the secure communication (SC) purpose and the SCS purpose, sequentially. In the SC phase, a block coordinate descent algorithm is proposed to optimize the dual-UAV trajectory and dual-UAV beamforming iteratively, using the trust-region successive convex approximation (SCA) and semidefinite relaxation (SDR) techniques. Then, a weighted distance minimization problem is formulated to determine the dual-UAV maneuvering positions suitable for the SCS purpose, which is solved by a heuristic greedy algorithm, followed by the joint optimization of source beamforming and jamming beamforming.

Paper number 75:
Title: Synthesis of safety certificates for discrete-time uncertain systems via convex optimization
Authors: Marta Fochesato, Han Wang, Antonis Papachristodoulou, Paul Goulart
Abstract: We study the problem of co-designing control barrier functions and linear state feedback controllers for discrete-time linear systems affected by additive disturbances. For disturbances of bounded magnitude, we provide a semi-definite program whose feasibility implies the existence of a control law and a certificate ensuring safety in the infinite horizon with respect to the worst-case disturbance realization in the uncertainty set. For disturbances with unbounded support, we rely on martingale theory to derive a second semi-definite program whose feasibility provides probabilistic safety guarantees holding joint-in-time over a finite time horizon. We examine several extensions, including (i) encoding of different types of input constraints, (ii) robustification against distributional ambiguity around the true distribution, (iii) design of safety filters, and (iv) extension to general safety specifications such as obstacle avoidance.

Paper number 76:
Title: ReSurgSAM2: Referring Segment Anything in Surgical Video via Credible Long-term Tracking
Authors: Haofeng Liu, Mingqi Gao, Xuxiao Luo, Ziyue Wang, Guanyi Qin, Junde Wu, Yueming Jin
Abstract: Surgical scene segmentation is critical in computer-assisted surgery and is vital for enhancing surgical quality and patient outcomes. Recently, referring surgical segmentation is emerging, given its advantage of providing surgeons with an interactive experience to segment the target object. However, existing methods are limited by low efficiency and short-term tracking, hindering their applicability in complex real-world surgical scenarios. In this paper, we introduce ReSurgSAM2, a two-stage surgical referring segmentation framework that leverages Segment Anything Model 2 to perform text-referred target detection, followed by tracking with reliable initial frame identification and diversity-driven long-term memory. For the detection stage, we propose a cross-modal spatial-temporal Mamba to generate precise detection and segmentation results. Based on these results, our credible initial frame selection strategy identifies the reliable frame for the subsequent tracking. Upon selecting the initial frame, our method transitions to the tracking stage, where it incorporates a diversity-driven memory mechanism that maintains a credible and diverse memory bank, ensuring consistent long-term tracking. Extensive experiments demonstrate that ReSurgSAM2 achieves substantial improvements in accuracy and efficiency compared to existing methods, operating in real-time at 61.2 FPS. Our code and datasets will be available at this https URL.

Paper number 77:
Title: Communication-Efficient Distributed Online Nonconvex Optimization with Time-Varying Constraints
Authors: Kunpeng Zhang, Lei Xu, Xinlei Yi, Guanghui Wen, Ming Cao, Karl H. Johansson, Tianyou Chai, Tao Yang
Abstract: This paper considers distributed online nonconvex optimization with time-varying inequality constraints over a network of agents, where the nonconvex local loss and convex local constraint functions can vary arbitrarily across iterations, and the information of them is privately revealed to each agent at each iteration. For a uniformly jointly strongly connected time-varying directed graph, we propose two distributed bandit online primal--dual algorithm with compressed communication to efficiently utilize communication resources in the one-point and two-point bandit feedback settings, respectively. In nonconvex optimization, finding a globally optimal decision is often NP-hard. As a result, the standard regret metric used in online convex optimization becomes inapplicable. To measure the performance of the proposed algorithms, we use a network regret metric grounded in the first-order optimality condition associated with the variational inequality. We show that the compressed algorithms establish sublinear network regret and cumulative constraint violation bounds. Finally, a simulation example is presented to validate the theoretical results.

Paper number 78:
Title: MC-Swarm: Minimal-Communication Multi-Agent Trajectory Planning and Deadlock Resolution for Quadrotor Swarm
Authors: Yunwoo Lee, Jungwon Park
Abstract: For effective multi-agent trajectory planning, it is important to consider lightweight communication and its potential asynchrony. This paper presents a distributed trajectory planning algorithm for a quadrotor swarm that operates asynchronously and requires no communication except during the initial planning phase. Moreover, our algorithm guarantees no deadlock under asynchronous updates and absence of communication during flight. To effectively ensure these points, we build two main modules: coordination state updater and trajectory optimizer. The coordination state updater computes waypoints for each agent toward its goal and performs subgoal optimization while considering deadlocks, as well as safety constraints with respect to neighbor agents and obstacles. Then, the trajectory optimizer generates a trajectory that ensures collision avoidance even with the asynchronous planning updates of neighboring agents. We provide a theoretical guarantee of collision avoidance with deadlock resolution and evaluate the effectiveness of our method in complex simulation environments, including random forests and narrow-gap mazes. Additionally, to reduce the total mission time, we design a faster coordination state update using lightweight communication. Lastly, our approach is validated through extensive simulations and real-world experiments with cluttered environment scenarios.

Paper number 79:
Title: MINIMALIST: switched-capacitor circuits for efficient in-memory computation of gated recurrent units
Authors: Sebastian Billaudelle, Laura Kriener, Filippo Moro, Tristan Torchet, Melika Payvand
Abstract: Recurrent neural networks (RNNs) have been a long-standing candidate for processing of temporal sequence data, especially in memory-constrained systems that one may find in embedded edge computing environments. Recent advances in training paradigms have now inspired new generations of efficient RNNs. We introduce a streamlined and hardware-compatible architecture based on minimal gated recurrent units (GRUs), and an accompanying efficient mixed-signal hardware implementation of the model. The proposed design leverages switched-capacitor circuits not only for in-memory computation (IMC), but also for the gated state updates. The mixed-signal cores rely solely on commodity circuits consisting of metal capacitors, transmission gates, and a clocked comparator, thus greatly facilitating scaling and transfer to other technology nodes. We benchmark the performance of our architecture on time series data, introducing all constraints required for a direct mapping to the hardware system. The direct compatibility is verified in mixed-signal simulations, reproducing data recorded from the software-only network model.

Paper number 80:
Title: A Mamba-based Network for Semi-supervised Singing Melody Extraction Using Confidence Binary Regularization
Authors: Xiaoliang He, Kangjie Dong, Jingkai Cao, Shuai Yu, Wei Li, Yi Yu
Abstract: Singing melody extraction (SME) is a key task in the field of music information retrieval. However, existing methods are facing several limitations: firstly, prior models use transformers to capture the contextual dependencies, which requires quadratic computation resulting in low efficiency in the inference stage. Secondly, prior works typically rely on frequencysupervised methods to estimate the fundamental frequency (f0), which ignores that the musical performance is actually based on notes. Thirdly, transformers typically require large amounts of labeled data to achieve optimal performances, but the SME task lacks of sufficient annotated data. To address these issues, in this paper, we propose a mamba-based network, called SpectMamba, for semi-supervised singing melody extraction using confidence binary regularization. In particular, we begin by introducing vision mamba to achieve computational linear complexity. Then, we propose a novel note-f0 decoder that allows the model to better mimic the musical performance. Further, to alleviate the scarcity of the labeled data, we introduce a confidence binary regularization (CBR) module to leverage the unlabeled data by maximizing the probability of the correct classes. The proposed method is evaluated on several public datasets and the conducted experiments demonstrate the effectiveness of our proposed method.

Paper number 81:
Title: Three Tone Networks and a Tessellation
Authors: Jeffrey R. Boland, Lane P. Hughston
Abstract: We show that the Eulerian tonnetz, which associates three minor chords to each major chord and three major chords to each minor chord, can be represented by a bipartite graph with twelve white vertices signifying major chords and twelve black vertices signifying minor chords. This so-called Levi graph uniquely determines the combinatorial geometry of a certain remarkable configuration of twelve points and twelve lines in the real projective plane with the property that three points lie on each line and three lines pass through each point. Interesting features of the tonnetz, such as the existence of Cohn's four hexatonic cycles, crucial for the understanding of nineteenth-century voice leading and extended harmony, can be read off rather directly as properties of the configuration. We show that analogous tone networks can be constructed for pentatonic music and twelve-tone music.

Paper number 82:
Title: A Cooperative Statistical Approach for Abnormal Node Detection with Adversary Resistance
Authors: Yingying Huangfu, Tian Bai
Abstract: Distinguishing abnormal nodes from those with normal packet loss in clusters helps reduce the loss of clustered network resources. The detection performance of existing detection schemes is limited by the techniques to quantify node behaviors, and most schemes cannot avoid being misled by the falsified information. This paper presents a novel probabilistic abnormal node detection scheme CSD -- Cooperative Statistical Detection -- for accurate and efficient detection in the existence of falsified detection data in clustered networks. Specifically, employing the likelihood ratio test (LRT) based detection method to measure node forwarding behaviors, we propose a modified Z-score based falsification-resistant mechanism to filter out falsifications. We show that both the false alarm and missed detection probabilities can decrease exponentially if and only if the transmissions from the nodes falsifying the data are less than half of the total. Furthermore, the optimal threshold of the modified Z-score method is derived, which guarantees perfect detection of our CSD under any falsification strategy in the proposed detection model. Evaluation results validate the effectiveness, robustness, and superiority of our scheme compared to the state-of-the-art.

Paper number 83:
Title: Signal Temporal Logic Control Synthesis among Uncontrollable Dynamic Agents with Conformal Prediction
Authors: Xinyi Yu, Yiqi Zhao, Xiang Yin, Lars Lindemann
Abstract: The control of dynamical systems under temporal logic specifications among uncontrollable dynamic agents is challenging due to the agents' a-priori unknown behavior. Existing works have considered the problem where either all agents are controllable, the agent models are deterministic and known, or no safety guarantees are provided. We propose a predictive control synthesis framework that guarantees, with high probability, the satisfaction of signal temporal logic (STL) tasks that are defined over a controllable system in the presence of uncontrollable stochastic agents. We use trajectory predictors and conformal prediction to construct probabilistic prediction regions for each uncontrollable agent that are valid over multiple future time steps. Specifically, we construct a normalized prediction region over all agents and time steps to reduce conservatism and increase data efficiency. We then formulate a worst-case bilevel mixed integer program (MIP) that accounts for all agent realizations within the prediction region to obtain an open-loop controller that provably guarantee task satisfaction with high probability. To efficiently solve this bilevel MIP, we propose an equivalent MIP program based on KKT conditions of the original bilevel formulation. Building upon this, we design a closed-loop controller, where both recursive feasibility and task satisfaction can be guaranteed with high probability. We illustrate our control synthesis framework on two case studies.

Paper number 84:
Title: Using Few-Shot Learning to Classify Primary Lung Cancer and Other Malignancy with Lung Metastasis in Cytological Imaging via Endobronchial Ultrasound Procedures
Authors: Ching-Kai Lin, Di-Chun Wei, Yun-Chien Cheng
Abstract: This study presents a computer-aided diagnosis (CAD) system to assist early detection of lung metastases during endobronchial ultrasound (EBUS) procedures, significantly reducing follow-up time and enabling timely treatment. Due to limited cytology images and morphological similarities among cells, classifying lung metastases is challenging, and existing research rarely targets this issue this http URL overcome data scarcity and improve classification, the authors propose a few-shot learning model using a hybrid pretrained backbone with fine-grained classification and contrastive learning. Parameter-efficient fine-tuning on augmented support sets enhances generalization and transferability. The model achieved 49.59% accuracy, outperforming existing methods. With 20 image samples, accuracy improved to 55.48%, showing strong potential for identifying rare or novel cancer types in low-data clinical environments.

Paper number 85:
Title: Iterated Invariant Extended Kalman Filter (IterIEKF)
Authors: Sven Goffin, Axel Barrau, Silvère Bonnabel, Olivier Brüls, Pierre Sacré
Abstract: We study the mathematical properties of the Invariant Extended Kalman Filter (IEKF) when iterating on the measurement update step, following the principles of the well-known Iterated Extended Kalman Filter. This iterative variant of the IEKF (IterIEKF) systematically improves its accuracy through Gauss-Newton-based relinearization, and exhibits additional theoretical properties, particularly in the low-noise regime, that resemble those of the linear Kalman filter. We apply the proposed approach to the problem of estimating the extended pose of a crane payload using an inertial measurement unit. Our results suggest that the IterIEKF significantly outperforms the IEKF when measurements are highly accurate.

Paper number 86:
Title: A Prudent Framework for Understanding Risk-Awareness in Demand Response
Authors: Liudong Chen, Bolun Xu
Abstract: We show that risk-aware behaviors in demand response originate from superquadratic state-dependent cost functions and price uncertainty with skewed distributions. We obtain such results through developing a novel theoretical demand response framework that combines non-anticipatory multi-stage decision-making with superquadratic cost functions. We introduce the concept of prudent demand, defined by a positive third-order derivative of the cost function, which is the first principle for risk-averse behavior despite a risk-neutral objective. Our analysis establishes that future price uncertainty affects immediate consumption decisions, and the extent of this response scales proportionally with the skewness of the price distribution. We visualize our theoretical findings through numerical simulations and illustrate their practical implications using a real-world case study.

Paper number 87:
Title: Predictive control for nonlinear stochastic systems: Closed-loop guarantees with unbounded noise
Authors: Johannes Köhler, Melanie N. Zeilinger
Abstract: We present a stochastic model predictive control framework for nonlinear systems subject to unbounded process noise with closed-loop guarantees. First, we provide a conceptual shrinking-horizon framework that utilizes general probabilistic reachable sets and minimizes the expected cost. Then, we provide a tractable receding-horizon formulation that uses a nominal state to minimize a deterministic quadratic cost and satisfy tightened constraints. Our theoretical analysis demonstrates recursive feasibility, satisfaction of chance constraints, and bounds on the expected cost for the resulting closed-loop system. We provide a constructive design for probabilistic reachable sets of nonlinear continuously differentiable systems using stochastic contraction metrics and an assumed bound on the covariance matrices. Numerical simulations highlight the computational efficiency and theoretical guarantees of the proposed method. Overall, this paper provides a framework for computationally tractable stochastic predictive control with closed-loop guarantees for nonlinear systems with unbounded noise.

Paper number 88:
Title: Rydberg Atomic Quantum Receivers for Classical Wireless Communications and Sensing: Their Models and Performance
Authors: Tierui Gong, Jiaming Sun, Chau Yuen, Guangwei Hu, Yufei Zhao, Yong Liang Guan, Chong Meng Samson See, Mérouane Debbah, Lajos Hanzo
Abstract: The significant progress of quantum sensing technologies offer numerous radical solutions for measuring a multitude of physical quantities at an unprecedented precision. Among them, Rydberg atomic quantum receivers (RAQRs) emerge as an eminent solution for detecting the electric field of radio frequency (RF) signals, exhibiting great potential in assisting classical wireless communications and sensing. So far, most experimental studies have aimed for the proof of physical concepts to reveal its promise, while the practical signal model of RAQR-aided wireless communications and sensing remained under-explored. Furthermore, the performance of RAQR-based wireless receivers and their advantages over classical RF receivers have not been fully characterized. To fill these gaps, we introduce the RAQR to the wireless community by presenting an end-to-end reception scheme. We then develop a corresponding equivalent baseband signal model relying on a realistic reception flow. Our scheme and model provide explicit design guidance to RAQR-aided wireless systems. We next study the performance of RAQR-aided wireless systems based on our model, and compare them to classical RF receivers. The results show that the RAQR is capable of achieving a substantial received signal-to-noise ratio (SNR) gain of over $27$ decibel (dB) and $40$ dB in the photon shot limit regime and the standard quantum limit regime, respectively.

Paper number 89:
Title: NExT-LF: A Novel Operational Modal Analysis Method via Tangential Interpolation
Authors: Gabriele Dessena, Marco Civera, Ali Yousefi, Cecilia Surace
Abstract: Operational Modal Analysis (OMA) is vital for identifying modal parameters under real-world conditions, yet existing methods often face challenges with noise sensitivity and stability. This work introduces NExT-LF, a novel method that combines the well-known Natural Excitation Technique (NExT) with the Loewner Framework (LF). NExT enables the extraction of Impulse Response Functions (IRFs) from output-only vibration data, which are then converted into the frequency domain and used by LF to estimate modal parameters. The proposed method is validated through numerical and experimental case studies. In the numerical study of a 2D Euler-Bernoulli cantilever beam, NExT-LF provides results consistent with analytical solutions and those from standard methods, NExT with Eigensystem Realization Algorithm (NExT-ERA) and Stochastic Subspace Identification with Canonical Variate Analysis (SSI). Additionally, NExT-LF demonstrates superior noise robustness, reliably identifying stable modes across various noise levels where NExT-ERA fails. Experimental validation on the Sheraton Universal Hotel is the first OMA application to this structure, confirming NExT-LF as a robust and efficient method for output-only modal parameter identification.

Paper number 90:
Title: RadioLLM: Introducing Large Language Model into Cognitive Radio via Hybrid Prompt and Token Reprogrammings
Authors: Shuai Chen, Yong Zu, Zhixi Feng, Shuyuan Yang, Mengchang Li
Abstract: The growing scarcity of spectrum resources and rapid proliferation of wireless devices make efficient radio network management critical. While deep learning-enhanced Cognitive Radio Technology (CRT) provides promising solutions for tasks such as radio signal classification (RSC), denoising, and spectrum allocation, existing DL-based CRT frameworks are typically task-specific and lack scalability in diverse real-world applications. This limitation naturally leads to the exploration of Large Language Models (LLMs), whose exceptional cross-domain generalization capabilities offer new potential for advancing CRT. To bridge this gap, we propose RadioLLM, a novel framework that integrates Hybrid Prompt and Token Reprogramming (HPTR) for combining radio signal features with expert knowledge, and a Frequency-Attuned Fusion (FAF) module for enhanced high-frequency feature modeling. Extensive evaluations on multiple benchmark datasets demonstrate that RadioLLM achieves superior performance compared to existing baselines in the majority of testing scenarios.

Paper number 91:
Title: Estimation of Food Intake Quantity Using Inertial Signals from Smartwatches
Authors: Ioannis Levi, Konstantinos Kyritsis, Vasileios Papapanagiotou, Georgios Tsakiridis, Anastasios Delopoulos
Abstract: Accurate monitoring of eating behavior is crucial for managing obesity and eating disorders such as bulimia nervosa. At the same time, existing methods rely on multiple and/or specialized sensors, greatly harming adherence and ultimately, the quality and continuity of data. This paper introduces a novel approach for estimating the weight of a bite, from a commercial smartwatch. Our publicly-available dataset contains smartwatch inertial data from ten participants, with manually annotated start and end times of each bite along with their corresponding weights from a smart scale, under semi-controlled conditions. The proposed method combines extracted behavioral features such as the time required to load the utensil with food, with statistical features of inertial signals, that serve as input to a Support Vector Regression model to estimate bite weights. Under a leave-one-subject-out cross-validation scheme, our approach achieves a mean absolute error (MAE) of 3.99 grams per bite. To contextualize this performance, we introduce the improvement metric, that measures the relative MAE difference compared to a baseline model. Our method demonstrates a 17.41% improvement, while the adapted state-of-the art method shows a -28.89% performance against that same baseline. The results presented in this work establish the feasibility of extracting meaningful bite weight estimates from commercial smartwatch inertial sensors alone, laying the groundwork for future accessible, non-invasive dietary monitoring systems.

Paper number 92:
Title: Data-Driven Input-Output Control Barrier Functions
Authors: Mohammad Bajelani, Klaske van Heusden
Abstract: Control Barrier Functions (CBFs) offer a framework for ensuring set invariance and designing constrained control laws. However, crafting a valid CBF relies on system-specific assumptions and the availability of an accurate system model, underscoring the need for systematic data-driven synthesis methods. This paper introduces a data-driven approach to synthesizing a CBF for discrete-time LTI systems using only input-output measurements. The method begins by computing the maximal control invariant set using an input-output data-driven representation, eliminating the need for precise knowledge of the system's order and explicit state estimation. The proposed CBF is then systematically derived from this set, which can accommodate multiple input-output constraints. Furthermore, the proposed CBF is leveraged to develop a minimally invasive safety filter that ensures recursive feasibility with an adaptive decay rate. To improve clarity, we assume a noise-free dataset, though the method can be extended using data-driven reachability to capture noise effects and handle uncertainty. Finally, the effectiveness of the proposed method is demonstrated on an unknown time-delay system.

Paper number 93:
Title: Ptychographic Image Reconstruction from Limited Data via Score-Based Diffusion Models with Physics-Guidance
Authors: Refik Mert Cam, Junjing Deng, Rajkumar Kettimuthu, Mathew J. Cherukara, Tekin Bicer
Abstract: Ptychography is a data-intensive computational imaging technique that achieves high spatial resolution over large fields of view. The technique involves scanning a coherent beam across overlapping regions and recording diffraction patterns. Conventional reconstruction algorithms require substantial overlap, increasing data volume and experimental time, reaching PiB-scale experimental data and weeks to month-long data acquisition times. To address this, we propose a reconstruction method employing a physics-guided score-based diffusion model. Our approach trains a diffusion model on representative object images to learn an object distribution prior. During reconstruction, we modify the reverse diffusion process to enforce data consistency, guiding reverse diffusion toward a physically plausible solution. This method requires a single pretraining phase, allowing it to generalize across varying scan overlap ratios and positions. Our results demonstrate that the proposed method achieves high-fidelity reconstructions with only a 20% overlap, while the widely employed rPIE method requires a 62% overlap to achieve similar accuracy. This represents a significant reduction in data requirements, offering an alternative to conventional techniques.

Paper number 94:
Title: Parameter-Varying Feedforward Control: A Kernel-Based Learning Approach
Authors: Max van Haren, Lennart Blanken, Tom Oomen
Abstract: The increasing demands for high accuracy in mechatronic systems necessitate the incorporation of parameter variations in feedforward control. The aim of this paper is to develop a data-driven approach for direct learning of parameter-varying feedforward control to increase tracking performance. The developed approach is based on kernel-regularized function estimation in conjunction with iterative learning to directly learn parameter-varying feedforward control from data. This approach enables high tracking performance for feedforward control of linear parameter-varying dynamics, providing flexibility to varying reference tasks. The developed framework is validated on a benchmark industrial experimental setup featuring a belt-driven carriage.

Paper number 95:
Title: An Analysis of Data Transformation Effects on Segment Anything 2
Authors: Clayton Bromley, Alexander Moore, Amar Saini, Doug Poland, Carmen Carrano
Abstract: Video object segmentation (VOS) is a critical task in the development of video perception and understanding. The Segment-Anything Model 2 (SAM 2), released by Meta AI, is the current state-of-the-art architecture for end-to-end VOS. SAM 2 performs very well on both clean video data and augmented data, and completely intelligent video perception requires an understanding of how this architecture is capable of achieving such quality results. To better understand how each step within the SAM 2 architecture permits high-quality video segmentation, a variety of complex video transformations are passed through the architecture, and the impact at each stage of the process is measured. It is observed that each progressive stage enables the filtering of complex transformation noise and the emphasis of the object of interest. Contributions include the creation of complex transformation video datasets, an analysis of how each stage of the SAM 2 architecture interprets these transformations, and visualizations of segmented objects through each stage. By better understanding how each model structure impacts overall video understanding, VOS development can work to improve real-world applicability and performance tracking, localizing, and segmenting objects despite complex cluttered scenes and obscurations.

Paper number 96:
Title: GBT-SAM: Adapting a Foundational Deep Learning Model for Generalizable Brain Tumor Segmentation via Efficient Integration of Multi-Parametric MRI Data
Authors: Cecilia Diana-Albelda, Roberto Alcover-Couso, Álvaro García-Martín, Jesus Bescos, Marcos Escudero-Viñolo
Abstract: Gliomas are aggressive brain tumors that require accurate imaging-based diagnosis, with segmentation playing a critical role in evaluating morphology and treatment decisions. Manual delineation of gliomas is time-consuming and prone to variability, motivating the use of deep learning to improve consistency and alleviate clinical workload. However, existing methods often fail to fully exploit the information available in multi-parametric MRI (mp-MRI), particularly inter-slice contextual features, and typically require considerable computational resources while lacking robustness across tumor type variations. We present GBT-SAM, a parameter-efficient deep learning framework that adapts the Segment Anything Model (SAM), a large-scale vision model, to volumetric mp-MRI data. GBT-SAM reduces input complexity by selecting fewer than 2.6\% of slices per scan while incorporating all four MRI modalities, preserving essential tumor-related information with minimal cost. Furthermore, our model is trained by a two-step fine-tuning strategy that incorporates a depth-aware module to capture inter-slice correlations and lightweight adaptation layers, resulting in just 6.5M trainable parameters, which is the lowest among SAM-based approaches. GBT-SAM achieves a Dice Score of 93.54 on the BraTS Adult Glioma dataset and demonstrates robust performance on Meningioma, Pediatric Glioma, and Sub-Saharan Glioma datasets. These results highlight GBT-SAM's potential as a computationally efficient and domain-robust framework for brain tumor segmentation using mp-MRI. Our code and models are available at this https URL .

Paper number 97:
Title: Automatic quality control in multi-centric fetal brain MRI super-resolution reconstruction
Authors: Thomas Sanchez, Vladyslav Zalevskyi, Angeline Mihailov, Gerard Martí-Juan, Elisenda Eixarch, Andras Jakab, Vincent Dunet, Mériam Koob, Guillaume Auzias, Meritxell Bach Cuadra
Abstract: Quality control (QC) has long been considered essential to guarantee the reliability of neuroimaging studies. It is particularly important for fetal brain MRI, where acquisitions and image processing techniques are less standardized than in adult imaging. In this work, we focus on automated quality control of super-resolution reconstruction (SRR) volumes of fetal brain MRI, an important processing step where multiple stacks of thick 2D slices are registered together and combined to build a single, isotropic and artifact-free T2 weighted volume. We propose FetMRQC$_{SR}$, a machine-learning method that extracts more than 100 image quality metrics to predict image quality scores using a random forest model. This approach is well suited to a problem that is high dimensional, with highly heterogeneous data and small datasets. We validate FetMRQC$_{SR}$ in an out-of-domain (OOD) setting and report high performance (ROC AUC = 0.89), even when faced with data from an unknown site or SRR method. We also investigate failure cases and show that they occur in $45\%$ of the images due to ambiguous configurations for which the rating from the expert is arguable. These results are encouraging and illustrate how a non deep learning-based method like FetMRQC$_{SR}$ is well suited to this multifaceted problem. Our tool, along with all the code used to generate, train and evaluate the model are available at this https URL .

Paper number 98:
Title: Deep Representation Learning for Unsupervised Clustering of Myocardial Fiber Trajectories in Cardiac Diffusion Tensor Imaging
Authors: Mohini Anand, Xavier Tricoche
Abstract: Understanding the complex myocardial architecture is critical for diagnosing and treating heart disease. However, existing methods often struggle to accurately capture this intricate structure from Diffusion Tensor Imaging (DTI) data, particularly due to the lack of ground truth labels and the ambiguous, intertwined nature of fiber trajectories. We present a novel deep learning framework for unsupervised clustering of myocardial fibers, providing a data-driven approach to identifying distinct fiber bundles. We uniquely combine a Bidirectional Long Short-Term Memory network to capture local sequential information along fibers, with a Transformer autoencoder to learn global shape features, with pointwise incorporation of essential anatomical context. Clustering these representations using a density-based algorithm identifies 33 to 62 robust clusters, successfully capturing the subtle distinctions in fiber trajectories with varying levels of granularity. Our framework offers a new, flexible, and quantitative way to analyze myocardial structure, achieving a level of delineation that, to our knowledge, has not been previously achieved, with potential applications in improving surgical planning, characterizing disease-related remodeling, and ultimately, advancing personalized cardiac care.

Paper number 99:
Title: The Communication and Computation Trade-off in Wireless Semantic Communications
Authors: Xuyang Chen, Chong Huang, Gaojie Chen, Daquan Feng, Pei Xiao
Abstract: Semantic communications have emerged as a crucial research direction for future wireless communication networks. However, as wireless systems become increasingly complex, the demands for computation and communication resources in semantic communications continue to grow rapidly. This paper investigates the trade-off between computation and communication in wireless semantic communications, taking into consideration transmission task delay and performance constraints within the semantic communication framework. We propose a novel tradeoff metric to analyze the balance between computation and communication in semantic transmissions and employ the deep reinforcement learning (DRL) algorithm to minimize this metric, thereby reducing the cost associated with balancing computation and communication. Through simulations, we analyze the tradeoff between computation and communication and demonstrate the effectiveness of optimizing this trade-off metric.

Paper number 100:
Title: TVC: Tokenized Video Compression with Ultra-Low Bitrate
Authors: Lebin Zhou, Cihan Ruan, Nam Ling, Wei Wang, Wei Jiang
Abstract: Tokenized visual representations have shown great promise in image compression, yet their extension to video remains underexplored due to the challenges posed by complex temporal dynamics and stringent bitrate constraints. In this paper, we propose Tokenized Video Compression (TVC), the first token-based dual-stream video compression framework designed to operate effectively at ultra-low bitrates. TVC leverages the powerful Cosmos video tokenizer to extract both discrete and continuous token streams. The discrete tokens (i.e., code maps generated by FSQ) are partially masked using a strategic masking scheme, then compressed losslessly with a discrete checkerboard context model to reduce transmission overhead. The masked tokens are reconstructed by a decoder-only transformer with spatiotemporal token prediction. Meanwhile, the continuous tokens, produced via an autoencoder (AE), are quantized and compressed using a continuous checkerboard context model, providing complementary continuous information at ultra-low bitrate. At the Decoder side, both streams are fused using ControlNet, with multi-scale hierarchical integration to ensure high perceptual quality alongside strong fidelity in reconstruction. This work mitigates the long-standing skepticism about the practicality of tokenized video compression and opens up new avenues for semantics-aware, token-native video compression.

Paper number 101:
Title: An Overview of the Prospects and Challenges of Using Artificial Intelligence for Energy Management Systems in Microgrids
Authors: Noor ul Misbah Khanum, Hayssam Dahrouj, Ramesh C. Bansal, Hissam Mouayad Tawfik
Abstract: Microgrids have emerged as a pivotal solution in the quest for a sustainable and energy-efficient future. While microgrids offer numerous advantages, they are also prone to issues related to reliably forecasting renewable energy demand and production, protecting against cyberattacks, controlling operational costs, optimizing power flow, and regulating the performance of energy management systems (EMS). Tackling these energy management challenges is essential to facilitate microgrid applications and seamlessly incorporate renewable energy resources. Artificial intelligence (AI) has recently demonstrated immense potential for optimizing energy management in microgrids, providing efficient and reliable solutions. This paper highlights the combined benefits of enabling AI-based methodologies in the energy management systems of microgrids by examining the applicability and efficiency of AI-based EMS in achieving specific technical and economic objectives. The paper also points out several future research directions that promise to spearhead AI-driven EMS, namely the development of self-healing microgrids, integration with blockchain technology, use of Internet of things (IoT), and addressing interpretability, data privacy, scalability, and the prospects to generative AI in the context of future AI-based EMS.

Paper number 102:
Title: Ophora: A Large-Scale Data-Driven Text-Guided Ophthalmic Surgical Video Generation Model
Authors: Wei Li, Ming Hu, Guoan Wang, Lihao Liu, Kaijin Zhou, Junzhi Ning, Xin Guo, Zongyuan Ge, Lixu Gu, Junjun He
Abstract: In ophthalmic surgery, developing an AI system capable of interpreting surgical videos and predicting subsequent operations requires numerous ophthalmic surgical videos with high-quality annotations, which are difficult to collect due to privacy concerns and labor consumption. Text-guided video generation (T2V) emerges as a promising solution to overcome this issue by generating ophthalmic surgical videos based on surgeon instructions. In this paper, we present Ophora, a pioneering model that can generate ophthalmic surgical videos following natural language instructions. To construct Ophora, we first propose a Comprehensive Data Curation pipeline to convert narrative ophthalmic surgical videos into a large-scale, high-quality dataset comprising over 160K video-instruction pairs, Ophora-160K. Then, we propose a Progressive Video-Instruction Tuning scheme to transfer rich spatial-temporal knowledge from a T2V model pre-trained on natural video-text datasets for privacy-preserved ophthalmic surgical video generation based on Ophora-160K. Experiments on video quality evaluation via quantitative analysis and ophthalmologist feedback demonstrate that Ophora can generate realistic and reliable ophthalmic surgical videos based on surgeon instructions. We also validate the capability of Ophora for empowering downstream tasks of ophthalmic surgical workflow understanding. Code is available at this https URL.

Paper number 103:
Title: Towards Anytime Optical Flow Estimation with Event Cameras
Authors: Yaozu Ye, Hao Shi, Kailun Yang, Ze Wang, Xiaoting Yin, Lei Sun, Yaonan Wang, Kaiwei Wang
Abstract: Event cameras respond to changes in log-brightness at the millisecond level, making them ideal for optical flow estimation. However, existing datasets from event cameras provide only low frame rate ground truth for optical flow, limiting the research potential of event-driven optical flow. To address this challenge, we introduce a low-latency event representation, Unified Voxel Grid, and propose EVA-Flow, an EVent-based Anytime Flow estimation network to produce high-frame-rate event optical flow with only low-frame-rate optical flow ground truth for supervision. Furthermore, we propose the Rectified Flow Warp Loss (RFWL) for the unsupervised assessment of intermediate optical flow. A comprehensive variety of experiments on MVSEC, DESC, and our EVA-FlowSet demonstrates that EVA-Flow achieves competitive performance, super-low-latency (5ms), time-dense motion estimation (200Hz), and strong generalization. Our code will be available at this https URL.

Paper number 104:
Title: RT-GAN: Recurrent Temporal GAN for Adding Lightweight Temporal Consistency to Frame-Based Domain Translation Approaches
Authors: Shawn Mathew, Saad Nadeem, Alvin C. Goh, Arie Kaufman
Abstract: Fourteen million colonoscopies are performed annually just in the U.S. However, the videos from these colonoscopies are not saved due to storage constraints (each video from a high-definition colonoscope camera can be in tens of gigabytes). Instead, a few relevant individual frames are saved for documentation/reporting purposes and these are the frames on which most current colonoscopy AI models are trained on. While developing new unsupervised domain translation methods for colonoscopy (e.g. to translate between real optical and virtual/CT colonoscopy), it is thus typical to start with approaches that initially work for individual frames without temporal consistency. Once an individual-frame model has been finalized, additional contiguous frames are added with a modified deep learning architecture to train a new model from scratch for temporal consistency. This transition to temporally-consistent deep learning models, however, requires significantly more computational and memory resources for training. In this paper, we present a lightweight solution with a tunable temporal parameter, RT-GAN (Recurrent Temporal GAN), for adding temporal consistency to individual frame-based approaches that reduces training requirements by a factor of 5. We demonstrate the effectiveness of our approach on two challenging use cases in colonoscopy: haustral fold segmentation (indicative of missed surface) and realistic colonoscopy simulator video generation. We also release a first-of-its kind temporal dataset for colonoscopy for the above use cases. The datasets, accompanying code, and pretrained models will be made available on our Computational Endoscopy Platform GitHub (this https URL). The supplementary video is available at this https URL.

Paper number 105:
Title: Robust Quickest Change Detection in Non-Stationary Processes
Authors: Yingze Hou, Yousef Oleyaeimotlagh, Rahul Mishra, Hoda Bidkhori, Taposh Banerjee
Abstract: Optimal algorithms are developed for robust detection of changes in non-stationary processes. These are processes in which the distribution of the data after change varies with time. The decision-maker does not have access to precise information on the post-change distribution. It is shown that if the post-change non-stationary family has a distribution that is least favorable in a well-defined sense, then the algorithms designed using the least favorable distributions are robust and optimal. Non-stationary processes are encountered in public health monitoring and space and military applications. The robust algorithms are applied to real and simulated data to show their effectiveness.

Paper number 106:
Title: On the Impact of Uncertainty and Calibration on Likelihood-Ratio Membership Inference Attacks
Authors: Meiyi Zhu, Caili Guo, Chunyan Feng, Osvaldo Simeone
Abstract: In a membership inference attack (MIA), an attacker exploits the overconfidence exhibited by typical machine learning models to determine whether a specific data point was used to train a target model. In this paper, we analyze the performance of the likelihood ratio attack (LiRA) within an information-theoretical framework that allows the investigation of the impact of the aleatoric uncertainty in the true data generation process, of the epistemic uncertainty caused by a limited training data set, and of the calibration level of the target model. We compare three different settings, in which the attacker receives decreasingly informative feedback from the target model: confidence vector (CV) disclosure, in which the output probability vector is released; true label confidence (TLC) disclosure, in which only the probability assigned to the true label is made available by the model; and decision set (DS) disclosure, in which an adaptive prediction set is produced as in conformal prediction. We derive bounds on the advantage of an MIA adversary with the aim of offering insights into the impact of uncertainty and calibration on the effectiveness of MIAs. Simulation results demonstrate that the derived analytical bounds predict well the effectiveness of MIAs.

Paper number 107:
Title: Clinically inspired enhance Explainability and Interpretability of an AI-Tool for BCC diagnosis based on expert annotation
Authors: Iván Matas, Carmen Serrano, Francisca Silva, Amalia Serrano, Tomás Toledo-Pastrana, Begoña Acha
Abstract: An AI tool has been developed to provide interpretable support for the diagnosis of BCC via teledermatology, thus speeding up referrals and optimizing resource utilization. The interpretability is provided in two ways: on the one hand, the main BCC dermoscopic patterns are found in the image to justify the BCC/Non BCC classification. Secondly, based on the common visual XAI Grad-CAM, a clinically inspired visual explanation is developed where the relevant features for diagnosis are located. Since there is no established ground truth for BCC dermoscopic features, a standard reference is inferred from the diagnosis of four dermatologists using an Expectation Maximization (EM) based algorithm. The results demonstrate significant improvements in classification accuracy and interpretability, positioning this approach as a valuable tool for early BCC detection and referral to dermatologists. The BCC/non-BCC classification achieved an accuracy rate of 90%. For Clinically-inspired XAI results, the detection of BCC patterns useful to clinicians reaches 99% accuracy. As for the Clinically-inspired Visual XAI results, the mean of the Grad-CAM normalized value within the manually segmented clinical features is 0.57, while outside this region it is 0.16. This indicates that the model struggles to accurately identify the regions of the BCC patterns. These results prove the ability of the AI tool to provide a useful explanation.

Paper number 108:
Title: Consensus Building in Human-robot Co-learning via Bias Controlled Nonlinear Opinion Dynamics and Non-verbal Communication through Robotic Eyes
Authors: Rajul Kumar, Adam Bhatti, Ningshi Yao
Abstract: Consensus between humans and robots is crucial as robotic agents become more prevalent and deeply integrated into our daily lives. This integration presents both unprecedented opportunities and notable challenges for effective collaboration. However, the active guidance of human actions and their integration in co-learning processes, where humans and robots mutually learn from each other, remains under-explored. This article demonstrates how consensus between human and robot opinions can be established by modeling decision-making processes as non-linear opinion dynamics. We utilize dynamic bias as a control parameter to steer the robot's opinion toward consensus and employ visual cues via a robotic eye gaze to guide human decisions. These non-verbal cues communicate the robot's future intentions, gradually guiding human decisions to align with them. To design robot behavior for consensus, we integrate a human opinion observation algorithm with the robot's opinion formation, controlling its actions based on that formed opinion. Experiments with $51$ participants ($N=51$) in a two-choice decision-making task show that effective consensus and trust can be established in a human--robot co-learning setting by guiding human decisions through nonverbal robotic cues and using bias-controlled opinion dynamics to shape robot behavior. Finally, we provide detailed information on the perceived cognitive load and the behavior of robotic eyes based on user feedback and post-experiment interviews.

Paper number 109:
Title: A Classification Benchmark for Artificial Intelligence Detection of Laryngeal Cancer from Patient Voice
Authors: Mary Paterson, James Moor, Luisa Cutillo
Abstract: Cases of laryngeal cancer are predicted to rise significantly in the coming years. Current diagnostic pathways are inefficient, putting undue stress on both patients and the medical system. Artificial intelligence offers a promising solution by enabling non-invasive detection of laryngeal cancer from patient voice, which could help prioritise referrals more effectively. A major barrier in this field is the lack of reproducible methods. Our work addresses this challenge by introducing a benchmark suite comprising 36 models trained and evaluated on open-source datasets. These models classify patients with benign and malignant voice pathologies. All models are accessible in a public repository, providing a foundation for future research. We evaluate three algorithms and three audio feature sets, including both audio-only inputs and multimodal inputs incorporating demographic and symptom data. Our best model achieves a balanced accuracy of 83.7%, sensitivity of 84.0%, specificity of 83.3%, and AUROC of 91.8%.

Paper number 110:
Title: ImprovNet -- Generating Controllable Musical Improvisations with Iterative Corruption Refinement
Authors: Keshav Bhandari, Sungkyun Chang, Tongyu Lu, Fareza R. Enus, Louis B. Bradshaw, Dorien Herremans, Simon Colton
Abstract: Despite deep learning's remarkable advances in style transfer across various domains, generating controllable performance-level musical style transfer for complete symbolically represented musical works remains a challenging area of research. Much of this is owed to limited datasets, especially for genres such as jazz, and the lack of unified models that can handle multiple music generation tasks. This paper presents ImprovNet, a transformer-based architecture that generates expressive and controllable musical improvisations through a self-supervised corruption-refinement training strategy. The improvisational style transfer is aimed at making meaningful modifications to one or more musical elements - melody, harmony or rhythm of the original composition with respect to the target genre. ImprovNet unifies multiple capabilities within a single model: it can perform cross-genre and intra-genre improvisations, harmonize melodies with genre-specific styles, and execute short prompt continuation and infilling tasks. The model's iterative generation framework allows users to control the degree of style transfer and structural similarity to the original composition. Objective and subjective evaluations demonstrate ImprovNet's effectiveness in generating musically coherent improvisations while maintaining structural relationships with the original pieces. The model outperforms Anticipatory Music Transformer in short continuation and infilling tasks and successfully achieves recognizable genre conversion, with 79\% of participants correctly identifying jazz-style improvisations of classical pieces. Our code and demo page can be found at this https URL.

Paper number 111:
Title: Optimization-free Smooth Control Barrier Function for Polygonal Collision Avoidance
Authors: Shizhen Wu, Yongchun Fang, Ning Sun, Biao Lu, Xiao Liang, Yiming Zhao
Abstract: Polygonal collision avoidance (PCA) is short for the problem of collision avoidance between two polygons (i.e., polytopes in planar) that own their dynamic equations. This problem suffers the inherent difficulty in dealing with non-smooth boundaries and recently optimization-defined metrics, such as signed distance field (SDF) and its variants, have been proposed as control barrier functions (CBFs) to tackle PCA problems. In contrast, we propose an optimization-free smooth CBF method in this paper, which is computationally efficient and proved to be nonconservative. It is achieved by three main steps: a lower bound of SDF is expressed as a nested Boolean logic composition first, then its smooth approximation is established by applying the latest log-sum-exp method, after which a specified CBF-based safety filter is proposed to address this class of problems. To illustrate its wide applications, the optimization-free smooth CBF method is extended to solve distributed collision avoidance of two underactuated nonholonomic vehicles and drive an underactuated container crane to avoid a moving obstacle respectively, for which numerical simulations are also performed.

Paper number 112:
Title: UAV-VLRR: Vision-Language Informed NMPC for Rapid Response in UAV Search and Rescue
Authors: Yasheerah Yaqoot, Muhammad Ahsan Mustafa, Oleg Sautenkov, Artem Lykov, Valerii Serpiva, Dzmitry Tsetserukou
Abstract: Emergency search and rescue (SAR) operations often require rapid and precise target identification in complex environments where traditional manual drone control is inefficient. In order to address these scenarios, a rapid SAR system, UAV-VLRR (Vision-Language-Rapid-Response), is developed in this research. This system consists of two aspects: 1) A multimodal system which harnesses the power of Visual Language Model (VLM) and the natural language processing capabilities of ChatGPT-4o (LLM) for scene interpretation. 2) A non-linearmodel predictive control (NMPC) with built-in obstacle avoidance for rapid response by a drone to fly according to the output of the multimodal system. This work aims at improving response times in emergency SAR operations by providing a more intuitive and natural approach to the operator to plan the SAR mission while allowing the drone to carry out that mission in a rapid and safe manner. When tested, our approach was faster on an average by 33.75% when compared with an off-the-shelf autopilot and 54.6% when compared with a human pilot. Video of UAV-VLRR: this https URL

Paper number 113:
Title: Decadal analysis of sea surface temperature patterns, climatology, and anomalies in temperate coastal waters with Landsat-8 TIRS observations
Authors: Yiqing Guo, Nagur Cherukuru, Eric Lehmann, Xiubin Qi, Mark Doubelld, S. L. Kesav Unnithan, Ming Feng
Abstract: Sea surface temperature (SST) is a fundamental physical parameter characterising the thermal state of sea surface. Due to the intricate thermal interactions between land, sea, and atmosphere, the spatial gradients of SST in coastal waters often appear at finer spatial scales than those in open ocean waters. The Thermal Infrared Sensor (TIRS) onboard Landsat-8, with its 100-meter spatial resolution, offers a unique opportunity to uncover fine-scale coastal SST patterns that would otherwise be overlooked by coarser-resolution thermal sensors. In this study, we first analysed the spatiotemporal patterns of SST in South Australia's temperate coastal waters from 2014 to 2023 by developing an operational approach for SST retrieval from the Landsat-8 TIRS sensor. A buoy was deployed off the coast of Port Lincoln, South Australia, to validate the quality of SST retrievals. Then the daily baseline climatology of SST with 100 m resolution was constructed, which allowed for the detection and analysis of anomalous SST events. Our results suggest the following: (1) the satellite-derived SST data aligned well with the in-situ measured SST values; (2) the semi-enclosed, shallow regions of Upper Spencer Gulf and Upper St Vincent Gulf showed higher temperatures during summer and cooler temperatures during winter than waters closer to the open ocean, resulting in a higher seasonal variation in SST; (3) the near-shore shallow areas in Spencer Gulf and St Vincent Gulf, and regions surrounding Kangaroo Island, were identified to have a higher probability of SST anomalies compared to the rest of the study area; and (4) anomalous SST events were more likely to happen during the warm months than the cool months. We hope these findings would be helpful in supporting the fishing and aquaculture industries in the coastal waters of South Australia.

Paper number 114:
Title: SCAN-BEST: Sub-6GHz-Aided Near-field Beam Selection with Formal Reliability Guarantees
Authors: Weicao Deng, Binpu Shi, Min Li, Osvaldo Simeone
Abstract: As millimeter-wave (mmWave) MIMO systems adopt larger antenna arrays, near-field propagation becomes increasingly prominent, especially for users close to the transmitter. Traditional far-field beam training methods become inadequate, while near-field training faces the challenge of large codebooks due to the need to resolve both angular and distance domains. To reduce in-band training overhead, prior work has proposed to leverage the spatial-temporal congruence between sub-6 GHz (sub-6G) and mmWave channels to predict the best mmWave beam within a near-field codebook from sub-6G channel estimates. To cope with the uncertainty caused by sub-6G/mmWave differences, we introduce a novel Sub-6G Channel Aided Near-field BEam SelecTion (SCAN-BEST) framework that wraps around any beam predictor to produce candidate beam subset with formal suboptimality guarantees. The proposed SCAN-BEST builds on conformal risk control (CRC), and is calibrated offline using limited calibration data. Its performance guarantees apply even in the presence of statistical shifts between calibration and deployment. Numerical results validate the theoretical properties and efficiency of SCAN-BEST.

Paper number 115:
Title: High-Quality Spatial Reconstruction and Orthoimage Generation Using Efficient 2D Gaussian Splatting
Authors: Qian Wang, Zhihao Zhan, Jialei He, Zhituo Tu, Xiang Zhu, Jie Yuan
Abstract: Highly accurate geometric precision and dense image features characterize True Digital Orthophoto Maps (TDOMs), which are in great demand for applications such as urban planning, infrastructure management, and environmental this http URL TDOM generation methods need sophisticated processes, such as Digital Surface Models (DSM) and occlusion detection, which are computationally expensive and prone to this http URL work presents an alternative technique rooted in 2D Gaussian Splatting (2DGS), free of explicit DSM and occlusion detection. With depth map generation, spatial information for every pixel within the TDOM is retrieved and can reconstruct the scene with high precision. Divide-and-conquer strategy achieves excellent GS training and rendering with high-resolution TDOMs at a lower resource cost, which preserves higher quality of rendering on complex terrain and thin structure without a decrease in efficiency. Experimental results demonstrate the efficiency of large-scale scene reconstruction and high-precision terrain modeling. This approach provides accurate spatial data, which assists users in better planning and decision-making based on maps.

Paper number 116:
Title: Learning Phase Distortion with Selective State Space Models for Video Turbulence Mitigation
Authors: Xingguang Zhang, Nicholas Chimitt, Xijun Wang, Yu Yuan, Stanley H. Chan
Abstract: Atmospheric turbulence is a major source of image degradation in long-range imaging systems. Although numerous deep learning-based turbulence mitigation (TM) methods have been proposed, many are slow, memory-hungry, and do not generalize well. In the spatial domain, methods based on convolutional operators have a limited receptive field, so they cannot handle a large spatial dependency required by turbulence. In the temporal domain, methods relying on self-attention can, in theory, leverage the lucky effects of turbulence, but their quadratic complexity makes it difficult to scale to many frames. Traditional recurrent aggregation methods face parallelization challenges. In this paper, we present a new TM method based on two concepts: (1) A turbulence mitigation network based on the Selective State Space Model (MambaTM). MambaTM provides a global receptive field in each layer across spatial and temporal dimensions while maintaining linear computational complexity. (2) Learned Latent Phase Distortion (LPD). LPD guides the state space model. Unlike classical Zernike-based representations of phase distortion, the new LPD map uniquely captures the actual effects of turbulence, significantly improving the model's capability to estimate degradation by reducing the ill-posedness. Our proposed method exceeds current state-of-the-art networks on various synthetic and real-world TM benchmarks with significantly faster inference speed.

Paper number 117:
Title: Inter-event Interval Microscopy for Event Cameras
Authors: Changqing Su, Yanqin Chen, Zihan Lin, Zhen Cheng, You Zhou, Bo Xiong, Zhaofei Yu, Tiejun Huang
Abstract: Event cameras, an innovative bio-inspired sensor, differ from traditional cameras by sensing changes in intensity rather than directly perceiving intensity and recording these variations as a continuous stream of "events". The intensity reconstruction from these sparse events has long been a challenging problem. Previous approaches mainly focused on transforming motion-induced events into videos or achieving intensity imaging for static scenes by integrating modulation devices at the event camera acquisition end. In this paper, for the first time, we achieve event-to-intensity conversion using a static event camera for both static and dynamic scenes in fluorescence microscopy. Unlike conventional methods that primarily rely on event integration, the proposed Inter-event Interval Microscopy (IEIM) quantifies the time interval between consecutive events at each pixel. With a fixed threshold in the event camera, the time interval can precisely represent the intensity. At the hardware level, the proposed IEIM integrates a pulse light modulation device within a microscope equipped with an event camera, termed Pulse Modulation-based Event-driven Fluorescence Microscopy. Additionally, we have collected IEIMat dataset under various scenes including high dynamic range and high-speed scenarios. Experimental results on the IEIMat dataset demonstrate that the proposed IEIM achieves superior spatial and temporal resolution, as well as a higher dynamic range, with lower bandwidth compared to other methods. The code and the IEIMat dataset will be made publicly available.

Paper number 118:
Title: Exploring Generative AI Techniques in Government: A Case Study
Authors: Sunyi Liu, Mengzhe Geng, Rebecca Hart
Abstract: The swift progress of Generative Artificial intelligence (GenAI), notably Large Language Models (LLMs), is reshaping the digital landscape. Recognizing this transformative potential, the National Research Council of Canada (NRC) launched a pilot initiative to explore the integration of GenAI techniques into its daily operation for performance excellence, where 22 projects were launched in May 2024. Within these projects, this paper presents the development of the intelligent agent Pubbie as a case study, targeting the automation of performance measurement, data management and insight reporting at the NRC. Cutting-edge techniques are explored, including LLM orchestration and semantic embedding via RoBERTa, while strategic fine-tuning and few-shot learning approaches are incorporated to infuse domain knowledge at an affordable cost. The user-friendly interface of Pubbie allows general government users to input queries in natural language and easily upload or download files with a simple button click, greatly reducing manual efforts and accessibility barriers.

Paper number 119:
Title: Assessing the Feasibility of Internet-Sourced Video for Automatic Cattle Lameness Detection
Authors: Md Fahimuzzman Sohan, A. H. Abdul Hafez, Raid Alzubi
Abstract: Cattle lameness is often caused by hoof injuries or interdigital dermatitis, leads to pain and significantly impacts essential physiological activities such as walking, feeding, and drinking. This study presents a deep learning-based model for detecting cattle lameness, sickness, or gait abnormalities using publicly available video data. The dataset consists of 50 unique videos from 40 individual cattle, recorded from various angles in both indoor and outdoor environments. Half of the dataset represents naturally walking (normal/non-lame) cattle, while the other half consists of cattle exhibiting gait abnormalities (lame). To enhance model robustness and generalizability, data augmentation was applied to the training data. The pre-processed videos were then classified using two deep learning models: ConvLSTM2D and 3D CNN. A comparative analysis of the results demonstrates strong classification performance. Specifically, the 3D CNN model achieved a video-level classification accuracy of 90%, with precision, recall, and f1-score of 90.9%, 90.9%, and 90.91% respectively. The ConvLSTM2D model exhibited a slightly lower accuracy of 85%. This study highlights the effectiveness of directly applying classification models to learn spatiotemporal features from video data, offering an alternative to traditional multi-stage approaches that typically involve object detection, pose estimation, and feature extraction. Besides, the findings demonstrate that the proposed deep learning models, particularly the 3D CNN, effectively classify and detect lameness in cattle while simplifying the processing pipeline.

Paper number 120:
Title: BLAB: Brutally Long Audio Bench
Authors: Orevaoghene Ahia, Martijn Bartelds, Kabir Ahuja, Hila Gonen, Valentin Hofmann, Siddhant Arora, Shuyue Stella Li, Vishal Puttagunta, Mofetoluwa Adeyemi, Charishma Buchireddy, Ben Walls, Noah Bennett, Shinji Watanabe, Noah A. Smith, Yulia Tsvetkov, Sachin Kumar
Abstract: Developing large audio language models (LMs) capable of understanding diverse spoken interactions is essential for accommodating the multimodal nature of human communication and can increase the accessibility of language technologies across different user populations. Recent work on audio LMs has primarily evaluated their performance on short audio segments, typically under 30 seconds, with limited exploration of long-form conversational speech segments that more closely reflect natural user interactions with these models. We introduce Brutally Long Audio Bench (BLAB), a challenging long-form audio benchmark that evaluates audio LMs on localization, duration estimation, emotion, and counting tasks using audio segments averaging 51 minutes in length. BLAB consists of 833+ hours of diverse, full-length audio clips, each paired with human-annotated, text-based natural language questions and answers. Our audio data were collected from permissively licensed sources and underwent a human-assisted filtering process to ensure task compliance. We evaluate six open-source and proprietary audio LMs on BLAB and find that all of them, including advanced models such as Gemini 2.0 Pro and GPT-4o, struggle with the tasks in BLAB. Our comprehensive analysis reveals key insights into the trade-offs between task difficulty and audio duration. In general, we find that audio LMs struggle with long-form speech, with performance declining as duration increases. They perform poorly on localization, temporal reasoning, counting, and struggle to understand non-phonemic information, relying more on prompts than audio content. BLAB serves as a challenging evaluation framework to develop audio LMs with robust long-form audio understanding capabilities.

Paper number 121:
Title: SonicRAG : High Fidelity Sound Effects Synthesis Based on Retrival Augmented Generation
Authors: Yu-Ren Guo, Wen-Kai Tai
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language processing (NLP) and multimodal learning, with successful applications in text generation and speech synthesis, enabling a deeper understanding and generation of multimodal content. In the field of sound effects (SFX) generation, LLMs have been leveraged to orchestrate multiple models for audio synthesis. However, due to the scarcity of annotated datasets, and the complexity of temproal modeling. current SFX generation techniques still fall short in achieving high-fidelity audio. To address these limitations, this paper introduces a novel framework that integrates LLMs with existing sound effect databases, allowing for the retrieval, recombination, and synthesis of audio based on user requirements. By leveraging this approach, we enhance the diversity and quality of generated sound effects while eliminating the need for additional recording costs, offering a flexible and efficient solution for sound design and application.
    