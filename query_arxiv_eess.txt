
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Balancing SoC in Battery Cells using Safe Action Perturbations
Authors: E Harshith Kumar Yadav, Rahul Narava, Anshika, Shashi Shekher Jha
Abstract: Managing equal charge levels in active cell balancing while charging a Li-ion battery is challenging. An imbalance in charge levels affects the state of health of the battery, along with the concerns of thermal runaway and fire hazards. Traditional methods focus on safety assurance as a trade-off between safety and charging time. Others deal with battery-specific conditions to ensure safety, therefore losing on the generalization of the control strategies over various configurations of batteries. In this work, we propose a method to learn safe battery charging actions by using a safety-layer as an add-on over a Deep Reinforcement Learning (RL) agent. The safety layer perturbs the agent's action to prevent the battery from encountering unsafe or dangerous states. Further, our Deep RL framework focuses on learning a generalized policy that can be effectively employed with varying configurations of batteries. Our experimental results demonstrate that the safety-layer based action perturbation incurs fewer safety violations by avoiding unsafe states along with learning a robust policy for several battery configurations.

Paper number 2:
Title: Propensity Formation-Containment Control of Fully Heterogeneous Multi-Agent Systems via Online Data-Driven Learning
Authors: Ao Cao, Fuyong Wang, Zhongxin Liu
Abstract: This paper introduces an online data-driven learning scheme designed to address a novel problem in propensity formation and containment control for fully heterogeneous multi-agent systems. Unlike traditional approaches that rely on the eigenvalues of the Laplacian matrix, this problem considers the determination of follower positions based on propensity factors released by leaders. To address the challenge of incomplete utilization of leader information in existing multi-leader control methods, the concept of an influential transit formation leader (ITFL) is introduced. An adaptive observer is developed for the agents, including the ITFL, to estimate the state of the tracking leader or the leader's formation. Building on these observations, a model-based control protocol is proposed, elucidating the relationship between the regulation equations and control gains, ensuring the asymptotic convergence of the agent's state. To eliminate the necessity for model information throughout the control process, a new online data-driven learning algorithm is devised for the control protocol. Finally, numerical simulation results are given to verify the effectiveness of the proposed method.

Paper number 3:
Title: Low-pass sampling in Model Predictive Path Integral Control
Authors: Piotr Kicki
Abstract: Model Predictive Path Integral (MPPI) control is a widely used sampling-based approach for real-time control, offering flexibility in handling arbitrary dynamics and cost functions. However, the original MPPI suffers from high-frequency noise in the sampled control trajectories, leading to actuator wear and inefficient exploration. In this work, we introduce Low-Pass Model Predictive Path Integral Control (LP-MPPI), which integrates low-pass filtering into the sampling process to eliminate detrimental high-frequency components and improve the effectiveness of the control trajectories exploration. Unlike prior approaches, LP-MPPI provides direct and interpretable control over the frequency spectrum of sampled trajectories, enhancing sampling efficiency and control smoothness. Through extensive evaluations in Gymnasium environments, simulated quadruped locomotion, and real-world F1TENTH autonomous racing, we demonstrate that LP-MPPI consistently outperforms state-of-the-art MPPI variants, achieving significant performance improvements while reducing control signal chattering.

Paper number 4:
Title: Forecasting Empty Container availability for Vehicle Booking System Application
Authors: Arthur Cartel Foahom Gouabou (AMU, LIS, I&amp;M), Mohammed Al-Kharaz (LIS), Faouzi Hakimi (AMU), Tarek Khaled (LIS, LIRICA), Kenza Amzil (LISPEN)
Abstract: Container terminals, pivotal nodes in the network of empty container movement, hold significant potential for enhancing operational efficiency within terminal depots through effective collaboration between transporters and terminal operators. This collaboration is crucial for achieving optimization, leading to streamlined operations and reduced congestion, thereby benefiting both parties. Consequently, there is a pressing need to develop the most suitable forecasting approaches to address this challenge. This study focuses on developing and evaluating a data-driven approach for forecasting empty container availability at container terminal depots within a Vehicle Booking System (VBS) framework. It addresses the gap in research concerning optimizing empty container dwell time and aims to enhance operational efficiencies in container terminal operations. Four forecasting models-Naive, ARIMA, Prophet, and LSTM-are comprehensively analyzed for their predictive capabilities, with LSTM emerging as the top performer due to its ability to capture complex time series patterns. The research underscores the significance of selecting appropriate forecasting techniques tailored to the specific requirements of container terminal operations, contributing to improved operational planning and management in maritime logistics.

Paper number 5:
Title: Set-based and Dynamical Feedback-augmented Hands-off Control
Authors: Andrei Sperilă, Sorin Olaru, Stéphane Drobot
Abstract: A novel set-theoretical approach to hands-off control is proposed, which focuses on spatial arguments for command limitation, rather than temporal ones. By employing dynamical feedback alongside invariant set-based constraints, actuation is employed only to drive the system's state inside a "hands-off region" of its state-space, where the plant may freely evolve in open-loop configuration. A computationally-efficient procedure with strong theoretical guarantees is devised, and its effectiveness is showcased via an intuitive practical example.

Paper number 6:
Title: From Pixels to Histopathology: A Graph-Based Framework for Interpretable Whole Slide Image Analysis
Authors: Alexander Weers, Alexander H. Berger, Laurin Lux, Peter Schüffler, Daniel Rueckert, Johannes C. Paetzold
Abstract: The histopathological classification of whole-slide images (WSIs) is a fundamental task in digital pathology; yet it requires extensive time and expertise from specialists. While deep learning methods show promising results, they typically process WSIs by dividing them into artificial patches, which inherently prevents a network from learning from the entire image context, disregards natural tissue structures and compromises interpretability. Our method overcomes this limitation through a novel graph-based framework that constructs WSI graph representations. The WSI-graph efficiently captures essential histopathological information in a compact form. We build tissue representations (nodes) that follow biological boundaries rather than arbitrary patches all while providing interpretable features for explainability. Through adaptive graph coarsening guided by learned embeddings, we progressively merge regions while maintaining discriminative local features and enabling efficient global information exchange. In our method's final step, we solve the diagnostic task through a graph attention network. We empirically demonstrate strong performance on multiple challenging tasks such as cancer stage classification and survival prediction, while also identifying predictive factors using Integrated Gradients. Our implementation is publicly available at this https URL

Paper number 7:
Title: DCAT: Dual Cross-Attention Fusion for Disease Classification in Radiological Images with Uncertainty Estimation
Authors: Jutika Borah, Hidam Kumarjit Singh
Abstract: Accurate and reliable image classification is crucial in radiology, where diagnostic decisions significantly impact patient outcomes. Conventional deep learning models tend to produce overconfident predictions despite underlying uncertainties, potentially leading to misdiagnoses. Attention mechanisms have emerged as powerful tools in deep learning, enabling models to focus on relevant parts of the input data. Combined with feature fusion, they can be effective in addressing uncertainty challenges. Cross-attention has become increasingly important in medical image analysis for capturing dependencies across features and modalities. This paper proposes a novel dual cross-attention fusion model for medical image analysis by addressing key challenges in feature integration and interpretability. Our approach introduces a bidirectional cross-attention mechanism with refined channel and spatial attention that dynamically fuses feature maps from EfficientNetB4 and ResNet34 leveraging multi-network contextual dependencies. The refined features through channel and spatial attention highlights discriminative patterns crucial for accurate classification. The proposed model achieved AUC of 99.75%, 100%, 99.93% and 98.69% and AUPR of 99.81%, 100%, 99.97%, and 96.36% on Covid-19, Tuberculosis, Pneumonia Chest X-ray images and Retinal OCT images respectively. The entropy values and several high uncertain samples give an interpretable visualization from the model enhancing transparency. By combining multi-scale feature extraction, bidirectional attention and uncertainty estimation, our proposed model strongly impacts medical image analysis.

Paper number 8:
Title: Robust Model Predictive Control of Fast Lithium-ion Battery Pretreatment for Safe Recycling
Authors: Meng Yuan, Adam Burman, Changfu Zou
Abstract: The proper disposal and repurposing of end-of-life electric vehicle batteries are critical for maximizing their environmental benefits. This study introduces a robust model predictive control (MPC) framework designed to optimize the battery discharging process during pre-treatment, ensuring both efficiency and safety. The proposed method explicitly incorporates temperature constraints to prevent overheating and potential hazards. By leveraging a control-oriented equivalent circuit model integrated with thermal dynamics, the MPC algorithm dynamically adjusts the discharging profile to maintain safe operating temperatures. Additionally, the robust controller is designed to account for model mismatches between the nonlinear battery dynamics and the linearized model, ensuring reliable performance under varying conditions. The effectiveness of this approach is demonstrated through simulations comparing the robust MPC method with conventional discharging strategies, including constant current-constant voltage (CC-CV) and constant current-constant temperature (CC-CT) methods. Results indicate that the robust MPC framework significantly reduces discharging time while adhering to safety constraints, offering a promising solution for the recycling and second-life applications of lithium-ion batteries.

Paper number 9:
Title: Ignition Point Reachability for Aerodynamically-Controlled Reusable Launch Vehicles
Authors: Benjamin Chung, Kazuya Echigo, Behçet Açıkmeşe
Abstract: We describe a successive convex programming (Sequential Convex Programming (SCP)) based approach for estimate the set of points where a 5-degree of freedom (5-DoF) reusable launch vehicle (RLV) returning to a landing site can transition from aerodynamic to propulsive descent. Determining the set of feasible ignition points that a RLV can use and then safely land is important for mission planning and range safety. However, past trajectory optimization approaches for RLVs consider substantially simplified versions of the vehicle dynamics. Furthermore, prior reachability analysis methods either do not extend to the full constraint set needed for an RLV or are too beset by the curse of dimensionality to handle the full 5-DoF dynamics. To solve this problem, we describe an algorithm that approximates the projection of a high dimensional reachable set onto a low dimensional space. Instead of computing all parts of the reachable space, we only calculate reachability in the projected space of interest by using repeated trajectory optimization to sample the reachable polytope in the reduced space. The optimization can take into account initial and terminal constraints as well as state and control constraints. We show that our algorithm is able to compute the projection of a reachable set into a low dimensional space by calculating the feasible ignition points for a two-phase aerodynamic/propulsive RLV landing trajectory, while also demonstrating the aerodynamic divert enabled by our body and fin actuator model.

Paper number 10:
Title: Channel and Spectrum Consumption Models for Urban Outdoor-to-Outdoor 28 GHz Wireless
Authors: Manav Kohli, Carlos E. Caicedo, Tingjun Chen, Irfan Tamim, Angel D. Estigarribia, Tianyi Dai, Igor Kadota, Dmitry Chizhik, Jinfeng Du, Rodolfo Feick, Reinaldo A. Valenzuela, Gil Zussman
Abstract: Next generation wireless and mobile networks will utilize millimeter-wave (mmWave) communication to achieve significantly increased data rates. However, since mmWave radio signals experience high path loss, the operation of mmWave networks will require accurate channel models designed for specific deployment sites. In this paper, we focus on the deployment area of the PAWR COSMOS testbed in New York City and report extensive 28 GHz channel measurements. These include over 46 million power measurements collected from over 3,000 links on 24 sidewalks at 4 different sites and in different settings. Using these measurements, we study the effects of the setup and environments (e.g., transmitter height and seasonal effects). We then discuss the obtained path gain values and their fitted lines, and the resulting effective azimuth beamforming gain. Based on these results, we also study the link SNR values that can be supported on individual sidewalks and the corresponding theoretically achievable data rates. Finally, we develop a process to transform the measurements and generate Spectrum Consumption Models (SCMs) based on the IEEE 1900.5.2 standard. The generated SCMs facilitate the evaluation of spectrum sharing and interference management scenarios since they capture all the directional propagation effects reflected in the measurements and provide a way to easily share the main propagation characterization results derived from the measurements. We believe that the results can inform the COSMOS testbed deployment process and provide a benchmark for other deployment efforts in dense urban areas.

Paper number 11:
Title: Gain-MLP: Improving HDR Gain Map Encoding via a Lightweight MLP
Authors: Trevor D. Canham, SaiKiran Tedla, Michael J. Murdoch, Michael S. Brown
Abstract: While most images shared on the web and social media platforms are encoded in standard dynamic range (SDR), many displays now can accommodate high dynamic range (HDR) content. Additionally, modern cameras can capture images in an HDR format but convert them to SDR to ensure maximum compatibility with existing workflows and legacy displays. To support both SDR and HDR, new encoding formats are emerging that store additional metadata in SDR images in the form of a gain map. When applied to the SDR image, the gain map recovers the HDR version of the image as needed. These gain maps, however, are typically down-sampled and encoded using standard image compression, such as JPEG and HEIC, which can result in unwanted artifacts. In this paper, we propose to use a lightweight multi-layer perceptron (MLP) network to encode the gain map. The MLP is optimized using the SDR image information as input and provides superior performance in terms of HDR reconstruction. Moreover, the MLP-based approach uses a fixed memory footprint (10 KB) and requires no additional adjustments to accommodate different image sizes or encoding parameters. We conduct extensive experiments on various MLP based HDR embedding strategies and demonstrate that our approach outperforms the current state-of-the-art.

Paper number 12:
Title: Formally Proving Invariant Systemic Properties of Control Programs Using Ghost Code and Integral Quadratic Constraints
Authors: Elias Khalife, Pierre-Loic Garoche, Mazen Farhood
Abstract: This paper focuses on formally verifying invariant properties of control programs both at the model and code levels. The physical process is described by an uncertain discrete-time state-space system, where the dependence of the state-space matrix-valued functions defining the system on the uncertainties can be rational. The proposed approaches make use of pointwise integral quadratic constraints (IQCs) to characterize the uncertainties affecting the behavior of the system. Various uncertainties can be characterized by pointwise IQCs, including static linear time-varying perturbations and sector-bounded nonlinearities. Using the IQC framework, a sound overapproximation of the uncertain system, which is expressible at the code level, is constructed. Tools such as Frama-C, ACSL, WP, and an Alt-Ergo plugin are employed to ensure the validity of the state and output invariant properties across both real and float models. The first proposed approach can be used to formally verify (local) invariant properties of the control code. This capability is demonstrated in a couple of examples involving gain-scheduled path-following controllers designed for an uncrewed aircraft system and an autonomous underwater vehicle. The second approach enables the verification of closed-loop invariant properties, i.e., invariant properties of the controlled system as a whole, in both real and float models, while preserving the integrity of the executable controller code. This is achieved by using ghost code attached to the control code for all elements related to the plant model with uncertainties, as the ghost code does not interfere with the executable code. The effectiveness of this approach is demonstrated in two examples on the control of a four-thruster hovercraft and the control of a two-mass rotational system.

Paper number 13:
Title: Low Range-Doppler Sidelobe ISAC Waveform Design: A Low-Complexity Approach
Authors: Peishi Li, Ming Li, Rang Liu, Qian Liu, A. Lee Swindlehurst
Abstract: Integrated sensing and communication (ISAC) is a pivotal enabler for next-generation wireless networks. A key challenge in ISAC systems lies in designing dual-functional waveforms that can achieve satisfactory radar sensing accuracy by effectively suppressing range-Doppler sidelobes. However, existing solutions are often computationally intensive, limiting their practicality in multi-input multi-output (MIMO) orthogonal frequency division multiplexing (OFDM) ISAC deployments. This paper presents a novel low-complexity algorithm leveraging the augmented Lagrangian method (ALM) and Riemannian conjugate gradient (RCG) optimization techniques to address these challenges. The proposed algorithm achieves superior sidelobe suppression compared to state-of-the-art methods while dramatically reducing computational complexity, making it highly suitable for real-world MIMO-OFDM ISAC systems. Simulation results demonstrate that the proposed approach not only outperforms existing benchmarks in sidelobe reduction but also accelerates convergence, ensuring efficient performance across communication and sensing tasks.

Paper number 14:
Title: Goal-Oriented Source Coding using LDPC Codes for Compressed-Domain Image Classification
Authors: Ahcen Aliouat, Elsa Dupraz
Abstract: In the emerging field of goal-oriented communications, the focus has shifted from reconstructing data to directly performing specific learning tasks, such as classification, segmentation, or pattern recognition, on the received coded data. In the commonly studied scenario of classification from compressed images, a key objective is to enable learning directly on entropy-coded data, thereby bypassing the computationally intensive step of data reconstruction. Conventional entropy-coding methods, such as Huffman and Arithmetic coding, are effective for compression but disrupt the data structure, making them less suitable for direct learning without decoding. This paper investigates the use of low-density parity-check (LDPC) codes -- originally designed for channel coding -- as an alternative entropy-coding approach. It is hypothesized that the structured nature of LDPC codes can be leveraged more effectively by deep learning models for tasks like classification. At the receiver side, gated recurrent unit (GRU) models are trained to perform image classification directly on LDPC-coded data. Experiments on datasets like MNIST, Fashion-MNIST, and CIFAR show that LDPC codes outperform Huffman and Arithmetic coding in classification tasks, while requiring significantly smaller learning models. Furthermore, the paper analyzes why LDPC codes preserve data structure more effectively than traditional entropy-coding techniques and explores the impact of key code parameters on classification performance. These results suggest that LDPC-based entropy coding offers an optimal balance between learning efficiency and model complexity, eliminating the need for prior decoding.

Paper number 15:
Title: Exergy Battery Modeling and P2P Trading Based Optimal Operation of Virtual Energy Station
Authors: Meng Song, Xinyi Jing, Jianyong Ding, Ciwei Gao, Mingyu Yan, Wensheng Luo, Mariusz Malinowski
Abstract: Virtual energy stations (VESs) work as retailers to provide electricity and natural gas sale services for integrated energy systems (IESs), and guide IESs energy consumption behaviors to tackle the varying market prices via integrated demand response (IDR). However, IES customers are risk averse and show low enthusiasm in responding to the IDR incentive signals. To address this problem, exergy is utilized to unify different energies and allowed to be virtually stored and withdrawn for arbitrage by IESs. The whole incentive mechanism operating process is innovatively characterized by a virtual exergy battery. Peer to peer (P2P) exergy trading based on shared exergy storage is also developed to reduce the energy cost of IESs without any extra transmission fee. In this way, IES can reduce the economic loss risk caused by the market price fluctuation via the different time (time dimension), multiple energy conversion (energy dimension), and P2P exergy trading (space dimension) arbitrage. Moreover, the optimal scheduling of VES and IESs is modeled by a bilevel optimization model. The consensus based alternating direction method of multipliers (CADMM) algorithm is utilized to solve this problem in a distributed way. Simulation results validate the effectiveness of the proposed incentive mechanism and show that the shared exergy storage can enhance the benefits of different type IESs by 18.96%, 3.49%, and 3.15 %, respectively.

Paper number 16:
Title: A Profit Sharing Mechanism for Coordinated Power Traffic System
Authors: Tianyu Sima, Mingyu Yan, Jianfeng Wen, Wensheng Luo, Mariusz Malinowski
Abstract: During the scheduling process, the traffic network operator (TNO) and the distribution network operator (DNO) act noncooperatively. Under the TNO management, the distribution of charging loads may exacerbate the local supply demand imbalance in the power distribution network (PDN), which negatively impacts the economic operation of the PDN. This paper proposes a profitsharing mechanism based on the principle of incentive compatibility for coordinating the traffic network (TN) and the PDN to minimize the operation cost of PDN. Under this mechanism, the scheduling process of the power traffic system is divided into two stages. At the prescheduling stage, the TNO allocates traffic flow and charging loads without considering the operation of the PDN, after which the DNO schedules and obtains the original cost. At the rescheduling stage, the DNO shares part of benefits of the optimal operation to the TNO to redispatch the EV charging to obtain a more effective charging plan, thus minimize the overall cost of PDN. Then, a bilevel model is developed to simulate the operation of the power traffic system with the proposed sharing scheme and identify the best sharing ratio. Finally, numerical results demonstrate that the PDN can achieve the minimum total cost and simultaneously the TN can also benefit from the proposed profit sharing mechanism.

Paper number 17:
Title: Impact of Frequency on Diffraction-Aided Wireless Positioning
Authors: Gaurav Duggal, Anand M. Kumar, R. Michael Buehrer, Harpreet S. Dhillon, Nishith Tripathi, Jeffrey H. Reed
Abstract: This paper tackles the challenge of accurate positioning in Non-Line-of-Sight (NLoS) environments, with a focus on indoor public safety scenarios where NLoS bias severely impacts localization performance. We explore Diffraction MultiPath Components (MPC) as a critical mechanism for Outdoor-to-Indoor (O2I) signal propagation and its role in positioning. The proposed system comprises outdoor Uncrewed Aerial Vehicle (UAV) transmitters and indoor receivers that require localization. To facilitate diffraction-based positioning, we develop a method to isolate diffraction MPCs at indoor receivers and validate its effectiveness using a ray-tracing-generated dataset, which we have made publicly available. Our evaluation across the FR1, FR2, and FR3 frequency bands within the 5G/6G spectrum confirms the viability of diffraction-based positioning techniques for next-generation wireless networks.

Paper number 18:
Title: WiFi-Diffusion: Achieving Fine-Grained WiFi Radio Map Estimation With Ultra-Low Sampling Rate by Diffusion Models
Authors: Zhiyuan Liu, Shuhang Zhang, Qingyu Liu, Hongliang Zhang, Lingyang Song
Abstract: Fine-grained radio map presents communication parameters of interest, e.g., received signal strength, at every point across a large geographical region. It can be leveraged to improve the efficiency of spectrum utilization for a large area, particularly critical for the unlicensed WiFi spectrum. The problem of fine-grained radio map estimation is to utilize radio samples collected by sparsely distributed sensors to infer the map. This problem is challenging due to the ultra-low sampling rate, where the number of available samples is far less than the fine-grained resolution required for radio map estimation. We propose WiFi-Diffusion -- a novel generative framework for achieving fine-grained WiFi radio map estimation using diffusion models. WiFi-Diffusion employs the creative power of generative AI to address the ultra-low sampling rate challenge and consists of three blocks: 1) a boost block, using prior information such as the layout of obstacles to optimize the diffusion model; 2) a generation block, leveraging the diffusion model to generate a candidate set of radio maps; and 3) an election block, utilizing the radio propagation model as a guide to find the best radio map from the candidate set. Extensive simulations demonstrate that 1) the fine-grained radio map generated by WiFi-Diffusion is ten times better than those produced by state-of-the-art (SOTA) when they use the same ultra-low sampling rate; and 2) WiFi-Diffusion achieves comparable fine-grained radio map quality with only one-fifth of the sampling rate required by SOTA.

Paper number 19:
Title: Dynamic IRS Allocation for Spectrum-Sharing MIMO Communication and Radar Systems
Authors: Daniyal Munir, Atta Ullah, Danish Mehmood Mughal, Min Young Chung, Hans D. Schotten
Abstract: This paper investigates the use of intelligent reflecting surfaces (IRS) to assist cellular communications and radar sensing operations in a communications and sensing setup. The IRS dynamically allocates reflecting elements to simultaneously localize a target and assist a user's communication. To achieve this, we propose a novel optimization framework that jointly addresses beamforming design and IRS element allocation. Specifically, we formulate a Weighted Minimum Mean Square Error (WMMSE)-based approach that iteratively optimizes the transmit and receive beamforming vectors, IRS phase shifts, and element allocation. The allocation mechanism adaptively balances the number of IRS elements dedicated to communication and sensing subsystems by leveraging the signal-to-noise-plus-interference-ratio (SINR) between the two. The proposed solution ensures efficient resource utilization while maintaining performance trade-offs. Numerical results demonstrate significant improvements in both communication and sensing SINRs under varying system parameters.

Paper number 20:
Title: Adaptive Mixture of Experts Learning for Robust Audio Spoofing Detection
Authors: Qixian Chen, Yuxiong Xu, Sara Mandelli, Sheng Li, Bin Li
Abstract: In audio spoofing detection, most studies rely on clean datasets, making models susceptible to real-world post-processing attacks, such as channel compression and noise. To overcome this challenge, we propose the Adaptive Mixture of Experts Learning (AMEL) framework, which enhances resilience by leveraging attack-specific knowledge and adapting dynamically to varied attack conditions. Specifically, AMEL utilizes Attack-Specific Experts (ASE) fine-tuned with Low-Rank Adaptation (LoRA), enabling each expert to target specific post-processing patterns while requiring only 1.12\% of the parameters needed for full fine-tuning. Furthermore, we introduce Dynamic Expert Aggregation (DEA), which adaptively selects and integrates expert knowledge to enhance the robustness of spoofing detection. Experimental results demonstrate that AMEL significantly enhances robustness by improving noise resilience and exhibiting greater adaptability to previously unseen post-processing methods compared to models relying on full fine-tuning. Additionally, our framework outperforms both single expert and simple average ensemble under various mixed attacks, demonstrating its superior robustness and adaptability in managing complex, real-world conditions.

Paper number 21:
Title: Unsupervised Learning for AoD Estimation in MISO Downlink LoS Transmissions
Authors: Jiaying Li, Hong Xing, Yuanwei Liu
Abstract: With the emerging of simultaneous localization and communication (SLAC), it becomes more and more attractive to perform angle of departure (AoD) estimation at the receiving Internet of Thing (IoT) user end for improved positioning accuracy, flexibility and enhanced user privacy. To address challenges like large number of real-time measurements required for latency-critical applications and enormous data collection for training deep learning models in conventional AoD estimation methods, we propose in this letter an unsupervised learning framework, which unifies training for both deterministic maximum likelihood (DML) and stochastic maximum likelihood (SML) based AoD estimation in multiple-input single-output (MISO) downlink (DL) wireless transmissions. Specifically, under the line-of-sight (LoS) assumption, we incorporate both the received signals and pilot-sequence information, as per its availability at the DL user, into the input of the deep learning model, and adopt a common neural network architecture compatible with input data in both DML and SML cases. Extensive numerical results validate that the proposed unsupervised learning based AoD estimation not only improves estimation accuracy, but also significantly reduces required number of observations, thereby reducing both estimation overhead and latency compared to various benchmarks.

Paper number 22:
Title: A Novel Environment Object Modeling Method for Vehicular ISAC Scenarios
Authors: Hanyuan Jiang, Yuxiang Zhang, Yameng Liu, Jianhua Zhang, Lei Tian, Tao Jiang
Abstract: Integrated Sensing and Communication (ISAC), as a fundamental technology of 6G, empowers Vehicle-to-Everything (V2X) systems with enhanced sensing capabilities. One of its promising applications is the reliance on constructed maps for vehicle positioning. Traditional positioning methods primarily rely on Line-of-Sight (LOS), but in urban vehicular scenarios, obstructions often result in predominantly Non-Line-of-Sight (NLOS) conditions. Existing research indicates that NLOS paths, characterized by one-bounce reflection on building walls with determined delay and angle, can support sensing and positioning. However, experimental validation remains insufficient. To address this gap, channel measurements are conducted in an urban street to explore the existence of strong reflected paths in the presence of a vehicle target. The results show significant power contribution from NLOS paths, with large Environmental Objects (EOs) playing a key role in shaping NLOS propagation. Then, a novel model for EO reflection is proposed to extend the Geometry-Based Stochastic Model (GBSM) for ISAC channel standardization. Simulation results validate the model's ability to capture EO's power and position characteristics, showing that higher EO-reflected power and closer distance to Rx reduce Delay Spread (DS), which is more favorable for positioning. This model provides theoretical guidance and empirical support for ISAC positioning algorithms and system design in vehicular scenarios.

Paper number 23:
Title: Optimal Hybrid Transmit Beamforming for mm-Wave Integrated Sensing and Communication
Authors: Jitendra Singh, Banda Naveen, Suraj Srivastava, Aditya K. Jagannatham, Lajos Hanzo
Abstract: A hybrid beamformer (HBF) is designed for integrated sensing and communication (ISAC)-aided millimeter wave (mmWave) systems. The ISAC base station (BS), relying on a limited number of radio frequency (RF) chains, supports multiple communication users (CUs) and simultaneously detects the radar target (RT). To maximize the probability of detection (PD) of the RT, and achieve rate fairness among the CUs, we formulate two problems for the optimization of the RF and baseband (BB) transmit precoders (TPCs): PD-maximization (PD-max) and geometric mean rate-maximization (GMR-max), while ensuring the quality of services (QoS) of the RT and CUs. Both problems are highly non-convex due to the intractable expressions of the PD and GMR and also due to the non-convex unity magnitude constraints imposed on each element of the RF TPC. To solve these problems, we first transform the intractable expressions into their tractable counterparts and propose a power-efficient bisection search and majorization and minimization-based alternating algorithms for the PD-max and GMR-max problems, respectively. Furthermore, both algorithms optimize the BB TPC and RF TPCs in an alternating fashion via the successive convex approximation (SCA) and penalty-based Riemannian conjugate gradient (PRCG) techniques, respectively. Specifically, in the PRCG method, we initially add all the constraints except for the unity magnitude constraint to the objective function as a penalty term and subsequently employ the RCG method for optimizing the RF TPC. Finally, we present our simulation results and compare them to the benchmarks for demonstrating the efficacy of the proposed algorithms.

Paper number 24:
Title: Fast Critical Clearing Time Calculation for Power Systems with Synchronous and Asynchronous Generation
Authors: Xuezao Wang, Yijun Xu, Wei Gu, Kai Liu, Shuai Lu, Mert Korkali, Lamine Mili
Abstract: The increasing penetration of renewables is replacing traditional synchronous generation in modern power systems with low-inertia asynchronous converter-interfaced generators (CIGs). This penetration threatens the dynamic stability of the modern power system. To assess the latter, we resort to the critical clearing time (CCT) as a stability index, which is typically computed through a large number of time-domain simulations. This is especially true for CIG-embedded power systems, where the complexity of the model is further increased. To alleviate the computing burden, we developed a trajectory sensitivity-based method for assessing the CCT in power systems with synchronous and asynchronous generators. This allows us to obtain the CCT cost-effectively. The simulation results reveal the excellent performance of the proposed method.

Paper number 25:
Title: Language Models for Automated Classification of Brain MRI Reports and Growth Chart Generation
Authors: Maryam Daniali, Shivaram Karandikar, Dabriel Zimmerman, J. Eric Schmitt, Matthew J. Buczek, Benjamin Jung, Laura Mercedes, Jakob Seidlitz, Vanessa Troiani, Lena Dorfschmidt, Eren Kafadar, Remo Williams, Susan Sotardi, Arastoo Vosough, Scott Haag, Jenna M. Schabdach, Aaron Alexander-Bloch
Abstract: Clinically acquired brain MRIs and radiology reports are valuable but underutilized resources due to the challenges of manual analysis and data heterogeneity. We developed fine-tuned language models (LMs) to classify brain MRI reports as normal (reports with limited pathology) or abnormal, fine-tuning BERT, BioBERT, ClinicalBERT, and RadBERT on 44,661 reports. We also explored the reasoning capabilities of a leading LM, Gemini 1.5-Pro, for normal report categorization. Automated image processing and modeling generated brain growth charts from LM-classified normal scans, comparing them to human-derived charts. Fine-tuned LMs achieved high classification performance (F1-Score >97%), with unbalanced training mitigating class imbalance. Performance was robust on out-of-distribution data, with full text outperforming summary (impression) sections. Gemini 1.5-Pro showed a promising categorization performance, especially with clinical inference. LM-derived brain growth charts were nearly identical to human-annotated charts (r = 0.99, p < 2.2e-16). Our LMs offer scalable analysis of radiology reports, enabling automated classification of brain MRIs in large datasets. One application is automated generation of brain growth charts for benchmarking quantitative image features. Further research is needed to address data heterogeneity and optimize LM reasoning.

Paper number 26:
Title: Formation Control of Multi-agent System with Local Interaction and Artificial Potential Field
Authors: Luoyin Zhao, Zheping Yan, Yuqing Wang, Raye Chen-Hua Yeow
Abstract: A novel local interaction control method (LICM) is proposed in this paper to realize the formation control of multi-agent system (MAS). A local interaction leader follower (LILF) structure is provided by coupling the advantages of information consensus and leader follower frame, the agents can obtain the state information of the leader by interacting with their neighbours, which will reduce the communication overhead of the system and the dependence on a single node of the topology. In addition, the artificial potential field (APF) method is introduced to achieve obstacle avoidance and collision avoidance between agents. Inspired by the stress response of animals, a stress response mechanism-artificial potential field (SRM-APF) is proposed, which will be triggered when the local minimum problem of APF occurs. Ultimately, the simulation experiments of three formation shapes, including triangular formation, square formation and hexagonal formation, validate the effectiveness of the proposed method.

Paper number 27:
Title: Lithium-ion Battery Capacity Prediction via Conditional Recurrent Generative Adversarial Network-based Time-Series Regeneration
Authors: Myisha A. Chowdhury, Gift Modekwe, Qiugang Lu
Abstract: Accurate capacity prediction is essential for the safe and reliable operation of batteries by anticipating potential failures beforehand. The performance of state-of-the-art capacity prediction methods is significantly hindered by the limited availability of training data, primarily attributed to the expensive experimentation and data sharing restrictions. To tackle this issue, this paper presents a recurrent conditional generative adversarial network (RCGAN) scheme to enrich the limited battery data by adding high-fidelity synthetic ones to improve the capacity prediction. The proposed RCGAN scheme consists of a generator network to generate synthetic samples that closely resemble the true data and a discriminator network to differentiate real and synthetic samples. Long shortterm memory (LSTM)-based generator and discriminator are leveraged to learn the temporal and spatial distributions in the multivariate time-series battery data. Moreover, the generator is conditioned on the capacity value to account for changes in battery dynamics due to the degradation over usage cycles. The effectiveness of the RCGAN is evaluated across six batteries from two benchmark datasets (NASA and MIT). The raw data is then augmented with synthetic samples from the RCGAN to train LSTM and gate recurrent unit (GRU) models for capacity prediction. Simulation results show that the models trained with augmented datasets significantly outperform those trained with the original datasets in capacity prediction.

Paper number 28:
Title: Indoor Positioning for Public Safety: Role of UAVs, LEOs, and Propagation-Aware Techniques
Authors: Gaurav Duggal, Harish K. Dureppagari, Harpreet S. Dhillon, Jeffrey H. Reed, R. Michael Buehrer
Abstract: Effective indoor positioning is critical for public safety, enabling first responders to locate at-risk individuals accurately during emergency scenarios. However, traditional Global Navigation Satellite Systems (GNSS) often perform poorly indoors due to poor coverage and non-line-of-sight (NLOS) conditions. Moreover, relying on fixed cellular infrastructure, such as terrestrial networks (TNs), may not be feasible, as indoor signal coverage from a sufficient number of base stations or WiFi access points cannot be guaranteed for accurate positioning. In this paper, we propose a rapidly deployable indoor positioning system (IPS) leveraging mobile anchors, including uncrewed aerial vehicles (UAVs) and Low-Earth-Orbit (LEO) satellites, and discuss the role of GNSS and LEOs in localizing the mobile anchors. Additionally, we discuss the role of sidelink-based positioning, which is introduced in 3rd Generation Partnership Project (3GPP) Release 18, in enabling public safety systems. By examining outdoor-to-indoor (O2I) signal propagation, particularly diffraction-based approaches, we highlight how propagation-aware positioning methods can outperform conventional strategies that disregard propagation mechanism information. The study highlights how emerging 5G Advanced and Non-Terrestrial Networks (NTN) features offer new avenues to improve positioning in challenging indoor environments, ultimately paving the way for cost-effective and resilient IPS solutions tailored to public safety applications.

Paper number 29:
Title: Power Swing Trajectory Influenced by Virtual Impedance-Based Current-Limiting Strategy
Authors: Yanshu Niu, Zhe Yang, Bikash C. Pal
Abstract: Grid-forming (GFM) inverter-based resources (IBRs) can emulate the external characteristics of synchronous generators (SGs) through appropriate control loop design. However, in systems with GFM IBRs, the apparent impedance trajectory under current limitation differs significantly from that of SG-based systems due to the limited overcurrent capability of power electronic devices. This difference challenges the power swing detection functions of distance relays designed for SG-based systems. This paper presents a theoretical analysis of the apparent impedance trajectory over a full power swing cycle under two typical current-limiting strategies: variable virtual impedance (VI) and adaptive VI. The analysis reveals that the trajectory under VI current-limiting strategies differs significantly from that of a conventional SG. The results also indicate that the control parameters affect the characteristics of the trajectory. In addition, the new trajectories challenge conventional power swing detection functions, increasing the risk of malfunction. Furthermore, the implementation of VI leads to a deterioration in system stability. The theoretical analysis is further validated through simulations on the MATLAB/Simulink platform.

Paper number 30:
Title: How Do Microstrip Losses Impact Near-Field Beam Depth in Dynamic Metasurface Antennas?
Authors: Panagiotis Gavriilidis, George C. Alexandropoulos
Abstract: The convergence of eXtremely Large (XL) antenna arrays and high-frequency bands in future wireless networks will inevitably give rise to near-field communications, localization, and sensing. Dynamic Metasurface Antennas (DMAs) have emerged as a key enabler of the XL Multiple-Input Multiple-Output (MIMO) paradigm, leveraging reconfigurable metamaterials to support large antenna arrays. However, DMAs are inherently lossy due to propagation losses in the microstrip lines and radiative losses from the metamaterial elements, which reduce their gain and alter their beamforming characteristics compared to a lossless aperture. In this paper, we address the gap in understanding how DMA losses affect near-field beamforming performance, by deriving novel analytical expressions for the beamforming gain of DMAs under misalignments between the focusing position and the intended user's position in 3D space. Additionally, we derive beam depth limits for varying attenuation conditions, from lossless to extreme attenuation, offering insights into the impact of losses on DMA near-field performance.

Paper number 31:
Title: Computing Modes of Instability of Parameterized Nonlinear Systems for Vulnerability Assessment
Authors: Jinghan Wang, Michael W. Fisher
Abstract: Engineered systems naturally experience large disturbances that can disrupt desired operation because the system may fail to recover to a stable equilibrium point. It is valuable to determine the mechanism of instability when the system is subject to a particular finite-time disturbance, because this information can be used to improve vulnerability detection, and to design controllers to reduce vulnerability. Often there exists a particular unstable equilibrium point on the region of attraction boundary of the stable equilibrium point such that the unstable eigenvector of the Jacobian at this unstable equilibrium point represents the mode of instability for the disturbance. Unfortunately, it is challenging to find this mode of instability, especially in high dimensional systems, because it is computationally intractable to obtain this particular unstable equilibrium point. This paper develops a novel algorithm for numerically computing the mode of instability for parameterized nonlinear systems without identifying the particular unstable equilibrium point, resulting in a computationally efficient method. The key idea is to first consider the setting where the system recovers, and to average the Jacobian along the system trajectory from the post-disturbance state up until the Jacobian becomes stable. As the system approaches inability to recover, the averaged Jacobians converge to the Jacobian at the particular unstable equilibrium point, and can be used to extract the unstable eigenvector representing the mode of instability. Convergence guarantees are provided for computing the mode of instability, both for the theoretical setting in continuous time, and for the proposed algorithm which relies on numerical integration. Numerical examples illustrate the successful application of the method to identify the mechanism of instability in power systems subject to temporary short circuits.

Paper number 32:
Title: AI-driven 6G Air Interface: Technical Usage Scenarios and Balanced Design Methodology
Authors: Xiaoyun Wang, Shuangfeng Han, Zhiming Liu, Qixing Wang, Jiangzhou Wang, Chih-Lin I
Abstract: This paper systematically analyzes the typical application scenarios and key technical challenges of AI in 6G air interface transmission, covering important areas such as performance enhancement of single functional modules, joint optimization of multiple functional modules, and low-complexity solutions to complex mathematical problems. Innovatively, a three-dimensional joint optimization design criterion is proposed, which comprehensively considers AI capability, quality, and cost. By maximizing the ratio of multi-scenario communication capability to comprehensive cost, a triangular equilibrium is achieved, effectively addressing the lack of consideration for quality and cost dimensions in existing design criteria. The effectiveness of the proposed method is validated through multiple design examples, and the technical pathways and challenges for air interface AI standardization are thoroughly discussed. This provides significant references for the theoretical research and engineering practice of 6G air interface AI technology.

Paper number 33:
Title: Low-Complexity MUSIC Algorithm: From Finite-Precision Perspective
Authors: Yiming Fang, Li Chen, Ang Chen, Weidong Wang
Abstract: The high computational complexity of the multiple signal classification (MUSIC) algorithm is mainly caused by the subspace decomposition and spectrum search, especially for frequent real-time applications or massive sensors. In this paper, we propose a low-complexity MUSIC algorithm from finite-precision arithmetic perspective. First, we analyze the computational bottlenecks of the classic low-complexity randomized unitary-based MUSIC (RU-MUSIC), formulating this computational issue as an inner product problem. Then, a mixed-precision method is introduced to address this problem. Specifically, this method partitions summations in inner products into blocks, where intra-block computations use low-precision arithmetic and inter-block sums use high-precision arithmetic. To further improve computational accuracy, we develop an adaptive-precision method that supports adaptive block sizes and multiple precision levels. Finally, simulation results show that the proposed finite-precision MUSIC design achieves direction-of-arrival (DOA) estimation performance similar to that using full-precision arithmetic while reducing more than 50\% computational cost.

Paper number 34:
Title: SCReedSolo: A Secure and Robust LSB Image Steganography Framework with Randomized Symmetric Encryption and Reed-Solomon Coding
Authors: Syed Rifat Raiyan, Md. Hasanul Kabir
Abstract: Image steganography is an information-hiding technique that involves the surreptitious concealment of covert informational content within digital images. In this paper, we introduce ${\rm SCR{\small EED}S{\small OLO}}$, a novel framework for concealing arbitrary binary data within images. Our approach synergistically leverages Random Shuffling, Fernet Symmetric Encryption, and Reed-Solomon Error Correction Codes to encode the secret payload, which is then discretely embedded into the carrier image using LSB (Least Significant Bit) Steganography. The combination of these methods addresses the vulnerability vectors of both security and resilience against bit-level corruption in the resultant stego-images. We show that our framework achieves a data payload of 3 bits per pixel for an RGB image, and mathematically assess the probability of successful transmission for the amalgamated $n$ message bits and $k$ error correction bits. Additionally, we find that ${\rm SCR{\small EED}S{\small OLO}}$ yields good results upon being evaluated with multiple performance metrics, successfully eludes detection by various passive steganalysis tools, and is immune to simple active steganalysis attacks. Our code and data are available at this https URL.

Paper number 35:
Title: A Unified Approach to Enforce Non-Negativity Constraint in Neural Network Approximation for Optimal Voltage Regulation
Authors: Jiaqi Wu, Jingyi Yuan, Yang Weng, Guangwen Wang
Abstract: Power system voltage regulation is crucial to maintain power quality while integrating intermittent renewable resources in distribution grids. However, the system model on the grid edge is often unknown, making it difficult to model physical equations for optimal control. Therefore, previous work proposes structured data-driven methods like input convex neural networks (ICNN) for "optimal" control without relying on a physical model. While ICNNs offer theoretical guarantees based on restrictive assumptions of non-negative neural network (NN) parameters, can one improve the approximation power with an extra step on negative duplication of inputs? We show that such added mirroring step fails to improve accuracy, as a linear combination of the original input and duplicated input is equivalent to a linear operation of ICNN's input without duplication. While this design can not improve performance, we propose a unified approach to embed the non-negativity constraint as a regularized optimization of NN, contrary to the existing methods, which added a loosely integrated second step for post-processing on parameter negation. Our integration directly ties back-propagation to simultaneously minimizing the approximation error while enforcing the convexity constraints. Numerical experiments validate the issues of the mirroring method and show that our integrated objective can avoid problems such as unstable training and non-convergence existing in other methods for optimal control.

Paper number 36:
Title: A Comparative Study of Invariance-Aware Loss Functions for Deep Learning-based Gridless Direction-of-Arrival Estimation
Authors: Kuan-Lin Chen, Bhaskar D. Rao
Abstract: Covariance matrix reconstruction has been the most widely used guiding objective in gridless direction-of-arrival (DoA) estimation for sparse linear arrays. Many semidefinite programming (SDP)-based methods fall under this category. Although deep learning-based approaches enable the construction of more sophisticated objective functions, most methods still rely on covariance matrix reconstruction. In this paper, we propose new loss functions that are invariant to the scaling of the matrices and provide a comparative study of losses with varying degrees of invariance. The proposed loss functions are formulated based on the scale-invariant signal-to-distortion ratio between the target matrix and the Gram matrix of the prediction. Numerical results show that a scale-invariant loss outperforms its non-invariant counterpart but is inferior to the recently proposed subspace loss that is invariant to the change of basis. These results provide evidence that designing loss functions with greater degrees of invariance is advantageous in deep learning-based gridless DoA estimation.

Paper number 37:
Title: Movable Cell-Free Massive MIMO For High-Speed Train Communications: A PPO-Based Antenna Position Optimization
Authors: Jie Dai, Yuchen Liu, Jiakang Zheng, Ruichen Zhang, Jiayi Zhang, Bo Ai
Abstract: In recent years, high-speed trains (HSTs) communications have developed rapidly to enhance the stability of train operations and improve passenger connectivity experiences. However, as the train continues to accelerate, urgent technological innovations are needed to overcome challenges such as frequency handover and significant Doppler effects. In this paper, we present a novel architecture featuring movable antennas (MAs) to fully exploit macro spatial diversity, enabling a cell-free (CF) massive multiple-input multiple-output (MIMO) system that supports high-speed train communications. Considering the high likelihood of line-of-sight (LoS) transmission in HST scenario, we derive the uplink spectral efficiency (SE) expression for the movable CF massive MIMO system. Moreover, an optimization problem is formulated to maximize the sum SE of the considered system by optimizing the positions of the antennas. Since the formulated problem is non-convex and highly non-linear, we improve a deep reinforcement learning algorithm to address it by using proximal policy optimization (PPO). Different from traditional optimization approaches, which optimize variables separately and alternately, our improved PPO-based approach optimizes all the variables in unison. Simulation results demonstrate that movable CF massive MIMO effectively suppresses the negative impact of the Doppler effect in HST communications.

Paper number 38:
Title: Spectral efficiency for mmWave downlink with beam misalignment in urban macro scenario
Authors: Jaroslaw Wojtun, Cezary Ziolkowski, Jan M. Kelner, Aniruddha Chandra, Rajeev Shukla, Anirban Ghosh, Ales Prokes, Tomas Mikulasek, Radek Zavorka, Petr Horky
Abstract: In this paper, we analyze the spectral efficiency for millimeter wave downlink with beam misalignment in urban macro scenario. For this purpose, we use a new approach based on the modified Shannon formula, which considers the propagation environment and antenna system coefficients. These factors are determined based on a multi-ellipsoidal propagation model. The obtained results show that under non-line-of-sight conditions, the appropriate selection of the antenna beam orientation may increase the spectral efficiency in relation to the direct line to a user.

Paper number 39:
Title: Power angular spectrum versus Doppler spectrum -- Measurements and analysis
Authors: Jan M. Kelner, Cezary Ziolkowski, Michal Kryk, Jaroslaw Wojtun, Leszek Nowosielski, Rafal Przesmycki, Marek Bugaj, Aniruddha Chandra, Rajeev Shukla, Anirban Ghosh, Ales Prokes, Tomas Mikulasek
Abstract: In this paper, we present an empirical verification of the method of determining the Doppler spectrum (DS) from the power angular spectrum (PAS). Measurements were made for the frequency of 3.5 GHz, under non-line-of-sight conditions in suburban areas characteristic of a university campus. In the static scenario, the measured PAS was the basis for the determination of DSs, which were compared with the DSs measured in the mobile scenario. The obtained results show that the proposed method gives some approximation to DS determined with the classic methods used so far.

Paper number 40:
Title: Variability of radio signal attenuation by single deciduous tree versus reception angle at 80 GHz
Authors: Jaroslaw Wojtun, Cezary Ziolkowski, Jan M. Kelner, Tomas Mikulasek, Radek Zavorka, Jiri Blumenstein, Alea Prokes, Aniruddha Chandra, Niraj Narayan, Anirban Ghosh
Abstract: Vegetation significantly affects radio signal attenuation, influenced by factors such as signal frequency, plant species, and foliage density. Existing attenuation models typically address specific scenarios, like single trees, rows of trees, or green spaces, with the ITU-R P.833 recommendation being a widely recognized standard. Most assessments for single trees focus on the primary radiation direction of the transmitting antenna. This paper introduces a novel approach to evaluating radio signal scattering by a single deciduous tree. Through measurements at 80 GHz and a bandwidth of approximately 2 GHz, we analyze how total signal attenuation varies with the reception angle relative to the transmitter-tree axis. The findings from various directional measurements contribute to a comprehensive attenuation model applicable to any reception angle and also highlight the impact of bandwidth on the received signal level.

Paper number 41:
Title: Iterative Motion Planning in Multi-agent Systems with Opportunistic Communication under Disturbance
Authors: Neelanga Thelasingha, Agung Julius, James Humann, James Dotterweich
Abstract: In complex multi-agent systems involving heterogeneous teams, uncertainty arises from numerous sources like environmental disturbances, model inaccuracies, and changing tasks. This causes planned trajectories to become infeasible, requiring replanning. Further, different communication architectures used in multi-agent systems give rise to asymmetric knowledge of planned trajectories across the agents. In such systems, replanning must be done in a communication-aware fashion. This paper establishes the conditions for synchronization and feasibility in epistemic planning scenarios introduced by opportunistic communication architectures. We also establish conditions on task satisfaction based on quantified recoverability of disturbances in an iterative planning scheme. We further validate these theoretical results experimentally in a UAV--UGV task assignment problem.

Paper number 42:
Title: Fuzzy Clustering for Low-Complexity Time Domain Chromatic Dispersion Compensation Scheme in Coherent Optical Fiber Communication Systems
Authors: Wenkai Wan, Aiying Yang, Peng Guo, Zhe Zhao, Tianjia Xu, Jinxuan Wu, Zhiheng Liu
Abstract: Chromatic dispersion compensation (CDC), implemented in either the time-domain or frequency-domain, is crucial for enhancing power efficiency in the digital signal processing of modern optical fiber communication systems. Developing low-complexity CDC schemes is essential for hardware implemention, particularly for high-speed and long-haul optical fiber communication systems. In this work, we propose a novel two-stage fuzzy clustered time-domain chromatic dispersion compensation scheme. Unlike hard decisions of CDC filter coefficients after determining the cluster centroids, our approach applies a soft fuzzy decision, allowing the coefficients to belong to multiple clusters. Experiments on a single-channel, single-polarization 20Gbaud 16-QAM 1800 km standard single-mode fiber communication system demonstrate that our approach has a complexity reduction of 53.8% and 40% compared with clustered TD-CDC and FD-CDC at a target Q-factor of 20% HD-FEC, respectively. Furthermore, the proposed method achieves the same optimal Q-factor as FD-CDC with a 27% complexity reduction.

Paper number 43:
Title: SING: Semantic Image Communications using Null-Space and INN-Guided Diffusion Models
Authors: Jiakang Chen, Selim F. Yilmaz, Di You, Pier Luigi Dragotti, Deniz Gündüz
Abstract: Joint source-channel coding systems based on deep neural networks (DeepJSCC) have recently demonstrated remarkable performance in wireless image transmission. Existing methods primarily focus on minimizing distortion between the transmitted image and the reconstructed version at the receiver, often overlooking perceptual quality. This can lead to severe perceptual degradation when transmitting images under extreme conditions, such as low bandwidth compression ratios (BCRs) and low signal-to-noise ratios (SNRs). In this work, we propose SING, a novel two-stage JSCC framework that formulates the recovery of high-quality source images from corrupted reconstructions as an inverse problem. Depending on the availability of information about the DeepJSCC encoder/decoder and the channel at the receiver, SING can either approximate the stochastic degradation as a linear transformation, or leverage invertible neural networks (INNs) for precise modeling. Both approaches enable the seamless integration of diffusion models into the reconstruction process, enhancing perceptual quality. Experimental results demonstrate that SING outperforms DeepJSCC and other approaches, delivering superior perceptual quality even under extremely challenging conditions, including scenarios with significant distribution mismatches between the training and test data.

Paper number 44:
Title: Limited-Resolution Hybrid Analog-Digital Precoding Design Using MIMO Detection Methods
Authors: Parisa Ramezani, Alva Kosasih, Emil Björnson
Abstract: While fully digital precoding achieves superior performance in massive multiple-input multiple-output (MIMO) systems, it comes with significant drawbacks in terms of computational complexity and power consumption, particularly when operating at millimeter-wave frequencies and beyond. Hybrid analog-digital architectures address this by reducing radio frequency (RF) chains while maintaining performance in sparse multipath environments. However, most hybrid precoder designs assume ideal, infinite-resolution analog phase shifters, which cannot be implemented in actual systems. Another practical constraint is the limited fronthaul capacity between the baseband processor and array, implying that each entry of the digital precoder must be picked from a finite set of quantization labels. This paper proposes novel designs for the limited-resolution analog and digital precoders by exploiting two well-known MIMO symbol detection algorithms, namely sphere decoding (SD) and expectation propagation (EP). The goal is to minimize the Euclidean distance between the optimal fully digital precoder and the hybrid precoder to minimize the degradation caused by the finite resolution of the analog and digital precoders. Taking an alternative optimization approach, we first apply the SD method to find the precoders in each iteration optimally. Then, we apply the lower-complexity EP method which finds a near-optimal solution at a reduced computational cost. The effectiveness of the proposed designs is validated via numerical simulations, where we show that the proposed symbol detection-based precoder designs significantly outperform the nearest point mapping scheme which is commonly used for finding a sub-optimal solution to discrete optimization problems.

Paper number 45:
Title: Automotive Battery Pack Standards and Design Characteristics: A Review
Authors: Saeid Haghbin, Morteza Rezaei Larijani, MohammadReza Zolghadri, Shahin Hedayati Kia
Abstract: The latest status and near-future trends of automotive battery packs are presented and discussed, with a focus on automakers. Desired pack specifications, aligned with regulatory standards, are outlined from an automaker's perspective. In response to these specifications, high-level solutions are proposed to converge toward a standard architecture for passenger cars Key aspects such as electrical performance, safety, mechanical integrity, reliability, environmental conditions, diagnostics, and practical considerations are examined. Furthermore, near-future developments and emerging applications, including battery use in airplanes, are discussed.

Paper number 46:
Title: Fourier-Based 3D Multistage Transformer for Aberration Correction in Multicellular Specimens
Authors: Thayer Alshaabi, Daniel E. Milkie, Gaoxiang Liu, Cyna Shirazinejad, Jason L. Hong, Kemal Achour, Frederik Görlitz, Ana Milunovic-Jevtic, Cat Simmons, Ibrahim S. Abuzahriyeh, Erin Hong, Samara Erin Williams, Nathanael Harrison, Evan Huang, Eun Seok Bae, Alison N. Killilea, David G. Drubin, Ian A. Swinburne, Srigokul Upadhyayula, Eric Betzig
Abstract: High-resolution tissue imaging is often compromised by sample-induced optical aberrations that degrade resolution and contrast. While wavefront sensor-based adaptive optics (AO) can measure these aberrations, such hardware solutions are typically complex, expensive to implement, and slow when serially mapping spatially varying aberrations across large fields of view. Here, we introduce AOViFT (Adaptive Optical Vision Fourier Transformer) -- a machine learning-based aberration sensing framework built around a 3D multistage Vision Transformer that operates on Fourier domain embeddings. AOViFT infers aberrations and restores diffraction-limited performance in puncta-labeled specimens with substantially reduced computational cost, training time, and memory footprint compared to conventional architectures or real-space networks. We validated AOViFT on live gene-edited zebrafish embryos, demonstrating its ability to correct spatially varying aberrations using either a deformable mirror or post-acquisition deconvolution. By eliminating the need for the guide star and wavefront sensing hardware and simplifying the experimental workflow, AOViFT lowers technical barriers for high-resolution volumetric microscopy across diverse biological samples.

Paper number 47:
Title: Routing Guidance for Emerging Transportation Systems with Improved Dynamic Trip Equity
Authors: Ting Bai, Anni Li, Gehui Xu, Christos G. Cassandras, Andreas A. Malikopoulos
Abstract: In this letter, we present a dynamic routing guidance system that optimizes route recommendations for individual vehicles within an emerging transportation system while enhancing travelers' trip equity. We develop a framework to quantify trip quality and equity in a dynamic travel environment, providing new insights into how routing guidance influences equity in road transportation. Our approach enables real-time routing by incorporating both monitored and anticipated traffic congestion. We provide conditions that ensure achieving perfect trip equity for all travelers in a free-flow network. Finally, simulation studies on 1,000 vehicles traversing an urban road network in Boston demonstrate that our proposed method improves trip equity by approximately 13.3\% compared to the shortest-route strategy. In addition, the results reveal that our approach redistributes travel costs across vehicle types through route optimization, contributing to a more equitable transportation system.

Paper number 48:
Title: Equivalent-Circuit Thermal Model for Batteries with One-Shot Parameter Identification
Authors: Myisha A. Chowdhury, Qiugang Lu
Abstract: Accurate state of temperature (SOT) estimation for batteries is crucial for regulating their temperature within a desired range to ensure safe operation and optimal performance. The existing measurement-based methods often generate noisy signals and cannot scale up for large-scale battery packs. The electrochemical model-based methods, on the contrary, offer high accuracy but are computationally expensive. To tackle these issues, inspired by the equivalentcircuit voltage model for batteries, this paper presents a novel equivalent-circuit electro-thermal model (ECTM) for modeling battery surface temperature. By approximating the complex heat generation inside batteries with data-driven nonlinear (polynomial) functions of key measurable parameters such as state-of-charge (SOC), current, and terminal voltage, our ECTM is simplified into a linear form that admits rapid solutions. Such simplified ECTM can be readily identified with one single (one-shot) cycle data. The proposed model is extensively validated with benchmark NASA, MIT, and Oxford battery datasets. Simulation results verify the accuracy of the model, despite being identified with one-shot cycle data, in predicting battery temperatures robustly under different battery degradation status and ambient conditions.

Paper number 49:
Title: Single-Carrier Waveform Design for Joint Sensing and Communication
Authors: Ayoub Ammar Boudjelal, Rania Yasmine Bir, Huseyin Arslan
Abstract: The emergence of 6G wireless networks demands solutions that seamlessly integrate communication and sensing. This letter proposes a novel waveform design for joint sensing and communication (JSAC) systems, combining single-carrier interleaved frequency division multiplexing (SC-IFDM), a 5G communication candidate signal, with frequency modulated continuous wave (FMCW), widely used for sensing. The proposed waveform leverages the sparse nature of FMCW within SC-IFDM to achieve orthogonal integration in three steps: SC-IFDM symbols are allocated alongside the sparse FMCW, followed by the SC-IFDM transform into the time domain, and a cyclic prefix (CP) is applied in which phase shifts are introduced to the FMCW. Additionally, an enhanced channel estimation method is incorporated to boost system performance. Simulation results demonstrate the proposed waveform's ability to deliver high-resolution sensing and superior communication performance, surpassing traditional multicarrier designs.

Paper number 50:
Title: COVID 19 Diagnosis Analysis using Transfer Learning
Authors: Anjali Dharmik
Abstract: Coronaviruses transmit COVID-19, a rapidly spreading disease. A Coronavirus infection (COVID-19) was first discovered in December 2019 in Wuhan, China, and spread rapidly throughout the planet in exactly some months. because of this, the virus can cause severe symptoms and even death, especially within the elderly and in people with medical conditions. The virus causes acute respiratory infections in humans. the primary case was diagnosed in China in 2019 and the pandemic started in 2020. Since the quantity of cases of COVID-19 is increasing daily, there are only a limited number of test kits available in hospitals. So, to stop COVID-19 from spreading among people, an automatic diagnosis system must be implemented. during this study, three pre-trained neural networks supported convolutional neural networks (VGG16, VGG19, ResNet50) are proposed for detecting Coronavirus pneumonia infected patients through X-rays and computerized tomography (CT). By using cross-validation, we've got implemented binary classifications with two classes (COVID-19, Normal (healthy)). Taking into consideration the results obtained, the pre-trained ResNet50 model provides the simplest classification performance (97.77% accuracy, 100% sensitivity, 93.33% specificity, 98.00% F1-score) among the opposite three used models over 6259 images.

Paper number 51:
Title: TEANet: A Transpose-Enhanced Autoencoder Network for Wearable Stress Monitoring
Authors: Md Santo Ali, Sapnil Sarker Bipro, Mohammod Abdul Motin, Sumaiya Kabir, Manish Sharma, M. E. H. Chowdhury
Abstract: Mental stress poses a significant public health concern due to its detrimental effects on physical and mental well-being, necessitating the development of continuous stress monitoring tools for wearable devices. Blood volume pulse (BVP) sensors, readily available in many smartwatches, offer a convenient and cost-effective solution for stress monitoring. This study proposes a deep learning approach, a Transpose-Enhanced Autoencoder Network (TEANet), for stress detection using BVP signals. The proposed TEANet model was trained and validated utilizing a self-collected RUET SPML dataset, comprising 19 healthy subjects, and the publicly available wearable stress and affect detection (WESAD) dataset, comprising 15 healthy subjects. It achieves the highest accuracy of 92.51% and 96.94%, F1 scores of 95.03% and 95.95%, and kappa of 0.7915 and 0.9350 for RUET SPML, and WESAD datasets respectively. The proposed TEANet effectively detects mental stress through BVP signals with high accuracy, making it a promising tool for continuous stress monitoring. Furthermore, the proposed model effectively addresses class imbalances and demonstrates high accuracy, underscoring its potential for reliable real-time stress monitoring using wearable devices.

Paper number 52:
Title: Redefining Orthogonal Co-Existence: A Mother Waveform Framework for DFT-Based Waveforms
Authors: Ayoub Ammar Boudjelal, Rania Yasmine Bir, Huseyin Arslan
Abstract: In this paper, we introduce the concept of a mother waveform to address key challenges in 5th generation (5G) and 6th generation (6G) networks, including spectral efficiency, backward compatibility, enhanced flexibility, and the integration of joint sensing and communication (JSAC). We propose single-carrier interleaved frequency division multiplexing (SC-IFDM) as the mother waveform and demonstrate, through rigorous mathematical modeling, that it can generate all discrete Fourier transform (DFT)-based waveforms without requiring structural modifications. Specifically, by selectively configuring lattice indices and phase adjustments, SC-IFDM enables seamless adaptation to diverse waveforms, such as orthogonal frequency division multiplexing (OFDM), orthogonal chirp division multiplexing (OCDM), orthogonal time-frequency space (OTFS), affine frequency division multiplexing (AFDM), and frequency-modulated continuous wave (FMCW) within a unified framework. Critical aspects such as coexistence strategies and resource allocation are thoroughly explored. Simulation results demonstrate the proposed frameworks ability to deliver superior communication performance, robust sensing capabilities, and efficient coexistence, surpassing traditional waveform designs in scalability and adaptability.

Paper number 53:
Title: A Continual Learning-driven Model for Accurate and Generalizable Segmentation of Clinically Comprehensive and Fine-grained Whole-body Anatomies in CT
Authors: Dazhou Guo, Zhanghexuan Ji, Yanzhou Su, Dandan Zheng, Heng Guo, Puyang Wang, Ke Yan, Yirui Wang, Qinji Yu, Zi Li, Minfeng Xu, Jianfeng Zhang, Haoshen Li, Jia Ge, Tsung-Ying Ho, Bing-Shen Huang, Tashan Ai, Kuaile Zhao, Na Shen, Qifeng Wang, Yun Bian, Tingyu Wu, Peng Du, Hua Zhang, Feng-Ming Kong, Alan L. Yuille, Cher Heng Tan, Chunyan Miao, Perry J. Pickhardt, Senxiang Yan, Ronald M. Summers, Le Lu, Dakai Jin, Xianghua Ye
Abstract: Precision medicine in the quantitative management of chronic diseases and oncology would be greatly improved if the Computed Tomography (CT) scan of any patient could be segmented, parsed and analyzed in a precise and detailed way. However, there is no such fully annotated CT dataset with all anatomies delineated for training because of the exceptionally high manual cost, the need for specialized clinical expertise, and the time required to finish the task. To this end, we proposed a novel continual learning-driven CT model that can segment complete anatomies presented using dozens of previously partially labeled datasets, dynamically expanding its capacity to segment new ones without compromising previously learned organ knowledge. Existing multi-dataset approaches are not able to dynamically segment new anatomies without catastrophic forgetting and would encounter optimization difficulty or infeasibility when segmenting hundreds of anatomies across the whole range of body regions. Our single unified CT segmentation model, CL-Net, can highly accurately segment a clinically comprehensive set of 235 fine-grained whole-body anatomies. Composed of a universal encoder, multiple optimized and pruned decoders, CL-Net is developed using 13,952 CT scans from 20 public and 16 private high-quality partially labeled CT datasets of various vendors, different contrast phases, and pathologies. Extensive evaluation demonstrates that CL-Net consistently outperforms the upper limit of an ensemble of 36 specialist nnUNets trained per dataset with the complexity of 5% model size and significantly surpasses the segmentation accuracy of recent leading Segment Anything-style medical image foundation models by large margins. Our continual learning-driven CL-Net model would lay a solid foundation to facilitate many downstream tasks of oncology and chronic diseases using the most widely adopted CT imaging.

Paper number 54:
Title: Indoor Fusion Positioning Based on "IMU-Ultrasonic-UWB" and Factor Graph Optimization Method
Authors: Fengyun Zhang, Jia Li, Xiaoqing Zhang, Shukai Duan, Shuang-Hua Yang
Abstract: This paper presents a high-precision positioning system that integrates ultra-wideband (UWB) time difference of arrival (TDoA) measurements, inertial measurement unit (IMU) data, and ultrasonic sensors through factor graph optimization. To overcome the shortcomings of standalone UWB systems in non-line-of-sight (NLOS) scenarios and the inherent drift associated with inertial navigation, we developed a novel hybrid fusion framework. First, a dynamic covariance estimation mechanism is incorporated, which automatically adjusts measurement weights based on real-time channel conditions. Then, a tightly-coupled sensor fusion architecture is employed, utilizing IMU pre-integration theory for temporal synchronization. Finally, a sliding-window factor graph optimization backend is utilized, incorporating NLOS mitigation constraints. Experimental results in complex indoor environments show a 38\% improvement in positioning accuracy compared to conventional Kalman filter-based approaches, achieving a 12.3 cm root mean square (RMS) error under dynamic motion conditions. The system maintains robust performance even with intermittent UWB signal availability, down to a 40\% packet reception rate, effectively suppressing IMU drift through multi-modal constraint fusion. This work offers a practical solution for applications that require reliable indoor positioning in GPS-denied environments.

Paper number 55:
Title: System Identification Under Multi-rate Sensing Environment
Authors: Hiroshi Okajima, Risa Furukawa, Nobutomo Matsunaga
Abstract: This paper proposes a system identification algorithm for systems with multi-rate sensors in a discrete-time framework. It is challenging to obtain an accurate mathematical model when the ratios of inputs and outputs are different in the system. A cyclic reformulation-based model for multi-rate systems is formulated, and the multi-rate system can be reduced to a linear time-invariant system to derive the model under the multi-rate sensing environment. The proposed algorithm integrates a cyclic reformulation with a state coordinate transformation of the cycled system to enable precise identification of systems under the multi-rate sensing environment. The effectiveness of the proposed system identification method is demonstrated using numerical simulations.

Paper number 56:
Title: Suppression and Regulation of Thermal Birefringence in Optical Voltage Sensor with Isomerism Electrodes and Arbitrary Electric Field Direction Modulation
Authors: Jun Li, Qifeng Xu, Yifan Lin, Nan Xie
Abstract: The insufficient stability and reliability of Optical Voltage Sensor is primarily caused by thermal stress induced birefringence. In this paper, a method based on arbitrary electric field direction modulation and isomerism electrodes is proposed to suppress or regulate it. With the aid of multi-physics Finite Element Method, Jones Matrix and the theory of photoelastic effect, it is found that metal or transparent isomerism electrodes can generate a special thermal stress distribution, which regulates the birefringence in the optical path and their induced measurement error. The experiment is conducted on a 10mm cubic bismuth germanite crystal, with cutting directions 110, -110 and 001. The experiment result shows that Cu isomerism electrodes with electric field angle of 59.9 degrees could generate 37% less birefringence error compared to parallel plate electrodes, in the temperature range from 25 degrees Celsius to 40 degrees Celsius. However, the Indium Tin Oxide electrodes with field angle of 29.6 degrees produces approximately 7 times error because of its bad ductility and thermal conduction. The proposed modeling and suppression method for birefringence is beneficial to design of high accuracy optical voltage sensor or electro-optical modulator.

Paper number 57:
Title: Layered Nonlinear Model Predictive Control for Robust Stabilization of Hybrid Systems
Authors: Zachary Olkin, Aaron D. Ames
Abstract: Computing the receding horizon optimal control of nonlinear hybrid systems is typically prohibitively slow, limiting real-time implementation. To address this challenge, we propose a layered Model Predictive Control (MPC) architecture for robust stabilization of hybrid systems. A high level "hybrid" MPC is solved at a slow rate to produce a stabilizing hybrid trajectory, potentially sub-optimally, including a domain and guard sequence. This domain and guard sequence is passed to a low level "fixed mode" MPC which is a traditional, time-varying, state-constrained MPC that can be solved rapidly, e.g., using nonlinear programming (NLP) tools. A robust version of the fixed mode MPC is constructed by using tracking error tubes that are not guaranteed to have finite size for all time. Using these tubes, we demonstrate that the speed at which the fixed mode MPC is re-calculated is directly tied to the robustness of the system, thereby justifying the layered approach. Finally, simulation examples of a five link bipedal robot and a controlled nonlinear bouncing ball are used to illustrate the formal results.

Paper number 58:
Title: Epidemic Forecasting with a Hybrid Deep Learning Method Using CNN LSTM With WOA GWO Optimization: Global COVID-19 Case Study
Authors: Mousa Alizadeh, Mohammad Hossein Samaei, Azam Seilsepour, Mohammad TH Beheshti
Abstract: Effective epidemic modeling is essential for managing public health crises, requiring robust methods to predict disease spread and optimize resource allocation. This study introduces a novel deep learning framework that advances time series forecasting for infectious diseases, with its application to COVID 19 data as a critical case study. Our hybrid approach integrates Convolutional Neural Networks (CNNs) and Long Short Term Memory (LSTM) models to capture spatial and temporal dynamics of disease transmission across diverse regions. The CNN extracts spatial features from raw epidemiological data, while the LSTM models temporal patterns, yielding precise and adaptable predictions. To maximize performance, we employ a hybrid optimization strategy combining the Whale Optimization Algorithm (WOA) and Gray Wolf Optimization (GWO) to fine tune hyperparameters, such as learning rates, batch sizes, and training epochs enhancing model efficiency and accuracy. Applied to COVID 19 case data from 24 countries across six continents, our method outperforms established benchmarks, including ARIMA and standalone LSTM models, with statistically significant gains in predictive accuracy (e.g., reduced RMSE). This framework demonstrates its potential as a versatile method for forecasting epidemic trends, offering insights for resource planning and decision making in both historical contexts, like the COVID 19 pandemic, and future outbreaks.

Paper number 59:
Title: High-Resolution Range-Doppler Imaging from One-Bit PMCW Radar via Generative Adversarial Networks
Authors: Jingxian Wang, Moritz Kahlert, Tai Fei, Changxu Zhang, Zhaoze Wang, Markus Gardill
Abstract: Digital modulation schemes such as PMCW have recently attracted increasing attention as possible replacements for FMCW modulation in future automotive radar systems. A significant obstacle to their widespread adoption is the expensive and power-consuming ADC required at gigahertz frequencies. To mitigate these challenges, employing low-resolution ADC, such as one-bit, has been suggested. Nonetheless, using one-bit sampling results in the loss of essential information. This study explores two RD imaging methods in PMCW radar systems utilizing NN. The first method merges standard RD signal processing with a GAN, whereas the second method uses an E2E strategy in which traditional signal processing is substituted with an NN-based RD module. The findings indicate that these methods can substantially improve the probability of detecting targets in the range-Doppler domain.

Paper number 60:
Title: Robust Co-Optimization of Distribution Network Hardening and Mobile Resource Scheduling with Decision-Dependent Uncertainty
Authors: Donglai Ma, Xiaoyu Cao, Bo Zeng, Chen Chen, Qiaozhu Zhai, Qing-Shan Jia, Xiaohong Guan
Abstract: This paper studies the robust co-planning of proactive network hardening and mobile hydrogen energy resources (MHERs) scheduling, which is to enhance the resilience of power distribution network (PDN) against the disastrous events. A decision-dependent robust optimization model is formulated with min-max resilience constraint and discrete recourse structure, which helps achieve the load survivability target considering endogenous uncertainties. Different from the traditional model with a fixed uncertainty set, we adopt a dynamic representation that explicitly captures the endogenous uncertainties of network contingency as well as the available hydrogen storage levels of MHERs, which induces a decision-dependent uncertainty (DDU) set. Also, the multi-period adaptive routing and energy scheduling of MHERs are modeled as a mixed-integer recourse problem for further decreasing the resilience cost. Then, a nested parametric column-and-constraint generation (N-PC&CG) algorithm is customized and developed to solve this challenging formulation. By leveraging the structural property of the DDU set as well as the combination of discrete recourse decisions and the corresponding extreme points, we derive a strengthened solution scheme with nontrivial enhancement strategies to realize efficient and exact computation. Numerical results on 14-bus test system and 56-bus real-world distribution network demonstrate the resilience benefits and economical feasibility of the proposed method under different damage severity levels. Moreover, the enhanced N-PC&CG shows a superior solution capability to support prompt decisions for resilient planning with DDU models.

Paper number 61:
Title: Joint Antenna Position and Transmit Power Optimization for Pinching Antenna-Assisted ISAC Systems
Authors: Yunhui Qin, Yaru Fu, Haijun Zhang
Abstract: This letter explores how pinching antennas, an advanced flexible-antenna system, can enhance the performance of integrated sensing and communication (ISAC) systems by leveraging their adaptability, cost-effectiveness, and ability to facilitate line-of-sight transmission. To achieve this, a joint antenna positioning and transmit power optimization problem is formulated to maximize the total communication data rate while meeting the target sensing requirements and the system energy constraint. To address the complex non-convex optimization problem, we propose a maximum entropy-based reinforcement learning (MERL) solution. By maximizing cumulative reward and policy entropy, this approach effectively balances exploration and exploitation to enhance robustness. Numerical results demonstrate that the proposed MERL algorithm surpasses other benchmark schemes in cumulative reward, total data rate, sensing signal-to-noise ratio, and stability.

Paper number 62:
Title: PD-Skygroundhook Controller for Semi-Active Suspension System Using Magnetorheological Fluid Dampers
Authors: Hansol Lim, Jee Won Lee, Seung-Bok Choi, Jongseong Brad Choi
Abstract: This paper presents a Proportional-Derivative (PD) Skygroundhook controller for magnetorheological (MR) dampers in semi-active suspensions. Traditional skyhook, Groundhook, and hybrid Skygroundhook controllers are well-known for their ability to reduce body and wheel vibrations; however, each approach has limitations in handling a broad frequency spectrum and often relies on abrupt switching. By adding a derivative action to the classical Skygroundhook logic, the proposed PD-Skygroundhook method enhances high-frequency damping and stabilizes transition behaviors. By leveraging the fast response of MR dampers, our controller adjusts the damper force continuously in real time to match the desired damping force of PD-Skygroundhook controller with efficient computation. Experimental evaluations under bump excitations and sine-sweeping tests demonstrate a significant reduction in sprung mass acceleration and unsprung mass acceleration, outperforming standard Skygroundhook in both ride comfort and road handling. These results highlight that the derivative action effectively reduces resonance peaks and smooths out force transitions of regular Skygroundhook. Our method offers a robust alternative to more computationally demanding semi-active controllers.

Paper number 63:
Title: Robust Deep Joint Source Channel Coding for Task-Oriented Semantic Communications
Authors: Taewoo Park, Eunhye Hong, Yo-Seb Jeon, Namyoon Lee, Yongjune Kim
Abstract: Semantic communications based on deep joint source-channel coding (JSCC) aim to improve communication efficiency by transmitting only task-relevant information. However, ensuring robustness to the stochasticity of communication channels remains a key challenge in learning-based JSCC. In this paper, we propose a novel regularization technique for learning-based JSCC to enhance robustness against channel noise. The proposed method utilizes the Kullback-Leibler (KL) divergence as a regularizer term in the training loss, measuring the discrepancy between two posterior distributions: one under noisy channel conditions (noisy posterior) and one for a noise-free system (noise-free posterior). Reducing this KL divergence mitigates the impact of channel noise on task performance by keeping the noisy posterior close to the noise-free posterior. We further show that the expectation of the KL divergence given the encoded representation can be analytically approximated using the Fisher information matrix and the covariance matrix of the channel noise. Notably, the proposed regularization is architecture-agnostic, making it broadly applicable to general semantic communication systems over noisy channels. Our experimental results validate that the proposed regularization consistently improves task performance across diverse semantic communication systems and channel conditions.

Paper number 64:
Title: A Block-Sparse Bayesian Learning Algorithm with Dictionary Parameter Estimation for Multi-Sensor Data Fusion
Authors: Jakob Möderl, Anders Malte Westerkam, Alexander Venus, Erik Leitinger
Abstract: We propose an sparse Bayesian learning (SBL)-based method that leverages group sparsity and multiple parameterized dictionaries to detect the relevant dictionary entries and estimate their continuous parameters by combining data from multiple independent sensors. In a MIMO multi-radar setup, we demonstrate its effectiveness in jointly detecting and localizing multiple objects, while also emphasizing its broader applicability to various signal processing tasks. A key benefit of the proposed SBL-based method is its ability to resolve correlated dictionary entries-such as closely spaced objects-resulting in uncorrelated estimates that improve subsequent estimation stages. Through numerical simulations, we show that our method outperforms the newtonized orthogonal matching pursuit (NOMP) algorithm when two objects cross paths using a single radar. Furthermore, we illustrate how fusing measurements from multiple independent radars leads to enhanced detection and localization performance

Paper number 65:
Title: Task-Oriented Feature Compression for Multimodal Understanding via Device-Edge Co-Inference
Authors: Cheng Yuan, Zhening Liu, Jiashu Lv, Jiawei Shao, Yufei Jiang, Jun Zhang, Xuelong Li
Abstract: With the rapid development of large multimodal models (LMMs), multimodal understanding applications are emerging. As most LMM inference requests originate from edge devices with limited computational capabilities, the predominant inference pipeline involves directly forwarding the input data to an edge server which handles all computations. However, this approach introduces high transmission latency due to limited uplink bandwidth of edge devices and significant computation latency caused by the prohibitive number of visual tokens, thus hindering delay-sensitive tasks and degrading user experience. To address this challenge, we propose a task-oriented feature compression (TOFC) method for multimodal understanding in a device-edge co-inference framework, where visual features are merged by clustering and encoded by a learnable and selective entropy model before feature projection. Specifically, we employ density peaks clustering based on K nearest neighbors to reduce the number of visual features, thereby minimizing both data transmission and computational complexity. Subsequently, a learnable entropy model with hyperprior is utilized to encode and decode merged features, further reducing transmission overhead. To enhance compression efficiency, multiple entropy models are adaptively selected based on the characteristics of the visual features, enabling a more accurate estimation of the probability distribution. Comprehensive experiments on seven visual question answering benchmarks validate the effectiveness of the proposed TOFC method. Results show that TOFC achieves up to 60% reduction in data transmission overhead and 50% reduction in system latency while maintaining identical task performance, compared with traditional image compression methods.

Paper number 66:
Title: FNSE-SBGAN: Far-field Speech Enhancement with Schrodinger Bridge and Generative Adversarial Networks
Authors: Tong Lei, Qinwen Hu, Ziyao Lin, Andong Li, Rilin Chen, Meng Yu, Dong Yu, Jing Lu
Abstract: The current dominant approach for neural speech enhancement relies on purely-supervised deep learning using simulated pairs of far-field noisy-reverberant speech (mixtures) and clean speech. However, these trained models often exhibit limited generalizability to real-recorded mixtures. To address this issue, this study investigates training enhancement models directly on real mixtures. Specifically, we revisit the single-channel far-field to near-field speech enhancement (FNSE) task, focusing on real-world data characterized by low signal-to-noise ratio (SNR), high reverberation, and mid-to-high frequency attenuation. We propose FNSE-SBGAN, a novel framework that integrates a Schrodinger Bridge (SB)-based diffusion model with generative adversarial networks (GANs). Our approach achieves state-of-the-art performance across various metrics and subjective evaluations, significantly reducing the character error rate (CER) by up to 14.58% compared to far-field signals. Experimental results demonstrate that FNSE-SBGAN preserves superior subjective quality and establishes a new benchmark for real-world far-field speech enhancement. Additionally, we introduce a novel evaluation framework leveraging matrix rank analysis in the time-frequency domain, providing systematic insights into model performance and revealing the strengths and weaknesses of different generative methods.

Paper number 67:
Title: Past, Present, and Future of Spatial Audio and Room Acoustics
Authors: Shoichi Koyama, Enzo De Sena, Prasanga Samarasinghe, Mark R. P. Thomas, Fabio Antonacci
Abstract: The study of spatial audio and room acoustics aims to create immersive audio experiences by modeling the physics and psychoacoustics of how sound behaves in space. In the long history of this research area, various key technologies have been developed based both on theoretical advancements and practical innovations. We highlight historical achievements, initiative activities, recent advancements, and future outlooks in the research area of spatial audio recording and reproduction, and room acoustic simulation, modeling, analysis, and control.

Paper number 68:
Title: Goal-Oriented Remote Tracking Through Correlated Observations in Pull-based Communications
Authors: Abolfazl Zakeri, Mohammad Moltafet, Marian Codreanu
Abstract: We address the real-time remote tracking problem in a status update system comprising two sensors, two independent information sources, and a remote monitor. The status updating follows a pull-based communication, where the monitor commands/pulls the sensors for status updates, i.e., the actual state of the sources. We consider that the observations are correlated, meaning that each sensor sent data could also include the state of the other source due to, e.g., inter-sensor communication or proximity-based monitoring. The effectiveness of data communication is measured by a generic distortion, capturing the underlying application goal. We provide optimal command/pulling policies for the monitor that minimize the average weighted sum distortion and transmission cost. Since the monitor cannot fully observe the exact state of each source, we propose a partially observable Markov decision process (POMDP) and reformulate it as a belief MDP problem. We then effectively truncate the infinite belief space and transform it into a finite-state MDP problem, which is solved via relative value iteration. Simulation results show the effectiveness of the derived policy over the age-optimal and max-age-first baseline policies.

Paper number 69:
Title: Moment-based Characterization of Spatially Distributed Sources in SAR Tomography
Authors: Colin Cros, Laurent Ferro-Famil (CESBIO)
Abstract: This paper presents a non-parametric method for 3-D imaging of natural volumes using Synthetic Aperture Radar tomography. This array processing-based technique aims at characterizing a spatially distributed density of incoherent sources, whose shape is imprecisely known. The proposed technique estimates the moments of the reflectivity density using a low-complexity covariance matching approach, and retrieves the mean location, dispersion, and power of the distributed source. Numerical simulations of realistic tomographic scenarios show that the proposed model-free scheme achieves better accuracy than slightly misspecified maximum likelihood estimators, derived from approximately known distribution shapes.

Paper number 70:
Title: How Good is my Histopathology Vision-Language Foundation Model? A Holistic Benchmark
Authors: Roba Al Majzoub, Hashmat Malik, Muzammal Naseer, Zaigham Zaheer, Tariq Mahmood, Salman Khan, Fahad Khan
Abstract: Recently, histopathology vision-language foundation models (VLMs) have gained popularity due to their enhanced performance and generalizability across different downstream tasks. However, most existing histopathology benchmarks are either unimodal or limited in terms of diversity of clinical tasks, organs, and acquisition instruments, as well as their partial availability to the public due to patient data privacy. As a consequence, there is a lack of comprehensive evaluation of existing histopathology VLMs on a unified benchmark setting that better reflects a wide range of clinical scenarios. To address this gap, we introduce HistoVL, a fully open-source comprehensive benchmark comprising images acquired using up to 11 various acquisition tools that are paired with specifically crafted captions by incorporating class names and diverse pathology descriptions. Our Histo-VL includes 26 organs, 31 cancer types, and a wide variety of tissue obtained from 14 heterogeneous patient cohorts, totaling more than 5 million patches obtained from over 41K WSIs viewed under various magnification levels. We systematically evaluate existing histopathology VLMs on Histo-VL to simulate diverse tasks performed by experts in real-world clinical scenarios. Our analysis reveals interesting findings, including large sensitivity of most existing histopathology VLMs to textual changes with a drop in balanced accuracy of up to 25% in tasks such as Metastasis detection, low robustness to adversarial attacks, as well as improper calibration of models evident through high ECE values and low model prediction confidence, all of which can affect their clinical implementation.

Paper number 71:
Title: Designing RF-Powered Battery-Less Electronic Shelf Labels With COTS Components
Authors: Jarne Van Mulders, Gilles Callebaut
Abstract: This paper presents a preliminary study exploring the feasibility of designing batteryless electronic shelf labels (ESLs) powered by radio frequency wireless power transfer using commercial off-the-shelf components. The proposed ESL design is validated through a dedicated testbed and involves a detailed analysis of design choices, including energy consumption, energy conversion, and storage solutions. A leaded aluminium electrolytic capacitor is selected as the primary energy storage element, balancing cost and performance while maintaining compactness. Experimental evaluations demonstrate that an ESL can update its display within 4 to 120 minutes, depending on input power and RF frequency, with harvester efficiencies reaching up to 30 %. Challenges such as low harvester efficiency, extended update times, and hardware constraints are identified, highlighting opportunities for future optimizations. This work provides valuable insights into system design considerations for RF-powered ESLs and establishes a foundation for further research in energy-neutral Internet of Things applications.

Paper number 72:
Title: A Unified Framework for Innovation-based Stochastic and Deterministic Event Triggers
Authors: Eva Julia Schmitt, Benjamin Noack
Abstract: Resources such as bandwidth and energy are limited in many wireless communications use cases, especially when large numbers of sensors and fusion centers need to exchange information frequently. One opportunity to overcome resource constraints is the use of event-based transmissions and estimation to transmit only information that contributes significantly to the reconstruction of the system's state. The design of efficient triggering policies and estimators is crucial for successful event-based transmissions. While previously deterministic and stochastic event triggering policies have been treated separately, this paper unifies the two approaches and gives insights into the design of consistent trigger-matching estimators. Two different estimators are presented, and different pairs of triggers and estimators are evaluated through simulation studies.

Paper number 73:
Title: Innovation diffusion dynamics toward long-term behavioral shifts
Authors: Lisa Piccinin, Valentina Breschi, Chiara Ravazzi, Fabrizio Dabbene, Mara Tanelli
Abstract: Sustainable technologies and services can play a pivotal role in the transition to "greener" habits. Their widespread adoption is thus crucial, and understanding how to foster this phenomenon in a systematic way could have a major impact on our future. With this in mind, in this work we propose an extension of the Friedkin-Johnsen opinion dynamics model toward characterizing the long-term impact of (structural) fostering policies. We then propose alternative nudging strategies that target a trade-off between widespread adoption and investments under budget constraints, showing the impact of our modeling and design choices on inclination shifts over a set of numerical tests.

Paper number 74:
Title: Compensating Hysteresis and Mechanical Misalignment in Piezo-Stepper Actuators
Authors: Max van Meer, Tim van Meijel, Emile van Halsema, Edwin Verschueren, Gert Witvoet, Tom Oomen
Abstract: Piezo-stepper actuators enable accurate positioning through the sequential contraction and expansion of piezoelectric elements, generating a walking motion. The aim of this paper is to reduce velocity ripples caused by parasitic effects, due to hysteresis in the piezoelectric material and mechanical misalignments, through suitable feedforward control. The presented approach involves the integration of a rate-dependent hysteresis model with a position-dependent feedforward learning scheme to compensate for these effects. Experimental results show that this approach leads to a significant reduction in the velocity ripples, even when the target velocity is changed. These results enable the use of piezo-stepper actuators in applications requiring high positioning accuracy and stiffness over a long stroke, without requiring expensive position sensors for high-gain feedback.

Paper number 75:
Title: OSLO-IC: On-the-Sphere Learned Omnidirectional Image Compression with Attention Modules and Spatial Context
Authors: Paul Wawerek-López, Navid Mahmoudian Bidgoli, Pascal Frossard, André Kaup, Thomas Maugey
Abstract: Developing effective 360-degree (spherical) image compression techniques is crucial for technologies like virtual reality and automated driving. This paper advances the state-of-the-art in on-the-sphere learning (OSLO) for omnidirectional image compression framework by proposing spherical attention modules, residual blocks, and a spatial autoregressive context model. These improvements achieve a 23.1% bit rate reduction in terms of WS-PSNR BD rate. Additionally, we introduce a spherical transposed convolution operator for upsampling, which reduces trainable parameters by a factor of four compared to the pixel shuffling used in the OSLO framework, while maintaining similar compression performance. Therefore, in total, our proposed method offers significant rate savings with a smaller architecture and can be applied to any spherical convolutional application.

Paper number 76:
Title: A Design of Denser-Graph-Frequency Graph Fourier Frames for Graph Signal Analysis
Authors: Kaito Nitani, Seisuke Kyochi
Abstract: This paper introduces a design method for densergraph-frequency graph Fourier frames (DGFFs) to enhance graph signal processing and analysis. The graph Fourier transform (GFT) enables us to analyze graph signals in the graph spectral domain and facilitates various graph signal processing tasks, such as filtering, sampling and reconstruction, denoising, and so on. However, the conventional GFT faces two significant limitations. First, unlike the discrete Fourier transform and its variants (such as discrete cosine transforms), the graph frequencies of the derived graph Fourier basis (GFB) from a given graph tend to be unevenly distributed or localized, which leads to biased spectral analysis. Second, the GFB used in GFT does not provide an efficient sparse representation of graph signals compared to overcomplete systems like frames. To overcome these challenges, we propose adding oscillating vectors with intermediate graph frequencies between the original vectors in the GFB for both undirected and directed graphs, constructing GFFs with densergraph frequencies. The resulting DGFFs are expected to enable more accurate graph signal analysis. Furthermore, we propose a graph filtering method based on the DGFFs. In experiments, we apply the DGFFs to practical applications such as graph signal recovery, demonstrating superior performance compared to existing GFBs.

Paper number 77:
Title: Prioritized Planning for Continuous-time Lifelong Multi-agent Pathfinding
Authors: Alvin Combrink, Sabino Francesco Roselli, Martin Fabian
Abstract: Multi-agent Path Finding (MAPF) is the problem of planning collision-free movements of agents such that they get from where they are to where they need to be. Commonly, agents are located on a graph and can traverse edges. This problem has many variations and has been studied for decades. Two such variations are the continuous-time and the lifelong MAPF problems. In the continuous-time MAPF problem, edges can have non-unit lengths and agents can traverse them at any real-valued time. Additionally, agent volumes are often included. In the lifelong MAPF problem, agents must attend to a continuous stream of incoming tasks. Much work has been devoted to designing solution methods within these two areas. However, to our knowledge, the combined problem of continuous-time lifelong MAPF has yet to be addressed. This work addresses continuous-time lifelong MAPF with agent volumes by presenting the fast and sub-optimal Continuous-time Prioritized Lifelong Planner (CPLP). CPLP continuously re-prioritizes tasks, assigns agents to them, and computes agent plans using a combination of two path planners; one based on CCBS and the other on SIPP. Experimental results with up to $400$ agents on graphs with $4000$ vertices demonstrate average computation times below $20$ ms per call. In online settings where available time to compute plans is limited, CPLP ensures collision-free movement even when failing to meet these time limits. Therefore, the robustness of CPLP highlights its potential for real-world applications.

Paper number 78:
Title: Equalization-Enhanced Phase Noise: Modeling and DSP-aware Analysis
Authors: Sebastian Jung, Tim Janz, Vahid Aref, Stephan ten Brink
Abstract: In coherent optical communication systems the laser phase noise is commonly modeled as a Wiener process. We propose a sliding-window based linearization of the phase noise, enabling a novel description. We show that, by stochastically modeling the residual error introduced by this approximation, equalization-enhanced phase noise (EEPN) can be described and decomposed into four different components. Furthermore, we analyze the four components separately and provide a stochastical model for each of them. This novel model allows to predict the impact of well-known algorithms in coherent digital signal processing (DSP) pipelines such as timing recovery (TR) and carrier phase recovery (CPR) on each of the terms. Thus, it enables to approximate the resulting signal affected by EEPN after each of these DSP steps and helps to derive appropriate ways of mitigating such effects.

Paper number 79:
Title: Anatomically and Metabolically Informed Diffusion for Unified Denoising and Segmentation in Low-Count PET Imaging
Authors: Menghua Xia, Kuan-Yin Ko, Der-Shiun Wang, Ming-Kai Chen, Qiong Liu, Huidong Xie, Liang Guo, Wei Ji, Jinsong Ouyang, Reimund Bayerlein, Benjamin A. Spencer, Quanzheng Li, Ramsey D. Badawi, Georges El Fakhri, Chi Liu
Abstract: Positron emission tomography (PET) image denoising, along with lesion and organ segmentation, are critical steps in PET-aided diagnosis. However, existing methods typically treat these tasks independently, overlooking inherent synergies between them as correlated steps in the analysis pipeline. In this work, we present the anatomically and metabolically informed diffusion (AMDiff) model, a unified framework for denoising and lesion/organ segmentation in low-count PET imaging. By integrating multi-task functionality and exploiting the mutual benefits of these tasks, AMDiff enables direct quantification of clinical metrics, such as total lesion glycolysis (TLG), from low-count inputs. The AMDiff model incorporates a semantic-informed denoiser based on diffusion strategy and a denoising-informed segmenter utilizing nnMamba architecture. The segmenter constrains denoised outputs via a lesion-organ-specific regularizer, while the denoiser enhances the segmenter by providing enriched image information through a denoising revision module. These components are connected via a warming-up mechanism to optimize multitask interactions. Experiments on multi-vendor, multi-center, and multi-noise-level datasets demonstrate the superior performance of AMDiff. For test cases below 20% of the clinical count levels from participating sites, AMDiff achieves TLG quantification biases of -26.98%, outperforming its ablated versions which yield biases of -35.85% (without the lesion-organ-specific regularizer) and -40.79% (without the denoising revision module).

Paper number 80:
Title: Artificial Intelligence-Driven Prognostic Classification of COVID-19 Using Chest X-rays: A Deep Learning Approach
Authors: Alfred Simbun, Suresh Kumar
Abstract: Background: The COVID-19 pandemic has overwhelmed healthcare systems, emphasizing the need for AI-driven tools to assist in rapid and accurate patient prognosis. Chest X-ray imaging is a widely available diagnostic tool, but existing methods for prognosis classification lack scalability and efficiency. Objective: This study presents a high-accuracy deep learning model for classifying COVID-19 severity (Mild, Moderate, and Severe) using Chest X-ray images, developed on Microsoft Azure Custom Vision. Methods: Using a dataset of 1,103 confirmed COVID-19 X-ray images from AIforCOVID, we trained and validated a deep learning model leveraging Convolutional Neural Networks (CNNs). The model was evaluated on an unseen dataset to measure accuracy, precision, and recall. Results: Our model achieved an average accuracy of 97%, with specificity of 99%, sensitivity of 87%, and an F1-score of 93.11%. When classifying COVID-19 severity, the model achieved accuracies of 89.03% (Mild), 95.77% (Moderate), and 81.16% (Severe). These results demonstrate the model's potential for real-world clinical applications, aiding in faster decision-making and improved resource allocation. Conclusion: AI-driven prognosis classification using deep learning can significantly enhance COVID-19 patient management, enabling early intervention and efficient triaging. Our study provides a scalable, high-accuracy AI framework for integrating deep learning into routine clinical workflows. Future work should focus on expanding datasets, external validation, and regulatory compliance to facilitate clinical adoption.

Paper number 81:
Title: Local-Global Learning of Interpretable Control Policies: The Interface between MPC and Reinforcement Learning
Authors: Thomas Banker, Nathan P. Lawrence, Ali Mesbah
Abstract: Making optimal decisions under uncertainty is a shared problem among distinct fields. While optimal control is commonly studied in the framework of dynamic programming, it is approached with differing perspectives of the Bellman optimality condition. In one perspective, the Bellman equation is used to derive a global optimality condition useful for iterative learning of control policies through interactions with an environment. Alternatively, the Bellman equation is also widely adopted to derive tractable optimization-based control policies that satisfy a local notion of optimality. By leveraging ideas from the two perspectives, we present a local-global paradigm for optimal control suited for learning interpretable local decision makers that approximately satisfy the global Bellman equation. The benefits and practical complications in local-global learning are discussed. These aspects are exemplified through case studies, which give an overview of two distinct strategies for unifying reinforcement learning and model predictive control. We discuss the challenges and trade-offs in these local-global strategies, towards highlighting future research opportunities for safe and optimal decision-making under uncertainty.

Paper number 82:
Title: Integrating AI for Human-Centric Breast Cancer Diagnostics: A Multi-Scale and Multi-View Swin Transformer Framework
Authors: Farnoush Bayatmakou, Reza Taleei, Milad Amir Toutounchian, Arash Mohammadi
Abstract: Despite advancements in Computer-Aided Diagnosis (CAD) systems, breast cancer remains one of the leading causes of cancer-related deaths among women worldwide. Recent breakthroughs in Artificial Intelligence (AI) have shown significant promise in development of advanced Deep Learning (DL) architectures for breast cancer diagnosis through mammography. In this context, the paper focuses on the integration of AI within a Human-Centric workflow to enhance breast cancer diagnostics. Key challenges are, however, largely overlooked such as reliance on detailed tumor annotations and susceptibility to missing views, particularly during test time. To address these issues, we propose a hybrid, multi-scale and multi-view Swin Transformer-based framework (MSMV-Swin) that enhances diagnostic robustness and accuracy. The proposed MSMV-Swin framework is designed to work as a decision-support tool, helping radiologists analyze multi-view mammograms more effectively. More specifically, the MSMV-Swin framework leverages the Segment Anything Model (SAM) to isolate the breast lobe, reducing background noise and enabling comprehensive feature extraction. The multi-scale nature of the proposed MSMV-Swin framework accounts for tumor-specific regions as well as the spatial characteristics of tissues surrounding the tumor, capturing both localized and contextual information. The integration of contextual and localized data ensures that MSMV-Swin's outputs align with the way radiologists interpret mammograms, fostering better human-AI interaction and trust. A hybrid fusion structure is then designed to ensure robustness against missing views, a common occurrence in clinical practice when only a single mammogram view is available.

Paper number 83:
Title: LEAVS: An LLM-based Labeler for Abdominal CT Supervision
Authors: Ricardo Bigolin Lanfredi, Yan Zhuang, Mark Finkelstein, Praveen Thoppey Srinivasan Balamuralikrishna, Luke Krembs, Brandon Khoury, Arthi Reddy, Pritam Mukherjee, Neil M. Rofsky, Ronald M. Summers
Abstract: Extracting structured labels from radiology reports has been employed to create vision models to simultaneously detect several types of abnormalities. However, existing works focus mainly on the chest region. Few works have been investigated on abdominal radiology reports due to more complex anatomy and a wider range of pathologies in the abdomen. We propose LEAVS (Large language model Extractor for Abdominal Vision Supervision). This labeler can annotate the certainty of presence and the urgency of seven types of abnormalities for nine abdominal organs on CT radiology reports. To ensure broad coverage, we chose abnormalities that encompass most of the finding types from CT reports. Our approach employs a specialized chain-of-thought prompting strategy for a locally-run LLM using sentence extraction and multiple-choice questions in a tree-based decision system. We demonstrate that the LLM can extract several abnormality types across abdominal organs with an average F1 score of 0.89, significantly outperforming competing labelers and humans. Additionally, we show that extraction of urgency labels achieved performance comparable to human annotations. Finally, we demonstrate that the abnormality labels contain valuable information for training a single vision model that classifies several organs as normal or abnormal. We release our code and structured annotations for a public CT dataset containing over 1,000 CT volumes.

Paper number 84:
Title: Parameter Invariance Analysis of Moment Equations Using Dulmage-Mendelsohn Decomposition
Authors: Akito Igarashi, Yutaka Hori
Abstract: Living organisms maintain stable functioning amid environmental fluctuations through homeostasis, a mechanism that preserves a system's behavior despite changes in environmental conditions. To elucidate homeostasis in stochastic biochemical reactions, theoretical tools for assessing population-level invariance under parameter perturbations are crucial. In this paper, we propose a systematic method for identifying the stationary moments that remain invariant under parameter perturbations by leveraging the structural properties of the stationary moment equations. A key step in this development is addressing the underdetermined nature of moment equations, which has traditionally made it difficult to characterize how stationary moments depend on system parameters. To overcome this, we utilize the Dulmage-Mendelsohn (DM) decomposition of the coefficient matrix to extract welldetermined subequations and reveal their hierarchical structure. Leveraging this structure, we identify stationary moments whose partial derivatives with respect to parameters are structurally zero, facilitating the exploration of fundamental constraints that govern homeostatic behavior in stochastic biochemical systems.

Paper number 85:
Title: On Sampling Time and Invariance
Authors: Spencer Schutz, Charlott Vallon, Ben Recht, Francesco Borrelli
Abstract: Invariant sets define regions of the state space where system constraints are always satisfied. The majority of numerical techniques for computing invariant sets - whether exact, approximate, or based on pure data-driven rollouts - have been developed for discrete-time systems with a fixed sampling time. Understanding how invariant sets change with sampling time is critical for designing adaptive-sampling control schemes that ensure constraint satisfaction. This paper investigates the relationship between control invariance and the sampling frequency of the feedback controller. We introduce the notion of M-step hold control invariance and demonstrate that it generalizes traditional control invariance. We propose a computational method to calculate M-step hold invariants and show its practical use to assess the link between the feedback control sampling frequency and constraint satisfaction. We extend the framework to account for robustness against model mismatches and discretization errors, paving the way for adaptive-sampling constrained control strategies.

Paper number 86:
Title: Continuous-time Data-driven Barrier Certificate Synthesis
Authors: Luke Rickard, Alessandro Abate, Kostas Margellos
Abstract: We consider the problem of verifying safety for continuous-time dynamical systems. Developing upon recent advancements in data-driven verification, we use only a finite number of sampled trajectories to learn a barrier certificate, namely a function which verifies safety. We train a safety-informed neural network to act as this certificate, with an appropriately designed loss function to encompass the safety conditions. In addition, we provide probabilistic generalisation guarantees from discrete samples of continuous trajectories, to unseen continuous ones. Numerical investigations demonstrate the efficacy of our approach and contrast it with related results in the literature.

Paper number 87:
Title: U2AD: Uncertainty-based Unsupervised Anomaly Detection Framework for Detecting T2 Hyperintensity in MRI Spinal Cord
Authors: Qi Zhang, Xiuyuan Chen, Ziyi He, Kun Wang, Lianming Wu, Hongxing Shen, Jianqi Sun
Abstract: T2 hyperintensities in spinal cord MR images are crucial biomarkers for conditions such as degenerative cervical myelopathy. However, current clinical diagnoses primarily rely on manual evaluation. Deep learning methods have shown promise in lesion detection, but most supervised approaches are heavily dependent on large, annotated datasets. Unsupervised anomaly detection (UAD) offers a compelling alternative by eliminating the need for abnormal data annotations. However, existing UAD methods rely on curated normal datasets and their performance frequently deteriorates when applied to clinical datasets due to domain shifts. We propose an Uncertainty-based Unsupervised Anomaly Detection framework, termed U2AD, to address these limitations. Unlike traditional methods, U2AD is designed to be trained and tested within the same clinical dataset, following a "mask-and-reconstruction" paradigm built on a Vision Transformer-based architecture. We introduce an uncertainty-guided masking strategy to resolve task conflicts between normal reconstruction and anomaly detection to achieve an optimal balance. Specifically, we employ a Monte-Carlo sampling technique to estimate reconstruction uncertainty mappings during training. By iteratively optimizing reconstruction training under the guidance of both epistemic and aleatoric uncertainty, U2AD reduces overall reconstruction variance while emphasizing regions. Experimental results demonstrate that U2AD outperforms existing supervised and unsupervised methods in patient-level identification and segment-level localization tasks. This framework establishes a new benchmark for incorporating uncertainty guidance into UAD, highlighting its clinical utility in addressing domain shifts and task conflicts in medical image anomaly detection. Our code is available: this https URL

Paper number 88:
Title: Kernel-based error bounds of bilinear Koopman surrogate models for nonlinear data-driven control
Authors: Robin Strässer, Manuel Schaller, Julian Berberich, Karl Worthmann, Frank Allgöwer
Abstract: We derive novel deterministic bounds on the approximation error of data-based bilinear surrogate models for unknown nonlinear systems. The surrogate models are constructed using kernel-based extended dynamic mode decomposition to approximate the Koopman operator in a reproducing kernel Hilbert space. Unlike previous methods that require restrictive assumptions on the invariance of the dictionary, our approach leverages kernel-based dictionaries that allow us to control the projection error via pointwise error bounds, overcoming a significant limitation of existing theoretical guarantees. The derived state- and input-dependent error bounds allow for direct integration into Koopman-based robust controller designs with closed-loop guarantees for the unknown nonlinear system. Numerical examples illustrate the effectiveness of the proposed framework.

Paper number 89:
Title: Data-Driven Estimation of Structured Singular Values
Authors: Margarita A. Guerrero, Braghadeesh Lakshminarayanan, Cristian R. Rojas
Abstract: Estimating the size of the modeling error is crucial for robust control. Over the years, numerous metrics have been developed to quantify the model error in a control relevant manner. One of the most important such metrics is the structured singular value, as it leads to necessary and sufficient conditions for ensuring stability and robustness in feedback control under structured model uncertainty. Although the computation of the structured singular value is often intractable, lower and upper bounds for it can often be obtained if a model of the system is known. In this paper, we introduce a fully data-driven method to estimate a lower bound for the structured singular value, by conducting experiments on the system and applying power iterations to the collected data. Our numerical simulations demonstrate that this method effectively lower bounds the structured singular value, yielding results comparable to those obtained using the Robust Control toolbox of MATLAB.

Paper number 90:
Title: CORDIC Is All You Need
Authors: Omkar Kokane, Adam Teman, Anushka Jha, Guru Prasath SL, Gopal Raut, Mukul Lokhande, S. V. Jaya Chand, Tanushree Dewangan, Santosh Kumar Vishvakarma
Abstract: Artificial intelligence necessitates adaptable hardware accelerators for efficient high-throughput million operations. We present pipelined architecture with CORDIC block for linear MAC computations and nonlinear iterative Activation Functions (AF) such as $tanh$, $sigmoid$, and $softmax$. This approach focuses on a Reconfigurable Processing Engine (RPE) based systolic array, with 40\% pruning rate, enhanced throughput up to 4.64$\times$, and reduction in power and area by 5.02 $\times$ and 4.06 $\times$ at CMOS 28 nm, with minor accuracy loss. FPGA implementation achieves a reduction of up to 2.5 $\times$ resource savings and 3 $\times$ power compared to prior works. The Systolic CORDIC engine for Reconfigurability and Enhanced throughput (SYCore) deploys an output stationary dataflow with the CAESAR control engine for diverse AI workloads such as Transformers, RNNs/LSTMs, and DNNs for applications like image detection, LLMs, and speech recognition. The energy-efficient and flexible approach extends the enhanced approach for edge AI accelerators supporting emerging workloads.

Paper number 91:
Title: Generalization of Video-Based Heart Rate Estimation Methods To Low Illumination and Elevated Heart Rates
Authors: Bhargav Acharya, William Saakyan, Barbara Hammer, Hanna Drimalla
Abstract: Heart rate is a physiological signal that provides information about an individual's health and affective state. Remote photoplethysmography (rPPG) allows the estimation of this signal from video recordings of a person's face. Classical rPPG methods make use of signal processing techniques, while recent rPPG methods utilize deep learning networks. Methods are typically evaluated on datasets collected in well-lit environments with participants at resting heart rates. However, little investigation has been done on how well these methods adapt to variations in illumination and heart rate. In this work, we systematically evaluate representative state-of-the-art methods for remote heart rate estimation. Specifically, we evaluate four classical methods and four deep learning-based rPPG estimation methods in terms of their generalization ability to changing scenarios, including low lighting conditions and elevated heart rates. For a thorough evaluation of existing approaches, we collected a novel dataset called CHILL, which systematically varies heart rate and lighting conditions. The dataset consists of recordings from 45 participants in four different scenarios. The video data was collected under two different lighting conditions (high and low) and normal and elevated heart rates. In addition, we selected two public datasets to conduct within- and cross-dataset evaluations of the rPPG methods. Our experimental results indicate that classical methods are not significantly impacted by low-light conditions. Meanwhile, some deep learning methods were found to be more robust to changes in lighting conditions but encountered challenges in estimating high heart rates. The cross-dataset evaluation revealed that the selected deep learning methods underperformed when influencing factors such as elevated heart rates and low lighting conditions were not present in the training set.

Paper number 92:
Title: ECLARE: Efficient cross-planar learning for anisotropic resolution enhancement
Authors: Samuel W. Remedios, Shuwen Wei, Shuo Han, Jinwei Zhang, Aaron Carass, Kurt G. Schilling, Dzung L. Pham, Jerry L. Prince, Blake E. Dewey
Abstract: In clinical imaging, magnetic resonance (MR) image volumes are often acquired as stacks of 2D slices, permitting decreased scan times, improved signal-to-noise ratio, and image contrasts unique to 2D MR pulse sequences. While this is sufficient for clinical evaluation, automated algorithms designed for 3D analysis perform sub-optimally on 2D-acquired scans, especially those with thick slices and gaps between slices. Super-resolution (SR) methods aim to address this problem, but previous methods do not address all of the following: slice profile shape estimation, slice gap, domain shift, and non-integer / arbitrary upsampling factors. In this paper, we propose ECLARE (Efficient Cross-planar Learning for Anisotropic Resolution Enhancement), a self-SR method that addresses each of these factors. ECLARE estimates the slice profile from the 2D-acquired multi-slice MR volume, trains a network to learn the mapping from low-resolution to high-resolution in-plane patches from the same volume, and performs SR with anti-aliasing. We compared ECLARE to cubic B-spline interpolation, SMORE, and other contemporary SR methods. We used realistic and representative simulations so that quantitative performance against a ground truth could be computed, and ECLARE outperformed all other methods in both signal recovery and downstream tasks. On real data for which there is no ground truth, ECLARE demonstrated qualitative superiority over other methods as well. Importantly, as ECLARE does not use external training data it cannot suffer from domain shift between training and testing. Our code is open-source and available at this https URL.

Paper number 93:
Title: Safe Multi-Robotic Arm Interaction via 3D Convex Shapes
Authors: Ali Umut Kaypak, Shiqing Wei, Prashanth Krishnamurthy, Farshad Khorrami
Abstract: Inter-robot collisions pose a significant safety risk when multiple robotic arms operate in close proximity. We present an online collision avoidance methodology leveraging 3D convex shape-based High-Order Control Barrier Functions (HOCBFs) to address this issue. While prior works focused on using Control Barrier Functions (CBFs) for human-robotic arm and single-arm collision avoidance, we explore the problem of collision avoidance between multiple robotic arms operating in a shared space. In our methodology, we utilize the proposed HOCBFs as centralized and decentralized safety filters. These safety filters are compatible with any nominal controller and ensure safety without significantly restricting the robots' workspace. A key challenge in implementing these filters is the computational overhead caused by the large number of safety constraints and the computation of a Hessian matrix per constraint. We address this challenge by employing numerical differentiation methods to approximate computationally intensive terms. The effectiveness of our method is demonstrated through extensive simulation studies and real-world experiments with Franka Research 3 robotic arms.

Paper number 94:
Title: Bayes and Biased Estimators Without Hyper-parameter Estimation: Comparable Performance to the Empirical-Bayes-Based Regularized Estimator
Authors: Yue Ju, Bo Wahlberg, Håkan Hjalmarsson
Abstract: Regularized system identification has become a significant complement to more classical system identification. It has been numerically shown that kernel-based regularized estimators often perform better than the maximum likelihood estimator in terms of minimizing mean squared error (MSE). However, regularized estimators often require hyper-parameter estimation. This paper focuses on ridge regression and the regularized estimator by employing the empirical Bayes hyper-parameter estimator. We utilize the excess MSE to quantify the MSE difference between the empirical-Bayes-based regularized estimator and the maximum likelihood estimator for large sample sizes. We then exploit the excess MSE expressions to develop both a family of generalized Bayes estimators and a family of closed-form biased estimators. They have the same excess MSE as the empirical-Bayes-based regularized estimator but eliminate the need for hyper-parameter estimation. Moreover, we conduct numerical simulations to show that the performance of these new estimators is comparable to the empirical-Bayes-based regularized estimator, while computationally, they are more efficient.

Paper number 95:
Title: Learning-based Estimation of Forward Kinematics for an Orthotic Parallel Robotic Mechanism
Authors: Jingzong Zhou, Yuhan Zhu, Xiaobin Zhang, Sunil Agrawal, Konstantinos Karydis
Abstract: This paper introduces a 3D parallel robot with three identical five-degree-of-freedom chains connected to a circular brace end-effector, aimed to serve as an assistive device for patients with cervical spondylosis. The inverse kinematics of the system is solved analytically, whereas learning-based methods are deployed to solve the forward kinematics. The methods considered herein include a Koopman operator-based approach as well as a neural network-based approach. The task is to predict the position and orientation of end-effector trajectories. The dataset used to train these methods is based on the analytical solutions derived via inverse kinematics. The methods are tested both in simulation and via physical hardware experiments with the developed robot. Results validate the suitability of deploying learning-based methods for studying parallel mechanism forward kinematics that are generally hard to resolve analytically.

Paper number 96:
Title: Excess Mean Squared Error of Empirical Bayes Estimators
Authors: Yue Ju, Bo Wahlberg, Håkan Hjalmarsson
Abstract: Empirical Bayes estimators are based on minimizing the average risk with the hyper-parameters in the weighting function being estimated from observed data. The performance of an empirical Bayes estimator is typically evaluated by its mean squared error (MSE). However, the explicit expression for its MSE is generally unavailable for finite sample sizes. To address this issue, we define a high-order analytical criterion: the excess MSE. It quantifies the performance difference between the maximum likelihood and empirical Bayes estimators. An explicit expression for the excess MSE of an empirical Bayes estimator employing a general data-dependent hyper-parameter estimator is derived. As specific instances, we provide excess MSE expressions for kernel-based regularized estimators using the scaled empirical Bayes, Stein unbiased risk estimation, and generalized cross-validation hyper-parameter estimators. Moreover, we propose a modification to the excess MSE expressions for regularized estimators for moderate sample sizes and show its improvement on accuracy in numerical simulations.

Paper number 97:
Title: UStyle: Waterbody Style Transfer of Underwater Scenes by Depth-Guided Feature Synthesis
Authors: Md Abu Bakr Siddique, Junliang Liu, Piyush Singh, Md Jahidul Islam
Abstract: The concept of waterbody style transfer remains largely unexplored in the underwater imaging and vision literature. Traditional image style transfer (STx) methods primarily focus on artistic and photorealistic blending, often failing to preserve object and scene geometry in images captured in high-scattering mediums such as underwater. The wavelength-dependent nonlinear attenuation and depth-dependent backscattering artifacts further complicate learning underwater image STx from unpaired data. This paper introduces UStyle, the first data-driven learning framework for transferring waterbody styles across underwater images without requiring prior reference images or scene information. We propose a novel depth-aware whitening and coloring transform (DA-WCT) mechanism that integrates physics-based waterbody synthesis to ensure perceptually consistent stylization while preserving scene structure. To enhance style transfer quality, we incorporate carefully designed loss functions that guide UStyle to maintain colorfulness, lightness, structural integrity, and frequency-domain characteristics, as well as high-level content in VGG and CLIP (contrastive language-image pretraining) feature spaces. By addressing domain-specific challenges, UStyle provides a robust framework for no-reference underwater image STx, surpassing state-of-the-art (SOTA) methods that rely solely on end-to-end reconstruction loss. Furthermore, we introduce the UF7D dataset, a curated collection of high-resolution underwater images spanning seven distinct waterbody styles, establishing a benchmark to support future research in underwater image STx. The UStyle inference pipeline and UF7D dataset are released at: this https URL.

Paper number 98:
Title: Expressive Music Data Processing and Generation
Authors: Jingwei Liu
Abstract: Musical expressivity and coherence are indispensable in music composition and performance, while often neglected in modern AI generative models. In this work, we introduce a listening-based data-processing technique that captures the expressivity in musical performance. This technique derived from Weber's law reflects the human perceptual truth of listening and preserves musical subtlety and expressivity in the training input. To facilitate musical coherence, we model the output interdependencies among multiple arguments in the music data such as pitch, duration, velocity, etc. in the neural networks based on the probabilistic chain rule. In practice, we decompose the multi-output sequential model into single-output submodels and condition previously sampled outputs on the subsequent submodels to induce conditional distributions. Finally, to select eligible sequences from all generations, a tentative measure based on the output entropy was proposed. The entropy sequence is set as a criterion to select predictable and stable generations, which is further studied under the context of informational aesthetic measures to quantify musical pleasure and information gain along the music tendency.

Paper number 99:
Title: Diffusion Dynamics Models with Generative State Estimation for Cloth Manipulation
Authors: Tongxuan Tian, Haoyang Li, Bo Ai, Xiaodi Yuan, Zhiao Huang, Hao Su
Abstract: Manipulating deformable objects like cloth is challenging due to their complex dynamics, near-infinite degrees of freedom, and frequent self-occlusions, which complicate state estimation and dynamics modeling. Prior work has struggled with robust cloth state estimation, while dynamics models, primarily based on Graph Neural Networks (GNNs), are limited by their locality. Inspired by recent advances in generative models, we hypothesize that these expressive models can effectively capture intricate cloth configurations and deformation patterns from data. Building on this insight, we propose a diffusion-based generative approach for both perception and dynamics modeling. Specifically, we formulate state estimation as reconstructing the full cloth state from sparse RGB-D observations conditioned on a canonical cloth mesh and dynamics modeling as predicting future states given the current state and robot actions. Leveraging a transformer-based diffusion model, our method achieves high-fidelity state reconstruction while reducing long-horizon dynamics prediction errors by an order of magnitude compared to GNN-based approaches. Integrated with model-predictive control (MPC), our framework successfully executes cloth folding on a real robotic system, demonstrating the potential of generative models for manipulation tasks with partial observability and complex dynamics.

Paper number 100:
Title: MUSE: A Real-Time Multi-Sensor State Estimator for Quadruped Robots
Authors: Ylenia Nisticò, João Carlos Virgolino Soares, Lorenzo Amatucci, Geoff Fink, Claudio Semini
Abstract: This paper introduces an innovative state estimator, MUSE (MUlti-sensor State Estimator), designed to enhance state estimation's accuracy and real-time performance in quadruped robot navigation. The proposed state estimator builds upon our previous work presented in [1]. It integrates data from a range of onboard sensors, including IMUs, encoders, cameras, and LiDARs, to deliver a comprehensive and reliable estimation of the robot's pose and motion, even in slippery scenarios. We tested MUSE on a Unitree Aliengo robot, successfully closing the locomotion control loop in difficult scenarios, including slippery and uneven terrain. Benchmarking against Pronto [2] and VILENS [3] showed 67.6% and 26.7% reductions in translational errors, respectively. Additionally, MUSE outperformed DLIO [4], a LiDAR-inertial odometry system in rotational errors and frequency, while the proprioceptive version of MUSE (P-MUSE) outperformed TSIF [5], with a 45.9% reduction in absolute trajectory error (ATE).

Paper number 101:
Title: Universal Speech Token Learning via Low-Bitrate Neural Codec and Pretrained Representations
Authors: Xue Jiang, Xiulian Peng, Yuan Zhang, Yan Lu
Abstract: Current large speech language models are mainly based on semantic tokens from discretization of self-supervised learned representations and acoustic tokens from a neural codec, following a semantic-modeling and acoustic-synthesis paradigm. However, semantic tokens discard paralinguistic attributes of speakers that is important for natural spoken communication, while prompt-based acoustic synthesis from semantic tokens has limits in recovering paralinguistic details and suffers from robustness issues, especially when there are domain gaps between the prompt and the target. This paper unifies two types of tokens and proposes the UniCodec, a universal speech token learning that encapsulates all semantics of speech, including linguistic and paralinguistic information, into a compact and semantically-disentangled unified token. Such a unified token can not only benefit speech language models in understanding with paralinguistic hints but also help speech generation with high-quality output. A low-bitrate neural codec is leveraged to learn such disentangled discrete representations at global and local scales, with knowledge distilled from self-supervised learned features. Extensive evaluations on multilingual datasets demonstrate its effectiveness in generating natural, expressive and long-term consistent output quality with paralinguistic attributes well preserved in several speech processing tasks.

Paper number 102:
Title: DiffGAP: A Lightweight Diffusion Module in Contrastive Space for Bridging Cross-Model Gap
Authors: Shentong Mo, Zehua Chen, Fan Bao, Jun Zhu
Abstract: Recent works in cross-modal understanding and generation, notably through models like CLAP (Contrastive Language-Audio Pretraining) and CAVP (Contrastive Audio-Visual Pretraining), have significantly enhanced the alignment of text, video, and audio embeddings via a single contrastive loss. However, these methods often overlook the bidirectional interactions and inherent noises present in each modality, which can crucially impact the quality and efficacy of cross-modal integration. To address this limitation, we introduce DiffGAP, a novel approach incorporating a lightweight generative module within the contrastive space. Specifically, our DiffGAP employs a bidirectional diffusion process tailored to bridge the cross-modal gap more effectively. This involves a denoising process on text and video embeddings conditioned on audio embeddings and vice versa, thus facilitating a more nuanced and robust cross-modal interaction. Our experimental results on VGGSound and AudioCaps datasets demonstrate that DiffGAP significantly improves performance in video/text-audio generation and retrieval tasks, confirming its effectiveness in enhancing cross-modal understanding and generation capabilities.

Paper number 103:
Title: A State Alignment-Centric Approach to Federated System Identification: The FedAlign Framework
Authors: Ertuğrul Keçeci, Müjde Güzelkaya, Tufan Kumbasar
Abstract: This paper presents FedAlign, a Federated Learning (FL) framework particularly designed for System Identification (SYSID) tasks by aligning state representations. Local workers can learn State-Space Models (SSMs) with equivalent representations but different dynamics. We demonstrate that directly aggregating these local SSMs via FedAvg results in a global model with altered system dynamics. FedAlign overcomes this problem by employing similarity transformation matrices to align state representations of local SSMs, thereby establishing a common parameter basin that retains the dynamics of local SSMs. FedAlign computes similarity transformation matrices via two distinct approaches: FedAlign-A and FedAlign-O. In FedAlign-A, we represent the global SSM in controllable canonical form (CCF). We apply control theory to analytically derive similarity transformation matrices that convert each local SSM into this form. Yet, establishing global SSM in CCF brings additional alignment challenges in multi input - multi output SYSID as CCF representation is not unique, unlike in single input - single output SYSID. In FedAlign-O, we address these alignment challenges by reformulating the local parameter basin alignment problem as an optimization task. We determine the parameter basin of a local worker as the common parameter basin and solve least square problems to obtain similarity transformation matrices needed to align the remaining local SSMs. Through the experiments conducted on synthetic and real-world datasets, we show that FedAlign outperforms FedAvg, converges faster, and provides improved stability of the global SSM thanks to the efficient alignment of local parameter basins.

Paper number 104:
Title: D4orm: Multi-Robot Trajectories with Dynamics-aware Diffusion Denoised Deformations
Authors: Yuhao Zhang, Keisuke Okumura, Heedo Woo, Ajay Shankar, Amanda Prorok
Abstract: This work presents an optimization method for generating kinodynamically feasible and collision-free multi-robot trajectories that exploits an incremental denoising scheme in diffusion models. Our key insight is that high-quality trajectories can be discovered merely by denoising noisy trajectories sampled from a distribution. This approach has no learning component, relying instead on only two ingredients: a dynamical model of the robots to obtain feasible trajectories via rollout, and a score function to guide denoising with Monte Carlo gradient approximation. The proposed framework iteratively optimizes the deformation from the previous round with this denoising process, allows \textit{anytime} refinement as time permits, supports different dynamics, and benefits from GPU acceleration. Our evaluations for differential-drive and holonomic teams with up to 16 robots in 2D and 3D worlds show its ability to discover high-quality solutions faster than other black-box optimization methods such as MPPI, approximately three times faster in a 3D holonomic case with 16 robots. As evidence for feasibility, we demonstrate zero-shot deployment of the planned trajectories on eight multirotors.

Paper number 105:
Title: Robust Full-Space Physical Layer Security for STAR-RIS-Aided Wireless Networks: Eavesdropper with Uncertain Location and Channel
Authors: Han Xiao, Xiaoyan Hu, Ang Li, Wenjie Wang, Kun Yang
Abstract: A robust full-space physical layer security (PLS) transmission scheme is proposed in this paper considering the full-space wiretapping challenge of wireless networks supported by simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS). Different from the existing schemes, the proposed PLS scheme takes account of the uncertainty on the eavesdropper's position within the 360$^\circ$ service area offered by the STAR-RIS. Specifically, the large system analytical method is utilized to derive the asymptotic expression of the average security rate achieved by the security user, considering that the base station (BS) only has the statistical information of the eavesdropper's channel state information (CSI) and the uncertainty of its location. To evaluate the effectiveness of the proposed PLS scheme, we first formulate an optimization problem aimed at maximizing the weighted sum rate of the security user and the public user. This optimization is conducted under the power allocation constraint, and some practical limitations for STAR-RIS implementation, through jointly designing the active and passive beamforming variables. A novel iterative algorithm based on the minimum mean-square error (MMSE) and cross-entropy optimization (CEO) methods is proposed to effectively address the established non-convex optimization problem with discrete variables. Simulation results indicate that the proposed robust PLS scheme can effectively mitigate the information leakage across the entire coverage area of the STAR-RIS-assisted system, leading to superior performance gain when compared to benchmark schemes encompassing traditional RIS-aided scheme.

Paper number 106:
Title: Nonparametric adaptive payload tracking for an offshore crane
Authors: Torbjørn Smith, Olav Egeland
Abstract: A nonparametric adaptive crane control system is proposed where the crane payload tracks a desired trajectory with feedback from the payload position. The payload motion is controlled with the position of the crane tip using partial feedback linearization. This is made possible by introducing a novel model structure given in Cartesian coordinates. This Cartesian model structure makes it possible to implement a nonparametric adaptive controller which cancels disturbances by approximating the effects of unknown disturbance forces and structurally unknown dynamics in a reproducing kernel Hilbert space (RKHS). It is shown that the nonparametric adaptive controller leads to uniformly ultimately bounded errors in the presence of unknown forces and unmodeled dynamics. Moreover, it is shown that the Cartesian formulation has certain advantages in payload tracking control also in the non-adaptive case. The performance of the nonparametric adaptive controller is validated in simulation and experiments with good results.

Paper number 107:
Title: Handling Weak Complementary Relationships for Audio-Visual Emotion Recognition
Authors: R. Gnana Praveen, Jahangir Alam
Abstract: Multimodal emotion recognition has recently drawn a lot of interest in affective computing as it has immense potential to outperform isolated unimodal approaches. Audio and visual modalities are two predominant contact-free channels in videos, which are often expected to carry a complementary relationship with each other. However, audio and visual channels may not always be complementary with each other, resulting in poor audio-visual feature representations, thereby degrading the performance of the system. In this paper, we propose a flexible audio-visual fusion model that can adapt to weak complementary relationships using a gated attention mechanism. Specifically, we extend the recursive joint cross-attention model by introducing gating mechanism in every iteration to control the flow of information between the input features and the attended features depending on the strength of their complementary relationship. For instance, if the modalities exhibit strong complementary relationships, the gating mechanism chooses cross-attended features, otherwise non-attended features. To further improve the performance of the system, we further introduce stage gating mechanism, which is used to control the flow of information across the gated outputs of each iteration. Therefore, the proposed model improves the performance of the system even when the audio and visual modalities do not have a strong complementary relationship with each other by adding more flexibility to the recursive joint cross attention mechanism. The proposed model has been evaluated on the challenging Affwild2 dataset and significantly outperforms the state-of-the-art fusion approaches.

Paper number 108:
Title: Bi-Criteria Optimization for Combinatorial Bandits: Sublinear Regret and Constraint Violation under Bandit Feedback
Authors: Vaneet Aggarwal, Shweta Jain, Subham Pokhriyal, Christopher John Quinn
Abstract: In this paper, we study bi-criteria optimization for combinatorial multi-armed bandits (CMAB) with bandit feedback. We propose a general framework that transforms discrete bi-criteria offline approximation algorithms into online algorithms with sublinear regret and cumulative constraint violation (CCV) guarantees. Our framework requires the offline algorithm to provide an $(\alpha, \beta)$-bi-criteria approximation ratio with $\delta$-resilience and utilize $\texttt{N}$ oracle calls to evaluate the objective and constraint functions. We prove that the proposed framework achieves sub-linear regret and CCV, with both bounds scaling as ${O}\left(\delta^{2/3} \texttt{N}^{1/3}T^{2/3}\log^{1/3}(T)\right)$. Crucially, the framework treats the offline algorithm with $\delta$-resilience as a black box, enabling flexible integration of existing approximation algorithms into the CMAB setting. To demonstrate its versatility, we apply our framework to several combinatorial problems, including submodular cover, submodular cost covering, and fair submodular maximization. These applications highlight the framework's broad utility in adapting offline guarantees to online bi-criteria optimization under bandit feedback.

Paper number 109:
Title: RENO: Real-Time Neural Compression for 3D LiDAR Point Clouds
Authors: Kang You, Tong Chen, Dandan Ding, M. Salman Asif, Zhan Ma
Abstract: Despite the substantial advancements demonstrated by learning-based neural models in the LiDAR Point Cloud Compression (LPCC) task, realizing real-time compression - an indispensable criterion for numerous industrial applications - remains a formidable challenge. This paper proposes RENO, the first real-time neural codec for 3D LiDAR point clouds, achieving superior performance with a lightweight model. RENO skips the octree construction and directly builds upon the multiscale sparse tensor representation. Instead of the multi-stage inferring, RENO devises sparse occupancy codes, which exploit cross-scale correlation and derive voxels' occupancy in a one-shot manner, greatly saving processing time. Experimental results demonstrate that the proposed RENO achieves real-time coding speed, 10 fps at 14-bit depth on a desktop platform (e.g., one RTX 3090 GPU) for both encoding and decoding processes, while providing 12.25% and 48.34% bit-rate savings compared to G-PCCv23 and Draco, respectively, at a similar quality. RENO model size is merely 1MB, making it attractive for practical applications. The source code is available at this https URL.

Paper number 110:
Title: Serenade: A Singing Style Conversion Framework Based On Audio Infilling
Authors: Lester Phillip Violeta, Wen-Chin Huang, Tomoki Toda
Abstract: We propose Serenade, a novel framework for the singing style conversion (SSC) task. Although singer identity conversion has made great strides in the previous years, converting the singing style of a singer has been an unexplored research area. We find three main challenges in SSC: modeling the target style, disentangling source style, and retaining the source melody. To model the target singing style, we use an audio infilling task by predicting a masked segment of the target mel-spectrogram with a flow-matching model using the complement of the masked target mel-spectrogram along with disentangled acoustic features. On the other hand, to disentangle the source singing style, we use a cyclic training approach, where we use synthetic converted samples as source inputs and reconstruct the original source mel-spectrogram as a target. Finally, to retain the source melody better, we investigate a post-processing module using a source-filter-based vocoder and resynthesize the converted waveforms using the original F0 patterns. Our results showed that the Serenade framework can handle generalized SSC tasks with the best overall similarity score, especially in modeling breathy and mixed singing styles. Moreover, although resynthesizing with the original F0 patterns alleviated out-of-tune singing and improved naturalness, we found a slight tradeoff in similarity due to not changing the F0 patterns into the target style.

Paper number 111:
Title: Pathology Image Restoration via Mixture of Prompts
Authors: Jiangdong Cai, Yan Chen, Zhenrong Shen, Haotian Jiang, Honglin Xiong, Kai Xuan, Lichi Zhang, Qian Wang
Abstract: In digital pathology, acquiring all-in-focus images is essential to high-quality imaging and high-efficient clinical workflow. Traditional scanners achieve this by scanning at multiple focal planes of varying depths and then merging them, which is relatively slow and often struggles with complex tissue defocus. Recent prevailing image restoration technique provides a means to restore high-quality pathology images from scans of single focal planes. However, existing image restoration methods are inadequate, due to intricate defocus patterns in pathology images and their domain-specific semantic complexities. In this work, we devise a two-stage restoration solution cascading a transformer and a diffusion model, to benefit from their powers in preserving image fidelity and perceptual quality, respectively. We particularly propose a novel mixture of prompts for the two-stage solution. Given initial prompt that models defocus in microscopic imaging, we design two prompts that describe the high-level image semantics from pathology foundation model and the fine-grained tissue structures via edge extraction. We demonstrate that, by feeding the prompt mixture to our method, we can restore high-quality pathology images from single-focal-plane scans, implying high potentials of the mixture of prompts to clinical usage. Code will be publicly available at this https URL.

Paper number 112:
Title: EgoEvGesture: Gesture Recognition Based on Egocentric Event Camera
Authors: Luming Wang, Hao Shi, Xiaoting Yin, Kailun Yang, Kaiwei Wang
Abstract: Egocentric gesture recognition is a pivotal technology for enhancing natural human-computer interaction, yet traditional RGB-based solutions suffer from motion blur and illumination variations in dynamic scenarios. While event cameras show distinct advantages in handling high dynamic range with ultra-low power consumption, existing RGB-based architectures face inherent limitations in processing asynchronous event streams due to their synchronous frame-based nature. Moreover, from an egocentric perspective, event cameras record data that include events generated by both head movements and hand gestures, thereby increasing the complexity of gesture recognition. To address this, we propose a novel network architecture specifically designed for event data processing, incorporating (1) a lightweight CNN with asymmetric depthwise convolutions to reduce parameters while preserving spatiotemporal features, (2) a plug-and-play state-space model as context block that decouples head movement noise from gesture dynamics, and (3) a parameter-free Bins-Temporal Shift Module (BSTM) that shifts features along bins and temporal dimensions to fuse sparse events efficiently. We further build the EgoEvGesture dataset, the first large-scale dataset for egocentric gesture recognition using event cameras. Experimental results demonstrate that our method achieves 62.7% accuracy in heterogeneous testing with only 7M parameters, 3.1% higher than state-of-the-art approaches. Notable misclassifications in freestyle motions stem from high inter-personal variability and unseen test patterns differing from training data. Moreover, our approach achieved a remarkable accuracy of 96.97% on DVS128 Gesture, demonstrating strong cross-dataset generalization capability. The dataset and models are made publicly available at this https URL.

Paper number 113:
Title: MambaIC: State Space Models for High-Performance Learned Image Compression
Authors: Fanhu Zeng, Hao Tang, Yihua Shao, Siyu Chen, Ling Shao, Yan Wang
Abstract: A high-performance image compression algorithm is crucial for real-time information transmission across numerous fields. Despite rapid progress in image compression, computational inefficiency and poor redundancy modeling still pose significant bottlenecks, limiting practical applications. Inspired by the effectiveness of state space models (SSMs) in capturing long-range dependencies, we leverage SSMs to address computational inefficiency in existing methods and improve image compression from multiple perspectives. In this paper, we integrate the advantages of SSMs for better efficiency-performance trade-off and propose an enhanced image compression approach through refined context modeling, which we term MambaIC. Specifically, we explore context modeling to adaptively refine the representation of hidden states. Additionally, we introduce window-based local attention into channel-spatial entropy modeling to reduce potential spatial redundancy during compression, thereby increasing efficiency. Comprehensive qualitative and quantitative results validate the effectiveness and efficiency of our approach, particularly for high-resolution image compression. Code is released at this https URL.

Paper number 114:
Title: DPF-Net: Physical Imaging Model Embedded Data-Driven Underwater Image Enhancement
Authors: Han Mei, Kunqian Li, Shuaixin Liu, Chengzhi Ma, Qianli Jiang
Abstract: Due to the complex interplay of light absorption and scattering in the underwater environment, underwater images experience significant degradation. This research presents a two-stage underwater image enhancement network called the Data-Driven and Physical Parameters Fusion Network (DPF-Net), which harnesses the robustness of physical imaging models alongside the generality and efficiency of data-driven methods. We first train a physical parameter estimate module using synthetic datasets to guarantee the trustworthiness of the physical parameters, rather than solely learning the fitting relationship between raw and reference images by the application of the imaging equation, as is common in prior studies. This module is subsequently trained in conjunction with an enhancement network, where the estimated physical parameters are integrated into a data-driven model within the embedding space. To maintain the uniformity of the restoration process amid underwater imaging degradation, we propose a physics-based degradation consistency loss. Additionally, we suggest an innovative weak reference loss term utilizing the entire dataset, which alleviates our model's reliance on the quality of individual reference images. Our proposed DPF-Net demonstrates superior performance compared to other benchmark methods across multiple test sets, achieving state-of-the-art results. The source code and pre-trained models are available on the project home page: this https URL.

Paper number 115:
Title: Closed-Loop Control and Disturbance Mitigation of an Underwater Multi-Segment Continuum Manipulator
Authors: Kyle L. Walker, Hsing-Yu Chen, Alix J. Partridge, Lucas Cruz da Silva, Adam A. Stokes, Francesco Giorgio-Serchi
Abstract: The use of soft and compliant manipulators in marine environments represents a promising paradigm shift for subsea inspection, with devices better suited to tasks owing to their ability to safely conform to items during contact. However, limitations driven by material characteristics often restrict the reach of such devices, with the complexity of obtaining state estimations making control non-trivial. Here, a detailed analysis of a 1m long compliant manipulator prototype for subsea inspection tasks is presented, including its mechanical design, state estimation technique, closed-loop control strategies, and experimental performance evaluation in underwater conditions. Results indicate that both the configuration-space and task-space controllers implemented are capable of positioning the end effector to desired locations, with deviations of <5% of the manipulator length spatially and to within 5^{o} of the desired configuration angles. The manipulator was also tested when subjected to various disturbances, such as loads of up to 300g and random point disturbances, and was proven to be able to limit displacement and restore the desired configuration. This work is a significant step towards the implementation of compliant manipulators in real-world subsea environments, proving their potential as an alternative to classical rigid-link designs.

Paper number 116:
Title: Polytope Volume Monitoring Problem: Formulation and Solution via Parametric Linear Program Based Control Barrier Function
Authors: Shizhen Wu, Jinyang Dong, Xu Fang, Ning Sun, Yongchun Fang
Abstract: Motivated by the latest research on feasible space monitoring of multiple control barrier functions (CBFs) as well as polytopic collision avoidance, this paper studies the Polytope Volume Monitoring (PVM) problem, whose goal is to design a control law for inputs of nonlinear systems to prevent the volume of some state-dependent polytope from decreasing to zero. Recent studies have explored the idea of applying Chebyshev ball method in optimization theory to solve the case study of PVM; however, the underlying difficulties caused by nonsmoothness have not been addressed. This paper continues the study on this topic, where our main contribution is to establish the relationship between nonsmooth CBF and parametric optimization theory through directional derivatives for the first time, so as to solve PVM problems more conveniently. In detail, inspired by Chebyshev ball approach, a parametric linear program (PLP) based nonsmooth barrier function candidate is established for PVM, and then, sufficient conditions for it to be a nonsmooth CBF are proposed, based on which a quadratic program (QP) based safety filter with guaranteed feasibility is proposed to address PVM problems. Finally, a numerical simulation example is given to show the efficiency of the proposed safety filter.

Paper number 117:
Title: MUKCa: Accurate and Affordable Cobot Calibration Without External Measurement Devices
Authors: Giovanni Franzese, Max Spahn, Jens Kober, Cosimo Della Santina
Abstract: To increase the reliability of collaborative robots in performing daily tasks, we require them to be accurate and not only repeatable. However, having a calibrated kinematics model is regrettably a luxury, as available calibration tools are usually more expensive than the robots themselves. With this work, we aim to contribute to the democratization of cobots calibration by providing an inexpensive yet highly effective alternative to existing tools. The proposed minimalist calibration routine relies on a 3D-printable tool as the only physical aid to the calibration process. This two-socket spherical-joint tool kinematically constrains the robot at the end effector while collecting the training set. An optimization routine updates the nominal model to ensure a consistent prediction for each socket and the undistorted mean distance between them. We validated the algorithm on three robotic platforms: Franka, Kuka, and Kinova Cobots. The calibrated models reduce the mean absolute error from the order of 10 mm to 0.2 mm for both Franka and Kuka robots. We provide two additional experimental campaigns with the Franka Robot to render the improvements more tangible. First, we implement Cartesian control with and without the calibrated model and use it to perform a standard peg-in-the-hole task with a tolerance of 0.4 mm between the peg and the hole. Second, we perform a repeated drawing task combining Cartesian control with learning from demonstration. Both tasks consistently failed when the model was not calibrated, while they consistently succeeded after calibration.

Paper number 118:
Title: Context-Aware Two-Step Training Scheme for Domain Invariant Speech Separation
Authors: Wupeng Wang, Zexu Pan, Jingru Lin, Shuai Wang, Haizhou Li
Abstract: Speech separation seeks to isolate individual speech signals from a multi-talk speech mixture. Despite much progress, a system well-trained on synthetic data often experiences performance degradation on out-of-domain data, such as real-world speech mixtures. To address this, we introduce a novel context-aware, two-stage training scheme for speech separation models. In this training scheme, the conventional end-to-end architecture is replaced with a framework that contains a context extractor and a segregator. The two modules are trained step by step to simulate the speech separation process of an auditory system. We evaluate the proposed training scheme through cross-domain experiments on both synthetic and real-world speech mixtures, and demonstrate that our new scheme effectively boosts separation quality across different domains without adaptation, as measured by signal quality metrics and word error rate (WER). Additionally, an ablation study on the real test set highlights that the context information, including phoneme and word representations from pretrained SSL models, serves as effective domain invariant training targets for separation models.

Paper number 119:
Title: Integration Error Regularization in Direct Optimal Control using Embedded Runge Kutta Methods
Authors: Jakob Harzer, Jochem De Schutter, Moritz Diehl
Abstract: In order to solve continuous-time optimal control problems, direct methods transcribe the infinite-dimensional problem to a nonlinear program (NLP) using numerical integration methods. In cases where the integration error can be manipulated by the chosen control trajectory, the transcription might produce spurious local NLP solutions as a by-product. While often this issue can be addressed by increasing the accuracy of the integration method, this is not always computationally acceptable, e.g., in the case of embedded optimization. Therefore, alternatively, we propose to estimate the integration error using established embedded Runge-Kutta methods and to regularize this estimate in the NLP cost function, using generalized norms. While this regularization is effective at eliminating spurious solutions, it inherently comes with a loss of optimality of valid solutions. The regularization can be tuned to minimize this loss, using a single parameter that can be intuitively interpreted as the maximum allowable estimated local integration error. In a numerical example based on a system with stiff dynamics, we show how this methodology enables the use of a computationally cheap explicit integration method, achieving a speedup of a factor of 3 compared to an otherwise more suitable implicit method, with a loss of optimality of only 3\%.

Paper number 120:
Title: Optimal Transmission Sequence Design with ISI Matching in Molecular Communication
Authors: Aravind Muraleedharan, Abhishek K. Gupta
Abstract: Molecular communication (MC) offers a groundbreaking approach to communication inspired by biological signaling. It is particularly suited for environments where traditional electromagnetic methods fail, such as fluid mediums or within the human body. This study focuses on addressing a major challenge in MC systems: inter symbol interference (ISI), which arises due to the random, diffusive propagation of molecules. We propose a novel technique that leverages transmission shaping to mitigate ISI effectively by designing optimal transmission pulse (or sequence) for symbols. Our approach centers on solving a multi-objective optimization problem that aims to maximize the separability of individual symbol's responses within the symbol duration while matching the interference caused by molecular spillover for all symbols. By making ISI of each symbol similar, the approach reduces the effect of previous symbols and thus not require any adaptive computations. We introduce a geometric analogy involving two families of ellipses to derive the optimal solution. Analytical insights are supported by numerical simulations to design optimized transmission profiles to enhance the resilience toward ISI. The proposed transmission shaping method is evaluated through symbol error rate (SER). These results mark a significant step forward in developing robust and efficient MC systems, opening doors to advanced applications in bio-inspired and nano-scale communication technologies.

Paper number 121:
Title: Exploiting Multistage Optimization Structure in Proximal Solvers
Authors: Roland Schwan, Daniel Kuhn, Colin N. Jones
Abstract: This paper presents an efficient structure-exploiting algorithm for multistage optimization problems, implemented as a new backend in the PIQP solver. The proposed method extends existing approaches by supporting full coupling between stages and global decision variables in the cost as well as equality and inequality constraints. The solver leverages a specialized block-tri-diagonal-arrow Cholesky factorization within a proximal interior-point framework to handle the underlying problem structure efficiently. The implementation features automatic structure detection and seamless integration with existing interfaces. Numerical experiments demonstrate significant performance improvements, achieving up to 13x speed-up compared to a generic sparse backend and matching/exceeding the performance of the state-of-the-art specialized solver HPIPM. The solver is particularly effective for applications such as model predictive control, robust scenario optimization, and periodic optimization problems.

Paper number 122:
Title: RL-TIME: Reinforcement Learning-based Task Replication in Multicore Embedded Systems
Authors: Roozbeh Siyadatzadeh, Mohsen Ansari, Muhammad Shafique, Alireza Ejlali
Abstract: Embedded systems power many modern applications and must often meet strict reliability, real-time, thermal, and power requirements. Task replication can improve reliability by duplicating a task's execution to handle transient and permanent faults, but blindly applying replication often leads to excessive overhead and higher temperatures. Existing design-time methods typically choose the number of replicas based on worst-case conditions, which can waste resources under normal operation. In this paper, we present RL-TIME, a reinforcement learning-based approach that dynamically decides the number of replicas according to actual system conditions. By considering both the reliability target and a core-level Thermal Safe Power (TSP) constraint at run-time, RL-TIME adapts the replication strategy to avoid unnecessary overhead and overheating. Experimental results show that, compared to state-of-the-art methods, RL-TIME reduces power consumption by 63%, increases schedulability by 53%, and respects TSP 72% more often.

Paper number 123:
Title: CDKFormer: Contextual Deviation Knowledge-Based Transformer for Long-Tail Trajectory Prediction
Authors: Yuansheng Lian, Ke Zhang, Meng Li
Abstract: Predicting the future movements of surrounding vehicles is essential for ensuring the safe operation and efficient navigation of autonomous vehicles (AVs) in urban traffic environments. Existing vehicle trajectory prediction methods primarily focus on improving overall performance, yet they struggle to address long-tail scenarios effectively. This limitation often leads to poor predictions in rare cases, significantly increasing the risk of safety incidents. Taking Argoverse 2 motion forecasting dataset as an example, we first investigate the long-tail characteristics in trajectory samples from two perspectives, individual motion and group interaction, and deriving deviation features to distinguish abnormal from regular scenarios. On this basis, we propose CDKFormer, a Contextual Deviation Knowledge-based Transformer model for long-tail trajectory prediction. CDKFormer integrates an attention-based scene context fusion module to encode spatiotemporal interaction and road topology. An additional deviation feature fusion module is proposed to capture the dynamic deviations in the target vehicle status. We further introduce a dual query-based decoder, supported by a multi-stream decoder block, to sequentially decode heterogeneous scene deviation features and generate multimodal trajectory predictions. Extensive experiments demonstrate that CDKFormer achieves state-of-the-art performance, significantly enhancing prediction accuracy and robustness for long-tailed trajectories compared to existing methods, thus advancing the reliability of AVs in complex real-world environments.

Paper number 124:
Title: Intrinsic Successive Convexification: Trajectory Optimization on Smooth Manifolds
Authors: Spencer Kraisler, Mehran Mesbahi, Behcet Acikmese
Abstract: A fundamental issue at the core of trajectory optimization on smooth manifolds is handling the implicit manifold constraint within the dynamics. The conventional approach is to enforce the dynamic model as a constraint. However, we show this approach leads to significantly redundant operations, as well as being heavily dependent on the state space representation. Specifically, we propose an intrinsic successive convexification methodology for optimal control on smooth manifolds. This so-called iSCvx is then applied to a representative example involving attitude trajectory optimization for a spacecraft subject to non-convex constraints.

Paper number 125:
Title: VasTSD: Learning 3D Vascular Tree-state Space Diffusion Model for Angiography Synthesis
Authors: Zhifeng Wang, Renjiao Yi, Xin Wen, Chenyang Zhu, Kai Xu
Abstract: Angiography imaging is a medical imaging technique that enhances the visibility of blood vessels within the body by using contrast agents. Angiographic images can effectively assist in the diagnosis of vascular diseases. However, contrast agents may bring extra radiation exposure which is harmful to patients with health risks. To mitigate these concerns, in this paper, we aim to automatically generate angiography from non-angiographic inputs, by leveraging and enhancing the inherent physical properties of vascular structures. Previous methods relying on 2D slice-based angiography synthesis struggle with maintaining continuity in 3D vascular structures and exhibit limited effectiveness across different imaging modalities. We propose VasTSD, a 3D vascular tree-state space diffusion model to synthesize angiography from 3D non-angiographic volumes, with a novel state space serialization approach that dynamically constructs vascular tree topologies, integrating these with a diffusion-based generative model to ensure the generation of anatomically continuous vasculature in 3D volumes. A pre-trained vision embedder is employed to construct vascular state space representations, enabling consistent modeling of vascular structures across multiple modalities. Extensive experiments on various angiographic datasets demonstrate the superiority of VasTSD over prior works, achieving enhanced continuity of blood vessels in synthesized angiographic synthesis for multiple modalities and anatomical regions.

Paper number 126:
Title: LangDA: Building Context-Awareness via Language for Domain Adaptive Semantic Segmentation
Authors: Chang Liu, Bavesh Balaji, Saad Hossain, C Thomas, Kwei-Herng Lai, Raviteja Vemulapalli, Alexander Wong, Sirisha Rambhatla
Abstract: Unsupervised domain adaptation for semantic segmentation (DASS) aims to transfer knowledge from a label-rich source domain to a target domain with no labels. Two key approaches in DASS are (1) vision-only approaches using masking or multi-resolution crops, and (2) language-based approaches that use generic class-wise prompts informed by target domain (e.g. "a {snowy} photo of a {class}"). However, the former is susceptible to noisy pseudo-labels that are biased to the source domain. The latter does not fully capture the intricate spatial relationships of objects -- key for dense prediction tasks. To this end, we propose LangDA. LangDA addresses these challenges by, first, learning contextual relationships between objects via VLM-generated scene descriptions (e.g. "a pedestrian is on the sidewalk, and the street is lined with buildings."). Second, LangDA aligns the entire image features with text representation of this context-aware scene caption and learns generalized representations via text. With this, LangDA sets the new state-of-the-art across three DASS benchmarks, outperforming existing methods by 2.6%, 1.4% and 3.9%.

Paper number 127:
Title: Mixed-granularity Implicit Representation for Continuous Hyperspectral Compressive Reconstruction
Authors: Jianan Li, Huan Chen, Wangcai Zhao, Rui Chen, Tingfa Xu
Abstract: Hyperspectral Images (HSIs) are crucial across numerous fields but are hindered by the long acquisition times associated with traditional spectrometers. The Coded Aperture Snapshot Spectral Imaging (CASSI) system mitigates this issue through a compression technique that accelerates the acquisition process. However, reconstructing HSIs from compressed data presents challenges due to fixed spatial and spectral resolution constraints. This study introduces a novel method using implicit neural representation for continuous hyperspectral image reconstruction. We propose the Mixed Granularity Implicit Representation (MGIR) framework, which includes a Hierarchical Spectral-Spatial Implicit Encoder for efficient multi-scale implicit feature extraction. This is complemented by a Mixed-Granularity Local Feature Aggregator that adaptively integrates local features across scales, combined with a decoder that merges coordinate information for precise reconstruction. By leveraging implicit neural representations, the MGIR framework enables reconstruction at any desired spatial-spectral resolution, significantly enhancing the flexibility and adaptability of the CASSI system. Extensive experimental evaluations confirm that our model produces reconstructed images at arbitrary resolutions and matches state-of-the-art methods across varying spectral-spatial compression ratios. The code will be released at this https URL.

Paper number 128:
Title: Semantic-Relevance Based Sensor Selection for Edge-AI Empowered Sensing Systems
Authors: Zhiyan Liu, Kaibin Huang
Abstract: The sixth-generation (6G) mobile network is envisioned to incorporate sensing and edge artificial intelligence (AI) as two key functions. Their natural convergence leads to the emergence of Integrated Sensing and Edge AI (ISEA), a novel paradigm enabling real-time acquisition and understanding of sensory information at the network edge. However, ISEA faces a communication bottleneck due to the large number of sensors and the high dimensionality of sensory features. Traditional approaches to communication-efficient ISEA lack awareness of semantic relevance, i.e., the level of relevance between sensor observations and the downstream task. To fill this gap, this paper presents a novel framework for semantic-relevance-aware sensor selection to achieve optimal end-to-end (E2E) task performance under heterogeneous sensor relevance and channel states. E2E sensing accuracy analysis is provided to characterize the sensing task performance in terms of selected sensors' relevance scores and channel states. Building on the results, the sensor-selection problem for accuracy maximization is formulated as an integer program and solved through a tight approximation of the objective. The optimal solution exhibits a priority-based structure, which ranks sensors based on a priority indicator combining relevance scores and channel states and selects top-ranked sensors. Low-complexity algorithms are then developed to determine the optimal numbers of selected sensors and features. Experimental results on both synthetic and real datasets show substantial accuracy gain achieved by the proposed selection scheme compared to existing benchmarks.

Paper number 129:
Title: Energy-Aware Task Allocation for Teams of Multi-mode Robots
Authors: Takumi Ito, Riku Funada, Mitsuji Sampei, Gennaro Notomista
Abstract: This work proposes a novel multi-robot task allocation framework for robots that can switch between multiple modes, e.g., flying, driving, or walking. We first provide a method to encode the multi-mode property of robots as a graph, where the mode of each robot is represented by a node. Next, we formulate a constrained optimization problem to decide both the task to be allocated to each robot as well as the mode in which the latter should execute the task. The robot modes are optimized based on the state of the robot and the environment, as well as the energy required to execute the allocated task. Moreover, the proposed framework is able to encompass kinematic and dynamic models of robots alike. Furthermore, we provide sufficient conditions for the convergence of task execution and allocation for both robot models.

Paper number 130:
Title: AV-Surf: Surface-Enhanced Geometry-Aware Novel-View Acoustic Synthesis
Authors: Hadam Baek, Hannie Shin, Jiyoung Seo, Chanwoo Kim, Saerom Kim, Hyeongbok Kim, Sangpil Kim
Abstract: Accurately modeling sound propagation with complex real-world environments is essential for Novel View Acoustic Synthesis (NVAS). While previous studies have leveraged visual perception to estimate spatial acoustics, the combined use of surface normal and structural details from 3D representations in acoustic modeling has been underexplored. Given their direct impact on sound wave reflections and propagation, surface normals should be jointly modeled with structural details to achieve accurate spatial acoustics. In this paper, we propose a surface-enhanced geometry-aware approach for NVAS to improve spatial acoustic modeling. To achieve this, we exploit geometric priors, such as image, depth map, surface normals, and point clouds obtained using a 3D Gaussian Splatting (3DGS) based framework. We introduce a dual cross-attention-based transformer integrating geometrical constraints into frequency query to understand the surroundings of the emitter. Additionally, we design a ConvNeXt-based spectral features processing network called Spectral Refinement Network (SRN) to synthesize realistic binaural audio. Experimental results on the RWAVS and SoundSpace datasets highlight the necessity of our approach, as it surpasses existing methods in novel view acoustic synthesis.

Paper number 131:
Title: STAR-RIS-Assisted Cell-Free Massive MIMO with Multi-antenna Users and Hardware Impairments Over Correlated Rayleigh Fading Channels
Authors: Jun Qian, Ross Murch, Khaled B. Letaief
Abstract: Integrating cell-free massive multiple-input multiple-output (MIMO) with simultaneous transmitting and reflecting reconfigurable intelligent surfaces (STAR-RISs) can provide ubiquitous connectivity and enhance coverage. This paper explores a STAR-RIS-assisted cell-free massive MIMO system featuring multi-antenna users, multi-antenna access points (APs), and multi-element STAR-RISs, accounting for transceiver hardware impairments. We first establish the system model of STAR-RIS-assisted cell-free massive MIMO systems with multi-antenna users. Subsequently, we analyze two uplink implementations: local processing and centralized decoding (Level 1), and fully centralized processing (Level 2), both implementations incorporating hardware impairments. We study the local and global minimum mean square error (MMSE) combining schemes to maximize the uplink spectral efficiency (SE) for Level 1 and Level 2, respectively. The MMSE-based successive interference cancellation detector is utilized to compute the uplink SE. We introduce the optimal large-scale fading decoding at the central processing unit and derive closed-form SE expressions utilizing maximum ratio combining at APs for Level 1. Our numerical results reveal that hardware impairments negatively affect SE performance, particularly at the user end. However, this degradation can be mitigated by increasing the number of user antennas. Enhancing the number of APs and STAR-RIS elements also improves performance and mitigates performance degradation. Notably, unlike conventional results based on direct links, our findings show that Level 2 consistently outperforms Level 1 with arbitrary combining schemes for the proposed STAR-RIS-assisted system.

Paper number 132:
Title: A Wearable Rehabilitation System to Assist Partially Hand Paralyzed Patients in Repetitive Exercises
Authors: Hussein Naeem Hasan
Abstract: The main purpose of the paper is development, implementation, and testing of a low-cost portable system to assist partially paralyzed patients in their hand rehabilitation after strokes or some injures. Rehabilitation includes time consuming and repetitive exercises which are costly and demotivating as well as the requirements of clinic attending and direct supervision of physiotherapists. In this work, the system consists of a graphical user interface (GUI) on a smartphone screen to instruct and motivate the patients to do their exercises by themselves. Through the GUI, the patients are instructed to do a sequence of exercises step by step, and the system measures the electrical activities (electromyographic signals EMG) of the user's forearm muscles by Myo armband. Depending on d database, the system can tell whether the patients have done correct movements or not. If a correct movement is detected, the system will inform the user through the GUI and move to the next exercise. For preliminary results, the system was extensively tested on a healthy person.

Paper number 133:
Title: In vivo validation of Wireless Power Transfer System for Magnetically Controlled Robotic Capsule Endoscopy
Authors: Alessandro Catania, Michele Bertozzi, Nikita J. Greenidge, Benjamin Calme, Gabriele Bandini, Christian Sbrana, Roberto Cecchi, Alice Buffi, Sebastiano Strangio, Pietro Valdastri, Giuseppe Iannaccone
Abstract: This paper presents the in vivo validation of an inductive wireless power transfer (WPT) system integrated for the first time into a magnetically controlled robotic capsule endoscopy platform. The proposed system enables continuous power delivery to the capsule without the need for onboard batteries, thus extending operational time and reducing size constraints. The WPT system operates through a resonant inductive coupling mechanism, based on a transmitting coil mounted on the end effector of a robotic arm that also houses an external permanent magnet and a localization coil for precise capsule manipulation. To ensure robust and stable power transmission in the presence of coil misalignment and rotation, a 3D receiving coil is integrated within the capsule. Additionally, a closed-loop adaptive control system, based on load-shift keying (LSK) modulation, dynamically adjusts the transmitted power to optimize efficiency while maintaining compliance with specific absorption rate (SAR) safety limits. The system has been extensively characterized in laboratory settings and validated through in vivo experiments using a porcine model, demonstrating reliable power transfer and effective robotic navigation in realistic gastrointestinal conditions: the average received power was 110 mW at a distance of 9 cm between the coils, with variable capsule rotation angles. The results confirm the feasibility of the proposed WPT approach for autonomous, battery-free robotic capsule endoscopy, paving the way for enhanced diagnostic in gastrointestinal medicine.

Paper number 134:
Title: A Hierarchical Region-Based Approach for Efficient Multi-Robot Exploration
Authors: Di Meng, Tianhao Zhao, Chaoyu Xue, Jun Wu, Qiuguo Zhu
Abstract: Multi-robot autonomous exploration in an unknown environment is an important application in this http URL exploration methods only use information around frontier points or viewpoints, ignoring spatial information of unknown areas. Moreover, finding the exact optimal solution for multi-robot task allocation is NP-hard, resulting in significant computational time consumption. To address these issues, we present a hierarchical multi-robot exploration framework using a new modeling method called RegionGraph. The proposed approach makes two main contributions: 1) A new modeling method for unexplored areas that preserves their spatial information across the entire space in a weighted graph called RegionGraph. 2) A hierarchical multi-robot exploration framework that decomposes the global exploration task into smaller subtasks, reducing the frequency of global planning and enabling asynchronous exploration. The proposed method is validated through both simulation and real-world experiments, demonstrating a 20% improvement in efficiency compared to existing methods.

Paper number 135:
Title: Low-PAPR OFDM-ISAC Waveform Design Based on Frequency-Domain Phase Differences
Authors: Kaimin Li, Jiahuan Wang, Haixia Cui, Bingpeng Zhou, Pingzhi Fan
Abstract: Low peak-to-average power ratio (PAPR) orthogonal frequency division multiplexing (OFDM) waveform design is a crucial issue in integrated sensing and communications (ISAC). This paper introduces an OFDM-ISAC waveform design that utilizes the entire spectrum simultaneously for both communication and sensing by leveraging a novel degree of freedom (DoF): the frequency-domain phase difference (PD). Based on this concept, we develop a novel PD-based OFDM-ISAC waveform structure and utilize it to design a PD-based Low-PAPR OFDM-ISAC (PLPOI) waveform. The design is formulated as an optimization problem incorporating four key constraints: the time-frequency relationship equation, frequency-domain unimodular constraints, PD constraints, and time-domain low PAPR requirements. To solve this challenging non-convex problem, we develop an efficient algorithm, ADMM-PLPOI, based on the alternating direction method of multipliers (ADMM) framework. Extensive simulation results demonstrate that the proposed PLPOI waveform achieves significant improvements in both PAPR and bit error rate (BER) performance compared to conventional OFDM-ISAC waveforms.

Paper number 136:
Title: Sensorless Remote Center of Motion Misalignment Estimation
Authors: Hao Yang, Lidia Al-Zogbi, Ahmet Yildiz, Nabil Simaan, Jie Ying Wu
Abstract: Laparoscopic surgery constrains instrument motion around a fixed pivot point at the incision into a patient to minimize tissue trauma. Surgical robots achieve this through either hardware to software-based remote center of motion (RCM) constraints. However, accurate RCM alignment is difficult due to manual trocar placement, patient motion, and tissue deformation. Misalignment between the robot's RCM point and the patient incision site can cause unsafe forces at the incision site. This paper presents a sensorless force estimation-based framework for dynamically assessing and optimizing RCM misalignment in robotic surgery. Our experiments demonstrate that misalignment exceeding 20 mm can generate large enough forces to potentially damage tissue, emphasizing the need for precise RCM positioning. For misalignment $D\geq $ 20 mm, our optimization algorithm estimates the RCM offset with an absolute error within 5 mm. Accurate RCM misalignment estimation is a step toward automated RCM misalignment compensation, enhancing safety and reducing tissue damage in robotic-assisted laparoscopic surgery.

Paper number 137:
Title: Specification-Oriented Automatic Design of Topologically Agnostic Antenna Structure
Authors: Adrian Bekasiewicz, Mariusz Dzwonkowski, Tom Dhaene, Ivo Couckuyt
Abstract: Design of antennas for modern applications is a challenging task that combines cognition-driven development of topology intertwined with tuning of its parameters using rigorous numerical optimization. However, the process can be streamlined by neglecting the engineering insight in favor of automatic de-termination of structure geometry. In this work, a specification-oriented design of topologically agnostic antenna is considered. The radiator is developed using a bi-stage algorithm that involves min-max classification of randomly-generated topologies followed by local tuning of the promising designs using a trust-region optimization applied to a feature-based representation of the structure frequency response. The automatically generated antenna is characterized by -10 dB bandwidth of over 600 MHz w.r.t. the center frequency of 6.5 GHz and a dual-lobe radiation pattern. The obtained performance figures make the radiator of use for in-door positioning applications. The design method has been favorably compared against the frequency-based trust-region optimization.

Paper number 138:
Title: Large-area Tomographic Tactile Skin with Air Pressure Sensing for Improved Force Estimation
Authors: Haofeng Chen, Bedrich Himmel, Jiri Kubik, Matej Hoffmann, Hyosang Lee
Abstract: This paper presents a dual-channel tactile skin that integrates Electrical Impedance Tomography (EIT) with air pressure sensing to achieve accurate multi-contact force detection. The EIT layer provides spatial contact information, while the air pressure sensor delivers precise total force measurement. Our framework combines these complementary modalities through: deep learning-based EIT image reconstruction, contact area segmentation, and force allocation based on relative conductivity intensities from EIT. The experiments demonstrated 15.1% average force estimation error in single-contact scenarios and 20.1% in multi-contact scenarios without extensive calibration data requirements. This approach effectively addresses the challenge of simultaneously localizing and quantifying multiple contact forces without requiring complex external calibration setups, paving the way for practical and scalable soft robotic skin applications.

Paper number 139:
Title: DehazeMamba: SAR-guided Optical Remote Sensing Image Dehazing with Adaptive State Space Model
Authors: Zhicheng Zhao, Jinquan Yan, Chenglong Li, Xiao Wang, Jin Tang
Abstract: Optical remote sensing image dehazing presents significant challenges due to its extensive spatial scale and highly non-uniform haze distribution, which traditional single-image dehazing methods struggle to address effectively. While Synthetic Aperture Radar (SAR) imagery offers inherently haze-free reference information for large-scale scenes, existing SAR-guided dehazing approaches face two critical limitations: the integration of SAR information often diminishes the quality of haze-free regions, and the instability of feature quality further exacerbates cross-modal domain shift. To overcome these challenges, we introduce DehazeMamba, a novel SAR-guided dehazing network built on a progressive haze decoupling fusion strategy. Our approach incorporates two key innovations: a Haze Perception and Decoupling Module (HPDM) that dynamically identifies haze-affected regions through optical-SAR difference analysis, and a Progressive Fusion Module (PFM) that mitigates domain shift through a two-stage fusion process based on feature quality assessment. To facilitate research in this domain, we present MRSHaze, a large-scale benchmark dataset comprising 8,000 pairs of temporally synchronized, precisely geo-registered SAR-optical images with high resolution and diverse haze conditions. Extensive experiments demonstrate that DehazeMamba significantly outperforms state-of-the-art methods, achieving a 0.73 dB improvement in PSNR and substantial enhancements in downstream tasks such as semantic segmentation. The dataset is available at this https URL.

Paper number 140:
Title: Vision-based automatic fruit counting with UAV
Authors: Hubert Szolc, Mateusz Wasala, Remigiusz Mietla, Kacper Iwicki, Tomasz Kryjak
Abstract: The use of unmanned aerial vehicles (UAVs) for smart agriculture is becoming increasingly popular. This is evidenced by recent scientific works, as well as the various competitions organised on this topic. Therefore, in this work we present a system for automatic fruit counting using UAVs. To detect them, our solution uses a vision algorithm that processes streams from an RGB camera and a depth sensor using classical image operations. Our system also allows the planning and execution of flight trajectories, taking into account the minimisation of flight time and distance covered. We tested the proposed solution in simulation and obtained an average score of 87.27/100 points from a total of 500 missions. We also submitted it to the UAV Competition organised as part of the ICUAS 2024 conference, where we achieved an average score of 84.83/100 points, placing 6th in a field of 23 teams and advancing to the finals.

Paper number 141:
Title: LIVEPOINT: Fully Decentralized, Safe, Deadlock-Free Multi-Robot Control in Cluttered Environments with High-Dimensional Inputs
Authors: Jeffrey Chen, Rohan Chandra
Abstract: Fully decentralized, safe, and deadlock-free multi-robot navigation in dynamic, cluttered environments is a critical challenge in robotics. Current methods require exact state measurements in order to enforce safety and liveness e.g. via control barrier functions (CBFs), which is challenging to achieve directly from onboard sensors like lidars and cameras. This work introduces LIVEPOINT, a decentralized control framework that synthesizes universal CBFs over point clouds to enable safe, deadlock-free real-time multi-robot navigation in dynamic, cluttered environments. Further, LIVEPOINT ensures minimally invasive deadlock avoidance behavior by dynamically adjusting agents' speeds based on a novel symmetric interaction metric. We validate our approach in simulation experiments across highly constrained multi-robot scenarios like doorways and intersections. Results demonstrate that LIVEPOINT achieves zero collisions or deadlocks and a 100% success rate in challenging settings compared to optimization-based baselines such as MPC and ORCA and neural methods such as MPNet, which fail in such environments. Despite prioritizing safety and liveness, LIVEPOINT is 35% smoother than baselines in the doorway environment, and maintains agility in constrained environments while still being safe and deadlock-free.

Paper number 142:
Title: Rapid and Inexpensive Inertia Tensor Estimation from a Single Object Throw
Authors: Till M. Blaha, Mike M. Kuijper, Radu Pop, Ewoud J.J. Smeur
Abstract: The inertia tensor is an important parameter in many engineering fields, but measuring it can be cumbersome and involve multiple experiments or accurate and expensive equipment. We propose a method to measure the moment of inertia tensor of a rigid body from a single spinning throw, by attaching a small and inexpensive stand-alone measurement device consisting of a gyroscope, accelerometer and a reaction wheel. The method includes a compensation for the increase of moment of inertia due to adding the measurement device to the body, and additionally obtains the location of the centre of gravity of the body as an intermediate result. Experiments performed with known rigid bodies show that the mean accuracy is around 2\%.

Paper number 143:
Title: Logic-in-Frames: Dynamic Keyframe Search via Visual Semantic-Logical Verification for Long Video Understanding
Authors: Weiyu Guo, Ziyang Chen, Shaoguang Wang, Jianxiang He, Yijie Xu, Jinhui Ye, Ying Sun, Hui Xiong
Abstract: Understanding long video content is a complex endeavor that often relies on densely sampled frame captions or end-to-end feature selectors, yet these techniques commonly overlook the logical relationships between textual queries and visual elements. In practice, computational constraints necessitate coarse frame subsampling, a challenge analogous to ``finding a needle in a haystack.'' To address this issue, we introduce a semantics-driven search framework that reformulates keyframe selection under the paradigm of Visual Semantic-Logical Search. Specifically, we systematically define four fundamental logical dependencies: 1) spatial co-occurrence, 2) temporal proximity, 3) attribute dependency, and 4) causal order. These relations dynamically update frame sampling distributions through an iterative refinement process, enabling context-aware identification of semantically critical frames tailored to specific query requirements. Our method establishes new SOTA performance on the manually annotated benchmark in key-frame selection metrics. Furthermore, when applied to downstream video question-answering tasks, the proposed approach demonstrates the best performance gains over existing methods on LongVideoBench and Video-MME, validating its effectiveness in bridging the logical gap between textual queries and visual-temporal reasoning. The code will be publicly available.

Paper number 144:
Title: Laplace-Net: Learning Dynamical Systems with External Forcing
Authors: Bernd Zimmering, Cecília Coelho, Vaibhav Gupta, Maria Maleshkova, Oliver Niggemann
Abstract: Modelling forced dynamical systems - where an external input drives the system state - is critical across diverse domains such as engineering, finance, and the natural sciences. In this work, we propose Laplace-Net, a decoupled, solver-free neural framework for learning forced and delay-aware systems. It leverages a Laplace transform-based approach to decompose internal dynamics, external inputs, and initial values into established theoretical concepts, enhancing interpretability. Laplace-Net promotes transferability since the system can be rapidly re-trained or fine-tuned for new forcing signals, providing flexibility in applications ranging from controller adaptation to long-horizon forecasting. Experimental results on eight benchmark datasets - including linear, non-linear, and delayed systems - demonstrate the method's improved accuracy and robustness compared to state-of-the-art approaches, particularly in handling complex and previously unseen inputs.

Paper number 145:
Title: PAUSE: Low-Latency and Privacy-Aware Active User Selection for Federated Learning
Authors: Ori Peleg, Natalie Lang, Stefano Rini, Nir Shlezinger, Kobi Cohen
Abstract: Federated learning (FL) enables multiple edge devices to collaboratively train a machine learning model without the need to share potentially private data. Federated learning proceeds through iterative exchanges of model updates, which pose two key challenges: First, the accumulation of privacy leakage over time, and second, communication latency. These two limitations are typically addressed separately: The former via perturbed updates to enhance privacy and the latter using user selection to mitigate latency - both at the expense of accuracy. In this work, we propose a method that jointly addresses the accumulation of privacy leakage and communication latency via active user selection, aiming to improve the trade-off among privacy, latency, and model performance. To achieve this, we construct a reward function that accounts for these three objectives. Building on this reward, we propose a multi-armed bandit (MAB)-based algorithm, termed Privacy-aware Active User SElection (PAUSE) which dynamically selects a subset of users each round while ensuring bounded overall privacy leakage. We establish a theoretical analysis, systematically showing that the reward growth rate of PAUSE follows that of the best-known rate in MAB literature. To address the complexity overhead of active user selection, we propose a simulated annealing-based relaxation of PAUSE and analyze its ability to approximate the reward-maximizing policy under reduced complexity. We numerically validate the privacy leakage, associated improved latency, and accuracy gains of our methods for the federated training in various scenarios.

Paper number 146:
Title: Robust Decision-Making Via Free Energy Minimization
Authors: Allahkaram Shafiei, Hozefa Jesawada, Karl Friston, Giovanni Russo
Abstract: Despite their groundbreaking performance, state-of-the-art autonomous agents can misbehave when training and environmental conditions become inconsistent, with minor mismatches leading to undesirable behaviors or even catastrophic failures. Robustness towards these training/environment ambiguities is a core requirement for intelligent agents and its fulfillment is a long-standing challenge when deploying agents in the real world. Here, departing from mainstream views seeking robustness through training, we introduce DR-FREE, a free energy model that installs this core property by design. It directly wires robustness into the agent decision-making mechanisms via free energy minimization. By combining a robust extension of the free energy principle with a novel resolution engine, DR-FREE returns a policy that is optimal-yet-robust against ambiguity. Moreover, for the first time, it reveals the mechanistic role of ambiguity on optimal decisions and requisite Bayesian belief updating. We evaluate DR-FREE on an experimental testbed involving real rovers navigating an ambiguous environment filled with obstacles. Across all the experiments, DR-FREE enables robots to successfully navigate towards their goal even when, in contrast, standard free energy minimizing agents that do not use DR-FREE fail. In short, DR-FREE can tackle scenarios that elude previous methods: this milestone may inspire both deployment in multi-agent settings and, at a perhaps deeper level, the quest for a biologically plausible explanation of how natural agents - with little or no training - survive in capricious environments.

Paper number 147:
Title: Sampling Innovation-Based Adaptive Compressive Sensing
Authors: Zhifu Tian, Tao Hu, Chaoyang Niu, Di Wu, Shu Wang
Abstract: Scene-aware Adaptive Compressive Sensing (ACS) has attracted significant interest due to its promising capability for efficient and high-fidelity acquisition of scene images. ACS typically prescribes adaptive sampling allocation (ASA) based on previous samples in the absence of ground truth. However, when confronting unknown scenes, existing ACS methods often lack accurate judgment and robust feedback mechanisms for ASA, thus limiting the high-fidelity sensing of the scene. In this paper, we introduce a Sampling Innovation-Based ACS (SIB-ACS) method that can effectively identify and allocate sampling to challenging image reconstruction areas, culminating in high-fidelity image reconstruction. An innovation criterion is proposed to judge ASA by predicting the decrease in image reconstruction error attributable to sampling increments, thereby directing more samples towards regions where the reconstruction error diminishes significantly. A sampling innovation-guided multi-stage adaptive sampling (AS) framework is proposed, which iteratively refines the ASA through a multi-stage feedback process. For image reconstruction, we propose a Principal Component Compressed Domain Network (PCCD-Net), which efficiently and faithfully reconstructs images under AS scenarios. Extensive experiments demonstrate that the proposed SIB-ACS method significantly outperforms the state-of-the-art methods in terms of image reconstruction fidelity and visual effects. Codes are available at this https URL.

Paper number 148:
Title: Highly Efficient Direct Analytics on Semantic-aware Time Series Data Compression
Authors: Guoyou Sun, Panagiotis Karras, Qi Zhang
Abstract: Semantic communication has emerged as a promising paradigm to tackle the challenges of massive growing data traffic and sustainable data communication. It shifts the focus from data fidelity to goal-oriented or task-oriented semantic transmission. While deep learning-based methods are commonly used for semantic encoding and decoding, they struggle with the sequential nature of time series data and high computation cost, particularly in resource-constrained IoT environments. Data compression plays a crucial role in reducing transmission and storage costs, yet traditional data compression methods fall short of the demands of goal-oriented communication systems. In this paper, we propose a novel method for direct analytics on time series data compressed by the SHRINK compression algorithm. Through experimentation using outlier detection as a case study, we show that our method outperforms baselines running on uncompressed data in multiple cases, with merely 1% difference in the worst case. Additionally, it achieves four times lower runtime on average and accesses approximately 10% of the data volume, which enables edge analytics with limited storage and computation power. These results demonstrate that our approach offers reliable, high-speed outlier detection analytics for diverse IoT applications while extracting semantics from time-series data, achieving high compression, and reducing data transmission.

Paper number 149:
Title: Digital Beamforming Enhanced Radar Odometry
Authors: Jingqi Jiang, Shida Xu, Kaicheng Zhang, Jiyuan Wei, Jingyang Wang, Sen Wang
Abstract: Radar has become an essential sensor for autonomous navigation, especially in challenging environments where camera and LiDAR sensors fail. 4D single-chip millimeter-wave radar systems, in particular, have drawn increasing attention thanks to their ability to provide spatial and Doppler information with low hardware cost and power consumption. However, most single-chip radar systems using traditional signal processing, such as Fast Fourier Transform, suffer from limited spatial resolution in radar detection, significantly limiting the performance of radar-based odometry and Simultaneous Localization and Mapping (SLAM) systems. In this paper, we develop a novel radar signal processing pipeline that integrates spatial domain beamforming techniques, and extend it to 3D Direction of Arrival estimation. Experiments using public datasets are conducted to evaluate and compare the performance of our proposed signal processing pipeline against traditional methodologies. These tests specifically focus on assessing structural precision across diverse scenes and measuring odometry accuracy in different radar odometry systems. This research demonstrates the feasibility of achieving more accurate radar odometry by simply replacing the standard FFT-based processing with the proposed pipeline. The codes are available at GitHub*.

Paper number 150:
Title: Channel Estimation for Pinching-Antenna Systems (PASS)
Authors: Jian Xiao, Ji Wang, Yuanwei Liu
Abstract: Pinching Antennas (PAs) represent a revolutionary flexible antenna technology that leverages dielectric waveguides and electromagnetic coupling to mitigate large-scale path loss. This letter is the first to explore channel estimation for Pinching-Antenna SyStems (PASS), addressing their uniquely ill-conditioned and underdetermined channel characteristics. In particular, two efficient deep learning-based channel estimators are proposed. 1) PAMoE: This estimator incorporates dynamic padding, feature embedding, fusion, and mixture of experts (MoE) modules, which effectively leverage the positional information of PAs and exploit expert diversity. 2) PAformer: This Transformer-style estimator employs the self-attention mechanism to predict channel coefficients in a per-antenna manner, which offers more flexibility to adaptively deal with dynamic numbers of PAs in practical deployment. Numerical results demonstrate that 1) the proposed deep learning-based channel estimators outperform conventional methods and exhibit excellent zero-shot learning capabilities, and 2) PAMoE delivers higher channel estimation accuracy via MoE specialization, while PAformer natively handles an arbitrary number of PAs, trading self-attention complexity for superior scalability.

Paper number 151:
Title: Parameter-free structure-texture image decomposition by unrolling
Authors: Laura Girometti, Jean-François Aujol, Antoine Guennec, Yann Traonmilin
Abstract: In this work, we propose a parameter-free and efficient method to tackle the structure-texture image decomposition problem. In particular, we present a neural network LPR-NET based on the unrolling of the Low Patch Rank model. On the one hand, this allows us to automatically learn parameters from data, and on the other hand to be computationally faster while obtaining qualitatively similar results compared to traditional iterative model-based methods. Moreover, despite being trained on synthetic images, numerical experiments show the ability of our network to generalize well when applied to natural images.

Paper number 152:
Title: Artificial Spacetimes for Reactive Control of Resource-Limited Robots
Authors: William H. Reinhardt, Marc Z. Miskin
Abstract: Field-based reactive control provides a minimalist, decentralized route to guiding robots that lack onboard computation. Such schemes are well suited to resource-limited machines like microrobots, yet implementation artifacts, limited behaviors, and the frequent lack of formal guarantees blunt adoption. Here, we address these challenges with a new geometric approach called artificial spacetimes. We show that reactive robots navigating control fields obey the same dynamics as light rays in general relativity. This surprising connection allows us to adopt techniques from relativity and optics for constructing and analyzing control fields. When implemented, artificial spacetimes guide robots around structured environments, simultaneously avoiding boundaries and executing tasks like rallying or sorting, even when the field itself is static. We augment these capabilities with formal tools for analyzing what robots will do and provide experimental validation with silicon-based microrobots. Combined, this work provides a new framework for generating composed robot behaviors with minimal overhead.

Paper number 153:
Title: Mixtures of ensembles: System separation and identification via optimal transport
Authors: Filip Elvander, Isabel Haasler
Abstract: Crowd dynamics and many large biological systems can be described as populations of agents or particles, which can only be observed on aggregate population level. Identifying the dynamics of agents is crucial for understanding these large systems. However, the population of agents is typically not homogeneous, and thus the aggregate observations consist of the superposition of multiple ensembles each governed by individual dynamics. In this work, we propose an optimal transport framework to jointly separate the population into several ensembles and identify each ensemble's dynamical system, based on aggregate observations of the population. We propose a bi-convex optimization problem, which we solve using a block coordinate descent with convergence guarantees. In numerical experiments, we demonstrate that the proposed approach exhibits close-to-oracle performance also in noisy settings, yielding accurate estimates of both the ensembles and the parameters governing their dynamics.

Paper number 154:
Title: Mixed Small Gain and Phase Theorem: A new view using Scale Relative Graphs
Authors: Eder Baron-Prada, Adolfo Anta, Alberto Padoan, Florian Dörfler
Abstract: We introduce a novel approach to feedback stability analysis for linear time-invariant (LTI) systems, overcoming the limitations of the sectoriality assumption in the small phase theorem. While phase analysis for single-input single-output (SISO) systems is well-established, multi-input multi-output (MIMO) systems lack a comprehensive phase analysis until recent advances introduced with the small-phase theorem. A limitation of the small-phase theorem is the sectorial condition, which states that an operator's eigenvalues must lie within a specified angle sector of the complex plane. We propose a framework based on Scaled Relative Graphs (SRGs) to remove this assumption. We derive two main results: a graphical set-based stability condition using SRGs and a small-phase theorem with no sectorial assumption. These results broaden the scope of phase analysis and feedback stability for MIMO systems.

Paper number 155:
Title: Decentralized Sensor Network Localization using Matrix-Parametrized Proximal Splittings
Authors: Peter Barkley, Robert L. Bassett
Abstract: We present a novel application of a recently-proposed matrix-parametrized proximal splitting method to sensor network localization, the problem of estimating the locations of a set of sensors using only noisy pairwise distance information between the sensors. The decentralized computation required by our approach respects the communication structure between sensors specified by the noisy SNL problem, thereby allowing individual sensors to estimate their location using only local computations and communication with their neighbors. Our proposed method experimentally outperforms a competing method for decentralized computation -- the alternating direction method of multipliers (ADMM) -- with respect to convergence rate and memory use. As an independent methodological contribution, we propose using the Sinkhorn-Knopp algorithm in a completely decentralized manner to construct the matrices which parametrize our proposed splitting method. We show that parameters selected using this method perform similarly to those selected via existing parameter selection methods while requiring far less computation. Unlike centralized interior point solution methods, our first order splitting method allows for efficient warm starting, and we demonstrate improvements in convergence using rough estimates of sensor location to warm start our algorithm. We also find that early termination of the algorithm provides more accurate location estimates than the minimizer of the node-based SDP relaxation of the SNL.

Paper number 156:
Title: An Information-Theoretic Analysis of Discrete-Time Control and Filtering Limitations by the I-MMSE Relationships
Authors: Neng Wan, Dapeng Li, Naira Hovakimyan, Petros G. Voulgaris
Abstract: Fundamental limitations or performance trade-offs/limits are important properties and constraints of both control and filtering systems. Among various trade-off metrics, total information rate that characterizes the sensitivity trade-offs and time-averaged performance of control and filtering systems was conventionally studied by using the differential entropy rate and Kolmogorov-Bode formula. In this paper, by extending the famous I-MMSE (mutual information -- minimum mean-square error) relationships to the discrete-time additive white Gaussian channels with and without feedback, a new paradigm is introduced to estimate and analyze total information rate as a control and filtering trade-off metric. Under this framework, we explore the trade-off properties of total information rate for a variety of the discrete-time control and filtering systems, e.g., LTI, LTV, and nonlinear, and propose an alternative approach to investigate total information rate via optimal estimation.

Paper number 157:
Title: Dehazing Ultrasound using Diffusion Models
Authors: Tristan S.W. Stevens, Faik C. Meral, Jason Yu, Iason Z. Apostolakis, Jean-Luc Robert, Ruud J.G. van Sloun
Abstract: Echocardiography has been a prominent tool for the diagnosis of cardiac disease. However, these diagnoses can be heavily impeded by poor image quality. Acoustic clutter emerges due to multipath reflections imposed by layers of skin, subcutaneous fat, and intercostal muscle between the transducer and heart. As a result, haze and other noise artifacts pose a real challenge to cardiac ultrasound imaging. In many cases, especially with difficult-to-image patients such as patients with obesity, a diagnosis from B-Mode ultrasound imaging is effectively rendered unusable, forcing sonographers to resort to contrast-enhanced ultrasound examinations or refer patients to other imaging modalities. Tissue harmonic imaging has been a popular approach to combat haze, but in severe cases is still heavily impacted by haze. Alternatively, denoising algorithms are typically unable to remove highly structured and correlated noise, such as haze. It remains a challenge to accurately describe the statistical properties of structured haze, and develop an inference method to subsequently remove it. Diffusion models have emerged as powerful generative models and have shown their effectiveness in a variety of inverse problems. In this work, we present a joint posterior sampling framework that combines two separate diffusion models to model the distribution of both clean ultrasound and haze in an unsupervised manner. Furthermore, we demonstrate techniques for effectively training diffusion models on radio-frequency ultrasound data and highlight the advantages over image data. Experiments on both in-vitro and in-vivo cardiac datasets show that the proposed dehazing method effectively removes haze while preserving signals from weakly reflected tissue.

Paper number 158:
Title: Advanced safety filter based on SOS Control Barrier and Lyapunov Functions
Authors: Michael Schneeberger, Silvia Mastellone, Florian Dörfler
Abstract: This paper presents a novel safety filter framework that ensures both safety and the preservation of the legacy control action within a nominal region. This modular design allows the safety filter to be integrated into the control hierarchy without compromising the performance of the existing legacy controller within the nominal region. This is accomplished by formulating multiple Control Barrier Functions (CBFs) and Control Lyapunov-like Functions (CLFs) conditions, alongside a forward invariance condition for the legacy controller, as sum-of-squares constraints utilizing Putinar's Positivstellensatz. Additionally, the state-dependent inequality constraints of the resulting Quadratic Program -- encoding the CBF and CLF conditions -- are designed to remain inactive within the nominal region, ensuring perfect tracking of the legacy control action. Our safety filter design is also the first to include quadratic input constraints, and does not need an explicit specification of the attractor, as it is implicitly defined by the legacy controller. To avoid the chattering effect and guarantee the uniqueness and Lipschitz continuity of solutions, the state-dependent inequality constraints of the Quadratic Program are selected to be sufficiently regular. Finally, we demonstrate the method in a detailed case study involving the control of a three-phase ac/dc power converter.

Paper number 159:
Title: An Overview of Automated Vehicle Longitudinal Platoon Formation Strategies
Authors: M Sabbir Salek, Mugdha Basu Thakur, Pardha Sai Krishna Ala, Mashrur Chowdhury, Matthias Schmid, Pamela Murray-Tuite, Sakib Mahmud Khan, Venkat Krovi
Abstract: Automated vehicle (AV) platooning has the potential to improve the safety, operational, and energy efficiency of surface transportation systems by limiting or eliminating human involvement in the driving tasks. The theoretical validity of the AV platooning strategies has been established and practical applications are being tested under real-world conditions. The emergence of sensors, communication, and control strategies has resulted in rapid and constant evolution of AV platooning strategies. In this paper, we review the state-of-the-art knowledge in AV longitudinal platoon formation using a five-component platooning framework, which includes vehicle model, information-receiving process, information flow topology, spacing policy, and controller and discuss the advantages and limitations of the components. Based on the discussion about existing strategies and associated limitations, potential future research directions are presented.

Paper number 160:
Title: Boundary Constraint-free Biomechanical Model-Based Surface Matching for Intraoperative Liver Deformation Correction
Authors: Zixin Yang, Richard Simon, Kelly Merrell, Cristian. A. Linte
Abstract: In image-guided liver surgery, 3D-3D non-rigid registration methods play a crucial role in estimating the mapping between the preoperative model and the intraoperative surface represented as point clouds, addressing the challenge of tissue deformation. Typically, these methods incorporate a biomechanical model, represented as a finite element model (FEM), into the strain energy term to regularize a surface matching term. We propose a 3D-3D non-rigid registration method that incorporates a modified FEM into the surface matching term. The modified FEM alleviates the need to specify boundary conditions, which is achieved by modifying the stiffness matrix of a FEM and using diagonal loading for stabilization. As a result, the modified surface matching term does not require the specification of boundary conditions or an additional strain energy term to regularize the surface matching term. Optimization is achieved through an accelerated gradient algorithm, further enhanced by our proposed method for determining the optimal step size. We evaluated our method and compared it to several state-of-the-art methods across various datasets. Our straightforward and effective approach consistently outperformed or achieved comparable performance to the state-of-the-art methods. Our code and datasets are available at this https URL.

Paper number 161:
Title: On the Regret of Recursive Methods for Discrete-Time Adaptive Control with Matched Uncertainty
Authors: Aren Karapetyan, Efe C. Balta, Anastasios Tsiamis, Andrea Iannelli, John Lygeros
Abstract: Continuous-time adaptive controllers for systems with a matched uncertainty often comprise an online parameter estimator and a corresponding parameterized controller to cancel the uncertainty. However, such methods are often impossible to implement directly, as they depend on an unobserved estimation error. We consider the equivalent discrete-time setting with a causal information structure, and propose a novel, online proximal point method-based adaptive controller, that under a sufficient excitation (SE) condition is asymptotically stable and achieves finite regret, scaling only with the time required to fulfill the SE. We show the same also for the widely-used recursive least squares with exponential forgetting controller under a stronger persistence of excitation condition.

Paper number 162:
Title: Rethinking model prototyping through the MedMNIST+ dataset collection
Authors: Sebastian Doerrich, Francesco Di Salvo, Julius Brockmann, Christian Ledig
Abstract: The integration of deep learning based systems in clinical practice is often impeded by challenges rooted in limited and heterogeneous medical datasets. In addition, the field has increasingly prioritized marginal performance gains on a few, narrowly scoped benchmarks over clinical applicability, slowing down meaningful algorithmic progress. This trend often results in excessive fine-tuning of existing methods on selected datasets rather than fostering clinically relevant innovations. In response, this work introduces a comprehensive benchmark for the MedMNIST+ dataset collection, designed to diversify the evaluation landscape across several imaging modalities, anatomical regions, classification tasks and sample sizes. We systematically reassess commonly used Convolutional Neural Networks (CNNs) and Vision Transformer (ViT) architectures across distinct medical datasets, training methodologies, and input resolutions to validate and refine existing assumptions about model effectiveness and development. Our findings suggest that computationally efficient training schemes and modern foundation models offer viable alternatives to costly end-to-end training. Additionally, we observe that higher image resolutions do not consistently improve performance beyond a certain threshold. This highlights the potential benefits of using lower resolutions, particularly in prototyping stages, to reduce computational demands without sacrificing accuracy. Notably, our analysis reaffirms the competitiveness of CNNs compared to ViTs, emphasizing the importance of comprehending the intrinsic capabilities of different architectures. Finally, by establishing a standardized evaluation framework, we aim to enhance transparency, reproducibility, and comparability within the MedMNIST+ dataset collection. Code is available at this https URL .

Paper number 163:
Title: LLM-based speaker diarization correction: A generalizable approach
Authors: Georgios Efstathiadis, Vijay Yadav, Anzar Abbas
Abstract: Speaker diarization is necessary for interpreting conversations transcribed using automated speech recognition (ASR) tools. Despite significant developments in diarization methods, diarization accuracy remains an issue. Here, we investigate the use of large language models (LLMs) for diarization correction as a post-processing step. LLMs were fine-tuned using the Fisher corpus, a large dataset of transcribed conversations. The ability of the models to improve diarization accuracy in a holdout dataset from the Fisher corpus as well as an independent dataset was measured. We report that fine-tuned LLMs can markedly improve diarization accuracy. However, model performance is constrained to transcripts produced using the same ASR tool as the transcripts used for fine-tuning, limiting generalizability. To address this constraint, an ensemble model was developed by combining weights from three separate models, each fine-tuned using transcripts from a different ASR tool. The ensemble model demonstrated better overall performance than each of the ASR-specific models, suggesting that a generalizable and ASR-agnostic approach may be achievable. We have made the weights of these models publicly available on HuggingFace at this https URL.

Paper number 164:
Title: Unified Fourier bases for signals on random graphs with group symmetries
Authors: Mahya Ghandehari, Jeannette Janssen, Silo Murphy
Abstract: We consider a recently proposed approach to graph signal processing (GSP) based on graphons. We show how the graphon-based approach to GSP applies to graphs sampled from a stochastic block model derived from a weighted Cayley graph. When SBM block sizes are equal, a nice Fourier basis can be derived from the representation theory of the underlying group. We explore how the SBM Fourier basis is affected when block sizes are not uniform. When block sizes are nearly uniform, we demonstrate that the group Fourier basis closely approximates the SBM Fourier basis. More specifically, we quantify the approximation error using matrix perturbation theory. When block sizes are highly non-uniform, the group-based Fourier basis can no longer be used. However, we show that partial information regarding the SBM Fourier basis can still be obtained from the underlying group.

Paper number 165:
Title: IVCA: Inter-Relation-Aware Video Complexity Analyzer
Authors: Junqi Liao, Yao Li, Zhuoyuan Li, Li Li, Dong Liu
Abstract: To address the real-time analysis requirements of video streaming applications, we propose an innovative inter-relation-aware video complexity analyzer (IVCA) to enhance the existing video complexity analyzer (VCA). The IVCA overcomes the limitations of the VCA by incorporating inter-frame relations, focusing on inter motion and reference structure. To begin with, we improve the accuracy of temporal features by integrating feature-domain motion estimation into the IVCA framework, which allows for a more nuanced understanding of motion across frames. Furthermore, inspired by the hierarchical reference structures utilized in modern codecs, we introduce layer-aware weights that effectively adjust the contributions of frame complexity across different layers, ensuring a more balanced representation of video characteristics. In addition, we broaden the analysis of temporal features by considering reference frames rather than relying solely on the preceding frame, thereby enriching the contextual understanding of video content. Experimental results demonstrate a significant enhancement in complexity estimation accuracy achieved by the IVCA, coupled with a negligible increase in time complexity, indicating its potential for real-time applications in video streaming scenarios. This advancement not only improves video processing efficiency but also paves the way for more sophisticated analytical tools in video technology.

Paper number 166:
Title: iCPS-DL: A Description Language for Autonomic Industrial Cyber-Physical Systems
Authors: Dimitrios Kouzapas, Christos G. Panayiotou, Demetrios G. Eliades
Abstract: Modern industrial systems require frequent updates to their cyber and physical infrastructures, often demanding considerable reconfiguration effort. This paper introduces the industrial Cyber-Physical Systems Description Language, iCPS-DL, which enables autonomic reconfigurations for industrial Cyber-Physical Systems. The iCPS-DL maps an industrial process using semantics for physical and cyber-physical components, a state estimation model, and agent interactions. A novel aspect is using communication semantics to ensure live interaction among distributed agents. Reasoning on the semantic description facilitates the configuration of the industrial process control loop. A Water Distribution Networks domain case study demonstrates iCPS-DL's application.

Paper number 167:
Title: USTC-TD: A Test Dataset and Benchmark for Image and Video Coding in 2020s
Authors: Zhuoyuan Li, Junqi Liao, Chuanbo Tang, Haotian Zhang, Yuqi Li, Yifan Bian, Xihua Sheng, Xinmin Feng, Yao Li, Changsheng Gao, Li Li, Dong Liu, Feng Wu
Abstract: Image/video coding has been a remarkable research area for both academia and industry for many years. Testing datasets, especially high-quality image/video datasets are desirable for the justified evaluation of coding-related research, practical applications, and standardization activities. We put forward a test dataset namely USTC-TD, which has been successfully adopted in the practical end-to-end image/video coding challenge of the IEEE International Conference on Visual Communications and Image Processing (VCIP) in 2022 and 2023. USTC-TD contains 40 images at 4K spatial resolution and 10 video sequences at 1080p spatial resolution, featuring various content due to the diverse environmental factors (e.g. scene type, texture, motion, view) and the designed imaging factors (e.g. illumination, lens, shadow). We quantitatively evaluate USTC-TD on different image/video features (spatial, temporal, color, lightness), and compare it with the previous image/video test datasets, which verifies its excellent compensation for the shortcomings of existing datasets. We also evaluate both classic standardized and recently learned image/video coding schemes on USTC-TD using objective quality metrics (PSNR, MS-SSIM, VMAF) and subjective quality metric (MOS), providing an extensive benchmark for these evaluated schemes. Based on the characteristics and specific design of the proposed test dataset, we analyze the benchmark performance and shed light on the future research and development of image/video coding. All the data are released online: this https URL.

Paper number 168:
Title: Three-dimensional Nonlinear Path-following Guidance with Bounded Input Constraints
Authors: Saurabh Kumar, Shashi Ranjan Kumar, Abhinav Sinha
Abstract: In this paper, we consider the tracking of arbitrary curvilinear geometric paths in three-dimensional output spaces of unmanned aerial vehicles (UAVs) without pre-specified timing requirements, commonly referred to as path-following problems, subjected to bounded inputs. Specifically, we propose a novel nonlinear path-following guidance law for a UAV that enables it to follow any smooth curvilinear path in three dimensions while accounting for the bounded control authority in the design. The proposed solution offers a general treatment of the path-following problem by removing the dependency on the path's geometry, which makes it applicable to paths with varying levels of complexity and smooth curvatures. Additionally, the proposed strategy draws inspiration from the pursuit guidance approach, which is known for its simplicity and ease of implementation. Theoretical analysis guarantees that the UAV converges to its desired path within a fixed time and remains on it irrespective of its initial configuration with respect to the path. Finally, the simulations demonstrate the merits and effectiveness of the proposed guidance strategy through a wide range of engagement scenarios, showcasing the UAV's ability to follow diverse curvilinear paths accurately.

Paper number 169:
Title: Kernel-Based Learning of Stable Nonlinear Systems
Authors: Matteo Scandella, Michelangelo Bin, Thomas Parisini
Abstract: Learning models of dynamical systems characterized by specific stability properties is of crucial importance in applications. Existing results mainly focus on linear systems or some limited classes of nonlinear systems and stability notions, and the general problem is still open. This article proposes a kernel-based nonlinear identification procedure to directly and systematically learn stable nonlinear discrete-time systems. In particular, the proposed method can be used to enforce, on the learned model, bounded-input-bounded-state stability, asymptotic gain, and input-to-state stability properties, as well as their incremental counterparts. To this aim, we build on the reproducing kernel theory and the Representer Theorem, which are suitably enhanced to handle stability constraints in the kernel properties and in the hyperparameters' selection algorithm. Once the methodology is detailed, and sufficient conditions for stability are singled out, the article reviews some widely used kernels and their applicability within the proposed framework. Finally, numerical results validate the theoretical findings showing, in particular, that stability may have a beneficial impact in long-term simulation with minimal impact on prediction.

Paper number 170:
Title: Stochastic Data-Driven Predictive Control: Chance-Constraint Satisfaction with Identified Multi-step Predictors
Authors: Haldun Balim, Andrea Carron, Melanie N. Zeilinger, Johannes Köhler
Abstract: We propose a novel data-driven stochastic model predictive control framework for uncertain linear systems with noisy output measurements. Our approach leverages multi-step predictors to efficiently propagate uncertainty, ensuring chance constraint satisfaction. In particular, we present a strategy to identify multi-step predictors and quantify the associated uncertainty using a surrogate (data-driven) state space model. Then, we utilize the derived distribution to formulate a constraint tightening that ensures chance constraint satisfaction despite the parametric uncertainty. A numerical example highlights the reduced conservatism of handling parametric uncertainty in the proposed method compared to state-of-the-art solutions.

Paper number 171:
Title: Personalized Speech Emotion Recognition in Human-Robot Interaction using Vision Transformers
Authors: Ruchik Mishra, Andrew Frye, Madan Mohan Rayguru, Dan O. Popa
Abstract: Emotions are an essential element in verbal communication, so understanding individuals' affect during a human-robot interaction (HRI) becomes imperative. This paper investigates the application of vision transformer models, namely ViT (Vision Transformers) and BEiT (BERT Pre-Training of Image Transformers) pipelines, for Speech Emotion Recognition (SER) in HRI. The focus is to generalize the SER models for individual speech characteristics by fine-tuning these models on benchmark datasets and exploiting ensemble methods. For this purpose, we collected audio data from different human subjects having pseudo-naturalistic conversations with the NAO robot. We then fine-tuned our ViT and BEiT-based models and tested these models on unseen speech samples from the participants. In the results, we show that fine-tuning vision transformers on benchmark datasets and and then using either these already fine-tuned models or ensembling ViT/BEiT models gets us the highest classification accuracies per individual when it comes to identifying four primary emotions from their speech: neutral, happy, sad, and angry, as compared to fine-tuning vanilla-ViTs or BEiTs.

Paper number 172:
Title: A Plug-and-Play Method for Guided Multi-contrast MRI Reconstruction based on Content/Style Modeling
Authors: Chinmay Rao, Matthias van Osch, Nicola Pezzotti, Jeroen de Bresser, Laurens Beljaards, Jakob Meineke, Elwin de Weerdt, Huangling Lu, Mariya Doneva, Marius Staring
Abstract: Since multiple MRI contrasts of the same anatomy contain redundant information, one contrast can be used as a prior for guiding the reconstruction of an undersampled subsequent contrast. To this end, several learning-based guided reconstruction methods have been proposed. However, a key challenge is the requirement of large paired training datasets comprising raw data and aligned reference images. We propose a modular two-stage approach for guided reconstruction addressing this issue, which additionally provides an explanatory framework for the multi-contrast problem in terms of the shared and non-shared generative factors underlying two given contrasts. A content/style model of two-contrast image data is learned from a largely unpaired image-domain dataset and is subsequently applied as a plug-and-play operator in iterative reconstruction. The disentanglement of content and style allows explicit representation of contrast-independent and contrast-specific factors. Based on this, incorporating prior information into the reconstruction reduces to simply replacing the aliased content of the image estimate with high-quality content derived from the reference scan. Combining this component with a data consistency step and introducing a general corrective process for the content yields an iterative scheme. We name this novel approach PnP-MUNIT. Various aspects like interpretability and convergence are explored via simulations. Furthermore, its practicality is demonstrated on the NYU fastMRI DICOM dataset and two in-house multi-coil raw datasets, obtaining up to 32.6% more acceleration over learning-based non-guided reconstruction for a given SSIM. In a radiological task, PnP-MUNIT allowed 33.3% more acceleration over clinical reconstruction at diagnostic quality.

Paper number 173:
Title: Brain Tumor Classification on MRI in Light of Molecular Markers
Authors: Jun Liu, Geng Yuan, Weihao Zeng, Hao Tang, Wenbin Zhang, Xue Lin, XiaoLin Xu, Dong Huang, Yanzhi Wang
Abstract: In research findings, co-deletion of the 1p/19q gene is associated with clinical outcomes in low-grade gliomas. The ability to predict 1p19q status is critical for treatment planning and patient follow-up. This study aims to utilize a specially MRI-based convolutional neural network for brain cancer detection. Although public networks such as RestNet and AlexNet can effectively diagnose brain cancers using transfer learning, the model includes quite a few weights that have nothing to do with medical images. As a result, the diagnostic results are unreliable by the transfer learning model. To deal with the problem of trustworthiness, we create the model from the ground up, rather than depending on a pre-trained model. To enable flexibility, we combined convolution stacking with a dropout and full connect operation, it improved performance by reducing overfitting. During model training, we also supplement the given dataset and inject Gaussian noise. We use three--fold cross-validation to train the best selection model. Comparing InceptionV3, VGG16, and MobileNetV2 fine-tuned with pre-trained models, our model produces better results. On an validation set of 125 codeletion vs. 31 not codeletion images, the proposed network achieves 96.37\% percent F1-score, 97.46\% percent precision, and 96.34\% percent recall when classifying 1p/19q codeletion and not codeletion images.

Paper number 174:
Title: MDiff-FMT: Morphology-aware Diffusion Model for Fluorescence Molecular Tomography with Small-scale Datasets
Authors: Peng Zhang, Qianqian Xue, Xingyu Liu, Guanglei Zhang, Wenjian Wang, Jiye Liang
Abstract: Fluorescence molecular tomography (FMT) is a sensitive optical imaging technology widely used in biomedical research. However, the ill-posedness of the inverse problem poses a huge challenge to FMT reconstruction. Although end-to-end deep learning algorithms have been widely used to address this critical issue, they still suffer from high data dependency and poor morphological restoration. In this paper, we report for the first time a morphology-aware diffusion model, MDiff-FMT, based on denoising diffusion probabilistic model (DDPM) to achieve high-fidelity morphological reconstruction for FMT. First, we use the noise addition of DDPM to simulate the process of the gradual degradation of morphological features, and achieve fine-grained reconstruction of morphological features through a stepwise probabilistic sampling mechanism, avoiding problems such as loss of structure details that may occur in end-to-end deep learning methods. Additionally, we introduce the conditional fluorescence image as structural prior information to sample a high-fidelity reconstructed image from the noisy images. Numerous numerical and real phantom experimental results show that the proposed MDiff-FMT achieves SOTA results in morphological reconstruction of FMT without relying on large-scale datasets.

Paper number 175:
Title: Co-learning Single-Step Diffusion Upsampler and Downsampler with Two Discriminators and Distillation
Authors: Sohwi Kim, Tae-Kyun Kim
Abstract: Super-resolution (SR) aims to reconstruct high-resolution (HR) images from their low-resolution (LR) counterparts, often relying on effective downsampling to generate diverse and realistic training pairs. In this work, we propose a co-learning framework that jointly optimizes a single-step diffusion-based upsampler and a learnable downsampler, enhanced by two discriminators and a cyclic distillation strategy. Our learnable downsampler is designed to better capture realistic degradation patterns while preserving structural details in the LR domain, which is crucial for enhancing SR performance. By leveraging a diffusion-based approach, our model generates diverse LR-HR pairs during training, enabling robust learning across varying degradations. We demonstrate the effectiveness of our method on both general real-world and domain-specific face SR tasks, achieving state-of-the-art performance in both fidelity and perceptual quality. Our approach not only improves efficiency with a single inference step but also ensures high-quality image reconstruction, bridging the gap between synthetic and real-world SR scenarios.

Paper number 176:
Title: Trajectory Optimization for Spatial Microstructure Control in Electron Beam Metal Additive Manufacturing
Authors: Mikhail Khrenov, Moon Tan, Lauren Fitzwater, Michelle Hobdari, Sneha Prabha Narra
Abstract: Metal additive manufacturing (AM) opens the possibility for spatial control of as-fabricated microstructure and properties. However, since the solid state diffusional transformations that drive microstructure outcomes are governed by nonlinear ODEs in terms of temperature, which is itself governed by PDEs over the entire part domain, solving for the system inputs needed to achieve desired microstructure distributions has proven difficult. In this work, we present a trajectory optimization approach for spatial control of microstructure in metal AM, which we demonstrate by controlling the hardness of a low-alloy steel in electron beam powder bed fusion (EB-PBF). To this end, we present models for thermal and microstructural dynamics. Next, we use experimental data to identify the parameters of the microstructure transformation dynamics. We then pose spatial microstructure control as a finite-horizon optimal control problem. The optimal power field trajectory is computed using an augmented Lagrangian differential dynamic programming (AL-DDP) method with GPU acceleration. The resulting time-varying power fields are then realized on an EB-PBF machine through an approximation scheme. Measurements of the resultant hardness shows that the optimized power field trajectory is able to closely produce the desired hardness distribution.

Paper number 177:
Title: Development and prospective validation of a prostate cancer detection, grading, and workflow optimization system at an academic medical center
Authors: Ramin Nateghi, Ruoji Zhou, Madeline Saft, Marina Schnauss, Clayton Neill, Ridwan Alam, Nicole Handa, Mitchell Huang, Eric V Li, Jeffery A Goldstein, Edward M Schaeffer, Menatalla Nadim, Fattaneh Pourakpour, Bogdan Isaila, Christopher Felicelli, Vikas Mehta, Behtash G Nezami, Ashley Ross, Ximing Yang, Lee AD Cooper
Abstract: Artificial intelligence may assist healthcare systems in meeting increasing demand for pathology services while maintaining diagnostic quality and reducing turnaround time and costs. We aimed to investigate the performance of an institutionally developed system for prostate cancer detection, grading, and workflow optimization and to contrast this with commercial alternatives. From August 2021 to March 2023, we scanned 21,396 slides from 1,147 patients receiving prostate biopsy. We developed models for cancer detection, grading, and screening of equivocal cases for IHC ordering. We compared the performance of task-specific prostate models with general-purpose foundation models in a prospectively collected dataset that reflects our patient population. We also evaluated the contributions of a bespoke model designed to improve sensitivity to small cancer foci and perception of low-resolution patterns. We found high concordance with pathologist ground-truth in detection (area under curve 98.5%, sensitivity 95.0%, and specificity 97.8%), ISUP grading (Cohen's kappa 0.869), grade group 3 or higher classification (area under curve 97.5%, sensitivity 94.9%, specificity 96.6%). Screening models could correctly classify 55% of biopsy blocks where immunohistochemistry was ordered with a 1.4% error rate. No statistically significant differences were observed between task-specific and foundation models in cancer detection, although the task-specific model is significantly smaller and faster. Institutions like academic medical centers that have high scanning volumes and report abstraction capabilities can develop highly accurate computational pathology models for internal use. These models have the potential to aid in quality control role and to improve resource allocation and workflow in the pathology lab to help meet future challenges in prostate cancer diagnosis.

Paper number 178:
Title: Two-Layer Attention Optimization for Bimanual Coordination
Authors: Justin Ting, Jing Shuang Li
Abstract: Bimanual tasks performed by human agents present unique optimal control considerations compared to cyberphysical agents. These considerations include minimizing attention, distributing attention across two isolated hands, and coordinating the two hands to reach a broader goal. In this work, we propose a two-layer controller that captures these considerations. The upper layer solves an attention distribution problem, while the two lower layer controllers (one per hand) tracks a trajectory using the solution given by the upper layer. We introduce a formulation of the attention controller where attention is a vector that is bound within a hyperbolic feasible region, which is determined by specifications of the task the lower layer controllers. This two-layer controller is used to optimize a single-player game of pong, where the agent must rally the ball between two paddles for as long as possible. We find that adding an attention layer on top of the lower controllers allows the agent to coordinate the left and right hands, which minimizes attention and control effort over the course of the rallying task.

Paper number 179:
Title: DG-PPU: Dynamical Graphs based Post-processing of Point Clouds extracted from Knee Ultrasounds
Authors: Injune Hwang, Karthik Saravanan, Caterina V Coralli, S Jack Tu, Stephen J Mellon
Abstract: Patients undergoing total knee arthroplasty (TKA) often experience non-specific anterior knee pain, arising from abnormal patellofemoral joint (PFJ) instability. Tracking PFJ motion is challenging since static imaging modalities like CT and MRI are limited by field of view and metal artefact interference. Ultrasounds offer an alternative modality for dynamic musculoskeletal imaging. We aim to achieve accurate visualisation of patellar tracking and PFJ motion, using 3D registration of point clouds extracted from ultrasound scans across different angles of joint flexion. Ultrasound images containing soft tissue are often mislabeled as bone during segmentation, resulting in noisy 3D point clouds that hinder accurate registration of the bony joint anatomy. Machine learning the intrinsic geometry of the knee bone may help us eliminate these false positives. As the intrinsic geometry of the knee does not change during PFJ motion, one may expect this to be robust across multiple angles of joint flexion. Our dynamical graphs-based post-processing algorithm (DG-PPU) is able to achieve this, creating smoother point clouds that accurately represent bony knee anatomy across different angles. After inverting these point clouds back to their original ultrasound images, we evaluated that DG-PPU outperformed manual data cleaning done by our lab technician, deleting false positives and noise with 98.2% precision across three different angles of joint flexion. DG-PPU is the first algorithm to automate the post-processing of 3D point clouds extracted from ultrasound scans. With DG-PPU, we contribute towards the development of a novel patellar mal-tracking assessment system with ultrasound, which currently does not exist.

Paper number 180:
Title: Enhancing reinforcement learning for population setpoint tracking in co-cultures
Authors: Sebastián Espinel-Ríos, Joyce Qiaoxi Mo, Dongda Zhang, Ehecatl Antonio del Rio-Chanona, José L. Avalos
Abstract: Efficient multiple setpoint tracking can enable advanced biotechnological applications, such as maintaining desired population levels in co-cultures for optimal metabolic division of labor. In this study, we employ reinforcement learning as a control method for population setpoint tracking in co-cultures, focusing on policy-gradient techniques where the control policy is parameterized by neural networks. However, achieving accurate tracking across multiple setpoints is a significant challenge in reinforcement learning, as the agent must effectively balance the contributions of various setpoints to maximize the expected system performance. Traditional return functions, such as those based on a quadratic cost, often yield suboptimal performance due to their inability to efficiently guide the agent toward the simultaneous satisfaction of all setpoints. To overcome this, we propose a novel return function that rewards the simultaneous satisfaction of multiple setpoints and diminishes overall reward gains otherwise, accounting for both stage and terminal system performance. This return function includes parameters to fine-tune the desired smoothness and steepness of the learning process. We demonstrate our approach considering an $\textit{Escherichia coli}$ co-culture in a chemostat with optogenetic control over amino acid synthesis pathways, leveraging auxotrophies to modulate growth.

Paper number 181:
Title: vesselFM: A Foundation Model for Universal 3D Blood Vessel Segmentation
Authors: Bastian Wittmann, Yannick Wattenberg, Tamaz Amiranashvili, Suprosanna Shit, Bjoern Menze
Abstract: Segmenting 3D blood vessels is a critical yet challenging task in medical image analysis. This is due to significant imaging modality-specific variations in artifacts, vascular patterns and scales, signal-to-noise ratios, and background tissues. These variations, along with domain gaps arising from varying imaging protocols, limit the generalization of existing supervised learning-based methods, requiring tedious voxel-level annotations for each dataset separately. While foundation models promise to alleviate this limitation, they typically fail to generalize to the task of blood vessel segmentation, posing a unique, complex problem. In this work, we present vesselFM, a foundation model designed specifically for the broad task of 3D blood vessel segmentation. Unlike previous models, vesselFM can effortlessly generalize to unseen domains. To achieve zero-shot generalization, we train vesselFM on three heterogeneous data sources: a large, curated annotated dataset, data generated by a domain randomization scheme, and data sampled from a flow matching-based generative model. Extensive evaluations show that vesselFM outperforms state-of-the-art medical image segmentation foundation models across four (pre-)clinically relevant imaging modalities in zero-, one-, and few-shot scenarios, therefore providing a universal solution for 3D blood vessel segmentation.

Paper number 182:
Title: Distributed Estimation with Quantized Measurements and Communication over Markovian Switching Topologies
Authors: Ying Wang, Jian Guo, Yanlong Zhao, Ji-feng Zhang
Abstract: This paper addresses distributed parameter estimation in stochastic dynamic systems with quantized measurements, constrained by quantized communication and Markovian switching directed topologies. To enable accurate recovery of the original signal from quantized communication signal, a persistent excitation-compliant linear compression encoding method is introduced. Leveraging this encoding, this paper proposes an estimation-fusion type quantized distributed identification algorithm under a stochastic approximation framework. The algorithm operates in two phases: first, it estimates neighboring estimates using quantized communication information, then it creates a fusion estimate by combining these estimates through a consensus-based distributed stochastic approximation approach. To tackle the difficulty caused by the coupling between these two estimates, two combined Lyapunov functions are constructed to analyze the convergence performance. Specifically, the mean-square convergence of the estimates is established under a conditional expectation-type cooperative excitation condition and the union topology containing a spanning tree. Besides, the convergence rate is derived to match the step size's order under suitable step-size coefficients. Furthermore, the impact of communication uncertainties including stochastic communication noise and Markov-switching rate is analyzed on the convergence rate. A numerical example illustrates the theoretical findings and highlights the joint effect of sensors under quantized communication.

Paper number 183:
Title: Learning of Patch-Based Smooth-Plus-Sparse Models for Image Reconstruction
Authors: Stanislas Ducotterd, Sebastian Neumayer, Michael Unser
Abstract: We aim at the solution of inverse problems in imaging, by combining a penalized sparse representation of image patches with an unconstrained smooth one. This allows for a straightforward interpretation of the reconstruction. We formulate the optimization as a bilevel problem. The inner problem deploys classical algorithms while the outer problem optimizes the dictionary and the regularizer parameters through supervised learning. The process is carried out via implicit differentiation and gradient-based optimization. We evaluate our method for denoising, super-resolution, and compressed-sensing magnetic-resonance imaging. We compare it to other classical models as well as deep-learning-based methods and show that it always outperforms the former and also the latter in some instances.

Paper number 184:
Title: Relative Pose Observability Analysis Using Dual Quaternions
Authors: Nicholas B. Andrews, Kristi A. Morgansen
Abstract: Relative pose (position and orientation) estimation is an essential component of many robotics applications. Fiducial markers, such as the AprilTag visual fiducial system, yield a relative pose measurement from a single marker detection and provide a powerful tool for pose estimation. In this paper, we perform a Lie algebraic nonlinear observability analysis on a nonlinear dual quaternion system that is composed of a relative pose measurement model and a relative motion model. We prove that many common dual quaternion expressions yield Jacobian matrices with advantageous block structures and rank properties that are beneficial for analysis. We show that using a dual quaternion representation yields an observability matrix with a simple block triangular structure and satisfies the necessary full rank condition.

Paper number 185:
Title: Quantitative Decentralized Stability Certificates for Grid-Forming Converter Control
Authors: Verena Häberle, Xiuqiang He, Linbin Huang, Florian Dörfler, Steven Low
Abstract: We propose a decentralized framework for guaranteeing the small-signal stability of future power systems with grid-forming converters. Our approach leverages dynamic loop-shifting techniques to compensate for the lack of passivity in the network dynamics and establishes decentralized parametric stability certificates, depending on the local device-level controls and incorporating the effects of the network dynamics. By following practical tuning rules, we are able to ensure plug-and-play operation without centralized coordination. Unlike prior works, our approach accommodates coupled frequency and voltage dynamics, incorporates network dynamics, and does not rely on specific network configurations or operating points, offering a general and scalable solution for the integration of power-electronics-based devices into future power systems. We validate our theoretical stability results through numerical case studies in a high-fidelity simulation model.

Paper number 186:
Title: Ro-To-Go! Robust Reactive Control with Signal Temporal Logic
Authors: Roland Ilyes, Lara Brudermüller, Nick Hawes, Bruno Lacerda
Abstract: Signal Temporal Logic (STL) robustness is a common objective for optimal robot control, but its dependence on history limits the robot's decision-making capabilities when used in Model Predictive Control (MPC) approaches. In this work, we introduce Signal Temporal Logic robustness-to-go (Ro-To-Go), a new quantitative semantics for the logic that isolates the contributions of suffix trajectories. We prove its relationship to formula progression for Metric Temporal Logic, and show that the robustness-to-go depends only on the suffix trajectory and progressed formula. We implement robustness-to-go as the objective in an MPC algorithm and use formula progression to efficiently evaluate it online. We test the algorithm in simulation and compare it to MPC using traditional STL robustness. Our experiments show that using robustness-to-go results in a higher success rate.

Paper number 187:
Title: Automating Hot-Rolling: Designing an Integrated Mechatronics System for Enhanced Efficiency in Sheet Metal Production
Authors: Mostafa A. Mostafa (1), Mohamed Khaled (1), Abdelrahman Ali (1), Amr Mostafa (1), Mariam Mohamed (1), Omar Ahmed (1), Osama Khalil (1) ((1) Egypt-Japan University of Science and Technology, Egypt)
Abstract: The hot-rolling process is a critical stage in sheet metal production within the heavy steel industry. Traditionally, parameter adjustments such as sheet metal velocity and roll gap are performed manually, leading to inefficiencies and limited precision. This project introduces an integrated mechatronics system designed to automate the control of rolling speed and sheet metal thickness, enhancing efficiency, consistency, and quality. The proposed system consists of a pair of rolls applying compression loads, with a mechanism for gap control, suitable motors and sensors, and dynamic modeling to optimize performance. Through simulation and practical implementation strategies, we demonstrate the feasibility of automating the hot-rolling process. By integrating mechatronics, this solution aims to modernize sheet metal production, improve productivity, and enhance product quality in the steel industry.

Paper number 188:
Title: Pulling Back Theorem for Generalizing the Diagonal Averaging Principle in Symplectic Geometry Mode Decomposition and Singular Spectrum Analysis
Authors: Hong-Yan Zhang, Haoting Liu, Zhi-Qiang Feng, Ci-Fei Dong, Rui-Jia Lin, Yu Zhou, Fu-Yun Li
Abstract: The symplectic geometry mode decomposition (SGMD) is a powerful method for analyzing time sequences. The SGMD is based on the upper conversion via embedding and down conversion via diagonal averaging principle (DAP) inherited from the singular spectrum analysis (SSA). However, there are two defects in the DAP: it just hold for the time delay $\tau=1$ in the trajectory matrix and it fails for the time sequence of type-1 with the form $X=\{x[n]\}^N_{n=1}$. In order to overcome these disadvantages, the inverse step for embedding is explored with binary Diophantine equation in number theory. The contributions of this work lie in three aspects: firstly, the pulling back theorem is proposed and proved, which state the general formula for converting the component of trajectory matrix to the component of time sequence for the general representation of time sequence and for any time delay $\tau\ge 1$; secondly a unified framework for decomposing both the deterministic and random time sequences into multiple modes is presented and explained; finally, the guidance of configuring the time delay is suggested, namely the time delay should be selected in a limited range via balancing the efficiency of matrix computation and accuracy of state estimation. It could be expected that the pulling back theorem will help the researchers and engineers to deepen the understanding of the theory and extend the applications of the SGMD and SSA in analyzing time sequences.

Paper number 189:
Title: Automatic quality control in multi-centric fetal brain MRI super-resolution reconstruction
Authors: Thomas Sanchez, Vladyslav Zalevskyi, Angeline Mihailov, Gerard Martí-Juan, Elisenda Eixarch, Andras Jakab, Vincent Dunet, Mériam Koob, Guillaume Auzias, Meritxell Bach Cuadra
Abstract: Quality control (QC) has long been considered essential to guarantee the reliability of neuroimaging studies. It is particularly important for fetal brain MRI, where acquisitions and image processing techniques are less standardized than in adult imaging. In this work, we focus on automated quality control of super-resolution reconstruction (SRR) volumes of fetal brain MRI, an important processing step where multiple stacks of thick 2D slices are registered together and combined to build a single, isotropic and artifact-free T2 weighted volume. We propose FetMRQC$_{SR}$, a machine-learning method that extracts more than 100 image quality metrics to predict image quality scores using a random forest model. This approach is well suited to a problem that is high dimensional, with highly heterogeneous data and small datasets. We validate FetMRQC$_{SR}$ in an out-of-domain (OOD) setting and report high performance (ROC AUC = 0.89), even when faced with data from an unknown site or SRR method. We also investigate failure cases and show that they occur in $45\%$ of the images due to ambiguous configurations for which the rating from the expert is arguable. These results are encouraging and illustrate how a non deep learning-based method like FetMRQC$_{SR}$ is well suited to this multifaceted problem. Our tool, along with all the code used to generate, train and evaluate the model will be released upon acceptance of the paper.

Paper number 190:
Title: ShieldNN: A Provably Safe NN Filter for Unsafe NN Controllers
Authors: James Ferlez, Mahmoud Elnaggar, Yasser Shoukry, Cody Fleming
Abstract: In this paper, we develop a novel closed-form Control Barrier Function (CBF) and associated controller shield for the Kinematic Bicycle Model (KBM) with respect to obstacle avoidance. The proposed CBF and shield -- designed by an algorithm we call ShieldNN -- provide two crucial advantages over existing methodologies. First, ShieldNN considers steering and velocity constraints directly with the non-affine KBM dynamics; this is in contrast to more general methods, which typically consider only affine dynamics and do not guarantee invariance properties under control constraints. Second, ShieldNN provides a closed-form set of safe controls for each state unlike more general methods, which typically rely on optimization algorithms to generate a single instantaneous for each state. Together, these advantages make ShieldNN uniquely suited as an efficient Multi-Obstacle Safe Actions (i.e. multiple-barrier-function shielding) during training time of a Reinforcement Learning (RL) enabled Neural Network controller. We show via experiments that ShieldNN dramatically increases the completion rate of RL training episodes in the presence of multiple obstacles, thus establishing the value of ShieldNN in training RL-based controllers.

Paper number 191:
Title: Stochastic Primal-Dual Three Operator Splitting Algorithm with Extension to Equivariant Regularization-by-Denoising
Authors: Junqi Tang, Matthias Ehrhardt, Carola-Bibiane Schönlieb
Abstract: In this work we propose a stochastic primal-dual three-operator splitting algorithm (TOS-SPDHG) for solving a class of convex three-composite optimization problems. Our proposed scheme is a direct three-operator splitting extension of the SPDHG algorithm [Chambolle et al. 2018]. We provide theoretical convergence analysis showing ergodic $O(1/K)$ convergence rate, and demonstrate the effectiveness of our approach in imaging inverse problems. Moreover, we further propose TOS-SPDHG-RED and TOS-SPDHG-eRED which utilizes the regularization-by-denoising (RED) framework to leverage pretrained deep denoising networks as priors.

Paper number 192:
Title: Report of the Medical Image De-Identification (MIDI) Task Group -- Best Practices and Recommendations
Authors: David A. Clunie, Adam Flanders, Adam Taylor, Brad Erickson, Brian Bialecki, David Brundage, David Gutman, Fred Prior, J Anthony Seibert, John Perry, Judy Wawira Gichoya, Justin Kirby, Katherine Andriole, Luke Geneslaw, Steve Moore, TJ Fitzgerald, Wyatt Tellis, Ying Xiao, Keyvan Farahani
Abstract: This report addresses the technical aspects of de-identification of medical images of human subjects and biospecimens, such that re-identification risk of ethical, moral, and legal concern is sufficiently reduced to allow unrestricted public sharing for any purpose, regardless of the jurisdiction of the source and distribution sites. All medical images, regardless of the mode of acquisition, are considered, though the primary emphasis is on those with accompanying data elements, especially those encoded in formats in which the data elements are embedded, particularly Digital Imaging and Communications in Medicine (DICOM). These images include image-like objects such as Segmentations, Parametric Maps, and Radiotherapy (RT) Dose objects. The scope also includes related non-image objects, such as RT Structure Sets, Plans and Dose Volume Histograms, Structured Reports, and Presentation States. Only de-identification of publicly released data is considered, and alternative approaches to privacy preservation, such as federated learning for artificial intelligence (AI) model development, are out of scope, as are issues of privacy leakage from AI model sharing. Only technical issues of public sharing are addressed.

Paper number 193:
Title: Exploring Robustness of Image Recognition Models on Hardware Accelerators
Authors: Nikolaos Louloudakis, Perry Gibson, José Cano, Ajitha Rajan
Abstract: As the usage of Artificial Intelligence (AI) on resource-intensive and safety-critical tasks increases, a variety of Machine Learning (ML) compilers have been developed, enabling compatibility of Deep Neural Networks (DNNs) with a variety of hardware acceleration devices. However, given that DNNs are widely utilized for challenging and demanding tasks, the behavior of these compilers must be verified. To this direction, we propose MutateNN, a tool that utilizes elements of both differential and mutation testing in order to examine the robustness of image recognition models when deployed on hardware accelerators with different capabilities, in the presence of faults in their target device code - introduced either by developers, or problems in their compilation process. We focus on the image recognition domain by applying mutation testing to 7 well-established DNN models, introducing 21 mutations of 6 different categories. We deployed our mutants on 4 different hardware acceleration devices of varying capabilities and observed that DNN models presented discrepancies of up to 90.3% in mutants related to conditional operators across devices. We also observed that mutations related to layer modification, arithmetic types and input affected severely the overall model performance (up to 99.8%) or led to model crashes, in a consistent manner across devices.

Paper number 194:
Title: Tell Me What You See: Text-Guided Real-World Image Denoising
Authors: Erez Yosef, Raja Giryes
Abstract: Image reconstruction from noisy sensor measurements is challenging and many methods have been proposed for it. Yet, most approaches focus on learning robust natural image priors while modeling the scene's noise statistics. In extremely low-light conditions, these methods often remain insufficient. Additional information is needed, such as multiple captures or, as suggested here, scene description. As an alternative, we propose using a text-based description of the scene as an additional prior, something the photographer can easily provide. Inspired by the remarkable success of text-guided diffusion models in image generation, we show that adding image caption information significantly improves image denoising and reconstruction for both synthetic and real-world images.

Paper number 195:
Title: Learning Service Slowdown using Observational Data
Authors: Xu Kuang, Gal Mendelson
Abstract: Being able to identify service slowdowns is crucial to many operational problems. We study how to use observational congestion data to learn service slowdown in a multi-server system that uses adaptive congestion control mechanisms. We show that a commonly used summary statistic that relies on the marginal congestion measured at individual servers can be highly inaccurate in the presence of adaptive congestion control. We propose a new statistic based on potential routing actions, and show it provides a much more robust signal for server slowdown in these settings. Unlike the marginal statistic, potential action aims to detect changes in the routing actions, and is able to uncover slowdowns even when they do not reflect in marginal congestion. Our results highlight the complexity in performing observational statistical analysis for service systems in the presence of adaptive congestion control. They also suggest that practitioners may want to combine multiple, orthogonal statistics to achieve reliable slowdown detection.

Paper number 196:
Title: Constraint-Generation Policy Optimization (CGPO): Nonlinear Programming for Policy Optimization in Mixed Discrete-Continuous MDPs
Authors: Michael Gimelfarb, Ayal Taitler, Scott Sanner
Abstract: We propose the Constraint-Generation Policy Optimization (CGPO) framework to optimize policy parameters within compact and interpretable policy classes for mixed discrete-continuous Markov Decision Processes (DC-MDP). CGPO can not only provide bounded policy error guarantees over an infinite range of initial states for many DC-MDPs with expressive nonlinear dynamics, but it can also provably derive optimal policies in cases where it terminates with zero error. Furthermore, CGPO can generate worst-case state trajectories to diagnose policy deficiencies and provide counterfactual explanations of optimal actions. To achieve such results, CGPO proposes a bilevel mixed-integer nonlinear optimization framework for optimizing policies in defined expressivity classes (e.g. piecewise linear) and reduces it to an optimal constraint generation methodology that adversarially generates worst-case state trajectories. Furthermore, leveraging modern nonlinear optimizers, CGPO can obtain solutions with bounded optimality gap guarantees. We handle stochastic transitions through chance constraints, providing high-probability performance guarantees. We also present a roadmap for understanding the computational complexities of different expressivity classes of policy, reward, and transition dynamics. We experimentally demonstrate the applicability of CGPO across various domains, including inventory control, management of a water reservoir system, and physics control. In summary, CGPO provides structured, compact and explainable policies with bounded performance guarantees, enabling worst-case scenario generation and counterfactual policy diagnostics.

Paper number 197:
Title: Neuromorphic Photonic Computing with an Electro-Optic Analog Memory
Authors: Sean Lam, Ahmed Khaled, Simon Bilodeau, Bicky A. Marquez, Paul R. Prucnal, Lukas Chrostowski, Bhavin J. Shastri, Sudip Shekhar
Abstract: Artificial intelligence (AI) has seen remarkable advancements across various domains, including natural language processing, computer vision, autonomous vehicles, and biology. However, the rapid expansion of AI technologies has escalated the demand for more powerful computing resources. As digital computing approaches fundamental limits, neuromorphic photonics emerges as a promising platform to complement existing digital systems. In neuromorphic photonic computing, photonic devices are controlled using analog signals. This necessitates the use of digital-to-analog converters (DAC) and analog-to-digital converters (ADC) for interfacing with these devices during inference and training. However, data movement between memory and these converters in conventional von Neumann computing architectures consumes energy. To address this, analog memory co-located with photonic computing devices is proposed. This approach aims to reduce the reliance on DACs and minimize data movement to enhance compute efficiency. This paper demonstrates a monolithically integrated neuromorphic photonic circuit with co-located capacitive analog memory and analyzes analog memory specifications for neuromorphic photonic computing using the MNIST dataset as a benchmark.

Paper number 198:
Title: Effect of Realistic Oscillator Phase Noise on the Performance of Cell-Free Massive MIMO Systems
Authors: Igor Zhilin, Evgenii Vinogradov, Ian Akyildiz
Abstract: As the demand for 6G technologies continues to grow, the radio access infrastructure is expected to become increasingly dense. Cell-free (CF) Massive MIMO systems provide remarkable flexibility by enabling coherent service to users through multiple Access Points (APs). This innovative paradigm necessitates precise and stable phase synchronization. This paper examines the standardized 5G New Radio (NR) framework, focusing on subcarrier spacing, OFDM symbol duration, and allocation, while investigating the impact of Phase Noise (PN) on the performance of scalable massive MIMO cell-free systems. Unlike existing studies that typically employ a simplified model of a free-running oscillator characterized by a Wiener process, we present a realistic phase noise model inspired by actual hardware, designed to accurately capture the Local Oscillator (LO) phase drift. Furthermore, our PN model extends its applicability beyond cell-free systems, making it relevant for any RF system operating within the sub-6 GHz band. This model provides a robust foundation for the practical design of cell-free systems, encompassing numerology and pilot allocation strategies. Our findings reveal that even cost-effective low-cost Local Oscillators can achieve sufficient stability, resulting in negligible degradation of uplink Spectral Efficiency (SE) within the standardized 5G Transmission Time Interval of 1 ms. These results affirm the viability of cell-free massive MIMO systems based on 5G standards and their potential integration into future 6G networks.

Paper number 199:
Title: Surgical-LVLM: Learning to Adapt Large Vision-Language Model for Grounded Visual Question Answering in Robotic Surgery
Authors: Guankun Wang, Long Bai, Wan Jun Nah, Jie Wang, Zhaoxi Zhang, Zhen Chen, Jinlin Wu, Mobarakol Islam, Hongbin Liu, Hongliang Ren
Abstract: Recent advancements in Surgical Visual Question Answering (Surgical-VQA) and related region grounding have shown great promise for robotic and medical applications, addressing the critical need for automated methods in personalized surgical mentorship. However, existing models primarily provide simple structured answers and struggle with complex scenarios due to their limited capability in recognizing long-range dependencies and aligning multimodal information. In this paper, we introduce Surgical-LVLM, a novel personalized large vision-language model tailored for complex surgical scenarios. Leveraging the pre-trained large vision-language model and specialized Visual Perception LoRA (VP-LoRA) blocks, our model excels in understanding complex visual-language tasks within surgical contexts. In addressing the visual grounding task, we propose the Token-Interaction (TIT) module, which strengthens the interaction between the grounding module and the language responses of the Large Visual Language Model (LVLM) after projecting them into the latent space. We demonstrate the effectiveness of Surgical-LVLM on several benchmarks, including EndoVis-17-VQLA, EndoVis-18-VQLA, and a newly introduced EndoVis Conversations dataset, which sets new performance standards. Our work contributes to advancing the field of automated surgical mentorship by providing a context-aware solution.

Paper number 200:
Title: AV-GS: Learning Material and Geometry Aware Priors for Novel View Acoustic Synthesis
Authors: Swapnil Bhosale, Haosen Yang, Diptesh Kanojia, Jiankang Deng, Xiatian Zhu
Abstract: Novel view acoustic synthesis (NVAS) aims to render binaural audio at any target viewpoint, given a mono audio emitted by a sound source at a 3D scene. Existing methods have proposed NeRF-based implicit models to exploit visual cues as a condition for synthesizing binaural audio. However, in addition to low efficiency originating from heavy NeRF rendering, these methods all have a limited ability of characterizing the entire scene environment such as room geometry, material properties, and the spatial relation between the listener and sound source. To address these issues, we propose a novel Audio-Visual Gaussian Splatting (AV-GS) model. To obtain a material-aware and geometry-aware condition for audio synthesis, we learn an explicit point-based scene representation with an audio-guidance parameter on locally initialized Gaussian points, taking into account the space relation from the listener and sound source. To make the visual scene model audio adaptive, we propose a point densification and pruning strategy to optimally distribute the Gaussian points, with the per-point contribution in sound propagation (e.g., more points needed for texture-less wall surfaces as they affect sound path diversion). Extensive experiments validate the superiority of our AV-GS over existing alternatives on the real-world RWAS and simulation-based SoundSpaces datasets.

Paper number 201:
Title: EmT: A Novel Transformer for Generalized Cross-subject EEG Emotion Recognition
Authors: Yi Ding, Chengxuan Tong, Shuailei Zhang, Muyun Jiang, Yong Li, Kevin Lim Jun Liang, Cuntai Guan
Abstract: Integrating prior knowledge of neurophysiology into neural network architecture enhances the performance of emotion decoding. While numerous techniques emphasize learning spatial and short-term temporal patterns, there has been limited emphasis on capturing the vital long-term contextual information associated with emotional cognitive processes. In order to address this discrepancy, we introduce a novel transformer model called emotion transformer (EmT). EmT is designed to excel in both generalized cross-subject EEG emotion classification and regression tasks. In EmT, EEG signals are transformed into a temporal graph format, creating a sequence of EEG feature graphs using a temporal graph construction module (TGC). A novel residual multi-view pyramid GCN module (RMPG) is then proposed to learn dynamic graph representations for each EEG feature graph within the series, and the learned representations of each graph are fused into one token. Furthermore, we design a temporal contextual transformer module (TCT) with two types of token mixers to learn the temporal contextual information. Finally, the task-specific output module (TSO) generates the desired outputs. Experiments on four publicly available datasets show that EmT achieves higher results than the baseline methods for both EEG emotion classification and regression tasks. The code is available at this https URL.

Paper number 202:
Title: Sequential Contrastive Audio-Visual Learning
Authors: Ioannis Tsiamas, Santiago Pascual, Chunghsin Yeh, Joan Serrà
Abstract: Contrastive learning has emerged as a powerful technique in audio-visual representation learning, leveraging the natural co-occurrence of audio and visual modalities in webscale video datasets. However, conventional contrastive audio-visual learning (CAV) methodologies often rely on aggregated representations derived through temporal aggregation, neglecting the intrinsic sequential nature of the data. This oversight raises concerns regarding the ability of standard approaches to capture and utilize fine-grained information within sequences. In response to this limitation, we propose sequential contrastive audiovisual learning (SCAV), which contrasts examples based on their non-aggregated representation space using multidimensional sequential distances. Audio-visual retrieval experiments with the VGGSound and Music datasets demonstrate the effectiveness of SCAV, with up to 3.5x relative improvements in recall against traditional aggregation-based contrastive learning and other previously proposed methods, which utilize more parameters and data. We also show that models trained with SCAV exhibit a significant degree of flexibility regarding the metric employed for retrieval, allowing us to use a hybrid retrieval approach that is both effective and efficient.

Paper number 203:
Title: Impact of Road Infrastructure and Traffic Scenarios on E-scooterists' Riding and Gaze Behavior
Authors: Dong Chen, Arman Hosseini, Arik Smith, Zeyang Zheng, David Xiang, Arsalan Heydarian, Omid Shoghli, Bradford Campbell
Abstract: The growing adoption of e-scooters has raised significant safety concerns, particularly due to a surge in injuries and fatalities. This study explores the relationship between road infrastructure, traffic scenarios, and e-scooterists' riding and gaze behaviors to improve road safety and user experience. A naturalistic study was conducted using instrumented e-scooters, capturing gaze patterns, fixation metrics, and head movement data across various road layouts and traffic scenarios. Key findings reveal that bike lanes offer a stable environment with reduced horizontal head movement and focused attention on the road, while shared roads and sidewalks lead to more dispersed gaze and increased head movement, indicating higher uncertainty and complexity. Interactions with other road users, such as navigating intersections, passing buses, riding near cars, and descending on downhill paths, demand greater cognitive load. Intersections require heightened visual focus and spatial awareness, reflected in increased horizontal eye and head movements. Interactions with vehicles prioritize visual scanning over head movement to maintain stability and avoid collisions, while high-speed and downhill riding demand focused attention on obstacles and the road surface. The results provide insights into e-scooter riders' behavior and physiological response analysis, paving the way for safer riding experiences and improved understanding of their needs.

Paper number 204:
Title: Federated Cubic Regularized Newton Learning with Sparsification-amplified Differential Privacy
Authors: Wei Huo, Changxin Liu, Kemi Ding, Karl Henrik Johansson, Ling Shi
Abstract: This paper investigates the use of the cubic-regularized Newton method within a federated learning framework while addressing two major concerns that commonly arise in federated learning: privacy leakage and communication bottleneck. We introduce a federated learning algorithm called Differentially Private Federated Cubic Regularized Newton (DP-FCRN). By leveraging second-order techniques, our algorithm achieves lower iteration complexity compared to first-order methods. We also incorporate noise perturbation during local computations to ensure privacy. Furthermore, we employ sparsification in uplink transmission, which not only reduces the communication costs but also amplifies the privacy guarantee. Specifically, this approach reduces the necessary noise intensity without compromising privacy protection. We analyze the convergence properties of our algorithm and establish the privacy guarantee. Finally, we validate the effectiveness of the proposed algorithm through experiments on a benchmark dataset.

Paper number 205:
Title: SINET: Sparsity-driven Interpretable Neural Network for Underwater Image Enhancement
Authors: Gargi Panda, Soumitra Kundu, Saumik Bhattacharya, Aurobinda Routray
Abstract: Improving the quality of underwater images is essential for advancing marine research and technology. This work introduces a sparsity-driven interpretable neural network (SINET) for the underwater image enhancement (UIE) task. Unlike pure deep learning methods, our network architecture is based on a novel channel-specific convolutional sparse coding (CCSC) model, ensuring good interpretability of the underlying image enhancement process. The key feature of SINET is that it estimates the salient features from the three color channels using three sparse feature estimation blocks (SFEBs). The architecture of SFEB is designed by unrolling an iterative algorithm for solving the $\ell_1$ regularized convolutional sparse coding (CSC) problem. Our experiments show that SINET surpasses state-of-the-art PSNR value by $1.05$ dB with $3873$ times lower computational complexity. Code can be found at: this https URL.

Paper number 206:
Title: PDMX: A Large-Scale Public Domain MusicXML Dataset for Symbolic Music Processing
Authors: Phillip Long, Zachary Novack, Taylor Berg-Kirkpatrick, Julian McAuley
Abstract: The recent explosion of generative AI-Music systems has raised numerous concerns over data copyright, licensing music from musicians, and the conflict between open-source AI and large prestige companies. Such issues highlight the need for publicly available, copyright-free musical data, in which there is a large shortage, particularly for symbolic music data. To alleviate this issue, we present PDMX: a large-scale open-source dataset of over 250K public domain MusicXML scores collected from the score-sharing forum MuseScore, making it the largest available copyright-free symbolic music dataset to our knowledge. PDMX additionally includes a wealth of both tag and user interaction metadata, allowing us to efficiently analyze the dataset and filter for high quality user-generated scores. Given the additional metadata afforded by our data collection process, we conduct multitrack music generation experiments evaluating how different representative subsets of PDMX lead to different behaviors in downstream models, and how user-rating statistics can be used as an effective measure of data quality. Examples can be found at this https URL.

Paper number 207:
Title: A Generalized Control Revision Method for Autonomous Driving Safety
Authors: Zehang Zhu, Yuning Wang, Tianqi Ke, Zeyu Han, Shaobing Xu, Qing Xu, John M. Dolan, Jianqiang Wang
Abstract: Safety is one of the most crucial challenges of autonomous driving vehicles, and one solution to guarantee safety is to employ an additional control revision module after the planning backbone. Control Barrier Function (CBF) has been widely used because of its strong mathematical foundation on safety. However, the incompatibility with heterogeneous perception data and incomplete consideration of traffic scene elements make existing systems hard to be applied in dynamic and complex real-world scenarios. In this study, we introduce a generalized control revision method for autonomous driving safety, which adopts both vectorized perception and occupancy grid map as inputs and comprehensively models multiple types of traffic scene constraints based on a new proposed barrier function. Traffic elements are integrated into one unified framework, decoupled from specific scenario settings or rules. Experiments on CARLA, SUMO, and OnSite simulator prove that the proposed algorithm could realize safe control revision under complicated scenes, adapting to various planning backbones, road topologies, and risk types. Physical platform validation also verifies the real-world application feasibility.

Paper number 208:
Title: Communication Constellation Design of Minimum Number of Satellites with Continuous Coverage and Inter-Satellite Link
Authors: Soobin Jeon, Sang-Young Park
Abstract: The recent advancement in research on distributed space systems that operate a large number of satellites as a single system urges the need for the investigation of satellite constellations. Communication constellations can be used to construct global or regional communication networks using inter-satellite and ground-to-satellite links. This study examines two challenges of communication constellations: continuous coverage and inter-satellite link connectivity. The bounded Voronoi diagram and APC decomposition are presented as continuous coverage analysis methods. For continuity analysis of the inter-satellite link, the relative motion between adjacent orbital planes is used to derive analytic solutions. The Walker-Delta constellation and common ground-track constellation design methods are introduced as examples to verify the analysis methods. The common ground-track constellations are classified into quasi-symmetric and optimal constellations. The optimal common ground-track constellation is optimized using the BILP algorithm. The simulation results compare the performance of the communication constellations according to various design methods.

Paper number 209:
Title: SPES: Spectrogram Perturbation for Explainable Speech-to-Text Generation
Authors: Dennis Fucci, Marco Gaido, Beatrice Savoldi, Matteo Negri, Mauro Cettolo, Luisa Bentivogli
Abstract: Spurred by the demand for interpretable models, research on eXplainable AI for language technologies has experienced significant growth, with feature attribution methods emerging as a cornerstone of this progress. While prior work in NLP explored such methods for classification tasks and textual applications, explainability intersecting generation and speech is lagging, with existing techniques failing to account for the autoregressive nature of state-of-the-art models and to provide fine-grained, phonetically meaningful explanations. We address this gap by introducing Spectrogram Perturbation for Explainable Speech-to-text Generation (SPES), a feature attribution technique applicable to sequence generation tasks with autoregressive models. SPES provides explanations for each predicted token based on both the input spectrogram and the previously generated tokens. Extensive evaluation on speech recognition and translation demonstrates that SPES generates explanations that are faithful and plausible to humans.

Paper number 210:
Title: Video-Guided Foley Sound Generation with Multimodal Controls
Authors: Ziyang Chen, Prem Seetharaman, Bryan Russell, Oriol Nieto, David Bourgin, Andrew Owens, Justin Salamon
Abstract: Generating sound effects for videos often requires creating artistic sound effects that diverge significantly from real-life sources and flexible control in the sound design. To address this problem, we introduce MultiFoley, a model designed for video-guided sound generation that supports multimodal conditioning through text, audio, and video. Given a silent video and a text prompt, MultiFoley allows users to create clean sounds (e.g., skateboard wheels spinning without wind noise) or more whimsical sounds (e.g., making a lion's roar sound like a cat's meow). MultiFoley also allows users to choose reference audio from sound effects (SFX) libraries or partial videos for conditioning. A key novelty of our model lies in its joint training on both internet video datasets with low-quality audio and professional SFX recordings, enabling high-quality, full-bandwidth (48kHz) audio generation. Through automated evaluations and human studies, we demonstrate that MultiFoley successfully generates synchronized high-quality sounds across varied conditional inputs and outperforms existing methods. Please see our project page for video results: this https URL

Paper number 211:
Title: An AI-driven multimodal smart home platform for continuous monitoring and intelligent assistance in post-stroke patients
Authors: Chenyu Tang, Ruizhi Zhang, Shuo Gao, Zihe Zhao, Zibo Zhang, Jiaqi Wang, Cong Li, Junliang Chen, Yanning Dai, Shengbo Wang, Ruoyu Juan, Qiaoying Li, Ruimou Xie, Xuhang Chen, Xinkai Zhou, Yunjia Xia, Jianan Chen, Fanghao Lu, Xin Li, Ninglli Wang, Peter Smielewski, Yu Pan, Hubin Zhao, Luigi G. Occhipinti
Abstract: At-home rehabilitation for post-stroke patients presents significant challenges, as continuous, personalized care is often limited outside clinical settings. Additionally, the absence of comprehensive solutions addressing diverse monitoring and assistance needs in home environments complicates recovery efforts. Here, we present a multimodal smart home platform designed for continuous, at-home rehabilitation of post-stroke patients, integrating wearable sensing, ambient monitoring, and adaptive automation. A plantar pressure insole equipped with a machine learning pipeline classifies users into motor recovery stages with up to 94% accuracy, enabling quantitative tracking of walking patterns. A head-mounted eye-tracking module supports cognitive assessments and hands-free control of household devices, while ambient sensors ensure sub-second response times for interaction. These data streams are fused locally via a hierarchical Internet of Things (IoT) architecture, protecting privacy and minimizing latency. An embedded large language model (LLM) agent, Auto-Care, continuously interprets multimodal data to provide real-time interventions-issuing personalized reminders, adjusting environmental conditions, and notifying caregivers. Implemented in a post-stroke context, this integrated smart home platform increases overall user satisfaction by an average of 115% (p<0.01) compared to traditional home environment. Beyond stroke, the system offers a scalable framework for patient-centered, long-term care in broader neurorehabilitation and aging-in-place applications.

Paper number 212:
Title: A3E: Aligned and Augmented Adversarial Ensemble for Accurate, Robust and Privacy-Preserving EEG Decoding
Authors: Xiaoqing Chen, Tianwang Jia, Dongrui Wu
Abstract: An electroencephalogram (EEG) based brain-computer interface (BCI) enables direct communication between the brain and external devices. However, EEG-based BCIs face at least three major challenges in real-world applications: data scarcity and individual differences, adversarial vulnerability, and data privacy. While previous studies have addressed one or two of these issues, simultaneous accommodation of all three challenges remains challenging and unexplored. This paper fills this gap, by proposing an Aligned and Augmented Adversarial Ensemble (A3E) algorithm and integrating it into three privacy protection scenarios (centralized source-free transfer, federated source-free transfer, and source data perturbation), achieving simultaneously accurate decoding, adversarial robustness, and privacy protection of EEG-based BCIs. Experiments on three public EEG datasets demonstrated that our proposed approach outperformed over 10 classic and state-of-the-art approaches in both accuracy and robustness in all three privacy-preserving scenarios, even outperforming state-of-the-art transfer learning approaches that do not consider privacy protection at all. This is the first time that three major challenges in EEG-based BCIs can be addressed simultaneously, significantly improving the practicalness of EEG decoding in real-world BCIs.

Paper number 213:
Title: Data-driven $H_{\infty}$ predictive control for constrained systems: a Lagrange duality approach
Authors: Wenhuang Wu, Lulu Guo, Nan Li, Hong Chen
Abstract: This article proposes a data-driven $H_{\infty}$ control scheme for time-domain constrained systems based on model predictive control formulation. The scheme combines $H_{\infty}$ control and minimax model predictive control, enabling more effective handling of external disturbances and time-domain constraints. First, by leveraging input-output-disturbance data, the scheme ensures $H_{\infty}$ performance of the closed-loop system. Then, a minimax optimization problem is converted into a more manageable minimization problem employing Lagrange duality, which reduces conservatism typically associated with ellipsoidal evaluations of time-domain constraints. The study examines key closed-loop properties, including stability, disturbance attenuation, and constraint satisfaction, achieved by the proposed data-driven moving horizon predictive control algorithm. The effectiveness and advantages of the proposed method are demonstrated through numerical simulations involving a batch reactor system, confirming its robustness and feasibility under noisy conditions.

Paper number 214:
Title: Training-Free Mitigation of Adversarial Attacks on Deep Learning-Based MRI Reconstruction
Authors: Mahdi Saberi, Chi Zhang, Mehmet Akcakaya
Abstract: Deep learning (DL) methods, especially those based on physics-driven DL, have become the state-of-the-art for reconstructing sub-sampled magnetic resonance imaging (MRI) data. However, studies have shown that these methods are susceptible to small adversarial input perturbations, or attacks, resulting in major distortions in the output images. Various strategies have been proposed to reduce the effects of these attacks, but they require retraining and may lower reconstruction quality for non-perturbed/clean inputs. In this work, we propose a novel approach for mitigating adversarial attacks on MRI reconstruction models without any retraining. Our framework is based on the idea of cyclic measurement consistency. The output of the model is mapped to another set of MRI measurements for a different sub-sampling pattern, and this synthesized data is reconstructed with the same model. Intuitively, without an attack, the second reconstruction is expected to be consistent with the first, while with an attack, disruptions are present. A novel objective function is devised based on this idea, which is minimized within a small ball around the attack input for mitigation. Experimental results show that our method substantially reduces the impact of adversarial perturbations across different datasets, attack types/strengths and PD-DL networks, and qualitatively and quantitatively outperforms conventional mitigation methods that involve retraining. Finally, we extend our mitigation method to two important practical scenarios: a blind setup, where the attack strength or algorithm is not known to the end user; and an adaptive attack setup, where the attacker has full knowledge of the defense strategy. Our approach remains effective in both cases.

Paper number 215:
Title: LAVCap: LLM-based Audio-Visual Captioning using Optimal Transport
Authors: Kyeongha Rho, Hyeongkeun Lee, Valentio Iverson, Joon Son Chung
Abstract: Automated audio captioning is a task that generates textual descriptions for audio content, and recent studies have explored using visual information to enhance captioning quality. However, current methods often fail to effectively fuse audio and visual data, missing important semantic cues from each modality. To address this, we introduce LAVCap, a large language model (LLM)-based audio-visual captioning framework that effectively integrates visual information with audio to improve audio captioning performance. LAVCap employs an optimal transport-based alignment loss to bridge the modality gap between audio and visual features, enabling more effective semantic extraction. Additionally, we propose an optimal transport attention module that enhances audio-visual fusion using an optimal transport assignment map. Combined with the optimal training strategy, experimental results demonstrate that each component of our framework is effective. LAVCap outperforms existing state-of-the-art methods on the AudioCaps dataset, without relying on large datasets or post-processing. Code is available at this https URL.

Paper number 216:
Title: Rough Stochastic Pontryagin Maximum Principle and an Indirect Shooting Method
Authors: Thomas Lew
Abstract: We derive first-order Pontryagin optimality conditions for stochastic optimal control with deterministic controls for systems modeled by rough differential equations (RDE) driven by Gaussian rough paths. This Pontryagin Maximum Principle (PMP) applies to systems following stochastic differential equations (SDE) driven by Brownian motion, yet it does not rely on forward-backward SDEs and involves the same Hamiltonian as the deterministic PMP. The proof consists of first deriving various integrable error bounds for solutions to nonlinear and linear RDEs by leveraging recent results on Gaussian rough paths. The PMP then follows using standard techniques based on needle-like variations. As an application, we propose the first indirect shooting method for nonlinear stochastic optimal control and show that it converges 10x faster than a direct method on a stabilization task.

Paper number 217:
Title: AAD-LLM: Neural Attention-Driven Auditory Scene Understanding
Authors: Xilin Jiang, Sukru Samet Dindar, Vishal Choudhari, Stephan Bickel, Ashesh Mehta, Guy M McKhann, Daniel Friedman, Adeen Flinker, Nima Mesgarani
Abstract: Auditory foundation models, including auditory large language models (LLMs), process all sound inputs equally, independent of listener perception. However, human auditory perception is inherently selective: listeners focus on specific speakers while ignoring others in complex auditory scenes. Existing models do not incorporate this selectivity, limiting their ability to generate perception-aligned responses. To address this, we introduce Intention-Informed Auditory Scene Understanding (II-ASU) and present Auditory Attention-Driven LLM (AAD-LLM), a prototype system that integrates brain signals to infer listener attention. AAD-LLM extends an auditory LLM by incorporating intracranial electroencephalography (iEEG) recordings to decode which speaker a listener is attending to and refine responses accordingly. The model first predicts the attended speaker from neural activity, then conditions response generation on this inferred attentional state. We evaluate AAD-LLM on speaker description, speech transcription and extraction, and question answering in multitalker scenarios, with both objective and subjective ratings showing improved alignment with listener intention. By taking a first step toward intention-aware auditory AI, this work explores a new paradigm where listener perception informs machine listening, paving the way for future listener-centered auditory systems. Demo and code available: this https URL.

Paper number 218:
Title: Video Super-Resolution: All You Need is a Video Diffusion Model
Authors: Zhihao Zhan, Wang Pang, Xiang Zhu, Yechao Bai
Abstract: We present a generic video super-resolution algorithm in this paper, based on the Diffusion Posterior Sampling framework with an unconditional video generation model in latent space. The video generation model, a diffusion transformer, functions as a space-time model. We argue that a powerful model, which learns the physics of the real world, can easily handle various kinds of motion patterns as prior knowledge, thus eliminating the need for explicit estimation of optical flows or motion parameters for pixel alignment. Furthermore, a single instance of the proposed video diffusion transformer model can adapt to different sampling conditions without re-training. Empirical results on synthetic and real-world datasets demonstrate that our method has strong capabilities to address video super-resolution challenges.

Paper number 219:
Title: Controlled Invariance in Fully Actuated Max-plus Linear Systems with Precedence Semimodules
Authors: Davide Zorzenon, Jörg Raisch
Abstract: Given a max-plus linear system and a semimodule, the problem of computing the maximal controlled invariant subsemimodule is still open to this day. In this paper, we consider this problem for the specific class of fully actuated systems and constraints in the form of precedence semimodules. The assumption of full actuation corresponds to the existence of an input for each component of the system state. A precedence semimodule is the set of solutions of inequalities typically used to represent time-window constraints. We prove that, in this setting, it is possible to (i) compute the maximal controlled invariant subsemimodule and (ii) decide the convergence of a fixed-point algorithm introduced by R.D. Katz in strongly polynomial time.

Paper number 220:
Title: Digital Twin-Enabled Blockage-Aware Dynamic mmWave Multi-Hop V2X Communication
Authors: Supat Roongpraiwan, Zongdian Li, Tao Yu, Kei Sakaguchi
Abstract: Millimeter wave (mmWave) technology in vehicle-to-everything (V2X) communication offers unprecedented data rates and low latency, but faces significant reliability challenges due to signal blockages and limited range. This paper introduces a novel system for managing dynamic multi-hop mmWave V2X communications in complex blocking environments. We present a system architecture that integrates a mobility digital twin (DT) with the multi-hop routing control plane, providing a comprehensive, real-time view of the network and its surrounding traffic environment. This integration enables the control plane to make informed routing decisions based on rich contextual data about vehicles, infrastructure, and potential signal blockages. Leveraging this DT-enhanced architecture, we propose an advanced routing algorithm that combines high-precision environmental data with trajectory prediction to achieve blockage-aware mmWave multi-hop V2X routing. Our algorithm anticipates network topology changes and adapts topology dynamically to maintain reliable connections. We evaluate our approach through proof-of-concept simulations using a mobility DT of the Nishishinjuku area. Results demonstrate that our DT-enabled routing strategy significantly outperforms conventional methods in maintaining reliable mmWave V2X connections across various traffic scenarios, including fully connected and mixed traffic environments.

Paper number 221:
Title: Open-Set Gait Recognition from Sparse mmWave Radar Point Clouds
Authors: Riccardo Mazzieri, Jacopo Pegoraro, Michele Rossi
Abstract: The adoption of Millimeter-Wave (mmWave) radar devices for human sensing, particularly gait recognition, has recently gathered significant attention due to their efficiency, resilience to environmental conditions, and privacy-preserving nature. In this work, we tackle the challenging problem of Open-set Gait Recognition (OSGR) from sparse mmWave radar point clouds. Unlike most existing research, which assumes a closed-set scenario, our work considers the more realistic open-set case, where unknown subjects might be present at inference time, and should be correctly recognized by the system. Point clouds are well-suited for edge computing applications with resource constraints, but are more significantly affected by noise and random fluctuations than other representations, like the more common micro-Doppler signature. This is the first work addressing open-set gait recognition with sparse point cloud data. To do so, we propose a novel neural network architecture that combines supervised classification with unsupervised reconstruction of the point clouds, creating a robust, rich, and highly regularized latent space of gait features. To detect unknown subjects at inference time, we introduce a probabilistic novelty detection algorithm that leverages the structured latent space and offers a tunable trade-off between inference speed and prediction accuracy. Along with this paper, we release mmGait10, an original human gait dataset featuring over five hours of measurements from ten subjects, under varied walking modalities. Extensive experimental results show that our solution attains F1-Score improvements by 24% over state-of-the-art methods, on average, and across multiple openness levels.

Paper number 222:
Title: An Analysis of Safety Guarantees in Multi-Task Bayesian Optimization
Authors: Jannis O. Luebsen, Annika Eichler
Abstract: This paper addresses the integration of additional information sources into a Bayesian optimization framework while ensuring that safety constraints are satisfied. The interdependencies between these information sources are modeled using an unknown correlation matrix. We explore how uniform error bounds must be adjusted to maintain constraint satisfaction throughout the optimization process, considering both Bayesian and frequentist statistical perspectives. This is achieved by appropriately scaling the error bounds based on a confidence interval that can be estimated from the data. Furthermore, the efficacy of the proposed approach is demonstrated through experiments on two benchmark functions and a controller parameter optimization problem. Our results highlight a significant improvement in sample efficiency, demonstrating the methods suitability for optimizing expensive-to-evaluate functions.

Paper number 223:
Title: Mirror Online Conformal Prediction with Intermittent Feedback
Authors: Bowen Wang, Matteo Zecchin, Osvaldo Simeone
Abstract: Online conformal prediction enables the runtime calibration of a pre-trained artificial intelligence model using feedback on its performance. Calibration is achieved through set predictions that are updated via online rules so as to ensure long-term coverage guarantees. While recent research has demonstrated the benefits of incorporating prior knowledge into the calibration process, this has come at the cost of replacing coverage guarantees with less tangible regret guarantees based on the quantile loss. This work introduces intermittent mirror online conformal prediction (IM-OCP), a novel runtime calibration framework that integrates prior knowledge, while maintaining long-term coverage and achieving sub-linear regret. IM-OCP features closed-form updates with minimal memory complexity, and is designed to operate under potentially intermittent feedback.

Paper number 224:
Title: Reinforcement Learning Outperforms Supervised Fine-Tuning: A Case Study on Audio Question Answering
Authors: Gang Li, Jizhong Liu, Heinrich Dinkel, Yadong Niu, Junbo Zhang, Jian Luan
Abstract: Recently, reinforcement learning (RL) has been shown to greatly enhance the reasoning capabilities of large language models (LLMs), and RL-based approaches have been progressively applied to visual multimodal tasks. However, the audio modality has largely been overlooked in these developments. Thus, we conduct a series of RL explorations in audio understanding and reasoning, specifically focusing on the audio question answering (AQA) task. We leverage the group relative policy optimization (GRPO) algorithm to Qwen2-Audio-7B-Instruct, and our experiments demonstrated state-of-the-art performance on the MMAU Test-mini benchmark, achieving an accuracy rate of 64.5%. The main findings in this technical report are as follows: 1) The GRPO algorithm can be effectively applied to large audio language models (LALMs), even when the model has only 8.2B parameters; 2) With only 38k post-training samples, RL significantly outperforms supervised fine-tuning (SFT), indicating that RL-based approaches can be effective without large datasets; 3) The explicit reasoning process has not shown significant benefits for AQA tasks, and how to efficiently utilize deep thinking remains an open question for further research; 4) LALMs still lag far behind humans auditory-language reasoning, suggesting that the RL-based approaches warrant further exploration. Our project is available at this https URL and this https URL.
    