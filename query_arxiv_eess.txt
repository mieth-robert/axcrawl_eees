
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: A Chinese Heart Failure Status Speech Database with Universal and Personalised Classification
Authors: Yue Pan, Liwei Liu, Changxin Li, Xinyao Wang, Yili Xia, Hanyue Zhang, Ming Chu
Abstract: Speech is a cost-effective and non-intrusive data source for identifying acute and chronic heart failure (HF). However, there is a lack of research on whether Chinese syllables contain HF-related information, as observed in other well-studied languages. This study presents the first Chinese speech database of HF patients, featuring paired recordings taken before and after hospitalisation. The findings confirm the effectiveness of the Chinese language in HF detection using both standard 'patient-wise' and personalised 'pair-wise' classification approaches, with the latter serving as an ideal speaker-decoupled baseline for future research. Statistical tests and classification results highlight individual differences as key contributors to inaccuracy. Additionally, an adaptive frequency filter (AFF) is proposed for frequency importance analysis. The data and demonstrations are published at this https URL.

Paper number 2:
Title: Transsion Multilingual Speech Recognition System for MLC-SLM 2025 Challenge
Authors: Xiaoxiao Li, An Zhu, Youhai Jiang, Fengjie Zhu
Abstract: This paper presents the architecture and performance of a novel Multilingual Automatic Speech Recognition (ASR) system developed by the Transsion Speech Team for Track 1 of the MLC-SLM 2025 Challenge. The proposed system comprises three key components: 1) a frozen Whisper-large-v3 based speech encoder, leveraging large-scale pretraining to ensure robust acoustic feature extraction; 2) a trainable adaptor module using Linear-ReLU-Linear transformation mechanisms to effectively align speech and text representations; and 3) a frozen Qwen2.5-7B-Instruct large language model (LLM) integrated with trainable LoRA for optimized contextual linguistic decoding. By systematically combining pretrained models with task specific fine-tuning, the system achieved a word/character error rate (WER/CER) of 9.83% across 11 languages in the evaluation set and ranked third place among global participants.

Paper number 3:
Title: Pixels Under Pressure: Exploring Fine-Tuning Paradigms for Foundation Models in High-Resolution Medical Imaging
Authors: Zahra TehraniNasab, Amar Kumar, Tal Arbel
Abstract: Advancements in diffusion-based foundation models have improved text-to-image generation, yet most efforts have been limited to low-resolution settings. As high-resolution image synthesis becomes increasingly essential for various applications, particularly in medical imaging domains, fine-tuning emerges as a crucial mechanism for adapting these powerful pre-trained models to task-specific requirements and data distributions. In this work, we present a systematic study, examining the impact of various fine-tuning techniques on image generation quality when scaling to high resolution 512x512 pixels. We benchmark a diverse set of fine-tuning methods, including full fine-tuning strategies and parameter-efficient fine-tuning (PEFT). We dissect how different fine-tuning methods influence key quality metrics, including Fréchet Inception Distance (FID), Vendi score, and prompt-image alignment. We also evaluate the utility of generated images in a downstream classification task under data-scarce conditions, demonstrating that specific fine-tuning strategies improve both generation fidelity and downstream performance when synthetic images are used for classifier training and evaluation on real images. Our code is accessible through the project website - this https URL.

Paper number 4:
Title: TOM: An Open-Source Tongue Segmentation Method with Multi-Teacher Distillation and Task-Specific Data Augmentation
Authors: Jiacheng Xie, Ziyang Zhang, Biplab Poudel, Congyu Guo, Yang Yu, Guanghui An, Xiaoting Tang, Lening Zhao, Chunhui Xu, Dong Xu
Abstract: Tongue imaging serves as a valuable diagnostic tool, particularly in Traditional Chinese Medicine (TCM). The quality of tongue surface segmentation significantly affects the accuracy of tongue image classification and subsequent diagnosis in intelligent tongue diagnosis systems. However, existing research on tongue image segmentation faces notable limitations, and there is a lack of robust and user-friendly segmentation tools. This paper proposes a tongue image segmentation model (TOM) based on multi-teacher knowledge distillation. By incorporating a novel diffusion-based data augmentation method, we enhanced the generalization ability of the segmentation model while reducing its parameter size. Notably, after reducing the parameter count by 96.6% compared to the teacher models, the student model still achieves an impressive segmentation performance of 95.22% mIoU. Furthermore, we packaged and deployed the trained model as both an online and offline segmentation tool (available at this https URL), allowing TCM practitioners and researchers to use it without any programming experience. We also present a case study on TCM constitution classification using segmented tongue patches. Experimental results demonstrate that training with tongue patches yields higher classification performance and better interpretability than original tongue images. To our knowledge, this is the first open-source and freely available tongue image segmentation tool.

Paper number 5:
Title: Potential and challenges of generative adversarial networks for super-resolution in 4D Flow MRI
Authors: Oliver Welin Odeback, Arivazhagan Geetha Balasubramanian, Jonas Schollenberger, Edward Ferdiand, Alistair A. Young, C. Alberto Figueroa, Susanne Schnell, Outi Tammisola, Ricardo Vinuesa, Tobias Granberg, Alexander Fyrdahl, David Marlevi
Abstract: 4D Flow Magnetic Resonance Imaging (4D Flow MRI) enables non-invasive quantification of blood flow and hemodynamic parameters. However, its clinical application is limited by low spatial resolution and noise, particularly affecting near-wall velocity measurements. Machine learning-based super-resolution has shown promise in addressing these limitations, but challenges remain, not least in recovering near-wall velocities. Generative adversarial networks (GANs) offer a compelling solution, having demonstrated strong capabilities in restoring sharp boundaries in non-medical super-resolution tasks. Yet, their application in 4D Flow MRI remains unexplored, with implementation challenged by known issues such as training instability and non-convergence. In this study, we investigate GAN-based super-resolution in 4D Flow MRI. Training and validation were conducted using patient-specific cerebrovascular in-silico models, converted into synthetic images via an MR-true reconstruction pipeline. A dedicated GAN architecture was implemented and evaluated across three adversarial loss functions: Vanilla, Relativistic, and Wasserstein. Our results demonstrate that the proposed GAN improved near-wall velocity recovery compared to a non-adversarial reference (vNRMSE: 6.9% vs. 9.6%); however, that implementation specifics are critical for stable network training. While Vanilla and Relativistic GANs proved unstable compared to generator-only training (vNRMSE: 8.1% and 7.8% vs. 7.2%), a Wasserstein GAN demonstrated optimal stability and incremental improvement (vNRMSE: 6.9% vs. 7.2%). The Wasserstein GAN further outperformed the generator-only baseline at low SNR (vNRMSE: 8.7% vs. 10.7%). These findings highlight the potential of GAN-based super-resolution in enhancing 4D Flow MRI, particularly in challenging cerebrovascular regions, while emphasizing the need for careful selection of adversarial strategies.

Paper number 6:
Title: CUTE-MRI: Conformalized Uncertainty-based framework for Time-adaptivE MRI
Authors: Paul Fischer, Jan Nikolas Morshuis, Thomas Küstner, Christian Baumgartner
Abstract: Magnetic Resonance Imaging (MRI) offers unparalleled soft-tissue contrast but is fundamentally limited by long acquisition times. While deep learning-based accelerated MRI can dramatically shorten scan times, the reconstruction from undersampled data introduces ambiguity resulting from an ill-posed problem with infinitely many possible solutions that propagates to downstream clinical tasks. This uncertainty is usually ignored during the acquisition process as acceleration factors are often fixed a priori, resulting in scans that are either unnecessarily long or of insufficient quality for a given clinical endpoint. This work introduces a dynamic, uncertainty-aware acquisition framework that adjusts scan time on a per-subject basis. Our method leverages a probabilistic reconstruction model to estimate image uncertainty, which is then propagated through a full analysis pipeline to a quantitative metric of interest (e.g., patellar cartilage volume or cardiac ejection fraction). We use conformal prediction to transform this uncertainty into a rigorous, calibrated confidence interval for the metric. During acquisition, the system iteratively samples k-space, updates the reconstruction, and evaluates the confidence interval. The scan terminates automatically once the uncertainty meets a user-predefined precision target. We validate our framework on both knee and cardiac MRI datasets. Our results demonstrate that this adaptive approach reduces scan times compared to fixed protocols while providing formal statistical guarantees on the precision of the final image. This framework moves beyond fixed acceleration factors, enabling patient-specific acquisitions that balance scan efficiency with diagnostic confidence, a critical step towards personalized and resource-efficient MRI.

Paper number 7:
Title: LyLA-Therm: Lyapunov-based Langevin Adaptive Thermodynamic Neural Network Controller
Authors: Saiedeh Akbari, Omkar Sudhir Patil, Warren E. Dixon
Abstract: Thermodynamic principles can be employed to design parameter update laws that address challenges such as the exploration vs. exploitation dilemma. In this paper, inspired by the Langevin equation, an update law is developed for a Lyapunov-based DNN control method, taking the form of a stochastic differential equation. The drift term is designed to minimize the system's generalized internal energy, while the diffusion term is governed by a user-selected generalized temperature law, allowing for more controlled fluctuations. The minimization of generalized internal energy in this design fulfills the exploitation objective, while the temperature-based stochastic noise ensures sufficient exploration. Using a Lyapunov-based stability analysis, the proposed Lyapunov-based Langevin Adaptive Thermodynamic (LyLA-Therm) neural network controller achieves probabilistic convergence of the tracking and parameter estimation errors to an ultimate bound. Simulation results demonstrate the effectiveness of the proposed approach, with the LyLA-Therm architecture achieving up to 20.66% improvement in tracking errors, up to 20.89% improvement in function approximation errors, and up to 11.31% improvement in off-trajectory function approximation errors compared to the baseline deterministic approach.

Paper number 8:
Title: Scalable Event-Based Video Streaming for Machines with MoQ
Authors: Andrew C. Freeman
Abstract: Lossy compression and rate-adaptive streaming are a mainstay in traditional video steams. However, a new class of neuromorphic ``event'' sensors records video with asynchronous pixel samples rather than image frames. These sensors are designed for computer vision applications, rather than human video consumption. Until now, researchers have focused their efforts primarily on application development, ignoring the crucial problem of data transmission. We survey the landscape of event-based video systems, discuss the technical issues with our recent scalable event streaming work, and propose a new low-latency event streaming format based on the latest additions to the Media Over QUIC protocol draft.

Paper number 9:
Title: Structure-preserving Optimal Kron-based Reduction of Radial Distribution Networks
Authors: Omid Mokhtari, Samuel Chevalier, Mads Almassalkhi
Abstract: Network reduction simplifies complex electrical networks to address computational challenges of large-scale transmission and distribution grids. Traditional network reduction methods are often based on a predefined set of nodes or lines to remain in the reduced network. This paper builds upon previous work on Optimal Kron-based Reduction of Networks (Opti-KRON), which was formulated as a mixed-integer linear program (MILP), to enhance the framework in two aspects. First, the scalability is improved via a cutting plane restriction, tightened Big~M bounds, and a zero-injection node reduction stage. Next, we introduce a radiality-preservation step to identify and recover nodes whose restoration ensures radiality of the reduced network. The model is validated through its application to the 533-bus distribution test system and a 3499-bus realistic test feeder for a set of representative loading scenarios. In the 533-bus system, an 85% reduction was achieved with a maximum voltage error below 0.0025 p.u., while in the 3499-bus feeder, over 94% reduction was obtained with maximum voltage errors below 0.002 p.u. Additionally, we show that the radialization step accelerates the runtime of optimal voltage control problems when applied to Kron-reduced networks.

Paper number 10:
Title: Systematic Evaluation of Wavelet-Based Denoising for MRI Brain Images: Optimal Configurations and Performance Benchmarks
Authors: Asadullah Bin Rahman, Masud Ibn Afjal, Md. Abdulla Al Mamun
Abstract: Medical imaging modalities including magnetic resonance imaging (MRI), computed tomography (CT), and ultrasound are essential for accurate diagnosis and treatment planning in modern healthcare. However, noise contamination during image acquisition and processing frequently degrades image quality, obscuring critical diagnostic details and compromising clinical decision-making. Additionally, enhancement techniques such as histogram equalization may inadvertently amplify existing noise artifacts, including salt-and-pepper distortions. This study investigates wavelet transform-based denoising methods for effective noise mitigation in medical images, with the primary objective of identifying optimal combinations of threshold values, decomposition levels, and wavelet types to achieve superior denoising performance and enhanced diagnostic accuracy. Through systematic evaluation across various noise conditions, the research demonstrates that the bior6.8 biorthogonal wavelet with universal thresholding at decomposition levels 2-3 consistently achieves optimal denoising performance, providing significant noise reduction while preserving essential anatomical structures and diagnostic features critical for clinical applications.

Paper number 11:
Title: Discrete VHCs for Propeller Motion of a Devil-Stick using purely Impulsive Inputs
Authors: Aakash Khandelwal, Ranjan Mukherjee
Abstract: The control problem of realizing propeller motion of a devil-stick in the vertical plane using impulsive forces applied normal to the stick is considered. This problem is an example of underactuated robotic juggling and has not been considered in the literature before. Inspired by virtual holonomic constraints, the concept of discrete virtual holonomic constraints (DVHC) is introduced for the first time to solve this orbital stabilization problem. At the discrete instants when impulsive inputs are applied, the location of the center-of-mass of the devil-stick is specified in terms of its orientation angle. This yields the discrete zero dynamics (DZD), which provides conditions for stable propeller motion. In the limiting case, when the rotation angle between successive applications of impulsive inputs is chosen to be arbitrarily small, the problem reduces to that of propeller motion under continuous forcing. A controller that enforces the DVHC, and an orbit stabilizing controller based on the impulse controlled Poincaré map approach are presented. The efficacy of the approach to trajectory design and stabilization is validated through simulations.

Paper number 12:
Title: Smart Charging Impact Analysis using Clustering Methods and Real-world Distribution Feeders
Authors: Ravi Raj Shrestha, Zhi Zhou, Limon Barua, Nazib Siddique, Karthikeyan Balasubramaniam, Yan Zhou, Lusha Wang
Abstract: The anticipated widespread adoption of electric vehicles (EVs) necessitates a critical evaluation of existing power distribution infrastructures, as EV integration imposes additional stress on distribution networks that can lead to component overloading and power quality degradation. Implementing smart charging mechanisms can mitigate these adverse effects and defer or even avoid upgrades. This study assesses the performance of two smart charging strategies - Time of Use (TOU) pricing and Load Balancing (LB) on seven representative real-world feeders identified using k-means clustering. A time series-based steady-state load flow analysis was conducted on these feeders to simulate the impact of EV charging under both strategies across four different EV enrollment scenarios and three representative days to capture seasonal load characteristics. A grid upgrade strategy has been proposed to strengthen the power grid to support EV integration with minimal cost. Results demonstrate that both TOU and LB strategies effectively manage the additional EV load with reduced upgrade requirement and cost to existing infrastructure compared to the case without smart charging strategies and LB outperforms TOU when the customer enrollment levels are high. These findings support the viability of smart charging in facilitating EV integration while maintaining distribution network reliability and reducing investment cost.

Paper number 13:
Title: SPIRiT Regularization: Parallel MRI with a Combination of Sensitivity Encoding and Linear Predictability
Authors: Nicholas Dwork, Alex McManus, Stephen Becker, Gennifer T. Smith
Abstract: Accelerated Magnetic Resonance Imaging (MRI) permits high quality images from fewer samples that can be collected with a faster scan. Two established methods for accelerating MRI include parallel imaging and compressed sensing. Two types of parallel imaging include linear predictability, which assumes that the Fourier samples are linearly related, and sensitivity encoding, which incorporates a priori knowledge of the sensitivity maps. In this work, we combine compressed sensing with both types of parallel imaging using a novel regularization term: SPIRiT regularization. When combined, the reconstructed images are improved. We demonstrate results on data of a brain, a knee, and an ankle.

Paper number 14:
Title: Zero-shot Volumetric CT Super-Resolution using 3D Gaussian Splatting with Upsampled 2D X-ray Projection Priors
Authors: Jeonghyun Noh, Hyun-Jic Oh, Byungju Chae, Won-Ki Jeong
Abstract: Computed tomography (CT) is widely used in clinical diagnosis, but acquiring high-resolution (HR) CT is limited by radiation exposure risks. Deep learning-based super-resolution (SR) methods have been studied to reconstruct HR from low-resolution (LR) inputs. While supervised SR approaches have shown promising results, they require large-scale paired LR-HR volume datasets that are often unavailable. In contrast, zero-shot methods alleviate the need for paired data by using only a single LR input, but typically struggle to recover fine anatomical details due to limited internal information. To overcome these, we propose a novel zero-shot 3D CT SR framework that leverages upsampled 2D X-ray projection priors generated by a diffusion model. Exploiting the abundance of HR 2D X-ray data, we train a diffusion model on large-scale 2D X-ray projection and introduce a per-projection adaptive sampling strategy. It selects the generative process for each projection, thus providing HR projections as strong external priors for 3D CT reconstruction. These projections serve as inputs to 3D Gaussian splatting for reconstructing a 3D CT volume. Furthermore, we propose negative alpha blending (NAB-GS) that allows negative values in Gaussian density representation. NAB-GS enables residual learning between LR and diffusion-based projections, thereby enhancing high-frequency structure reconstruction. Experiments on two datasets show that our method achieves superior quantitative and qualitative results for 3D CT SR.

Paper number 15:
Title: Locally Differentially Private Multi-Sensor Fusion Estimation With System Intrinsic Randomness
Authors: Xinhao Yan, Bo Chen, Hailong Huang
Abstract: This paper focuses on the privacy-preserving multi-sensor fusion estimation (MSFE) problem with differential privacy considerations. Most existing research efforts are directed towards the exploration of traditional differential privacy, also referred to as centralized differential privacy (CDP). It is important to note that CDP is tailored to protect the privacy of statistical data at fusion center such as averages and sums rather than individual data at sensors, which renders it inappropriate for MSFE. Additionally, the definitions and assumptions of CDP are primarily applicable for large-scale systems that require statistical results mentioned above. Therefore, to address these limitations, this paper introduces a more recent advancement known as \emph{local differential privacy (LDP)} to enhance the privacy of MSFE. We provide some rigorous definitions about LDP based on the intrinsic properties of MSFE rather than directly presenting the assumptions under CDP. Subsequently, the LDP is proved to be realized with system intrinsic randomness, which is useful and has never been considered before. Furthermore, the Gaussian mechanism is designed when the intrinsic randomness is insufficient. The lower bound of the covariance for extra injected Gaussian noises is determined by integrating system information with privacy budgets. Moreover, the optimal fusion estimators under intrinsic and extra disturbances are respectively designed in the linear minimum variance sense. Finally, the effectiveness of the proposed methods is verified through numerical simulations, encompassing both one-dimensional and high-dimensional scenarios.

Paper number 16:
Title: Pathology-Informed Latent Diffusion Model for Anomaly Detection in Lymph Node Metastasis
Authors: Jiamu Wang, Keunho Byeon, Jinsol Song, Anh Nguyen, Sangjeong Ahn, Sung Hak Lee, Jin Tae Kwak
Abstract: Anomaly detection is an emerging approach in digital pathology for its ability to efficiently and effectively utilize data for disease diagnosis. While supervised learning approaches deliver high accuracy, they rely on extensively annotated datasets, suffering from data scarcity in digital pathology. Unsupervised anomaly detection, however, offers a viable alternative by identifying deviations from normal tissue distributions without requiring exhaustive annotations. Recently, denoising diffusion probabilistic models have gained popularity in unsupervised anomaly detection, achieving promising performance in both natural and medical imaging datasets. Building on this, we incorporate a vision-language model with a diffusion model for unsupervised anomaly detection in digital pathology, utilizing histopathology prompts during reconstruction. Our approach employs a set of pathology-related keywords associated with normal tissues to guide the reconstruction process, facilitating the differentiation between normal and abnormal tissues. To evaluate the effectiveness of the proposed method, we conduct experiments on a gastric lymph node dataset from a local hospital and assess its generalization ability under domain shift using a public breast lymph node dataset. The experimental results highlight the potential of the proposed method for unsupervised anomaly detection across various organs in digital pathology. Code: this https URL.

Paper number 17:
Title: Explainable Knowledge Distillation for Efficient Medical Image Classification
Authors: Aqib Nazir Mir, Danish Raza Rizvi
Abstract: This study comprehensively explores knowledge distillation frameworks for COVID-19 and lung cancer classification using chest X-ray (CXR) images. We employ high-capacity teacher models, including VGG19 and lightweight Vision Transformers (Visformer-S and AutoFormer-V2-T), to guide the training of a compact, hardware-aware student model derived from the OFA-595 supernet. Our approach leverages hybrid supervision, combining ground-truth labels with teacher models' soft targets to balance accuracy and computational efficiency. We validate our models on two benchmark datasets: COVID-QU-Ex and LCS25000, covering multiple classes, including COVID-19, healthy, non-COVID pneumonia, lung, and colon cancer. To interpret the spatial focus of the models, we employ Score-CAM-based visualizations, which provide insight into the reasoning process of both teacher and student networks. The results demonstrate that the distilled student model maintains high classification performance with significantly reduced parameters and inference time, making it an optimal choice in resource-constrained clinical environments. Our work underscores the importance of combining model efficiency with explainability for practical, trustworthy medical AI solutions.

Paper number 18:
Title: A Refined Alternating Optimization for Sum Rate Maximization in SIM-Aided Multiuser MISO Systems
Authors: Eduard E. Bahingayi, Shuying Lin, Murat Uysal, Marco Di Renzo, Le-Nam Tran
Abstract: Stacked intelligent metasurfaces (SIMs) have emerged as a disruptive technology for future wireless networks. To investigate their capabilities, we study the sum rate maximization problem in an SIM-based multiuser (MU) multiple-input single-output (MISO) downlink system. A vast majority of pioneer studies, if not all, address this fundamental problem using the prevailing alternating optimization (AO) framework, where the digital beamforming (DB) and SIM phase shifts are optimized alternately. However, many of these approaches suffer from suboptimal performance, quickly leading to performance saturation, when the number of SIM layers increases assuming the \emph{fixed SIM thickness}. In this letter, we demonstrate that significant performance gains can still be achieved, and such saturation does not occur with the proposed method in the considered setting. To this end, we provide practical design guidelines to improve AO-based optimization of digital precoders and SIM phase shifts. Specifically, we show that (i) optimizing the SIM phase shifts first yields significant performance improvements, compared to optimizing the DB first; and (ii) when applying projected gradient (PG) methods, which are gradually becoming more popular to optimize the phase shifts thanks to their scalability, we find that using an iterative PG method achieves better performance than the single PG step, which is commonly used in existing solutions. Based on these customizations, the proposed method achieves a higher achievable sum rate (ASR) of up to $\ensuremath{115.53\%}$, compared to benchmark schemes for the scenarios under consideration.

Paper number 19:
Title: Performance Analysis of RIS-Aided High-Mobility Wireless Systems
Authors: Hanwen Hu, Jiancheng An, Lu Gan, Chau Yuen
Abstract: Reconfigurable intelligent surface (RIS) technology holds immense potential for increasing the performance of wireless networks. Therefore, RIS is also regarded as one of the solutions to address communication challenges in high-mobility scenarios, such as Doppler shift and fast fading. This paper investigates a high-speed train (HST) multiple-input single-output (MISO) communication system aided by a RIS. We propose a block coordinate descent (BCD) algorithm to jointly optimize the RIS phase shifts and the transmit beamforming vectors to maximize the channel gain. Numerical results are provided to demonstrate that the proposed algorithm significantly enhances the system performance, achieving an average channel gain improvement of 15 dB compared to traditional schemes. Additionally, the introduction of RIS eliminates outage probability and improves key performance metrics such as achievable rate, channel capacity, and bit error rate (BER). These findings highlight the critical role of RIS in enhancing HST communication systems.

Paper number 20:
Title: Bladder Cancer Diagnosis with Deep Learning: A Multi-Task Framework and Online Platform
Authors: Jinliang Yu, Mingduo Xie, Yue Wang, Tianfan Fu, Xianglai Xu, Jiajun Wang
Abstract: Clinical cystoscopy, the current standard for bladder cancer diagnosis, suffers from significant reliance on physician expertise, leading to variability and subjectivity in diagnostic outcomes. There is an urgent need for objective, accurate, and efficient computational approaches to improve bladder cancer diagnostics. Leveraging recent advancements in deep learning, this study proposes an integrated multi-task deep learning framework specifically designed for bladder cancer diagnosis from cystoscopic images. Our framework includes a robust classification model using EfficientNet-B0 enhanced with Convolutional Block Attention Module (CBAM), an advanced segmentation model based on ResNet34-UNet++ architecture with self-attention mechanisms and attention gating, and molecular subtyping using ConvNeXt-Tiny to classify molecular markers such as HER-2 and Ki-67. Additionally, we introduce a Gradio-based online diagnostic platform integrating all developed models, providing intuitive features including multi-format image uploads, bilingual interfaces, and dynamic threshold adjustments. Extensive experimentation demonstrates the effectiveness of our methods, achieving outstanding accuracy (93.28%), F1-score (82.05%), and AUC (96.41%) for classification tasks, and exceptional segmentation performance indicated by a Dice coefficient of 0.9091. The online platform significantly improved the accuracy, efficiency, and accessibility of clinical bladder cancer diagnostics, enabling practical and user-friendly deployment. The code is publicly available. Our multi-task framework and integrated online tool collectively advance the field of intelligent bladder cancer diagnosis by improving clinical reliability, supporting early tumor detection, and enabling real-time diagnostic feedback. These contributions mark a significant step toward AI-assisted decision-making in urology.

Paper number 21:
Title: Mitigating Hallucinations in LM-Based TTS Models via Distribution Alignment Using GFlowNets
Authors: Chenlin Liu, Minghui Fang, Patrick Zhang, Wei Zhou, Jie Gao, Jiqing Han
Abstract: Language Model (LM)-based Text-to-Speech (TTS) systems often generate hallucinated speech that deviates from input text. Existing mitigation strategies either demand excessive training resources or introduce significant inference latency. In this paper, we propose GFlOwNet-guided distribution AlignmenT (GOAT) for LM-based TTS, a post-training framework that mitigates hallucinations without relying on massive resources or inference cost. Specifically, we first conduct an uncertainty analysis, revealing a strong positive correlation between hallucination and model uncertainty. Based on this, we reformulate TTS generation as a trajectory flow optimization problem and introduce an enhanced Subtrajectory Balance objective together with a sharpened internal reward as target distribution. We further integrate reward temperature decay and learning rate optimization for stability and performance balance. Extensive experiments show that GOAT reduce over 50% character error rates on challenging test cases and lowering uncertainty by up to 58%, demonstrating its strong generalization ability and effectiveness.

Paper number 22:
Title: DoSReMC: Domain Shift Resilient Mammography Classification using Batch Normalization Adaptation
Authors: Uğurcan Akyüz, Deniz Katircioglu-Öztürk, Emre K. Süslü, Burhan Keleş, Mete C. Kaya, Gamze Durhan, Meltem G. Akpınar, Figen B. Demirkazık, Gözde B. Akar
Abstract: Numerous deep learning-based solutions have been developed for the automatic recognition of breast cancer using mammography images. However, their performance often declines when applied to data from different domains, primarily due to domain shift - the variation in data distributions between source and target domains. This performance drop limits the safe and equitable deployment of AI in real-world clinical settings. In this study, we present DoSReMC (Domain Shift Resilient Mammography Classification), a batch normalization (BN) adaptation framework designed to enhance cross-domain generalization without retraining the entire model. Using three large-scale full-field digital mammography (FFDM) datasets - including HCTP, a newly introduced, pathologically confirmed in-house dataset - we conduct a systematic cross-domain evaluation with convolutional neural networks (CNNs). Our results demonstrate that BN layers are a primary source of domain dependence: they perform effectively when training and testing occur within the same domain, and they significantly impair model generalization under domain shift. DoSReMC addresses this limitation by fine-tuning only the BN and fully connected (FC) layers, while preserving pretrained convolutional filters. We further integrate this targeted adaptation with an adversarial training scheme, yielding additional improvements in cross-domain generalizability. DoSReMC can be readily incorporated into existing AI pipelines and applied across diverse clinical environments, providing a practical pathway toward more robust and generalizable mammography classification systems.

Paper number 23:
Title: EffortNet: A Deep Learning Framework for Objective Assessment of Speech Enhancement Technologies Using EEG-Based Alpha Oscillations
Authors: Ching-Chih Sung, Cheng-Hung Hsin, Yu-Anne Shiah, Bo-Jyun Lin, Yi-Xuan Lai, Chia-Ying Lee, Yu-Te Wang, Borchin Su, Yu Tsao
Abstract: This paper presents EffortNet, a novel deep learning framework for decoding individual listening effort from electroencephalography (EEG) during speech comprehension. Listening effort represents a significant challenge in speech-hearing research, particularly for aging populations and those with hearing impairment. We collected 64-channel EEG data from 122 participants during speech comprehension under four conditions: clean, noisy, MMSE-enhanced, and Transformer-enhanced speech. Statistical analyses confirmed that alpha oscillations (8-13 Hz) exhibited significantly higher power during noisy speech processing compared to clean or enhanced conditions, confirming their validity as objective biomarkers of listening effort. To address the substantial inter-individual variability in EEG signals, EffortNet integrates three complementary learning paradigms: self-supervised learning to leverage unlabeled data, incremental learning for progressive adaptation to individual characteristics, and transfer learning for efficient knowledge transfer to new subjects. Our experimental results demonstrate that Effort- Net achieves 80.9% classification accuracy with only 40% training data from new subjects, significantly outperforming conventional CNN (62.3%) and STAnet (61.1%) models. The probability-based metric derived from our model revealed that Transformer-enhanced speech elicited neural responses more similar to clean speech than MMSEenhanced speech. This finding contrasted with subjective intelligibility ratings but aligned with objective metrics. The proposed framework provides a practical solution for personalized assessment of hearing technologies, with implications for designing cognitive-aware speech enhancement systems.

Paper number 24:
Title: Why we need a standardized state of health definition for electric vehicle battery packs -- a proposal for energy- and capacity-based metrics
Authors: Philip Bilfinger, Markus Schreiber, Philipp Rosner, Kareem Abo Gamra, Jan Schöberl, Cristina Grosu, Markus Lienkamp
Abstract: Range and performance are key customer-relevant properties of electric vehicles. Both degrade over time due to battery aging, thus impacting business decisions throughout a vehicle's lifecycle, such as efficient utilization and asset valuation. For practical assessment, aging is often simplified into a single figure of merit - the state of health - typically defined by the battery pack's remaining capacity or energy. However, no standardized method for measuring the state of health at the vehicle level has been established, leaving both academia and industry without a clear consensus. Ultimately, standardization is crucial to increase transparency and build confidence in the long-term reliability of electric vehicles' battery packs. In this article, we propose a standard measurement procedure for assessing the capacity- and energy-based state of health, leveraging onboard charging to enable reproducibility and scalability. Additionally, we demonstrate how differential voltage analysis can provide deeper insights into battery aging at the vehicle level.

Paper number 25:
Title: Data-Driven Abstraction and Synthesis for Stochastic Systems with Unknown Dynamics
Authors: Mahdi Nazeri, Thom Badings, Anne-Kathrin Schmuck, Sadegh Soudjani, Alessandro Abate
Abstract: We study the automated abstraction-based synthesis of correct-by-construction control policies for stochastic dynamical systems with unknown dynamics. Our approach is to learn an abstraction from sampled data, which is represented in the form of a finite Markov decision process (MDP). In this paper, we present a data-driven technique for constructing finite-state interval MDP (IMDP) abstractions of stochastic systems with unknown nonlinear dynamics. As a distinguishing and novel feature, our technique only requires (1) noisy state-input-state observations and (2) an upper bound on the system's Lipschitz constant. Combined with standard model-checking techniques, our IMDP abstractions enable the synthesis of policies that satisfy probabilistic temporal properties (such as "reach-while-avoid") with a predefined confidence. Our experimental results show the effectiveness and robustness of our approach.

Paper number 26:
Title: Lightweight Gradient Descent Optimization for Mitigating Hardware Imperfections in RIS Systems
Authors: Pedro H. C. de Souza (1), Luiz A. M. Pereira (1), Faustino R. Gómez (1), Elsa M. Materón (1), Jorge Ricardo Mejía-Salazar (1) ((1) National Institute of Telecommunications)
Abstract: Ongoing discussions about the future of wireless communications are reaching a turning point as standardization activities for the sixth generation of mobile networks (6G) become more mature. New technologies must now face renewed scrutiny by the industry and academia in order to be ready for deployment in the near future. Recently, reconfigurable intelligent surfaces (RISs) gained attention as a promising solution for improving the propagation conditions of signal transmission in general. The RIS is a planar array of tunable resonant elements designed to dynamically and precisely manipulate the reflection of incident electromagnetic waves. However, the physical structure of the RIS and its components may be subject to practical limitations and imperfections. It is imperative that the hardware imperfections (HWIs) associated with the RIS be analyzed, so that it remains a feasible technology from a practical standpoint. Moreover, solutions for mitigating the HWIs must be considered, as is discussed in this work. More specifically, we introduce a gradient descent optimization for mitigating HWIs in RIS-aided wideband communication systems. Numerical results show that the proposed optimization is able to compensate for HWIs such as the phase-shift noise (PSN) and RIS surface deformations.

Paper number 27:
Title: Deep Equilibrium Convolutional Sparse Coding for Hyperspectral Image Denoising
Authors: Jin Ye, Jingran Wang, Fengchao Xiong, Jingzhou Chen, Yuntao Qian
Abstract: Hyperspectral images (HSIs) play a crucial role in remote sensing but are often degraded by complex noise patterns. Ensuring the physical property of the denoised HSIs is vital for robust HSI denoising, giving the rise of deep unfolding-based methods. However, these methods map the optimization of a physical model to a learnable network with a predefined depth, which lacks convergence guarantees. In contrast, Deep Equilibrium (DEQ) models treat the hidden layers of deep networks as the solution to a fixed-point problem and models them as infinite-depth networks, naturally consistent with the optimization. Under the framework of DEQ, we propose a Deep Equilibrium Convolutional Sparse Coding (DECSC) framework that unifies local spatial-spectral correlations, nonlocal spatial self-similarities, and global spatial consistency for robust HSI denoising. Within the convolutional sparse coding (CSC) framework, we enforce shared 2D convolutional sparse representation to ensure global spatial consistency across bands, while unshared 3D convolutional sparse representation captures local spatial-spectral details. To further exploit nonlocal self-similarities, a transformer block is embedded after the 2D CSC. Additionally, a detail enhancement module is integrated with the 3D CSC to promote image detail preservation. We formulate the proximal gradient descent of the CSC model as a fixed-point problem and transform the iterative updates into a learnable network architecture within the framework of DEQ. Experimental results demonstrate that our DECSC method achieves superior denoising performance compared to state-of-the-art methods.

Paper number 28:
Title: Frequency Selective Reflection of Wideband Signals with Reconfigurable Intelligent Surfaces
Authors: Pedro H. C. de Souza (1), Luciano Mendes (1) ((1) National Institute of Telecommunications - Inatel)
Abstract: Recently, the reconfigurable intelligent surface (RIS) technology has ushered in the prospect of control over the wireless propagation environment. By establishing alternative propagation paths for the transmitted signals, and by reflecting them in a controllable manner, the RIS is able to improve the signal reception. However, an aspect often overlooked is the potential bandwidth restrictions on the wideband signal reflected by the RIS. If not carefully considered, this can become an impediment for the adoption of the RIS in the next generation of communications systems. Therefore, in this work we propose a RIS configuration method that provides frequency selective signal reflection for wideband signals.

Paper number 29:
Title: Are Virtual DES Images a Valid Alternative to the Real Ones?
Authors: Ana C. Perre, Luís A. Alexandre, Luís C. Freire
Abstract: Contrast-enhanced spectral mammography (CESM) is an imaging modality that provides two types of images, commonly known as low-energy (LE) and dual-energy subtracted (DES) images. In many domains, particularly in medicine, the emergence of image-to-image translation techniques has enabled the artificial generation of images using other images as input. Within CESM, applying such techniques to generate DES images from LE images could be highly beneficial, potentially reducing patient exposure to radiation associated with high-energy image acquisition. In this study, we investigated three models for the artificial generation of DES images (virtual DES): a pre-trained U-Net model, a U-Net trained end-to-end model, and a CycleGAN model. We also performed a series of experiments to assess the impact of using virtual DES images on the classification of CESM examinations into malignant and non-malignant categories. To our knowledge, this is the first study to evaluate the impact of virtual DES images on CESM lesion classification. The results demonstrate that the best performance was achieved with the pre-trained U-Net model, yielding an F1 score of 85.59% when using the virtual DES images, compared to 90.35% with the real DES images. This discrepancy likely results from the additional diagnostic information in real DES images, which contributes to a higher classification accuracy. Nevertheless, the potential for virtual DES image generation is considerable and future advancements may narrow this performance gap to a level where exclusive reliance on virtual DES images becomes clinically viable.

Paper number 30:
Title: On the Compromise Between Performance and Efficiency in RIS-aided Communication Systems
Authors: P. H. C. de Souza (1), M. Khazaee (1), L. L. Mendes (1) ((1) National Institute of Telecommunications - Inatel)
Abstract: The reconfigurable intelligent surface (RIS) technology for metasurfaces is ushering in a new paradigm for wireless communication systems. It provides an accessible way for controlling the interaction between electromagnetic waves with the propagation medium. One particularly important aspect is the configuration of the RIS elements or reflectors. Simply stated, the objective of the RIS configuration is to choose the optimum phase-shift combination that maximizes the channel capacity. Recently, neural networks (NNs) were proposed for tackling this task and results have shown that the proposed NN promotes far less reconfigurations of the RIS, consequently reducing the configuration overhead. Beyond that, the RIS can be repurposed for tackling the Doppler shift in high-mobility communication systems. Despite not being its usual primary goal, results have also demonstrated that the RIS can compensate for the Doppler shift at a small cost in performance. However, the typical reflection-only constraint for RIS systems limits the spatial coverage and signal amplification potential achieved by such systems. Therefore, the simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) can be employed to address these limitations by its dual functionality of transmitting and reflecting signals concurrently. It can be shown that the STAR-RIS can augment coverage, energy efficiency, and latency reduction, while enhancing sum-rate and physical-layer security across several wireless contexts.

Paper number 31:
Title: Synthesis and SOS-based Stability Verification of a Neural-Network-Based Controller for a Two-wheeled Inverted Pendulum
Authors: Alvaro Detailleur, Dalim Wahby, Guillaume Ducard, Christopher Onder
Abstract: This work newly establishes the feasibility and practical value of a sum of squares (SOS)-based stability verification procedure for applied control problems utilizing neural-network-based controllers (NNCs). It successfully verifies closed-loop stability properties of a NNC synthesized using a generalizable procedure to imitate a robust, tube-based model predictive controller (MPC) for a two-wheeled inverted pendulum demonstrator system. This is achieved by first developing a state estimator and control-oriented model for the two-wheeled inverted pendulum. Next, this control-oriented model is used to synthesize a baseline linear-quadratic regulator (LQR) and a robust, tube-based MPC, which is computationally too demanding for real-time execution on the demonstrator system's embedded hardware. The generalizable synthesis procedure generates an NNC imitating the robust, tube-based MPC. Via an SOS-based stability verification procedure, a certificate of local asymptotic stability and a relevant inner estimate of the region of attraction (RoA) are obtained for the closed-loop system incorporating this NNC. Finally, experimental results on the physical two-wheeled inverted pendulum demonstrate that the NNC both stabilizes the system, and improves the control performance compared to the baseline LQR in both regulation and reference-tracking tasks.

Paper number 32:
Title: Label Uncertainty for Ultrasound Segmentation
Authors: Malini Shivaram, Gautam Rajendrakumar Gare, Laura Hutchins, Jacob Duplantis, Thomas Deiss, Thales Nogueira Gomes, Thong Tran, Keyur H. Patel, Thomas H Fox, Amita Krishnan, Deva Ramanan, Bennett DeBoisblanc, Ricardo Rodriguez, John Galeotti
Abstract: In medical imaging, inter-observer variability among radiologists often introduces label uncertainty, particularly in modalities where visual interpretation is subjective. Lung ultrasound (LUS) is a prime example-it frequently presents a mixture of highly ambiguous regions and clearly discernible structures, making consistent annotation challenging even for experienced clinicians. In this work, we introduce a novel approach to both labeling and training AI models using expert-supplied, per-pixel confidence values. Rather than treating annotations as absolute ground truth, we design a data annotation protocol that captures the confidence that radiologists have in each labeled region, modeling the inherent aleatoric uncertainty present in real-world clinical data. We demonstrate that incorporating these confidence values during training leads to improved segmentation performance. More importantly, we show that this enhanced segmentation quality translates into better performance on downstream clinically-critical tasks-specifically, estimating S/F oxygenation ratio values, classifying S/F ratio change, and predicting 30-day patient readmission. While we empirically evaluate many methods for exposing the uncertainty to the learning model, we find that a simple approach that trains a model on binarized labels obtained with a (60%) confidence threshold works well. Importantly, high thresholds work far better than a naive approach of a 50% threshold, indicating that training on very confident pixels is far more effective. Our study systematically investigates the impact of training with varying confidence thresholds, comparing not only segmentation metrics but also downstream clinical outcomes. These results suggest that label confidence is a valuable signal that, when properly leveraged, can significantly enhance the reliability and clinical utility of AI in medical imaging.

Paper number 33:
Title: A Central Chilled Water Plant Model for Designing Learning-Based Controllers
Authors: Zhong Guo, Prabir Barooah
Abstract: We describe a framework of modeling a central chilled water plant (CCWP) that consists of an aggregate cooling coil, a number of heterogeneous chillers and cooling towers, and a chilled water-based thermal energy storage system. We improve upon existing component models from the open literature using a constrained optimization-based framework to ensure that the models respect capacities of all the heat exchangers (cooling coils, chillers, and cooling towers) irrespective of the inputs provided. As a result, the proposed model has a wider range of validity compared to existing models; the latter can produce highly erroneous outputs when inputs are not within normal operating range. This feature is essential for training learning-based controllers that can choose inputs beyond normal operating conditions and is lacking in currently available models. The overall plant model is implemented in Matlab and is made publicly available. Simulation of a CCWP with closed loop control is provided as an illustration.

Paper number 34:
Title: Hessian-based lightweight neural network for brain vessel segmentation on a minimal training dataset
Authors: Alexandra Bernadotte, Elfimov Nikita, Mikhail Shutov, Ivan Menshikov
Abstract: Accurate segmentation of blood vessels in brain magnetic resonance angiography (MRA) is essential for successful surgical procedures, such as aneurysm repair or bypass surgery. Currently, annotation is primarily performed through manual segmentation or classical methods, such as the Frangi filter, which often lack sufficient accuracy. Neural networks have emerged as powerful tools for medical image segmentation, but their development depends on well-annotated training datasets. However, there is a notable lack of publicly available MRA datasets with detailed brain vessel annotations. To address this gap, we propose a novel semi-supervised learning lightweight neural network with Hessian matrices on board for 3D segmentation of complex structures such as tubular structures, which we named HessNet. The solution is a Hessian-based neural network with only 6000 parameters. HessNet can run on the CPU and significantly reduces the resource requirements for training neural networks. The accuracy of vessel segmentation on a minimal training dataset reaches state-of-the-art results. It helps us create a large, semi-manually annotated brain vessel dataset of brain MRA images based on the IXI dataset (annotated 200 images). Annotation was performed by three experts under the supervision of three neurovascular surgeons after applying HessNet. It provides high accuracy of vessel segmentation and allows experts to focus only on the most complex important cases. The dataset is available at this https URL.

Paper number 35:
Title: Discrete Radar based on Modulo Arithmetic
Authors: Nishant Mehrotra, Sandesh Rao Mattu, Saif Khan Mohammed, Ronny Hadani, Robert Calderbank
Abstract: Zak-OTFS is modulation scheme where signals are formed in the delay-Doppler (DD) domain, converted to the time domain (DD) for transmission and reception, then returned to the DD domain for processing. We describe how to use the same architecture for radar sensing. The intended delay resolution is $\frac{1}{B}$ where $B$ is the radar bandwidth, and the intended Doppler resolution is $\frac{1}{T}$ where $T$ is the transmission time. We form a radar waveform in the DD domain, illuminate the scattering environment, match filter the return, then correlate with delay and Doppler shifts of the transmitted waveform. This produces an image of the scattering environment, and the radar ambiguity function expresses the blurriness of this image. The possible delay and Doppler shifts generate the continuous Heisenberg-Weyl group which has been widely studied in the theory of radar. We describe how to approach the problem of waveform design, not from the perspective of this continuous group, but from the perspective of a discrete group of delay and Doppler shifts, where the discretization is determined by the intended delay and Doppler resolution of the radar. We describe how to approach the problem of shaping the ambiguity surface through symplectic transformations that normalize our discrete Heisenberg-Weyl group. The complexity of traditional continuous radar signal processing is $\mathcal{O}\big(B^2T^2\big)$. We describe how to reduce this complexity to $\mathcal{O}\big(BT\log T\big)$ by choosing the radar waveform to be a common eigenvector of a maximal commutative subgroup of our discrete Heisenberg-Weyl group. The theory of symplectic transformations also enables defining libraries of optimal radar waveforms with small peak-to-average power ratios.

Paper number 36:
Title: A Grant-free Coded Random Access Scheme for Near-field Communications
Authors: Enrico Testi, Giulia Torcolacci, Nicolò Decarli, Davide Dardari, Enrico Paolini
Abstract: The industrial Internet of things (IIoT) is revolutionizing industrial processes by facilitating massive machine-type communications among countless interconnected devices. To efficiently handle the resulting large-scale and sporadic traffic, grant-free random access protocols-especially coded random access (CRA)-have emerged as scalable and reliable solutions. At the same time, advancements in wireless hardware, including extremely large-scale MIMO arrays and high-frequency communication (e.g., mmWave, Terahertz), are pushing network operations into the near-field propagation regime, allowing for dense connectivity and enhanced spatial multiplexing. This paper proposes an innovative approach that combines near-field spatial multiplexing with the interference mitigation capabilities of CRA, utilizing an extremely large aperture array at the access point. This integration improves reliability and reduces access latency, offering a robust framework for IIoT connectivity in next-generation 6G networks.

Paper number 37:
Title: Estimation-Theoretic Bias Reduction for Oscillometric Blood Pressure Readings
Authors: Masoud Nateghi, Reza Sameni
Abstract: Oscillometry is the standard method for non-invasive, cuff-based blood pressure (BP) measurement, but it introduces systematic errors that may impact clinical accuracy. This study investigates the sources of these errors--primarily the limitations of oscillometry itself and respiration-induced fluctuations--using BP waveform data from the MIMIC database. Oscillometry tends to underestimate systolic BP and overestimate diastolic BP, while respiration introduces cyclical variations that further degrade measurement precision. To mitigate these effects, we propose an estimation-theoretic framework employing least squares (LS) and maximum likelihood (ML) methods for correcting both single and repeated BP measurements. LS estimation supports conventional multi-measurement averaging protocols, whereas the ML approach incorporates prior knowledge of measurement errors, offering improved performance. Our results demonstrate that leveraging statistical priors across multiple readings can enhance the accuracy of non-invasive BP monitoring, with potential implications for improving cardiovascular diagnosis and treatment.

Paper number 38:
Title: A 16.28 ppm/°C Temperature Coefficient, 0.5V Low-Voltage CMOS Voltage Reference with Curvature Compensation
Authors: Harshith Reddy, Pankaj Arora
Abstract: This paper presents a fully-integrated CMOS voltage reference designed in a 90 nm process node using low voltage threshold (LVT) transistor models. The voltage reference leverages subthreshold operation and near-weak inversion characteristics, backed by an all-region MOSFET model. The proposed design achieves a very low operating supply voltage of 0.5 V and a remarkably low temperature coefficient of 16.28 ppm/°C through the mutual compensation of CTAT, PTAT, and curvature-correction currents, over a wide range from -40 °C to 130 °C. A stable reference voltage of 205 mV is generated with a line sensitivity of 1.65 %/V and a power supply rejection ratio (PSRR) of -50 dB at 10 kHz. The circuit achieves all these parameters while maintaining a good power efficiency, consuming only 0.67 {\mu}W.

Paper number 39:
Title: Scalable FPGA Framework for Real-Time Denoising in High-Throughput Imaging: A DRAM-Optimized Pipeline using High-Level Synthesis
Authors: Weichien Liao
Abstract: High-throughput imaging workflows, such as Parallel Rapid Imaging with Spectroscopic Mapping (PRISM), generate data at rates that exceed conventional real-time processing capabilities. We present a scalable FPGA-based preprocessing pipeline for real-time denoising, implemented via High-Level Synthesis (HLS) and optimized for DRAM-backed buffering. Our architecture performs frame subtraction and averaging directly on streamed image data, minimizing latency through burst-mode AXI4 interfaces. The resulting kernel operates below the inter-frame interval, enabling inline denoising and reducing dataset size for downstream CPU/GPU analysis. Validated under PRISM-scale acquisition, this modular FPGA framework offers a practical solution for latency-sensitive imaging workflows in spectroscopy and microscopy.

Paper number 40:
Title: Denoising by neural network for muzzle blast detection
Authors: Hadrien Pujol, Matteo Bevillacqua, Christophe Thirard, Thierry Mazoyer
Abstract: Acoem develops gunshot detection systems, consisting of a microphone array and software that detects and locates shooters on the battlefield.  The performance of such systems is obviously affected by the acoustic environment in which they are operating: in particular, when mounted on a moving military vehicle, the presence of noise reduces the detection performance of the software. To limit the influence of the acoustic environment, a neural network has been developed. Instead of using a heavy convolutional neural network, a lightweight neural network architecture was chosen to limit the computational resources required to embed the algorithm on as many hardware platforms as possible.  Thanks to the combination of a two hidden layer perceptron and appropriate signal processing techniques, the detection rate of impulsive muzzle blast waveforms (the wave coming from the detonation and indicating the position of the shooter) is significantly increased. With a rms value of noise of the same order as the muzzle blast peak amplitude, the detect rate is more than doubled with this denoising processing.

Paper number 41:
Title: Human Feedback Driven Dynamic Speech Emotion Recognition
Authors: Ilya Fedorov, Dmitry Korobchenko
Abstract: This work proposes to explore a new area of dynamic speech emotion recognition. Unlike traditional methods, we assume that each audio track is associated with a sequence of emotions active at different moments in time. The study particularly focuses on the animation of emotional 3D avatars. We propose a multi-stage method that includes the training of a classical speech emotion recognition model, synthetic generation of emotional sequences, and further model improvement based on human feedback. Additionally, we introduce a novel approach to modeling emotional mixtures based on the Dirichlet distribution. The models are evaluated based on ground-truth emotions extracted from a dataset of 3D facial animations. We compare our models against the sliding window approach. Our experimental results show the effectiveness of Dirichlet-based approach in modeling emotional mixtures. Incorporating human feedback further improves the model quality while providing a simplified annotation procedure.

Paper number 42:
Title: Fusing Structural Phenotypes with Functional Data for Early Prediction of Primary Angle Closure Glaucoma Progression
Authors: Swati Sharma, Thanadet Chuangsuwanich, Royston K.Y. Tan, Shimna C. Prasad, Tin A. Tun, Shamira A. Perera, Martin L. Buist, Tin Aung, Monisha E. Nongpiur, Michaël J. A. Girard
Abstract: Purpose: To classify eyes as slow or fast glaucoma progressors in patients with primary angle closure glaucoma (PACG) using an integrated approach combining optic nerve head (ONH) structural features and sector-based visual field (VF) functional parameters. Methods: PACG patients with >5 reliable VF tests over >5 years were included. Progression was assessed in Zeiss Forum, with baseline VF within six months of OCT. Fast progression was VFI decline <-2.0% per year; slow progression >-2.0% per year. OCT volumes were AI-segmented to extract 31 ONH parameters. The Glaucoma Hemifield Test defined five regions per hemifield, aligned with RNFL distribution. Mean sensitivity per region was combined with structural parameters to train ML classifiers. Multiple models were tested, and SHAP identified key predictors. Main outcome measures: Classification of slow versus fast progressors using combined structural and functional data. Results: We analyzed 451 eyes from 299 patients. Mean VFI progression was -0.92% per year; 369 eyes progressed slowly and 82 rapidly. The Random Forest model combining structural and functional features achieved the best performance (AUC = 0.87, 2000 Monte Carlo iterations). SHAP identified six key predictors: inferior MRW, inferior and inferior-temporal RNFL thickness, nasal-temporal LC curvature, superior nasal VF sensitivity, and inferior RNFL and GCL+IPL thickness. Models using only structural or functional features performed worse with AUC of 0.82 and 0.78, respectively. Conclusions: Combining ONH structural and VF functional parameters significantly improves classification of progression risk in PACG. Inferior ONH features, MRW and RNFL thickness, were the most predictive, highlighting the critical role of ONH morphology in monitoring disease progression.

Paper number 43:
Title: XAI-Driven Spectral Analysis of Cough Sounds for Respiratory Disease Characterization
Authors: Patricia Amado-Caballero, Luis Miguel San-José-Revuelta, María Dolores Aguilar-García, José Ramón Garmendia-Leiza, Carlos Alberola-López, Pablo Casaseca-de-la-Higuera
Abstract: This paper proposes an eXplainable Artificial Intelligence (XAI)-driven methodology to enhance the understanding of cough sound analysis for respiratory disease management. We employ occlusion maps to highlight relevant spectral regions in cough spectrograms processed by a Convolutional Neural Network (CNN). Subsequently, spectral analysis of spectrograms weighted by these occlusion maps reveals significant differences between disease groups, particularly in patients with COPD, where cough patterns appear more variable in the identified spectral regions of interest. This contrasts with the lack of significant differences observed when analyzing raw spectrograms. The proposed approach extracts and analyzes several spectral features, demonstrating the potential of XAI techniques to uncover disease-specific acoustic signatures and improve the diagnostic capabilities of cough sound analysis by providing more interpretable results.

Paper number 44:
Title: Holo-Artisan: A Personalized Multi-User Holographic Experience for Virtual Museums on the Edge Intelligence
Authors: Nan-Hong Kuo, Hojjat Baghban
Abstract: We present Holo-Artisan, a novel system architecture enabling immersive multi-user experiences in virtual museums through true holographic displays and personalized edge intelligence. In our design, local edge computing nodes process real-time user data -- including pose, facial expression, and voice -- for multiple visitors concurrently. Generative AI models then drive digital artworks (e.g., a volumetric Mona Lisa) to respond uniquely to each viewer. For instance, the Mona Lisa can return a smile to one visitor while engaging in a spoken Q\&A with another, all in real time. A cloud-assisted collaboration platform composes these interactions in a shared scene using a universal scene description, and employs ray tracing to render high-fidelity, personalized views with a direct pipeline to glasses-free holographic displays. To preserve user privacy and continuously improve personalization, we integrate federated learning (FL) -- edge devices locally fine-tune AI models and share only model updates for aggregation. This edge-centric approach minimizes latency and bandwidth usage, ensuring a synchronized shared experience with individual customization. Through Holo-Artisan, static museum exhibits are transformed into dynamic, living artworks that engage each visitor in a personal dialogue, heralding a new paradigm of cultural heritage interaction.

Paper number 45:
Title: A Vision-Based Shared-Control Teleoperation Scheme for Controlling the Robotic Arm of a Four-Legged Robot
Authors: Murilo Vinicius da Silva, Matheus Hipolito Carvalho, Juliano Negri, Thiago Segreto, Gustavo J. G. Lahr, Ricardo V. Godoy, Marcelo Becker
Abstract: In hazardous and remote environments, robotic systems perform critical tasks demanding improved safety and efficiency. Among these, quadruped robots with manipulator arms offer mobility and versatility for complex operations. However, teleoperating quadruped robots is challenging due to the lack of integrated obstacle detection and intuitive control methods for the robotic arm, increasing collision risks in confined or dynamically changing workspaces. Teleoperation via joysticks or pads can be non-intuitive and demands a high level of expertise due to its complexity, culminating in a high cognitive load on the operator. To address this challenge, a teleoperation approach that directly maps human arm movements to the robotic manipulator offers a simpler and more accessible solution. This work proposes an intuitive remote control by leveraging a vision-based pose estimation pipeline that utilizes an external camera with a machine learning-based model to detect the operator's wrist position. The system maps these wrist movements into robotic arm commands to control the robot's arm in real-time. A trajectory planner ensures safe teleoperation by detecting and preventing collisions with both obstacles and the robotic arm itself. The system was validated on the real robot, demonstrating robust performance in real-time control. This teleoperation approach provides a cost-effective solution for industrial applications where safety, precision, and ease of use are paramount, ensuring reliable and intuitive robotic control in high-risk environments.

Paper number 46:
Title: \textit{adder-viz}: Real-Time Visualization Software for Transcoding Event Video
Authors: Andrew C. Freeman, Luke Reinkensmeyer
Abstract: Recent years have brought about a surge in neuromorphic ``event'' video research, primarily targeting computer vision applications. Event video eschews video frames in favor of asynchronous, per-pixel intensity samples. While much work has focused on a handful of representations for specific event cameras, these representations have shown limitations in flexibility, speed, and compressibility. We previously proposed the unified AD{\Delta}ER representation to address these concerns. This paper introduces numerous improvements to the \textit{adder-viz} software for visualizing real-time event transcode processes and applications in-the-loop. The MIT-licensed software is available from a centralized repository at \href{this https URL}{this https URL}.

Paper number 47:
Title: Optimal Interference Signal for Masking an Acoustic Source
Authors: Hongyun Wang, Hong Zhou
Abstract: In an environment where acoustic privacy or deliberate signal obfuscation is desired, it is necessary to mask the acoustic signature generated in essential operations. We consider the problem of masking the effect of an acoustic source in a target region where possible detection sensors are located. Masking is achieved by placing interference signals near the acoustic source. We introduce a theoretical and computational framework for designing such interference signals with the goal of minimizing the residual amplitude in the target region. For the three-dimensional (3D) forced wave equation with spherical symmetry, we derive analytical quasi-steady periodic solutions for several canonical cases. We examine the phenomenon of self-masking where an acoustic source with certain spatial forcing profile masks itself from detection outside its forcing footprint. We then use superposition of spherically symmetric solutions to investigate masking in a given target region. We analyze and optimize the performance of using one or two point-forces deployed near the acoustic source for masking in the target region. For the general case where the spatial forcing profile of the acoustic source lacks spherical symmetry, we develop an efficient numerical method for solving the 3D wave equation. Potential applications of this work include undersea acoustic communication security, undersea vehicles stealth, and protection against acoustic surveillance.

Paper number 48:
Title: Nonlinear Federated System Identification
Authors: Omkar Tupe, Max Hartman, Lav R. Varshney, Saurav Prakash
Abstract: We consider federated learning of linearly-parameterized nonlinear systems. We establish theoretical guarantees on the effectiveness of federated nonlinear system identification compared to centralized approaches, demonstrating that the convergence rate improves as the number of clients increases. Although the convergence rates in the linear and nonlinear cases differ only by a constant, this constant depends on the feature map $\phi$, which can be carefully chosen in the nonlinear setting to increase excitation and improve performance. We experimentally validate our theory in physical settings where client devices are driven by i.i.d. control inputs and control policies exhibiting i.i.d. random perturbations, ensuring non-active exploration. Experiments use trajectories from nonlinear dynamical systems characterized by real-analytic feature functions, including polynomial and trigonometric components, representative of physical systems including pendulum and quadrotor dynamics. We analyze the convergence behavior of the proposed method under varying noise levels and data distributions. Results show that federated learning consistently improves convergence of any individual client as the number of participating clients increases.

Paper number 49:
Title: Toward Sustainable Subterranean mMTC: Space-Air-Ground-Underground Networks Powered by LoRaWAN and Wireless Energy Transfer
Authors: Kaiqiang Lin, Mohamed-Slim Alouini
Abstract: Wireless underground sensor networks (WUSNs), which enable real-time sensing and monitoring of underground resources by underground devices (UDs), hold great promise for delivering substantial social and economic benefits across various verticals. However, due to the harsh subterranean environment, scarce network resources, and restricted communication coverage, WUSNs face significant challenges in supporting sustainable massive machine-type communications (mMTC), particularly in remote, disaster-stricken, and hard-to-reach areas. To complement this, we conceptualize in this study a novel space-air-ground-underground integrated network (SAGUIN) architecture that seamlessly incorporates satellite systems, aerial platforms, terrestrial networks, and underground communications. On this basis, we integrate LoRaWAN and wireless energy transfer (WET) technologies into SAGUIN to enable sustainable subterranean mMTC. We begin by reviewing the relevant technical background and presenting the architecture and implementation challenges of SAGUIN. Then, we employ simulations to model a remote underground pipeline monitoring scenario to evaluate the feasibility and performance of SAGUIN based on LoRaWAN and WET technologies, focusing on the effects of parameters such as underground conditions, time allocation, LoRaWAN spread factor (SF) configurations, reporting periods, and harvested energy levels. Our results evidence that the proposed SAGUIN system, when combined with the derived time allocation strategy and an appropriate SF, can effectively extend the operational lifetime of UDs, thereby facilitating sustainable subterranean mMTC. Finally, we pinpoint key challenges and future research directions for SAGUIN.

Paper number 50:
Title: Comparative Evaluation of Text and Audio Simplification: A Methodological Replication Study
Authors: Prosanta Barai, Gondy Leroy, Arif Ahmed
Abstract: This study serves as a methodological replication of Leroy et al. (2022) research, which investigated the impact of text simplification on healthcare information comprehension in the evolving multimedia landscape. Building upon the original studys insights, our replication study evaluates audio content, recognizing its increasing importance in disseminating healthcare information in the digital age. Specifically, we explored the influence of text simplification on perceived and actual difficulty when users engage with audio content automatically generated from that text. Our replication involved 44 participants for whom we assessed their comprehension of healthcare information presented as audio created using Leroy et al. (2022) original and simplified texts. The findings from our study highlight the effectiveness of text simplification in enhancing perceived understandability and actual comprehension, aligning with the original studys results. Additionally, we examined the role of education level and language proficiency, shedding light on their potential impact on healthcare information access and understanding. This research underscores the practical value of text simplification tools in promoting health literacy. It suggests the need for tailored communication strategies to reach diverse audiences effectively in the healthcare domain.

Paper number 51:
Title: On the Performance of Linear Adaptive Filters driven by the Ergodic Chaotic Logistic Map
Authors: Andreas Mueller
Abstract: Chaotic dynamical systems are increasingly considered for use in coding and transmission systems. This stems from their parameter sensitivity and spectral characteristics. The latter are relevant for channel estimation methods. In particular the logistic map $f_\lambda =\lambda x\left( 1-x\right) $ has been employed in chaotic coding and spread spectrum transmission systems. For $\lambda =4$ the statistical properties of sequences generated by $f_4$ are considered as ideal drive signals for channel estimation schemes. This assumption is proven in the present paper. To this end the higher order statistical moments and the autocorrelation of time series generated by $f_4$ are derived. It is shown that for $\lambda =4$ the zero mean time series is uncorrelated. The adaptation performance of finite impulse response (FIR) digital adaptive filters (DAF) used for channel estimation is analyzed. It is shown that using zero mean sequences of $f_4$ leads to the maximal possible FIR DAF performance. An optimal value for the damping parameter in the LMS scheme is derived that leads to the maximal performance and ensures stability. The analytic considerations are confirmed by simulation results.

Paper number 52:
Title: Learning ECG Representations via Poly-Window Contrastive Learning
Authors: Yi Yuan, Joseph Van Duyn, Runze Yan, Zhuoyi Huang, Sulaiman Vesal, Sergey Plis, Xiao Hu, Gloria Hyunjung Kwak, Ran Xiao, Alex Fedorov
Abstract: Electrocardiogram (ECG) analysis is foundational for cardiovascular disease diagnosis, yet the performance of deep learning models is often constrained by limited access to annotated data. Self-supervised contrastive learning has emerged as a powerful approach for learning robust ECG representations from unlabeled signals. However, most existing methods generate only pairwise augmented views and fail to leverage the rich temporal structure of ECG recordings. In this work, we present a poly-window contrastive learning framework. We extract multiple temporal windows from each ECG instance to construct positive pairs and maximize their agreement via statistics. Inspired by the principle of slow feature analysis, our approach explicitly encourages the model to learn temporally invariant and physiologically meaningful features that persist across time. We validate our approach through extensive experiments and ablation studies on the PTB-XL dataset. Our results demonstrate that poly-window contrastive learning consistently outperforms conventional two-view methods in multi-label superclass classification, achieving higher AUROC (0.891 vs. 0.888) and F1 scores (0.680 vs. 0.679) while requiring up to four times fewer pre-training epochs (32 vs. 128) and 14.8% in total wall clock pre-training time reduction. Despite processing multiple windows per sample, we achieve a significant reduction in the number of training epochs and total computation time, making our method practical for training foundational models. Through extensive ablations, we identify optimal design choices and demonstrate robustness across various hyperparameters. These findings establish poly-window contrastive learning as a highly efficient and scalable paradigm for automated ECG analysis and provide a promising general framework for self-supervised representation learning in biomedical time-series data.

Paper number 53:
Title: UniCoM: A Universal Code-Switching Speech Generator
Authors: Sangmin Lee, Woojin Chung, Seyun Um, Hong-Goo Kang
Abstract: Code-switching (CS), the alternation between two or more languages within a single speaker's utterances, is common in real-world conversations and poses significant challenges for multilingual speech technology. However, systems capable of handling this phenomenon remain underexplored, primarily due to the scarcity of suitable datasets. To resolve this issue, we propose Universal Code-Mixer (UniCoM), a novel pipeline for generating high-quality, natural CS samples without altering sentence semantics. Our approach utilizes an algorithm we call Substituting WORDs with Synonyms (SWORDS), which generates CS speech by replacing selected words with their translations while considering their parts of speech. Using UniCoM, we construct Code-Switching FLEURS (CS-FLEURS), a multilingual CS corpus designed for automatic speech recognition (ASR) and speech-to-text translation (S2TT). Experimental results show that CS-FLEURS achieves high intelligibility and naturalness, performing comparably to existing datasets on both objective and subjective metrics. We expect our approach to advance CS speech technology and enable more inclusive multilingual systems.

Paper number 54:
Title: CUPE: Contextless Universal Phoneme Encoder for Language-Agnostic Speech Processing
Authors: Abdul Rehman, Jian-Jun Zhang, Xiaosong Yang
Abstract: Universal phoneme recognition typically requires analyzing long speech segments and language-specific patterns. Many speech processing tasks require pure phoneme representations free from contextual influence, which motivated our development of CUPE - a lightweight model that captures key phoneme features in just 120 milliseconds, about one phoneme's length. CUPE processes short, fixed-width windows independently and, despite fewer parameters than current approaches, achieves competitive cross-lingual performance by learning fundamental acoustic patterns common to all languages. Our extensive evaluation through supervised and self-supervised training on diverse languages, including zero-shot tests on the UCLA Phonetic Corpus, demonstrates strong cross-lingual generalization and reveals that effective universal speech processing is possible through modeling basic acoustic patterns within phoneme-length windows.

Paper number 55:
Title: An Enhanced Audio Feature Tailored for Anomalous Sound Detection Based on Pre-trained Models
Authors: Guirui Zhong, Qing Wang, Jun Du, Lei Wang, Mingqi Cai, Xin Fang
Abstract: Anomalous Sound Detection (ASD) aims at identifying anomalous sounds from machines and has gained extensive research interests from both academia and industry. However, the uncertainty of anomaly location and much redundant information such as noise in machine sounds hinder the improvement of ASD system performance. This paper proposes a novel audio feature of filter banks with evenly distributed intervals, ensuring equal attention to all frequency ranges in the audio, which enhances the detection of anomalies in machine sounds. Moreover, based on pre-trained models, this paper presents a parameter-free feature enhancement approach to remove redundant information in machine audio. It is believed that this parameter-free strategy facilitates the effective transfer of universal knowledge from pre-trained tasks to the ASD task during model fine-tuning. Evaluation results on the Detection and Classification of Acoustic Scenes and Events (DCASE) 2024 Challenge dataset demonstrate significant improvements in ASD performance with our proposed methods.

Paper number 56:
Title: Integrated Take-off Management and Trajectory Optimization for Merging Control in Urban Air Mobility Corridors
Authors: Yingqi Liu, Tianlu Pan, Jingjun Tan, Renxin Zhong, Can Chen
Abstract: Urban Air Mobility (UAM) has the potential to revolutionize daily transportation, offering rapid and efficient aerial mobility services. Take-off and merging phases are critical for air corridor operations, requiring the coordination of take-off aircraft and corridor traffic while ensuring safety and seamless transition. This paper proposes an integrated take-off management and trajectory optimization for merging control in UAM corridors. We first introduce a novel take-off airspace design. To our knowledge, this paper is one of the first to propose a structured design for take-off airspace. Based on the take-off airspace design, we devise a hierarchical coordinated take-off and merging management (HCTMM) strategy. To be specific, the take-off airspace design can simplify aircraft dynamics and thus reduce the dimensionality of the trajectory optimization problem whilst mitigating obstacle avoidance complexities. The HCTMM strategy strictly ensures safety and improves the efficiency of take-off and merging operations. At the tactical level, a scheduling algorithm coordinates aircraft take-off times and selects dynamic merging points to reduce conflicts and ensure smooth take-off and merging processes. At the operational level, a trajectory optimization strategy ensures that each aircraft reaches the dynamic merging point efficiently while satisfying safety constraints. Simulation results show that, compared to representative strategies with fixed or dynamic merging points, the HCTMM strategy significantly improves operational efficiency and reduces computational burden, while ensuring safety under various corridor traffic conditions. Further results confirm the scalability of the HCTMM strategy and the computational efficiency enabled by the proposed take-off airspace design.

Paper number 57:
Title: A Solvable Molecular Switch Model for Stable Temporal Information Processing
Authors: H. I. Nurdin, C. A. Nijhuis
Abstract: This paper studies an input-driven one-state differential equation model initially developed for an experimentally demonstrated dynamic molecular switch that switches like synapses in the brain do. The linear-in-the-state and nonlinear-in-the-input model is exactly solvable, and it is shown that it also possesses mathematical properties of convergence and fading memory that enable stable processing of time-varying inputs by nonlinear dynamical systems. Thus, the model exhibits the co-existence of biologically-inspired behavior and desirable mathematical properties for stable learning on sequential data. The results give theoretical support for the use of the dynamic molecular switches as computational units in deep cascaded/layered feedforward and recurrent architectures as well as other more general structures for neuromorphic computing. They could also inspire more general exactly solvable models that can be fitted to emulate arbitrary physical devices which can mimic brain-inspired behaviour and perform stable computation on input signals.

Paper number 58:
Title: Control-Based Online Distributed Optimization
Authors: Wouter J. A. van Weerelt, Nicola Bastianello
Abstract: In this paper we design a novel class of online distributed optimization algorithms leveraging control theoretical techniques. We start by focusing on quadratic costs, and assuming to know an internal model of their variation. In this set-up, we formulate the algorithm design as a robust control problem, showing that it yields a fully distributed algorithm. We also provide a distributed routine to acquire the internal model. We show that the algorithm converges exactly to the sequence of optimal solutions. We empirically evaluate the performance of the algorithm for different choices of parameters. Additionally, we evaluate the performance of the algorithm for quadratic problems with inexact internal model and non-quadratic problems, and show that it outperforms alternative algorithms in both scenarios.

Paper number 59:
Title: Jointly Computation- and Communication-Efficient Distributed Learning
Authors: Xiaoxing Ren, Nicola Bastianello, Karl H. Johansson, Thomas Parisini
Abstract: We address distributed learning problems over undirected networks. Specifically, we focus on designing a novel ADMM-based algorithm that is jointly computation- and communication-efficient. Our design guarantees computational efficiency by allowing agents to use stochastic gradients during local training. Moreover, communication efficiency is achieved as follows: i) the agents perform multiple training epochs between communication rounds, and ii) compressed transmissions are used. We prove exact linear convergence of the algorithm in the strongly convex setting. We corroborate our theoretical results by numerical comparisons with state of the art techniques on a classification task.

Paper number 60:
Title: Self-supervised physics-informed generative networks for phase retrieval from a single X-ray hologram
Authors: Xiaogang Yang (1), Dawit Hailu (2), Vojtěch Kulvait (2), Thomas Jentschke (2), Silja Flenner (2), Imke Greving (2), Stuart I. Campbell (1), Johannes Hagemann (3), Christian G. Schroer (3, 4, 5), Tak Ming Wong (2, 6), Julian Moosmann (2) ((1) NSLS-II, Brookhaven National Laboratory, Upton, USA, (2) Institute of Materials Physics, Helmholtz-Zentrum Hereon, Geesthacht, Germany, (3) Center for X-ray and Nano Science CXNS, Deutsches Elektronen-Synchrotron DESY, Hamburg, Germany, (4) Department of Physics, Universität Hamburg, Hamburg, Germany, (5) Helmholtz Imaging, Deutsches Elektronen-Synchrotron DESY, Hamburg, Germany, (6) Institute of Metallic Biomaterials, Helmholtz-Zentrum Hereon, Geesthacht, Germany)
Abstract: X-ray phase contrast imaging significantly improves the visualization of structures with weak or uniform absorption, broadening its applications across a wide range of scientific disciplines. Propagation-based phase contrast is particularly suitable for time- or dose-critical in vivo/in situ/operando (tomography) experiments because it requires only a single intensity measurement. However, the phase information of the wave field is lost during the measurement and must be recovered. Conventional algebraic and iterative methods often rely on specific approximations or boundary conditions that may not be met by many samples or experimental setups. In addition, they require manual tuning of reconstruction parameters by experts, making them less adaptable for complex or variable conditions. Here we present a self-learning approach for solving the inverse problem of phase retrieval in the near-field regime of Fresnel theory using a single intensity measurement (hologram). A physics-informed generative adversarial network is employed to reconstruct both the phase and absorbance of the unpropagated wave field in the sample plane from a single hologram. Unlike most deep learning approaches for phase retrieval, our approach does not require paired, unpaired, or simulated training data. This significantly broadens the applicability of our approach, as acquiring or generating suitable training data remains a major challenge due to the wide variability in sample types and experimental configurations. The algorithm demonstrates robust and consistent performance across diverse imaging conditions and sample types, delivering quantitative, high-quality reconstructions for both simulated data and experimental datasets acquired at beamline P05 at PETRA III (DESY, Hamburg), operated by Helmholtz-Zentrum Hereon. Furthermore, it enables the simultaneous retrieval of both phase and absorption information.

Paper number 61:
Title: High-Capacity and Low-PAPR BICM-OFDM Systems Using Non-Equiprobable and Non-Uniform Constellation Shaping With Clipping and Filtering
Authors: Eito Kurihara, Hideki Ochiai
Abstract: We address a design of high-capacity and low-peak-to-average power ratio (PAPR) orthogonal frequency-division multiplexing (OFDM) systems based on bit-interleaved coded modulation (BICM) utilizing non-equiprobable and non-uniform (NENU) constellations as well as clipping and filtering (CAF). The proposed constellations are generated using a truncated Gaussian distribution, and the merging of constellation points, where the former creates a non-uniform constellation (NUC), and the latter decreases the number of signal points without compromising the achievable bit-wise mutual information (BMI). Since the proposed constellations are uniquely determined by only the two parameters, each associated with NUC and cardinality, the complexity required for the numerical optimization process can be significantly low. We focus on the constellation design based on one dimension, i.e., pulse amplitude modulation (PAM), which facilitates the reduction of demapping complexity for the BICM receiver. The use of CAF at the transmitter can efficiently reduce the PAPR of OFDM signals; however, it introduces clipping noise that may degrade error rate performance, making the application of clipping noise cancellation (CNC) at the receiver essential. Therefore, we optimize the NENU constellations in the presence of CAF and CNC. Simulation results demonstrate that the combination of constellation shaping with CAF and CNC enables BICM-OFDM systems to simultaneously achieve low PAPR and high spectral efficiency over additive white Gaussian noise (AWGN) as well as frequency-selective Rayleigh fading channels. Furthermore, comparative studies confirm that the proposed system significantly outperforms the single-carrier counterpart (i.e., DFT-precoded BICM-OFDM) in terms of PAPR and bit error rate (BER) performance over fading channels.

Paper number 62:
Title: CM2LoD3: Reconstructing LoD3 Building Models Using Semantic Conflict Maps
Authors: Franz Hanke, Antonia Bieringer, Olaf Wysocki, Boris Jutzi
Abstract: Detailed 3D building models are crucial for urban planning, digital twins, and disaster management applications. While Level of Detail 1 (LoD)1 and LoD2 building models are widely available, they lack detailed facade elements essential for advanced urban analysis. In contrast, LoD3 models address this limitation by incorporating facade elements such as windows, doors, and underpasses. However, their generation has traditionally required manual modeling, making large-scale adoption challenging. In this contribution, CM2LoD3, we present a novel method for reconstructing LoD3 building models leveraging Conflict Maps (CMs) obtained from ray-to-model-prior analysis. Unlike previous works, we concentrate on semantically segmenting real-world CMs with synthetically generated CMs from our developed Semantic Conflict Map Generator (SCMG). We also observe that additional segmentation of textured models can be fused with CMs using confidence scores to further increase segmentation performance and thus increase 3D reconstruction accuracy. Experimental results demonstrate the effectiveness of our CM2LoD3 method in segmenting and reconstructing building openings, with the 61% performance with uncertainty-aware fusion of segmented building textures. This research contributes to the advancement of automated LoD3 model reconstruction, paving the way for scalable and efficient 3D city modeling. Our project is available: this https URL

Paper number 63:
Title: Understanding and Utilizing Dynamic Coupling in Free-Floating Space Manipulators for On-Orbit Servicing
Authors: Gargi Das, Daegyun Choi, Donghoon Kim
Abstract: This study proposes a dynamic coupling-informed trajectory optimization algorithm for free-floating space manipulator systems (SMSs). Dynamic coupling between the base and the manipulator arms plays a critical role in influencing the system's behavior. While prior research has predominantly focused on minimizing this coupling, often overlooking its potential advantages, this work investigates how dynamic coupling can instead be leveraged to improve trajectory planning. Singular value decomposition (SVD) of the dynamic coupling matrix is employed to identify the dominant components governing coupling behavior. A quantitative metric is then formulated to characterize the strength and directionality of the coupling and is incorporated into a trajectory optimization framework. To assess the feasibility of the optimized trajectory, a sliding mode control-based tracking controller is designed to generate the required joint torque inputs. Simulation results demonstrate that explicitly accounting for dynamic coupling in trajectory planning enables more informed and potentially more efficient operation, offering new directions for the control of free-floating SMSs.

Paper number 64:
Title: Diffusion MRI with Machine Learning
Authors: Davood Karimi, Simon K. Warfield
Abstract: \hspace{2mm} Diffusion-weighted magnetic resonance imaging (dMRI) of the brain offers unique capabilities including noninvasive probing of tissue microstructure and structural connectivity. It is widely used for clinical assessment of disease and injury, and for neuroscience research. Analyzing the dMRI data to extract useful information for medical and scientific purposes can be challenging. The dMRI measurements may suffer from strong noise and artifacts, and may exhibit high inter-session and inter-scanner variability in the data, as well as inter-subject heterogeneity in brain structure. Moreover, the relationship between measurements and the phenomena of interest can be highly complex. Recent years have witnessed increasing use of machine learning methods for dMRI analysis. This manuscript aims to assess these efforts, with a focus on methods that have addressed data preprocessing and harmonization, microstructure mapping, tractography, and white matter tract analysis. We study the main findings, strengths, and weaknesses of the existing methods and suggest topics for future research. We find that machine learning may be exceptionally suited to tackle some of the difficult tasks in dMRI analysis. However, for this to happen, several shortcomings of existing methods and critical unresolved issues need to be addressed. There is a pressing need to improve evaluation practices, to increase the availability of rich training datasets and validation benchmarks, as well as model generalizability, reliability, and explainability concerns.

Paper number 65:
Title: Fast-DDPM: Fast Denoising Diffusion Probabilistic Models for Medical Image-to-Image Generation
Authors: Hongxu Jiang, Muhammad Imran, Teng Zhang, Yuyin Zhou, Muxuan Liang, Kuang Gong, Wei Shao
Abstract: Denoising diffusion probabilistic models (DDPMs) have achieved unprecedented success in computer vision. However, they remain underutilized in medical imaging, a field crucial for disease diagnosis and treatment planning. This is primarily due to the high computational cost associated with (1) the use of large number of time steps (e.g., 1,000) in diffusion processes and (2) the increased dimensionality of medical images, which are often 3D or 4D. Training a diffusion model on medical images typically takes days to weeks, while sampling each image volume takes minutes to hours. To address this challenge, we introduce Fast-DDPM, a simple yet effective approach capable of improving training speed, sampling speed, and generation quality simultaneously. Unlike DDPM, which trains the image denoiser across 1,000 time steps, Fast-DDPM trains and samples using only 10 time steps. The key to our method lies in aligning the training and sampling procedures to optimize time-step utilization. Specifically, we introduced two efficient noise schedulers with 10 time steps: one with uniform time step sampling and another with non-uniform sampling. We evaluated Fast-DDPM across three medical image-to-image generation tasks: multi-image super-resolution, image denoising, and image-to-image translation. Fast-DDPM outperformed DDPM and current state-of-the-art methods based on convolutional networks and generative adversarial networks in all tasks. Additionally, Fast-DDPM reduced the training time to 0.2x and the sampling time to 0.01x compared to DDPM. Our code is publicly available at: this https URL.

Paper number 66:
Title: NucleiMix: Realistic Data Augmentation for Nuclei Instance Segmentation
Authors: Jiamu Wang, Jin Tae Kwak
Abstract: Nuclei instance segmentation is an essential task in pathology image analysis, serving as the foundation for many downstream applications. The release of several public datasets has significantly advanced research in this area, yet many existing methods struggle with data imbalance issues. To address this challenge, this study introduces a data augmentation method, called NucleiMix, which is designed to balance the distribution of nuclei types by increasing the number of rare-type nuclei within datasets. NucleiMix operates in two phases. In the first phase, it identifies candidate locations similar to the surroundings of rare-type nuclei and inserts rare-type nuclei into the candidate locations. In the second phase, it employs a progressive inpainting strategy using a pre-trained diffusion model to seamlessly integrate rare-type nuclei into their new environments in replacement of major-type nuclei or background locations. We systematically evaluate the effectiveness of NucleiMix on three public datasets using two popular nuclei instance segmentation models. The results demonstrate the superior ability of NucleiMix to synthesize realistic rare-type nuclei and to enhance the quality of nuclei segmentation and classification in an accurate and robust manner.

Paper number 67:
Title: Utility-Scale Bifacial Solar Photovoltaic System: Optimum Sizing and Techno-Economic Evaluation
Authors: Sharaf K. Magableh, Caisheng Wang, Feng Lin
Abstract: Classical monofacial solar photovoltaic systems have gained prevalence and are widely reported in the literature because they have a lower initial cost compared with bifacial systems. However, limited investigation of both systems has been done on a utility scale with different performance indicators. This paper introduces a multifaceted comparative analysis including various aspects like energy generation, reliability, environmental effect, economic viability, and footprint area. Real measured data, including ambient temperature, solar irradiance, and a utility-scale load, were used for studying both systems in the City of Detroit. The optimal system sizing and energy management strategy are attained using the Whale optimization algorithm. Minimizing the loss of power supply probability and sizing the number of photovoltaic panels (NPV) are carried out for both cases. Results revealed that the bifacial solar system generates more power with a lower NPV, a smaller installation area, and hence a lower levelized cost of energy for the entire project lifetime compared to the monofacial system. Accordingly, the bifacial system outlined in this paper is recommended and can be implemented in various locations to establish a sustainable solar energy system that is economically feasible with clean energy production for the entire project's lifespan.

Paper number 68:
Title: Physics-Driven Autoregressive State Space Models for Medical Image Reconstruction
Authors: Bilal Kabas, Fuat Arslan, Valiyeh A. Nezhad, Saban Ozturk, Emine U. Saritas, Tolga Çukur
Abstract: Medical image reconstruction from undersampled acquisitions is an ill-posed inverse problem requiring accurate recovery of anatomical structures from incomplete measurements. Physics-driven (PD) network models have gained prominence for this task by integrating data-consistency mechanisms with learned priors, enabling improved performance over purely data-driven approaches. However, reconstruction quality still hinges on the network's ability to disentangle artifacts from true anatomical signals-both of which exhibit complex, multi-scale contextual structure. Convolutional neural networks (CNNs) capture local correlations but often struggle with non-local dependencies. While transformers aim to alleviate this limitation, practical implementations involve design compromises to reduce computational cost by balancing local and non-local sensitivity, occasionally resulting in performance comparable to CNNs. To address these challenges, we propose MambaRoll, a novel physics-driven autoregressive state space model (SSM) for high-fidelity and efficient image reconstruction. MambaRoll employs an unrolled architecture where each cascade autoregressively predicts finer-scale feature maps conditioned on coarser-scale representations, enabling consistent multi-scale context propagation. Each stage is built on a hierarchy of scale-specific PD-SSM modules that capture spatial dependencies while enforcing data consistency through residual correction. To further improve scale-aware learning, we introduce a Deep Multi-Scale Decoding (DMSD) loss, which provides supervision at intermediate spatial scales in alignment with the autoregressive design. Demonstrations on accelerated MRI and sparse-view CT reconstructions show that MambaRoll consistently outperforms state-of-the-art CNN-, transformer-, and SSM-based methods.

Paper number 69:
Title: Inverse Problem Sampling in Latent Space Using Sequential Monte Carlo
Authors: Idan Achituve, Hai Victor Habi, Amir Rosenfeld, Arnon Netzer, Idit Diamant, Ethan Fetaya
Abstract: In image processing, solving inverse problems is the task of finding plausible reconstructions of an image that was corrupted by some (usually known) degradation operator. Commonly, this process is done using a generative image model that can guide the reconstruction towards solutions that appear natural. The success of diffusion models over the last few years has made them a leading candidate for this task. However, the sequential nature of diffusion models makes this conditional sampling process challenging. Furthermore, since diffusion models are often defined in the latent space of an autoencoder, the encoder-decoder transformations introduce additional difficulties. To address these challenges, we suggest a novel sampling method based on sequential Monte Carlo (SMC) in the latent space of diffusion models. We name our method LD-SMC. We define a generative model for the data using additional auxiliary observations and perform posterior inference with SMC sampling based on a reverse diffusion process. Empirical evaluations on ImageNet and FFHQ show the benefits of LD-SMC over competing methods in various inverse problem tasks and especially in challenging inpainting tasks.

Paper number 70:
Title: Three-Dimensional MRI Reconstruction with Gaussian Representations: Tackling the Undersampling Problem
Authors: Tengya Peng, Ruyi Zha, Zhen Li, Xiaofeng Liu, Qing Zou
Abstract: Three-Dimensional Gaussian Splatting (3DGS) has shown substantial promise in the field of computer vision, but remains unexplored in the field of magnetic resonance imaging (MRI). This study explores its potential for the reconstruction of isotropic resolution 3D MRI from undersampled k-space data. We introduce a novel framework termed 3D Gaussian MRI (3DGSMR), which employs 3D Gaussian distributions as an explicit representation for MR volumes. Experimental evaluations indicate that this method can effectively reconstruct voxelized MR images, achieving a quality on par with that of well-established 3D MRI reconstruction techniques found in the literature. Notably, the 3DGSMR scheme operates under a self-supervised framework, obviating the need for extensive training datasets or prior model training. This approach introduces significant innovations to the domain, notably the adaptation of 3DGS to MRI reconstruction and the novel application of the existing 3DGS methodology to decompose MR signals, which are presented in a complex-valued format.

Paper number 71:
Title: Impact Analysis of Utility-Scale Energy Storage on the ERCOT Grid in Reducing Renewable Generation Curtailments and Emissions
Authors: Cody Buehner, Sharaf K. Magableh, Oraib Dawaghreh, Caisheng Wang
Abstract: This paper explores the solutions for minimizing renewable energy (RE) curtailment in the Texas Electric Reliability Council of Texas (ERCOT) grid. By utilizing current and future planning data from ERCOT and the System Advisor Model from the National Renewable Energy Laboratory, we examine how future renewable energy (RE) initiatives, combined with utility-scale energy storage, can reduce CO2 emissions while reshaping Texas's energy mix. The study projects the energy landscape from 2023 to 2033, considering the planned phase-out of fossil fuel plants and the integration of new wind/solar projects. By comparing emissions under different load scenarios, with and without storage, we demonstrate storage's role in optimizing RE utilization. The findings of this paper provide actionable guidance for energy stakeholders, underscoring the need to expand wind and solar projects with strategic storage solutions to maximize Texas's RE capacity and substantially reduce CO2 emissions.

Paper number 72:
Title: Assessing the Performance and Impact of PV Technologies on Storage in Hybrid Renewable Systems
Authors: Sharaf K. Magableh, Oraib Dawaghreh, Xuesong Wang, Caisheng Wang
Abstract: Traditional monofacial photovoltaic (mPV) systems are commonly adopted and well-documented because of their lower upfront costs in comparison to bifacial photovoltaic (bPV) systems. This study investigates how PV technologies impact energy storage in grid-scale hybrid renewable systems, focusing on optimizing and assessing the performance of mPV and bPV technologies integrated with pumped storage hydropower. Using Ludington City, Michigan as a case study and analyzing realworld data such as solar irradiance, ambient temperature, and utility-scale load profiles, the research highlights the operational and economic benefits of bPV systems. The results reveal that bPV systems can pump approximately 10.38% more water annually to the upper reservoir while achieving a lower levelized cost of energy ($0.0578/kWh for bPV vs. $0.0672/kWh for mPV). This study underscores the outstanding potential of bPV systems in enhancing energy storage and management strategies, contributing to a more sustainable and resilient renewable energy future.

Paper number 73:
Title: A Time Splitting Based Optimization Method for Nonlinear MHE
Authors: Shuting Wu, Yifei Wang, Jingzhe Wang, Apostolos I. Rikos, Xu Du
Abstract: Moving Horizon Estimation~(MHE) is essentially an optimization-based approach designed to estimate the states of dynamic systems within a moving time horizon. Traditional MHE solutions become computationally prohibitive due to the \textit{curse of dimensionality} arising from increasing problem complexity and growing length of time horizon. To address this issue, we propose novel computationally efficient algorithms for solving nonlinear MHE problems. Specifically, we first introduce a distributed reformulation utilizing a time-splitting technique. Leveraging this reformulation, we develop the Efficient Gauss-Newton Augmented Lagrangian Alternating Direction Inexact Newton (ALADIN) to achieve computational efficiency. Additionally, to accommodate limited computational capabilities inherent in some sub-problem solvers, we propose the Efficient Sensitivity Assisted ALADIN, which enables sub-problems to be solved inexactly without hindering computational efficiency. Furthermore, recognizing scenarios where sub-problem solvers possess no computational power, we propose a Distributed Sequential Quadratic Programming (SQP) that relies solely on first- and second-order information of local objective functions. We demonstrate the performance and advantages of our proposed methods through numerical experiments on differential drive robots case, a practical nonlinear MHE problem. Our results demonstrate that the three proposed algorithms achieve computational efficiency while preserving high accuracy, thereby satisfying the real-time requirements of MHE.

Paper number 74:
Title: Secure Communications for All Users in Low-Resolution IRS-aided Systems Under Imperfect and Unknown CSI
Authors: Monir Abughalwa, Diep N. Nguyen, Dinh Thai Hoang, Thang X. Vu, Eryk Dutkiewicz, Symeon Chatzinotas
Abstract: Provisioning secrecy for all users, given the heterogeneity and uncertainty of their channel conditions, locations, and the unknown location of the attacker/eavesdropper, is challenging and not always feasible. This work takes the first step to guarantee secrecy for all users where a low resolution intelligent reflecting surfaces (IRS) is used to enhance legitimate users' reception and thwart the potential eavesdropper (Eve) from intercepting. In real-life scenarios, due to hardware limitations of the IRS' passive reflective elements (PREs), the use of a full-resolution (continuous) phase shift (CPS) is impractical. In this paper, we thus consider a more practical case where the phase shift (PS) is modeled by a low-resolution (quantized) phase shift (QPS) while addressing the phase shift error (PSE) induced by the imperfect channel state information (CSI). To that end, we aim to maximize the minimum secrecy rate (SR) among all users by jointly optimizing the transmitter's beamforming vector and the IRS's passive reflective elements (PREs) under perfect/imperfect/unknown CSI. The resulting optimization problem is non-convex and even more complicated under imperfect/unknown CSI. The resulting optimization problem is non-convex and even more complicated under imperfect/unknown CSI. To tackle it, we linearize the objective function and decompose the problem into sequential subproblems. When the perfect CSI is not available, we use the successive convex approximation (SCA) approach to transform imperfect CSI related semi-infinite constraints into finite linear matrix inequalities (LMI). We prove that our proposed algorithm converges to a locally optimal solution with low computational complexity. Extensive simulations with practical settings show that our approach can ensure secure communication for all users while the IRS's PREs are quantized and are affected by the PSE.

Paper number 75:
Title: "Security for Everyone" in Finite Blocklength IRS-aided Systems With Perfect and Imperfect CSI
Authors: Monir Abughalwa, Diep N. Nguyen, Dinh Thai Hoang, Van-Dinh Nguyen, Ming Zeng, Quoc-Viet Pham, Eryk Dutkiewicz
Abstract: Provisioning secrecy for all users, given the heterogeneity in their channel conditions, locations, and the unknown location of the attacker/eavesdropper, is challenging and not always feasible. The problem is even more difficult under finite blocklength constraints that are popular in ultra-reliable low-latency communication (URLLC) and massive machine-type communications (mMTC). This work takes the first step to guarantee secrecy for all URLLC/mMTC users in the finite blocklength regime (FBR) where intelligent reflecting surfaces (IRS) are used to enhance legitimate users' reception and thwart the potential eavesdropper (Eve) from intercepting. To that end, we aim to maximize the minimum secrecy rate (SR) among all users by jointly optimizing the transmitter's beamforming and IRS's passive reflective elements (PREs) under the FBR latency constraints. The resulting optimization problem is non-convex and even more complicated under imperfect channel state information (CSI). To tackle it, we linearize the objective function, and decompose the problem into sequential subproblems. When perfect CSI is not available, we use the successive convex approximation (SCA) approach to transform imperfect CSI-related semi-infinite constraints into finite linear matrix inequalities (LMI). We prove that our proposed algorithm converges to a locally optimal solution with low computational complexity thanks to our closed-form linearization approach. This makes the solution scalable for large IRS deployments. Extensive simulations with practical settings show that our approach can ensure secure communication for all users while satisfying FBR constraints even with only imperfect CSI.

Paper number 76:
Title: Versatile Framework for Song Generation with Prompt-based Control
Authors: Yu Zhang, Wenxiang Guo, Changhao Pan, Zhiyuan Zhu, Ruiqi Li, Jingyu Lu, Rongjie Huang, Ruiyuan Zhang, Zhiqing Hong, Ziyue Jiang, Zhou Zhao
Abstract: Song generation focuses on producing controllable high-quality songs based on various prompts. However, existing methods struggle to generate vocals and accompaniments with prompt-based control and proper alignment. Additionally, they fall short in supporting various tasks. To address these challenges, we introduce VersBand, a multi-task song generation framework for synthesizing high-quality, aligned songs with prompt-based control. VersBand comprises these primary models: 1) VocalBand, a decoupled model, leverages the flow-matching method for generating singing styles, pitches, and mel-spectrograms, allowing fast, high-quality vocal generation with style control. 2) AccompBand, a flow-based transformer model, incorporates the Band-MOE, selecting suitable experts for enhanced quality, alignment, and control. This model allows for generating controllable, high-quality accompaniments aligned with vocals. 3) Two generation models, LyricBand for lyrics and MelodyBand for melodies, contribute to the comprehensive multi-task song generation system, allowing for extensive control based on multiple prompts. Experimental results show that VersBand outperforms baseline models across multiple song generation tasks using objective and subjective metrics. Demos and codes are available at this https URL and this https URL.

Paper number 77:
Title: Integrating Grid impedance estimation method into Advanced Angle Estimation Kalman Filter in GFL inverter
Authors: Phuoc Sang Nguyen, Ghavameddin Nourbakhsh, Gerard Ledwich
Abstract: The growing integration of power electronic converter-interfaced distributed energy resources into modern power systems presents significant challenges for system monitoring, protection, and control. Grid impedance plays a critical role in the operation and stability assessment of grid-connected inverter systems. This study presents a real-time grid impedance estimation method based on the Discrete Fourier Transform. The proposed method is integrated with the Advanced Angle Estimation Kalman Filter using a Linear Quadratic Regulator current controller (AAEKF-LQR), assisting the use of impedance information for accurate instantaneous phase angle estimation. Simulation results confirm that the proposed impedance estimation method interacts effectively with the AAEKF-LQR controller, maintaining stable system performance under weak grid conditions. The approach also demonstrates the ability to deliver fast and accurate impedance estimation during operational variations in grid conditions, thereby supporting stable inverter operation.

Paper number 78:
Title: The ECME Algorithm Using Factor Analysis for DOA Estimation in Nonuniform Noise
Authors: Mingyan Gong
Abstract: Maximum likelihood factor analysis has been applied to direction of arrival (DOA) estimation in unknown nonuniform noise and a variety of iterative approaches have been developed. In particular, the Factor Analysis for Anisotropic Noise (FAAN) method proposed by Stoica and Babu has excellent convergence properties. In this article, the Expectation/Conditional Maximization Either (ECME) algorithm, an extension of the expectation-maximization algorithm, is designed, which has almost the same computational complexity at each iteration as the FAAN method. However, numerical results show that the ECME algorithm yields faster stable convergence and is computationally more efficient. Importantly, the signal subspace estimated by the ECME algorithm can be employed for the subspace based DOA estimation in unknown nonuniform noise.

Paper number 79:
Title: Discriminating Distal Ischemic Stroke from Seizure-Induced Stroke Mimics Using Dynamic Susceptibility Contrast MRI
Authors: Marijn Borghouts, Richard McKinley, Manuel Köstner, Josien Pluim, Roland Wiest, Ruisheng Su
Abstract: Distinguishing acute ischemic strokes (AIS) from stroke mimics (SMs), particularly in cases involving medium and small vessel occlusions, remains a significant diagnostic challenge. While computed tomography (CT) based protocols are commonly used in emergency settings, their sensitivity for detecting distal occlusions is limited. This study explores the potential of magnetic resonance perfusion (MRP) imaging as a tool for differentiating distal AIS from epileptic seizures, a prevalent SM. Using a retrospective dataset of 162 patients (129 AIS, 33 seizures), we extracted region-wise perfusion map descriptors (PMDs) from dynamic susceptibility contrast (DSC) images. Statistical analyses identified several brain regions, located mainly in the temporal and occipital lobe, exhibiting significant group differences in certain PMDs. Hemispheric asymmetry analyses further highlighted these regions as discriminative. A logistic regression model trained on PMDs achieved an area under the receiver operating characteristic (AUROC) curve of 0.90, and an area under the precision recall curve (AUPRC) of 0.74, with a specificity of 92% and a sensitivity of 73%, suggesting strong performance in distinguishing distal AIS from seizures. These findings support further exploration of MRP-based PMDs as interpretable features for distinguishing true strokes from various mimics. The code is openly available at our GitHub this https URL{this http URL\_extraction\_and\_analysis

Paper number 80:
Title: Spectral Efficiency Considerations for 6G
Authors: Joseph Boccuzzi
Abstract: As wireless connectivity continues to evolve towards 6G, there is an ever-increasing demand to not only deliver higher throughput, lower latency, and improved reliability, but also do so as efficiently as possible. To this point, the term efficiency has been quantified through applications to Spectral Efficiency (SE) and Energy Efficiency (EE). In this paper we introduce a new system metric called Radio Resource Utilization Efficiency (RUE). This metric quantifies the efficiency of the available radio resources (Spectrum, Access Method, Time Slots, Data Symbols, etc.) used to deliver future 6G demands. We compare the system performance of Typical Cellular and Cell-Free Massive MIMO deployments as a vehicle to demonstrate the need for this new metric. We begin by providing a concise treatment of items impacting SE by introducing three categories: 5G Radio Resources, Practical Limitations (such as channel matrix rank deficiency) and Implementation Losses (SINR degradation). For the example Radio Access Technology configuration analyzed, we show 5G yields an RUE of 47% (revealing significant room for improvement when defining 6G). Practical limitation assumptions are compared to 5G Multi-User MIMO (MU-MIMO) measurements conducted in a commercialized deployment. SE losses are characterized to offer guidance to advanced algorithms employing Machine Learning (ML) based techniques. We present the benefits of increasing the transmission Bandwidth (BW) from 100MHz to 1.6GHz. We describe a Next Generation RAN architecture that can support 6G and AI-RAN.

Paper number 81:
Title: Monotone Neural Control Barrier Certificates
Authors: Alireza Nadali, Ashutosh Trivedi, Majid Zamani, Saber Jafarpour
Abstract: This work presents a neurosymbolic framework for synthesizing and verifying safety controllers in high-dimensional monotone dynamical systems using only linear sample complexity, without requiring explicit models or conservative Lipschitz bounds. The approach combines the expressiveness of neural networks with the rigor of symbolic reasoning via barrier certificates, functional analogs of inductive invariants that formally guarantee safety. Prior data-driven methods often treat dynamics as black-box models, relying on dense state-space discretization or Lipschitz overapproximations, leading to exponential sample complexity. In contrast, monotonicity -- a pervasive structural property in many real-world systems -- provides a symbolic scaffold that simplifies both learning and verification. Exploiting order preservation reduces verification to localized boundary checks, transforming a high-dimensional problem into a tractable, low-dimensional one. Barrier certificates are synthesized using monotone neural networks -- architectures with embedded monotonicity constraints -- trained via gradient-based optimization guided by barrier conditions. This enables scalable, formally sound verification directly from simulation data, bridging black-box learning and formal guarantees within a unified neurosymbolic framework. Empirical results on three large-scale benchmarks -- a 1,000-dimensional freeway traffic model, a 50-dimensional urban traffic network, and a 13,000-dimensional power grid -- demonstrate the scalability and effectiveness of the approach in real-world, safety-critical systems.

Paper number 82:
Title: DCT-MARL: A Dynamic Communication Topology-Based MARL Algorithm for Connected Vehicle Platoon Control
Authors: Yaqi Xu, Yan Shi, Jin Tian, Fanzeng Xia, Tongxin Li, Shanzhi Chen, Yuming Ge
Abstract: With the rapid advancement of vehicular communication facilities and autonomous driving technologies, connected vehicle platooning has emerged as a promising approach to improve traffic efficiency and driving safety. Reliable Vehicle-to-Vehicle (V2V) communication is critical to achieving efficient cooperative control. However, in the real-world traffic environment, V2V communication may suffer from time-varying delay and packet loss, leading to degraded control performance and even safety risks. To mitigate the adverse effects of non-ideal communication, this paper proposes a Dynamic Communication Topology based Multi-Agent Reinforcement Learning (DCT-MARL) algorithm for robust cooperative platoon control. Specifically, the state space is augmented with historical control action and delay to enhance robustness against communication delay. To mitigate the impact of packet loss, a multi-key gated communication mechanism is introduced, which dynamically adjusts the communication topology based on the correlation between vehicles and their current communication status. Simulation results demonstrate that the proposed DCT-MARL significantly outperforms state-of-the-art methods in terms of string stability and driving comfort, validating its superior robustness and effectiveness.

Paper number 83:
Title: A Novel Vascular Risk Scoring Framework for Quantifying Sex-Specific Cerebral Perfusion from 3D pCASL MRI
Authors: Sneha Noble, Neelam Sinha, Vaanathi Sundareshan, Thomas Gregor Issac
Abstract: The influence of sex and age on cerebral perfusion is recognized, but the specific impacts on regional cerebral blood flow (CBF) and vascular risk remain to be fully characterized. In this study, 3D pseudo-continuous arterial spin labeling (pCASL) MRI was used to identify sex and age related CBF patterns, and a vascular risk score (VRS) was developed based on normative perfusion profiles. Perfusion data from 186 cognitively healthy participants (89 males, 97 females; aged 8 to 92 years), obtained from a publicly available dataset, were analyzed. An extension of the 3D Simple Linear Iterative Clustering (SLIC) supervoxel algorithm was applied to CBF maps to group neighboring voxels with similar intensities into anatomically meaningful regions. Regional CBF features were extracted and used to train a convolutional neural network (CNN) for sex classification and perfusion pattern analysis. Global, age related CBF changes were also assessed. Participant specific VRS was computed by comparing individual CBF profiles to age and sex specific normative data to quantify perfusion deficits. A 95 percent accuracy in sex classification was achieved using the proposed supervoxel based method, and distinct perfusion signatures were identified. Higher CBF was observed in females in medial Brodmann areas 6 and 10, area V5, occipital polar cortex, and insular regions. A global decline in CBF with age was observed in both sexes. Individual perfusion deficits were quantified using VRS, providing a personalized biomarker for early hypoperfusion. Sex and age specific CBF patterns were identified, and a personalized vascular risk biomarker was proposed, contributing to advancements in precision neurology.

Paper number 84:
Title: Latent Interpolation Learning Using Diffusion Models for Cardiac Volume Reconstruction
Authors: Niklas Bubeck, Suprosanna Shit, Chen Chen, Can Zhao, Pengfei Guo, Dong Yang, Georg Zitzlsberger, Daguang Xu, Bernhard Kainz, Daniel Rueckert, Jiazhen Pan
Abstract: Cardiac Magnetic Resonance (CMR) imaging is a critical tool for diagnosing and managing cardiovascular disease, yet its utility is often limited by the sparse acquisition of 2D short-axis slices, resulting in incomplete volumetric information. Accurate 3D reconstruction from these sparse slices is essential for comprehensive cardiac assessment, but existing methods face challenges, including reliance on predefined interpolation schemes (e.g., linear or spherical), computational inefficiency, and dependence on additional semantic inputs such as segmentation labels or motion data. To address these limitations, we propose a novel Cardiac Latent Interpolation Diffusion (CaLID) framework that introduces three key innovations. First, we present a data-driven interpolation scheme based on diffusion models, which can capture complex, non-linear relationships between sparse slices and improves reconstruction accuracy. Second, we design a computationally efficient method that operates in the latent space and speeds up 3D whole-heart upsampling time by a factor of 24, reducing computational overhead compared to previous methods. Third, with only sparse 2D CMR images as input, our method achieves SOTA performance against baseline methods, eliminating the need for auxiliary input such as morphological guidance, thus simplifying workflows. We further extend our method to 2D+T data, enabling the effective modeling of spatiotemporal dynamics and ensuring temporal coherence. Extensive volumetric evaluations and downstream segmentation tasks demonstrate that CaLID achieves superior reconstruction quality and efficiency. By addressing the fundamental limitations of existing approaches, our framework advances the state of the art for spatio and spatiotemporal whole-heart reconstruction, offering a robust and clinically practical solution for cardiovascular imaging.

Paper number 85:
Title: A Systematic Study of Deep Learning Models and xAI Methods for Region-of-Interest Detection in MRI Scans
Authors: Justin Yiu, Kushank Arora, Daniel Steinberg, Rohit Ghiya
Abstract: Magnetic Resonance Imaging (MRI) is an essential diagnostic tool for assessing knee injuries. However, manual interpretation of MRI slices remains time-consuming and prone to inter-observer variability. This study presents a systematic evaluation of various deep learning architectures combined with explainable AI (xAI) techniques for automated region of interest (ROI) detection in knee MRI scans. We investigate both supervised and self-supervised approaches, including ResNet50, InceptionV3, Vision Transformers (ViT), and multiple U-Net variants augmented with multi-layer perceptron (MLP) classifiers. To enhance interpretability and clinical relevance, we integrate xAI methods such as Grad-CAM and Saliency Maps. Model performance is assessed using AUC for classification and PSNR/SSIM for reconstruction quality, along with qualitative ROI visualizations. Our results demonstrate that ResNet50 consistently excels in classification and ROI identification, outperforming transformer-based models under the constraints of the MRNet dataset. While hybrid U-Net + MLP approaches show potential for leveraging spatial features in reconstruction and interpretability, their classification performance remains lower. Grad-CAM consistently provided the most clinically meaningful explanations across architectures. Overall, CNN-based transfer learning emerges as the most effective approach for this dataset, while future work with larger-scale pretraining may better unlock the potential of transformer models.

Paper number 86:
Title: FPGA Design and Implementation of Fixed-Point Fast Divider Using Goldschmidt Division Algorithm and Mitchell Multiplication Algorithm
Authors: Jinkun Yang
Abstract: This paper presents a variable bit-width fixed-point fast divider using Goldschmidt division algorithm and Mitchell multiplication algorithm. Described using Verilog HDL and implemented on a Xilinx XC7Z020-2CLG400I FPGA, the proposed divider achieves over 99% computational accuracy with a minimum latency of 99.1 ns, which is 31.7 ns faster than existing single-precision dividers. Compared with a Goldschmidt divider using a Vedic multiplier, the proposed design reduces Slice Registers by 46.68%, Slice LUTs by 4.93%, and Slices by 11.85%, with less than 1% accuracy loss and only 24.1 ns additional delay. These results demonstrate an improved balance between computational speed and resource utilization, making the divider well-suited for high-performance FPGA-based systems with strict resource constraints.

Paper number 87:
Title: Assessment of Power System Stability Considering Multiple Time-Scale Dynamics: Insights into Hopf Bifurcations in Presence of GFL and GFM IBRs
Authors: Luis David Pabon Ospina
Abstract: Real power systems exhibit dynamics that evolve across a wide range of time scales, from very fast to very slow phenomena. Historically, incorporating these wide-ranging dynamics into a single model has been impractical. As a result, power engineers rely on time-scale decomposition to simplify models. When fast phenomena are evaluated, slow dynamics are neglected (assumed stable), and vice versa. This paper challenges this paradigm by showing the importance of assessing power system stability while considering multiple time scales simultaneously. Using the concept of Hopf bifurcations, it exemplifies instability issues that would be missed if multi-time-scale dynamics are not considered. Although this work employs both grid-following and grid-forming inverter-based resource models, it is not a direct comparison. Instead, it presents a case study demonstrating how one technology can complement the other from a multi time-scale dynamics perspective.

Paper number 88:
Title: Recursive Gaussian Process Regression with Integrated Monotonicity Assumptions for Control Applications
Authors: Ricus Husmann, Sven Weishaupt, Harald Aschemann
Abstract: In this paper, we present an extension to the recursive Gaussian Process (RGP) regression that enables the satisfaction of inequality constraints and is well suited for a real-time execution in control applications. The soft inequality constraints are integrated by introducing an additional extended Kalman Filter (EKF) update step using pseudo-measurements. The sequential formulation of the algorithm and several developed heuristics ensure both the performance and a low computational effort of the algorithm. A special focus lies on an efficient consideration of monotonicity assumptions for GPs in the form of inequality constraints. The algorithm is statistically validated in simulations, where the possible advantages in comparison with the standard RGP algorithm become obvious. The paper is concluded with a successful experimental validation of the developed algorithm for the monotonicity-preserving learning of heat transfer values for the control of a vapor compression cycle evaporator, leveraging a previously published partial input output linearization (IOL).

Paper number 89:
Title: CREMA: A Contrastive Regularized Masked Autoencoder for Robust ECG Diagnostics across Clinical Domains
Authors: Junho Song, Jong-Hwan Jang, DongGyun Hong, Joon-myoung Kwon, Yong-Yeon Jo
Abstract: Electrocardiogram (ECG) diagnosis remains challenging due to limited labeled data and the need to capture subtle yet clinically meaningful variations in rhythm and morphology. We present CREMA (Contrastive Regularized Masked Autoencoder), a foundation model for 12-lead ECGs designed to learn generalizable representations through self-supervised pretraining. CREMA combines generative learning and contrastive regularization via a Contrastive Regularized MAE loss, and employs a Signal Transformer (SiT) architecture to capture both local waveform details and global temporal dependencies. We evaluate CREMA on benchmark datasets and real-world clinical environments, including deployment scenarios with significant distribution shifts. CREMA outperforms supervised baselines and existing self-supervised models in both linear probing and fine-tuning evaluations. Notably, it maintains superior performance across diverse clinical domains, such as emergency care, highlighting its robustness under real-world conditions. These results demonstrate that CREMA serves as a scalable and reliable foundation model for ECG diagnostics, supporting downstream applications across heterogeneous and high-risk clinical settings.

Paper number 90:
Title: Polytope Volume Monitoring Problem: Formulation and Solution via Parametric Linear Program Based Control Barrier Function
Authors: Shizhen Wu, Jinyang Dong, Xu Fang, Ning Sun, Yongchun Fang
Abstract: Motivated by the latest research on feasible space monitoring of multiple control barrier functions (CBFs) as well as polytopic collision avoidance, this paper studies the Polytope Volume Monitoring (PVM) problem, whose goal is to design a control law for inputs of nonlinear systems to prevent the volume of some state-dependent polytope from decreasing to zero. Recent studies have explored the idea of applying Chebyshev ball method in optimization theory to solve the case study of PVM; however, the underlying difficulties caused by nonsmoothness have not been addressed. This paper continues the study on this topic, where our main contribution is to establish the relationship between nonsmooth CBF and parametric optimization theory through directional derivatives for the first time, to solve PVM problems more conveniently. In detail, inspired by Chebyshev ball approach, a parametric linear program (PLP) based nonsmooth barrier function candidate is established for PVM, and then, sufficient conditions for it to be a nonsmooth CBF are proposed, based on which a quadratic program (QP) based safety filter with guaranteed feasibility is proposed to address PVM problems. Finally, a numerical simulation example is given to show the efficiency of the proposed safety filter.

Paper number 91:
Title: Online Convex Optimization and Integral Quadratic Constraints: An automated approach to regret analysis
Authors: Fabian Jakob, Andrea Iannelli
Abstract: We propose a novel approach for analyzing dynamic regret of first-order constrained online convex optimization algorithms for strongly convex and Lipschitz-smooth objectives. Crucially, we provide a general analysis that is applicable to a wide range of first-order algorithms that can be expressed as an interconnection of a linear dynamical system in feedback with a first-order oracle. By leveraging Integral Quadratic Constraints (IQCs), we derive a semi-definite program which, when feasible, provides a regret guarantee for the online algorithm. For this, the concept of variational IQCs is introduced as the generalization of IQCs to time-varying monotone operators. Our bounds capture the temporal rate of change of the problem in the form of the path length of the time-varying minimizer and the objective function variation. In contrast to standard results in OCO, our results do not require nerither the assumption of gradient boundedness, nor that of a bounded feasible set. Numerical analyses showcase the ability of the approach to capture the dependence of the regret on the function class condition number.

Paper number 92:
Title: Linear time-and-space-invariant relaxation systems
Authors: Tihol Ivanov Donchev, Brayan M. Shali, Rodolphe Sepulchre
Abstract: This paper generalizes the physical property of relaxation from linear time-invariant (LTI) to linear time-and-space-invariant (LTSI) systems. It is shown that the defining features of relaxation -- complete monotonicity, passivity, and memory-based storage -- carry over seamlessly to the spatio-temporal domain. An LTSI system is shown to be of relaxation type if and only if its associated spatio-temporal Hankel operator is cyclically monotone. This implies the existence of an intrinsic quadratic storage functional defined uniquely by past inputs, independently of any state-space realization. As in the LTI case, LTSI relaxation systems are shown to be those systems for which the state-space concept of storage coincides with the input-output concept of fading memory functional.

Paper number 93:
Title: Realizing Fully-Connected Layers Over the Air via Reconfigurable Intelligent Surfaces
Authors: Meng Hua, Chenghong Bian, Haotian Wu, Deniz Gündüz
Abstract: By leveraging the waveform superposition property of the multiple access channel, over-the-air computation (AirComp) enables the execution of digital computations through analog means in the wireless domain, leading to faster processing and reduced latency. In this paper, we propose a novel approach to implement a neural network (NN) consisting of digital fully connected (FC) layers using physically reconfigurable hardware. Specifically, we investigate reconfigurable intelligent surfaces (RISs)-assisted multiple-input multiple-output (MIMO) systems to emulate the functionality of a NN for over-the-air inference. In this setup, both the RIS and the transceiver are jointly configured to manipulate the ambient wireless propagation environment, effectively reproducing the adjustable weights of a digital FC layer. We refer to this new computational paradigm as \textit{AirFC}. We formulate an imitation error minimization problem between the effective channel created by RIS and a target FC layer by jointly optimizing over-the-air parameters. To solve this non-convex optimization problem, an extremely low-complexity alternating optimization algorithm is proposed, where semi-closed-form/closed-form solutions for all optimization variables are derived. Simulation results show that the RIS-assisted MIMO-based AirFC can achieve competitive classification accuracy. Furthermore, it is also shown that a multi-RIS configuration significantly outperforms a single-RIS setup, particularly in line-of-sight (LoS)-dominated channels.

Paper number 94:
Title: Machine Learning Approaches to Vocal Register Classification in Contemporary Male Pop Music
Authors: Alexander Kim, Charlotte Botha
Abstract: For singers of all experience levels, one of the most daunting challenges in learning technical repertoire is navigating placement and vocal register in and around the passagio (passage between chest voice and head voice registers). Particularly in pop music, where a single artist may use a variety of timbre's and textures to achieve a desired quality, it can be difficult to identify what vocal register within the vocal range a singer is using. This paper presents two methods for classifying vocal registers in an audio signal of male pop music through the analysis of textural features of mel-spectrogram images. Additionally, we will discuss the practical integration of these models for vocal analysis tools, and introduce a concurrently developed software called AVRA which stands for Automatic Vocal Register Analysis. Our proposed methods achieved consistent classification of vocal register through both Support Vector Machine (SVM) and Convolutional Neural Network (CNN) models, which supports the promise of more robust classification possibilities across more voice types and genres of singing.

Paper number 95:
Title: Fine-Tuning ASR for Stuttered Speech: Personalized vs. Generalized Approaches
Authors: Dena Mujtaba, Nihar Mahapatra
Abstract: Stuttering -- characterized by involuntary disfluencies such as blocks, prolongations, and repetitions -- is often misinterpreted by automatic speech recognition (ASR) systems, resulting in elevated word error rates and making voice-driven technologies inaccessible to people who stutter. The variability of disfluencies across speakers and contexts further complicates ASR training, compounded by limited annotated stuttered speech data. In this paper, we investigate fine-tuning ASRs for stuttered speech, comparing generalized models (trained across multiple speakers) to personalized models tailored to individual speech characteristics. Using a diverse range of voice-AI scenarios, including virtual assistants and video interviews, we evaluate how personalization affects transcription accuracy. Our findings show that personalized ASRs significantly reduce word error rates, especially in spontaneous speech, highlighting the potential of tailored models for more inclusive voice technologies.

Paper number 96:
Title: Deep regularization networks for inverse problems with noisy operators
Authors: Fatemeh Pourahmadian, Yang Xu
Abstract: A supervised learning approach is proposed for regularization of large inverse problems where the main operator is built from noisy data. This is germane to superresolution imaging via the sampling indicators of the inverse scattering theory. We aim to accelerate the spatiotemporal regularization process for this class of inverse problems to enable real-time imaging. In this approach, a neural operator maps each pattern on the right-hand side of the scattering equation to its affiliated regularization parameter. The network is trained in two steps which entails: (1) training on low-resolution regularization maps furnished by the Morozov discrepancy principle with nonoptimal thresholds, and (2) optimizing network predictions through minimization of the Tikhonov loss function regulated by the validation loss. Step 2 allows for tailoring of the approximate maps of Step 1 toward construction of higher quality images. This approach enables direct learning from test data and dispenses with the need for a-priori knowledge of the optimal regularization maps. The network, trained on low-resolution data, quickly generates dense regularization maps for high-resolution imaging. We highlight the importance of the training loss function on the network's generalizability. In particular, we demonstrate that networks informed by the logic of discrepancy principle lead to images of higher contrast. In this case, the training process involves many-objective optimization. We propose a new method to adaptively select the appropriate loss weights during training without requiring an additional optimization process. The proposed approach is synthetically examined for imaging damage evolution in an elastic plate. The results indicate that the discrepancy-informed regularization networks not only accelerate the imaging process, but also remarkably enhance the image quality in complex environments.

Paper number 97:
Title: A Survey of Foundation Models for IoT: Taxonomy and Criteria-Based Analysis
Authors: Hui Wei, Dong Yoon Lee, Shubham Rohal, Zhizhang Hu, Ryan Rossi, Shiwei Fang, Shijia Pan
Abstract: Foundation models have gained growing interest in the IoT domain due to their reduced reliance on labeled data and strong generalizability across tasks, which address key limitations of traditional machine learning approaches. However, most existing foundation model based methods are developed for specific IoT tasks, making it difficult to compare approaches across IoT domains and limiting guidance for applying them to new tasks. This survey aims to bridge this gap by providing a comprehensive overview of current methodologies and organizing them around four shared performance objectives by different domains: efficiency, context-awareness, safety, and security & privacy. For each objective, we review representative works, summarize commonly-used techniques and evaluation metrics. This objective-centric organization enables meaningful cross-domain comparisons and offers practical insights for selecting and designing foundation model based solutions for new IoT tasks. We conclude with key directions for future research to guide both practitioners and researchers in advancing the use of foundation models in IoT applications.

Paper number 98:
Title: A MILP-Based Solution to Multi-Agent Motion Planning and Collision Avoidance in Constrained Environments
Authors: Akshay Jaitly, Jack Cline, Siavash Farzan
Abstract: We propose a mixed-integer linear program (MILP) for multi-agent motion planning that embeds Polytopic Action-based Motion Planning (PAAMP) into a sequence-then-solve pipeline. Region sequences confine each agent to adjacent convex polytopes, while a big-M hyperplane model enforces inter-agent separation. Collision constraints are applied only to agents sharing or neighboring a region, which reduces binary variables exponentially compared with naive formulations. An L1 path-length-plus-acceleration cost yields smooth trajectories. We prove finite-time convergence and demonstrate on representative multi-agent scenarios with obstacles that our formulation produces collision-free trajectories an order of magnitude faster than an unstructured MILP baseline.

Paper number 99:
Title: Capturing Stable HDR Videos Using a Dual-Camera System
Authors: Qianyu Zhang, Bolun Zheng, Lingyu Zhu, Hangjia Pan, Zunjie Zhu, Zongpeng Li, Shiqi Wang
Abstract: High Dynamic Range (HDR) video acquisition using the alternating exposure (AE) paradigm has garnered significant attention due to its cost-effectiveness with a single consumer camera. However, despite progress driven by deep neural networks, these methods remain prone to temporal flicker in real-world applications due to inter-frame exposure inconsistencies. To address this challenge while maintaining the cost-effectiveness of the AE paradigm, we propose a novel learning-based HDR video generation solution. Specifically, we propose a dual-stream HDR video generation paradigm that decouples temporal luminance anchoring from exposure-variant detail reconstruction, overcoming the inherent limitations of the AE paradigm. To support this, we design an asynchronous dual-camera system (DCS), which enables independent exposure control across two cameras, eliminating the need for synchronization typically required in traditional multi-camera setups. Furthermore, an exposure-adaptive fusion network (EAFNet) is formulated for the DCS system. EAFNet integrates a pre-alignment subnetwork that aligns features across varying exposures, ensuring robust feature extraction for subsequent fusion, an asymmetric cross-feature fusion subnetwork that emphasizes reference-based attention to effectively merge these features across exposures, and a reconstruction subnetwork to mitigate ghosting artifacts and preserve fine details. Extensive experimental evaluations demonstrate that the proposed method achieves state-of-the-art performance across various datasets, showing the remarkable potential of our solution in HDR video reconstruction. The codes and data captured by DCS will be available at this https URL.

Paper number 100:
Title: DIFFA: Large Language Diffusion Models Can Listen and Understand
Authors: Jiaming Zhou, Hongjie Chen, Shiwan Zhao, Jian Kang, Jie Li, Enzhi Wang, Yujie Guo, Haoqin Sun, Hui Wang, Aobo Kong, Yong Qin, Xuelong Li
Abstract: Recent advances in large language models (LLMs) have shown remarkable capabilities across textual and multimodal domains. In parallel, diffusion-based language models have emerged as a promising alternative to the autoregressive paradigm, offering improved controllability, bidirectional context modeling, and robust generation. However, their application to the audio modality remains underexplored. In this work, we introduce \textbf{DIFFA}, the first diffusion-based large audio-language model designed to perform spoken language understanding. DIFFA integrates a frozen diffusion language model with a lightweight dual-adapter architecture that bridges speech understanding and natural language reasoning. We employ a two-stage training pipeline: first, aligning semantic representations via an ASR objective; then, learning instruction-following abilities through synthetic audio-caption pairs automatically generated by prompting LLMs. Despite being trained on only 960 hours of ASR and 127 hours of synthetic instruction data, DIFFA demonstrates competitive performance on major benchmarks, including MMSU, MMAU, and VoiceBench, outperforming several autoregressive open-source baselines. Our results reveal the potential of diffusion-based language models for efficient and scalable audio understanding, opening a new direction for speech-driven AI. Our code will be available at this https URL.

Paper number 101:
Title: Prescriptive Agents based on RAG for Automated Maintenance (PARAM)
Authors: Chitranshu Harbola, Anupam Purwar
Abstract: Industrial machinery maintenance requires timely intervention to prevent catastrophic failures and optimize operational efficiency. This paper presents an integrated Large Language Model (LLM)-based intelligent system for prescriptive maintenance that extends beyond traditional anomaly detection to provide actionable maintenance recommendations. Building upon our prior LAMP framework for numerical data analysis, we develop a comprehensive solution that combines bearing vibration frequency analysis with multi agentic generation for intelligent maintenance planning. Our approach serializes bearing vibration data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM processing, enabling few-shot anomaly detection with high accuracy. The system classifies fault types (inner race, outer race, ball/roller, cage faults) and assesses severity levels. A multi-agentic component processes maintenance manuals using vector embeddings and semantic search, while also conducting web searches to retrieve comprehensive procedural knowledge and access up-to-date maintenance practices for more accurate and in-depth recommendations. The Gemini model then generates structured maintenance recommendations includes immediate actions, inspection checklists, corrective measures, parts requirements, and timeline specifications. Experimental validation in bearing vibration datasets demonstrates effective anomaly detection and contextually relevant maintenance guidance. The system successfully bridges the gap between condition monitoring and actionable maintenance planning, providing industrial practitioners with intelligent decision support. This work advances the application of LLMs in industrial maintenance, offering a scalable framework for prescriptive maintenance across machinery components and industrial sectors.

Paper number 102:
Title: A "good regulator theorem" for embodied agents
Authors: Nathaniel Virgo, Martin Biehl, Manuel Baltieri, Matteo Capucci
Abstract: In a classic paper, Conant and Ashby claimed that "every good regulator of a system must be a model of that system." Artificial Life has produced many examples of systems that perform tasks with apparently no model in sight; these suggest Conant and Ashby's theorem doesn't easily generalise beyond its restricted setup. Nevertheless, here we show that a similar intuition can be fleshed out in a different way: whenever an agent is able to perform a regulation task, it is possible for an observer to interpret it as having "beliefs" about its environment, which it "updates" in response to sensory input. This notion of belief updating provides a notion of model that is more sophisticated than Conant and Ashby's, as well as a theorem that is more broadly applicable. However, it necessitates a change in perspective, in that the observer plays an essential role in the theory: models are not a mere property of the system but are imposed on it from outside. Our theorem holds regardless of whether the system is regulating its environment in a classic control theory setup, or whether it's regulating its own internal state; the model is of its environment either way. The model might be trivial, however, and this is how the apparent counterexamples are resolved.
    