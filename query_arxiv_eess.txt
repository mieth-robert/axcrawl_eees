
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: An Overview of the JPEG AI Learning-Based Image Coding Standard
Authors: Semih Esenlik, Yaojun Wu, Zhaobin Zhang, Ye-Kui Wang, Kai Zhang, Li Zhang, João Ascenso, Shan Liu
Abstract: JPEG AI is an emerging learning-based image coding standard developed by Joint Photographic Experts Group (JPEG). The scope of the JPEG AI is the creation of a practical learning-based image coding standard offering a single-stream, compact compressed domain representation, targeting both human visualization and machine consumption. Scheduled for completion in early 2025, the first version of JPEG AI focuses on human vision tasks, demonstrating significant BD-rate reductions compared to existing standards, in terms of MS-SSIM, FSIM, VIF, VMAF, PSNR-HVS, IW-SSIM and NLPD quality metrics. Designed to ensure broad interoperability, JPEG AI incorporates various design features to support deployment across diverse devices and applications. This paper provides an overview of the technical features and characteristics of the JPEG AI standard.

Paper number 2:
Title: Incomplete Multi-view Clustering via Hierarchical Semantic Alignment and Cooperative Completion
Authors: Xiaojian Ding, Lin Zhao, Xian Li, Xiaoying Zhu
Abstract: Incomplete multi-view data, where certain views are entirely missing for some samples, poses significant challenges for traditional multi-view clustering methods. Existing deep incomplete multi-view clustering approaches often rely on static fusion strategies or two-stage pipelines, leading to suboptimal fusion results and error propagation issues. To address these limitations, this paper proposes a novel incomplete multi-view clustering framework based on Hierarchical Semantic Alignment and Cooperative Completion (HSACC). HSACC achieves robust cross-view fusion through a dual-level semantic space design. In the low-level semantic space, consistency alignment is ensured by maximizing mutual information across views. In the high-level semantic space, adaptive view weights are dynamically assigned based on the distributional affinity between individual views and an initial fused representation, followed by weighted fusion to generate a unified global representation. Additionally, HSACC implicitly recovers missing views by projecting aligned latent representations into high-dimensional semantic spaces and jointly optimizes reconstruction and clustering objectives, enabling cooperative learning of completion and clustering. Experimental results demonstrate that HSACC significantly outperforms state-of-the-art methods on five benchmark datasets. Ablation studies validate the effectiveness of the hierarchical alignment and dynamic weighting mechanisms, while parameter analysis confirms the model's robustness to hyperparameter variations.

Paper number 3:
Title: Millimeter Wave Inverse Pinhole Imaging
Authors: Akarsh Prabhakara, Yawen Liu, Aswin C. Sankaranarayanan, Anthony Rowe, Swarun Kumar
Abstract: Millimeter wave (mmWave) radars are popular for perception in vision-denied contexts due to their compact size. This paper explores emerging use-cases that involve static mount or momentarily-static compact radars, for example, a hovering drone. The key challenge with static compact radars is that their limited form-factor also limits their angular resolution. This paper presents Umbra, a mmWave high resolution imaging system, that introduces the concept of rotating mmWave "inverse pinholes" for angular resolution enhancement. We present the imaging system model, design, and evaluation of mmWave inverse pinholes. The inverse pinhole is attractive for its lightweight nature, which enables low-power rotation, upgrading static-mount radars. We also show how propellers in aerial vehicles act as natural inverse pinholes and can enjoy the benefits of high-resolution imaging even while they are momentarily static, e.g., hovering. Our evaluation shows Umbra resolving up to 2.5$^{\circ}$ with just a single antenna, a 5$\times$ improvement compared to 14$^{\circ}$ from a compact mmWave radar baseline.

Paper number 4:
Title: Switchboard-Affect: Emotion Perception Labels from Conversational Speech
Authors: Amrit Romana, Jaya Narain, Tien Dung Tran, Andrea Davis, Jason Fong, Ramya Rasipuram, Vikramjit Mitra
Abstract: Understanding the nuances of speech emotion dataset curation and labeling is essential for assessing speech emotion recognition (SER) model potential in real-world applications. Most training and evaluation datasets contain acted or pseudo-acted speech (e.g., podcast speech) in which emotion expressions may be exaggerated or otherwise intentionally modified. Furthermore, datasets labeled based on crowd perception often lack transparency regarding the guidelines given to annotators. These factors make it difficult to understand model performance and pinpoint necessary areas for improvement. To address this gap, we identified the Switchboard corpus as a promising source of naturalistic conversational speech, and we trained a crowd to label the dataset for categorical emotions (anger, contempt, disgust, fear, sadness, surprise, happiness, tenderness, calmness, and neutral) and dimensional attributes (activation, valence, and dominance). We refer to this label set as Switchboard-Affect (SWB-Affect). In this work, we present our approach in detail, including the definitions provided to annotators and an analysis of the lexical and paralinguistic cues that may have played a role in their perception. In addition, we evaluate state-of-the-art SER models, and we find variable performance across the emotion categories with especially poor generalization for anger. These findings underscore the importance of evaluation with datasets that capture natural affective variations in speech. We release the labels for SWB-Affect to enable further analysis in this domain.

Paper number 5:
Title: Image-based Facial Rig Inversion
Authors: Tianxiang Yang, Marco Volino, Armin Mustafa, Greg Maguire, Robert Kosk
Abstract: We present an image-based rig inversion framework that leverages two modalities: RGB appearance and RGB-encoded normal maps. Each modality is processed by an independent Hiera transformer backbone, and the extracted features are fused to regress 102 rig parameters derived from the Facial Action Coding System (FACS). Experiments on synthetic and scanned datasets demonstrate that the method generalizes to scanned data, producing faithful reconstructions.

Paper number 6:
Title: Cyber-Resilient System Identification for Power Grid through Bayesian Integration
Authors: Shimiao Li, Guannan Qu, Bryan Hooi, Vyas Sekar, Soummya Kar, Larry Pileggi
Abstract: Power grids increasingly need real-time situational awareness under the ever-evolving cyberthreat landscape. Advances in snapshot-based system identification approaches have enabled accurately estimating states and topology from a snapshot of measurement data, under random bad data and topology errors. However, modern interactive, targeted false data can stay undetectable to these methods, and significantly compromise estimation accuracy. This work advances system identification that combines snapshot-based method with time-series model via Bayesian Integration, to advance cyber resiliency against both random and targeted false data. Using a distance-based time-series model, this work can leverage historical data of different distributions induced by changes in grid topology and other settings. The normal system behavior captured from historical data is integrated into system identification through a Bayesian treatment, to make solutions robust to targeted false data. We experiment on mixed random anomalies (bad data, topology error) and targeted false data injection attack (FDIA) to demonstrate our method's 1) cyber resilience: achieving over 70% reduction in estimation error under FDIA; 2) anomalous data identification: being able to alarm and locate anomalous data; 3) almost linear scalability: achieving comparable speed with the snapshot-based baseline, both taking <1min per time tick on the large 2,383-bus system using a laptop CPU.

Paper number 7:
Title: Multi-Period Sparse Optimization for Proactive Grid Blackout Diagnosis
Authors: Qinghua Ma, Reetam Sen Biswas, Denis Osipov, Guannan Qu, Soummya Kar, Shimiao Li
Abstract: Existing or planned power grids need to evaluate survivability under extreme events, like a number of peak load overloading conditions, which could possibly cause system collapses (i.e. blackouts). For realistic extreme events that are correlated or share similar patterns, it is reasonable to expect that the dominant vulnerability or failure sources behind them share the same locations but with different severity. Early warning diagnosis that proactively identifies the key vulnerabilities responsible for a number of system collapses of interest can significantly enhance resilience. This paper proposes a multi-period sparse optimization method, enabling the discovery of {persistent failure sources} across a sequence of collapsed systems with increasing system stress, such as rising demand or worsening contingencies. This work defines persistency and efficiently integrates persistency constraints to capture the ``hidden'' evolving vulnerabilities. Circuit-theory based power flow formulations and circuit-inspired optimization heuristics are used to facilitate the scalability of the method. Experiments on benchmark systems show that the method reliably tracks persistent vulnerability locations under increasing load stress, and solves with scalability to large systems ({on average} taking {around} 200 s per scenario on 2000+ bus systems).

Paper number 8:
Title: Dual Detection Framework for Faults and Integrity Attacks in Cyber-Physical Control Systems
Authors: Xixing Xue, Dong Shen, Steven X. Ding, Dong Zhao
Abstract: Anomaly detection plays a vital role in the security and safety of cyber-physical control systems, and accurately distinguishing between different anomaly types is crucial for system recovery and mitigation. This study proposes a dual detection framework for anomaly detection and discrimination. By leveraging the dynamic characteristics of control loops and the stealthiness features of integrity attacks, the closed-loop stealthiness condition is first derived, and two dedicated detectors are designed and deployed on the controller side and the plant side, respectively, enabling joint plant fault and cyber attack detection. Moreover, by jointly analyzing the residual response of the two detectors corresponding to different anomalies, it is proved that the proposed method can distinguish between faults and integrity attacks due to the detectors' individual residual spaces. According to the detector's residual space, the fault and attack detection performance is further improved by a two-stage optimization scheme. Simulation results validate the effectiveness of the proposed approach.

Paper number 9:
Title: DiffOPF: Diffusion Solver for Optimal Power Flow
Authors: Milad Hoseinpour, Vladimir Dvorkin
Abstract: The optimal power flow (OPF) is a multi-valued, non-convex mapping from loads to dispatch setpoints. The variability of system parameters (e.g., admittances, topology) further contributes to the multiplicity of dispatch setpoints for a given load. Existing deep learning OPF solvers are single-valued and thus fail to capture the variability of system parameters unless fully represented in the feature space, which is prohibitive. To solve this problem, we introduce a diffusion-based OPF solver, termed \textit{DiffOPF}, that treats OPF as a conditional sampling problem. The solver learns the joint distribution of loads and dispatch setpoints from operational history, and returns the marginal dispatch distributions conditioned on loads. Unlike single-valued solvers, DiffOPF enables sampling statistically credible warm starts with favorable cost and constraint satisfaction trade-offs. We explore the sample complexity of DiffOPF to ensure the OPF solution within a prescribed distance from the optimization-based solution, and verify this experimentally on power system benchmarks.

Paper number 10:
Title: Belief Space Control of Safety-Critical Systems Under State-Dependent Measurement Noise
Authors: Rohan Walia, Mitchell Black, Andrew Schoer, Kevin Leahy
Abstract: Safety-critical control is imperative for deploying autonomous systems in the real world. Control Barrier Functions (CBFs) offer strong safety guarantees when accurate system and sensor models are available. However, widely used additive, fixed-noise models are not representative of complex sensor modalities with state-dependent error characteristics. Although CBFs have been designed to mitigate uncertainty using fixed worst-case bounds on measurement noise, this approach can lead to overly-conservative control. To solve this problem, we extend the Belief Control Barrier Function (BCBF) framework to accommodate state-dependent measurement noise via the Generalized Extended Kalman Filter (GEKF) algorithm, which models measurement noise as a linear function of the state. Using the original BCBF framework as baseline, we demonstrate the performance of the BCBF-GEKF approach through simulation results on a 1D single integrator setpoint tracking scenario and 2D unicycle kinematics trajectory tracking scenario. Our results confirm that the BCBF-GEKF approach offers less conservative control with greater safety.

Paper number 11:
Title: Resource-Aware Stealthy Attacks in Vehicle Platoons
Authors: Ali Eslami, Mohammad Pirani
Abstract: Connected and Autonomous Vehicles (CAVs) are transforming modern transportation by enabling cooperative applications such as vehicle platooning, where multiple vehicles travel in close formation to improve efficiency and safety. However, the heavy reliance on inter-vehicle communication makes platoons highly susceptible to attacks, where even subtle manipulations can escalate into severe physical consequences. While existing research has largely focused on defending against attacks, far less attention has been given to stealthy adversaries that aim to covertly manipulate platoon behavior. This paper introduces a new perspective on the attack design problem by demonstrating how attackers can guide platoons toward their own desired trajectories while remaining undetected. We outline conditions under which such attacks are feasible, analyze their dependence on communication topologies and control protocols, and investigate the resources required by the attacker. By characterizing the resources needed to launch stealthy attacks, we address system vulnerabilities and informing the design of resilient countermeasures. Our findings reveal critical weaknesses in current platoon architectures and anomaly detection mechanisms and provide methods to develop more secure and trustworthy CAV systems.

Paper number 12:
Title: Generalized Pinching-Antenna Systems: A Tutorial on Principles, Design Strategies, and Future Directions
Authors: Yanqing Xu, Jingjing Cui, Yongxu Zhu, Zhiguo Ding, Tsung-Hui Chang, Robert Schober, Vincent W.S. Wong, Octavia A. Dobre, George K. Karagiannidis, H. Vincent Poor, Xiaohu You
Abstract: Pinching-antenna systems have emerged as a novel and transformative flexible-antenna architecture for next-generation wireless networks. They offer unprecedented flexibility and spatial reconfigurability by enabling dynamic positioning and activation of radiating elements along a signal-guiding medium (e.g., dielectric waveguides), which is not possible with conventional fixed antenna systems. In this paper, we introduce the concept of generalized pinching antenna systems, which retain the core principle of creating localized radiation points on demand, but can be physically realized in a variety of settings. These include implementations based on dielectric waveguides, leaky coaxial cables, surface-wave guiding structures, and other types of media, employing different feeding methods and activation mechanisms (e.g., mechanical, electronic, or hybrid). Despite differences in their physical realizations, they all share the same inherent ability to form, reposition, or deactivate radiation sites as needed, enabling user-centric and dynamic coverage. We first describe the underlying physical mechanisms of representative generalized pinching-antenna realizations and their associated wireless channel models, highlighting their unique propagation and reconfigurability characteristics compared with conventional antennas. Then, we review several representative pinching-antenna system architectures, ranging from single- to multiple-waveguide configurations, and discuss advanced design strategies tailored to these flexible deployments. Furthermore, we examine their integration with emerging wireless technologies to enable synergistic, user-centric solutions. Finally, we identify key open research challenges and outline future directions, charting a pathway toward the practical deployment of generalized pinching antennas in next-generation wireless networks.

Paper number 13:
Title: Reinforcement Learning for Unsupervised Domain Adaptation in Spatio-Temporal Echocardiography Segmentation
Authors: Arnaud Judge, Nicolas Duchateau, Thierry Judge, Roman A. Sandler, Joseph Z. Sokol, Christian Desrosiers, Olivier Bernard, Pierre-Marc Jodoin
Abstract: Domain adaptation methods aim to bridge the gap between datasets by enabling knowledge transfer across domains, reducing the need for additional expert annotations. However, many approaches struggle with reliability in the target domain, an issue particularly critical in medical image segmentation, where accuracy and anatomical validity are essential. This challenge is further exacerbated in spatio-temporal data, where the lack of temporal consistency can significantly degrade segmentation quality, and particularly in echocardiography, where the presence of artifacts and noise can further hinder segmentation performance. To address these issues, we present RL4Seg3D, an unsupervised domain adaptation framework for 2D + time echocardiography segmentation. RL4Seg3D integrates novel reward functions and a fusion scheme to enhance key landmark precision in its segmentations while processing full-sized input videos. By leveraging reinforcement learning for image segmentation, our approach improves accuracy, anatomical validity, and temporal consistency while also providing, as a beneficial side effect, a robust uncertainty estimator, which can be used at test time to further enhance segmentation performance. We demonstrate the effectiveness of our framework on over 30,000 echocardiographic videos, showing that it outperforms standard domain adaptation techniques without the need for any labels on the target domain. Code is available at this https URL.

Paper number 14:
Title: Integrated Massive Communication and Target Localization in 6G Cell-Free Networks
Authors: Junyuan Gao, Weifeng Zhu, Shuowen Zhang, Yongpeng Wu, Jiannong Cao, Giuseppe Caire, Liang Liu
Abstract: This paper presents an initial investigation into the combination of integrated sensing and communication (ISAC) and massive communication, both of which are largely regarded as key scenarios in sixth-generation (6G) wireless networks. Specifically, we consider a cell-free network comprising a large number of users, multiple targets, and distributed base stations (BSs). In each time slot, a random subset of users becomes active, transmitting pilot signals that can be scattered by the targets before reaching the BSs. Unlike conventional massive random access schemes, where the primary objectives are device activity detection and channel estimation, our framework also enables target localization by leveraging the multipath propagation effects introduced by the targets. However, due to the intricate dependency between user channels and target locations, characterizing the posterior distribution required for minimum mean-square error (MMSE) estimation presents significant computational challenges. To handle this problem, we propose a hybrid message passing-based framework that incorporates multiple approximations to mitigate computational complexity. Numerical results demonstrate that the proposed approach achieves high-accuracy device activity detection, channel estimation, and target localization simultaneously, validating the feasibility of embedding localization functionality into massive communication systems for future 6G networks.

Paper number 15:
Title: A Density-Informed Multimodal Artificial Intelligence Framework for Improving Breast Cancer Detection Across All Breast Densities
Authors: Siva Teja Kakileti, Bharath Govindaraju, Sudhakar Sampangi, Geetha Manjunath
Abstract: Mammography, the current standard for breast cancer screening, has reduced sensitivity in women with dense breast tissue, contributing to missed or delayed diagnoses. Thermalytix, an AI-based thermal imaging modality, captures functional vascular and metabolic cues that may complement mammographic structural data. This study investigates whether a breast density-informed multi-modal AI framework can improve cancer detection by dynamically selecting the appropriate imaging modality based on breast tissue composition. A total of 324 women underwent both mammography and thermal imaging. Mammography images were analyzed using a multi-view deep learning model, while Thermalytix assessed thermal images through vascular and thermal radiomics. The proposed framework utilized Mammography AI for fatty breasts and Thermalytix AI for dense breasts, optimizing predictions based on tissue type. This multi-modal AI framework achieved a sensitivity of 94.55% (95% CI: 88.54-100) and specificity of 79.93% (95% CI: 75.14-84.71), outperforming standalone mammography AI (sensitivity 81.82%, specificity 86.25%) and Thermalytix AI (sensitivity 92.73%, specificity 75.46%). Importantly, the sensitivity of Mammography dropped significantly in dense breasts (67.86%) versus fatty breasts (96.30%), whereas Thermalytix AI maintained high and consistent sensitivity in both (92.59% and 92.86%, respectively). This demonstrates that a density-informed multi-modal AI framework can overcome key limitations of unimodal screening and deliver high performance across diverse breast compositions. The proposed framework is interpretable, low-cost, and easily deployable, offering a practical path to improving breast cancer screening outcomes in both high-resource and resource-limited settings.

Paper number 16:
Title: Integrated Sensing and Communication: Towards Multifunctional Perceptive Network
Authors: Yuanhao Cui, Jiali Nie, Fan Liu, Weijie Yuan, Zhiyong Feng, Xiaojun Jing, Yulin Liu, Jie Xu, Christos Masouros, Shuguang Cui
Abstract: The capacity-maximization design philosophy has driven the growth of wireless networks for decades. However, with the slowdown in recent data traffic demand, the mobile industry can no longer rely solely on communication services to sustain development. In response, Integrated Sensing and Communications (ISAC) has emerged as a transformative solution, embedding sensing capabilities into communication networks to enable multifunctional wireless systems. This paradigm shift expands the role of networks from sole data transmission to versatile platforms supporting diverse applications. In this review, we provide a bird's-eye view of ISAC for new researchers, highlighting key challenges, opportunities, and application scenarios to guide future exploration in this field.

Paper number 17:
Title: Error Rate Analysis and Low-Complexity Receiver Design for Zero-Padded AFDM
Authors: Qin Yi, Zeping Sui, Zilong Liu
Abstract: This paper studies the error rate performance and low-complexity receiver design for zero-padded affine frequency division multiplexing (ZP-AFDM) systems. By exploiting the unique ZP-aided lower triangular structure of the time domain (TD) channel matrix, we propose {a novel low-complexity} minimum mean square error (MMSE) detector and {a} maximum ratio combining-based TD (MRC-TD) detector. Furthermore, the theoretical bit error rate (BER) {performance} of both MMSE and maximum likelihood detectors {is} analyzed. Simulation results demonstrate {that} the proposed detectors can achieve identical BER performance to that of {the conventional MMSE detector based on matrix inversion} while {enjoying significantly reduced complexity.}

Paper number 18:
Title: Integrated Sensing and Communication with Tri-Hybrid Beamforming Across Electromagnetically Reconfigurable Antennas
Authors: Jiangong Chen, Xia Lei, Yuchen Zhang, Kaitao Meng, Christos Masouros
Abstract: Beamforming with a sufficient number of antennas is one of the most significant technologies for both Multi-user (MU) Multiple-input Multiple-output (MIMO) communication and MIMO radar sensing in Integrated Sensing and Communication (ISAC) systems. However, its performance suffers from limited Degrees of Freedom (DoFs) in conventional hybrid beamforming systems. To overcome this, we propose an Electromagnetically Reconfigurable Antenna (ERA)-aided ISAC system, where transmit ERAs dynamically adjust their radiation patterns to enhance system DoFs and improve overall performance. Specifically, we design a tri-hybrid beamforming optimization framework combining digital, analog, and Electromagnetic (EM) beamforming to jointly maximize communication rate and sensing Signal-to-Clutter-plus-Noise Ratio (SCNR). Furthermore, an integrated Fractional Programming (FP) and Manifold Optimization (MO) approach is developed to transform the problem into tractable subproblems with closed-form updates. Simulation results verify that the proposed ERA-ISAC system achieves almost 10 dB Sensing and Communication (S&C) performance gain compared to its conventional hybrid beamforming counterparts with Omnidirectional Antenna (OA).

Paper number 19:
Title: A Deep State-Space Model Compression Method using Upper Bound on Output Error
Authors: Hiroki Sakamoto, Kazuhiro Sato
Abstract: We study deep state-space models (Deep SSMs) that contain linear-quadratic-output (LQO) systems as internal blocks and present a compression method with a provable output error guarantee. We first derive an upper bound on the output error between two Deep SSMs and show that the bound can be expressed via the $h^2$-error norms between the layerwise LQO systems, thereby providing a theoretical justification for existing model order reduction (MOR)-based compression. Building on this bound, we formulate an optimization problem in terms of the $h^2$-error norm and develop a gradient-based MOR method. On the IMDb task from the Long Range Arena benchmark, we demonstrate that our compression method achieves strong performance. Moreover, unlike prior approaches, we reduce roughly 80% of trainable parameters without retraining, with only a 4-5% performance drop.

Paper number 20:
Title: Spatially Aware Self-Supervised Models for Multi-Channel Neural Speaker Diarization
Authors: Jiangyu Han, Ruoyu Wang, Yoshiki Masuyama, Marc Delcroix, Johan Rohdin, Jun Du, Lukas Burget
Abstract: Self-supervised models such as WavLM have demonstrated strong performance for neural speaker diarization. However, these models are typically pre-trained on single-channel recordings, limiting their effectiveness in multi-channel scenarios. Existing diarization systems built on these models often rely on DOVER-Lap to combine outputs from individual channels. Although effective, this approach incurs substantial computational overhead and fails to fully exploit spatial information. In this work, building on DiariZen, a pipeline that combines WavLM-based local endto-end neural diarization with speaker embedding clustering, we introduce a lightweight approach to make pre-trained WavLM spatially aware by inserting channel communication modules into the early layers. Our method is agnostic to both the number of microphone channels and array topologies, ensuring broad applicability. We further propose to fuse multi-channel speaker embeddings by leveraging spatial attention weights. Evaluations on five public datasets show consistent improvements over single-channel baselines and demonstrate superior performance and efficiency compared with DOVER-Lap. Our source code is publicly available at this https URL.

Paper number 21:
Title: Proceedings of the second edition of the International Symposium on Computational Sensing (ISCS25)
Authors: Thomas Feuillen, Amirafshar Moshtaghpour
Abstract: The International Symposium on Computational Sensing (ISCS) brings together researchers from optical microscopy, electron microscopy, RADAR, astronomical imaging, biomedical imaging, remote sensing, and signal processing. With a particular focus on applications and demonstrators, the purpose of this symposium is to be a forum where researchers in computational sensing working in seemingly unrelated applications can learn, discover, and exchange on their new findings and challenges. This 3-day symposium in the heart of Europe features 6 keynotes speakers and is open to extended abstracts for scientific presentations and show-and-tell demonstrations.

Paper number 22:
Title: High-Resolution PTDF-Based Planning of Storage and Transmission Under High Renewables
Authors: Kevin Wu, Rabab Haider, Pascal Van Hentenryck
Abstract: Transmission Expansion Planning (TEP) optimizes power grid upgrades and investments to ensure reliable, efficient, and cost-effective electricity delivery while addressing grid constraints. To support growing demand and renewable energy integration, energy storage is emerging as a pivotal asset that provides temporal flexibility and alleviates congestion. This paper develops a multiperiod, two-stage PTDF formulation that co-optimizes transmission upgrades and storage siting/sizing. To ensure scalability, a trust-region, multicut Benders scheme warm-started from per-representative-day optima is proposed. Applied to a 2,000-bus synthetic Texas system under high-renewable projections, the method attains final optimality gaps below 1% and yields a plan with storage at about 180 nodes (32% of peak renewable capacity). These results demonstrate that the proposed PTDF-based methodology efficiently handles large distributed storage fleets, demonstrating scalability at high spatial resolution

Paper number 23:
Title: A Human-Vector Susceptible--Infected--Susceptible Model for Analyzing and Controlling the Spread of Vector-Borne Diseases
Authors: Lorenzo Zino, Alessandro Casu, Alessandro Rizzo
Abstract: We propose an epidemic model for the spread of vector-borne diseases. The model, which is built extending the classical susceptible-infected-susceptible model, accounts for two populations -- humans and vectors -- and for cross-contagion between the two species, whereby humans become infected upon interaction with carrier vectors, and vectors become carriers after interaction with infected humans. We formulate the model as a system of ordinary differential equations and leverage monotone systems theory to rigorously characterize the epidemic dynamics. Specifically, we characterize the global asymptotic behavior of the disease, determining conditions for quick eradication of the disease (i.e., for which all trajectories converge to a disease-free equilibrium), or convergence to a (unique) endemic equilibrium. Then, we incorporate two control actions: namely, vector control and incentives to adopt protection measures. Using the derived mathematical tools, we assess the impact of these two control actions and determine the optimal control policy.

Paper number 24:
Title: Bridging Theory and Practice in Reconfigurable Fluid Antenna Systems
Authors: Halvin Yang, Yizhe Zhao, Kai-Kit Wong, Hsiao-Hwa Chen, Chan-Byoung Chae
Abstract: Fluid antennas, including those based on liquid, mechanical, and pixel-based technologies, are poised to significantly enhance next-generation wireless systems by adaptively optimizing their radiation characteristics. Many theoretical analyses assumed near-instant reconfiguration, perfect channel knowledge, static or slowly varying propagation environments, and ideal material properties that rarely hold in practice. In this article, we dissect these common assumptions and contrast them with the realities of finite actuation time, limited and imperfect channel state information, rapidly changing fading conditions, electromagnetic coupling, and mechanical constraints. Through illustrative examples and simulations, we demonstrate how ignoring these factors can lead to overestimated gains in capacity, coverage, etc.. We then propose modeling refinements, experimental validation methods, and emerging control algorithms that better account for real-world constraints. Our findings highlight that, while reconfigurable antennas remain highly promising for B5G/6G and Internet of things (IoT) applications, their full potential can only be realized by incorporating practical considerations into system design and performance evaluation.

Paper number 25:
Title: A Scalable MVDR Beamforming Algorithm That is Linear in the Number of Antennas
Authors: Sanjaya Herath, Armin Gerami, Kevin Wagner, Ramani Duraiswami, Christopher A. Metzler
Abstract: The Minimum Variance Distortionless Response (MVDR) beamforming technique is widely applied in array systems to mitigate interference. However, applying MVDR to large arrays is computationally challenging; its computational complexity scales cubically with the number of antenna elements. In this paper, we introduce a scalable MVDR beamforming method tailored for massive arrays. Our approach, which is specific to scenarios where the signal of interest is below the noise floor (e.g.,~GPS), leverages the Sherman-Morrison formula, low-rank Singular Value Decomposition (SVD) approximations, and algebraic manipulation. Using our approach, we reduce the computational complexity from cubic to linear in the number of antennas. We evaluate the proposed method through simulations, comparing its computational efficiency and beamforming accuracy with the conventional MVDR approach. Our method significantly reduces the computational load while maintaining high beamforming accuracy for large-scale arrays. This solution holds promise for real-time applications of MVDR beamforming in fields like radar, sonar, and wireless communications, where massive antenna arrays are proliferating.

Paper number 26:
Title: Joint Channel and CFO Estimation From Beam-Swept Synchronization Signal Under Strong Inter-Cell Interference
Authors: Bowen Li, Junting Chen, Nikolaos Pappas
Abstract: Complete awareness of the wireless environment, crucial for future intelligent networks, requires sensing all transmitted signals, not just the strongest. A fundamental barrier is estimating the target signal when it is buried under strong co-channel interference from other transmitters, a failure of which renders the signal unusable. This work proposes a maximum likelihood (ML)-based cross-preamble estimation framework that exploits carrier frequency offset (CFO) constancy across beam-swept synchronization signals (SS), coherently aggregating information across multiple observations to reinforce the desired signal against overwhelming interference. Cramer-Rao lower bound (CRLB) analysis and simulation demonstrate reliable estimation even when the signal is over a thousand times weaker than the interference. A low-altitude radio-map case study further verifies the framework's practical effectiveness.

Paper number 27:
Title: Improved Voltage Regulation with Optimal Design of Decentralized Volt-VAr Control
Authors: Daniel Russell, Dakota Hamilton, Mads R. Almassalkhi, Hamid R. Ossareh
Abstract: Integration of distributed energy resources has created a need for autonomous, dynamic voltage regulation. Decentralized Volt-VAr Control (VVC) of grid-connected inverters presents a unique opportunity for voltage management but, if designed poorly, can lead to unstable behavior when in feedback with the grid. We model the grid-VVC closed-loop dynamics with a linearized power flow approach, leveraging historical data, which shows improvement over the commonly used LinDistFlow model. This model is used to design VVC slopes by minimizing steady-state voltage deviation from the nominal value, subject to a non-convex spectral radius stability constraint, which has not been previously implemented within this context. We compare this constraint to existing convex restrictions and demonstrate, through simulations on a realistic feeder, that using the spectral radius results in more effective voltage regulation.

Paper number 28:
Title: Dynamic-Key-Aware Co-Simulation Framework for Next Generation of SCADA Systems Encrypted by Quantum-Key-Distribution Techniques
Authors: Ziqing Zhu
Abstract: To address growing cybersecurity challenges in modern power dispatch systems, this paper proposes a multi-layer modeling and optimization framework for SCADA systems enhanced with quantum key distribution (QKD). While most existing applications of QKD in the power sector focus on building secure point-to-point communication tunnels, they rarely consider the system-level coupling between key dynamics and control scheduling. In contrast, our approach integrates quantum key generation, consumption, inventory prediction, and control latency into a unified model, enabling key-aware reconfiguration of SCADA control chains based on task security demands and real-time resource constraints. To resolve conflicts in key resource allocation between transmission system operators (TSOs) and distribution system operators (DSOs), we formulate a bi-level Stackelberg game and transform it into a mathematical program with complementarity constraints (MPCC). We further develop an efficient Level Decomposition-Complementarity Pruning (LD-CP) algorithm to solve the problem. To support reproducible evaluation, we build an end-to-end co-simulation platform that integrates physical-layer disruptions via OpenQKD-Sim, Q3P/IEC-104 protocol stack binding, and real-time control-chain monitoring through Grafana. Experimental results on the IEEE 39- and 118-bus systems show that our method increases task success rate by 25%, reduces peak frequency deviation by 70%, and improves key utilization to 83%. This work lays the foundation for future quantum-secure control systems in power grid operations.

Paper number 29:
Title: Through-the-Earth Magnetic Induction Communication and Networking: A Comprehensive Survey
Authors: Honglei Ma, Erwu Liu, Wei Ni, Zhijun Fang, Rui Wang, Yongbin Gao, Dusit Niyato, Ekram Hossain
Abstract: Magnetic induction (MI) communication (MIC) has emerged as a promising candidate for underground communication networks due to its excellent penetration capabilities. Integration with Space-Air-Ground-Underground (SAGUI) networks in next-generation mobile communication systems requires a well-defined network architecture. A recent discovery in MIC research, MI fast fading, remains in its early stages and presents unique challenges. This paper provides a comprehensive survey on through-the-earth (TTE) MIC, covering MI applications, channel modeling, point-to-point MIC design, relay techniques, network frameworks, and emerging technologies. We compare various MIC applications to highlight TTE-specific challenges and review the principles of channel modeling, addressing both MI slow fading and MI fast fading, along with its potential impact on existing MIC theories. We conduct a fine-grained decomposition of MI channel power gain into four distinct physical parameters, and propose a novel geometric model to analyze MI fast fading. We also summarize MI relay techniques, examine crosstalk effects in relay and high-density networks, and explore key research tasks within the OSI framework for a holistic MI network protocol in SAGUI. To bridge the gaps identified, we propose a MIC framework that supports TCP/IP and Linux, enabling full implementation of existing and emerging MIC solutions. This framework empowers researchers to leverage Linux resources and deep learning platforms for accelerated development of MIC in SAGUI networks. Remaining research challenges, open issues, and promising novel techniques are further identified to advance MIC research.

Paper number 30:
Title: Further Results on Safety-Critical Stabilization of Force-Controlled Nonholonomic Mobile Robots
Authors: Bo Wang, Tianyu Han, Guangwei Wang
Abstract: In this paper, we address the stabilization problem for force-controlled nonholonomic mobile robots under safety-critical constraints. We propose a continuous, time-invariant control law based on the gamma m-quadratic programming (gamma m-QP) framework, which unifies control Lyapunov functions (CLFs) and control barrier functions (CBFs) to enforce both stability and safety in the closed-loop system. For the first time, we construct a global, time-invariant, strict Lyapunov function for the closed-loop nonholonomic mobile robot system with a nominal stabilization controller in polar coordinates; this strict Lyapunov function then serves as the CLF in the QP design. Next, by exploiting the inherent cascaded structure of the vehicle dynamics, we develop a CBF for the mobile robot via an integrator backstepping procedure. Our main results guarantee both asymptotic stability and safety for the closed-loop system. Both the simulation and experimental results are presented to illustrate the effectiveness and performance of our approach.

Paper number 31:
Title: Decoding in the presence of ISI without interleaving ORBGRAND AI
Authors: Ken R. Duffy, Moritz Grundei, Jane A. Millward, Muralidhar Rangaswamy, Muriel Medard
Abstract: Inter symbol interference (ISI), which occurs in a wide variety of channels, is a result of time dispersion. It can be mitigated by equalization which results in noise coloring. For such colored noise, we propose a decoder called Ordered Reliability Bit Guessing Random Additive Noise Decoding (ORBGRANDAI) which is inspired by the development of approximate independence in statistical physics. By foregoing interleaving, ORBGRAND-AI can deliver the same, or lower, block error rate (BLER) for the same amount of energy per information bit in an ISI channel as a state-of-the-art soft input decoder, such as Cyclic Redundancy Check Assisted-Successive Cancellation List (CA-SCL) decoding, with an interleaver. To assess the decoding performance of ORBGRAND-AI, we consider delay tap models and their associated colored noise. In particular, we examine a two-tap dicode ISI channel as well as an ISI channel derived from data from RFView, a physics-informed modeling and simulation tool. We investigate the dicode and RFView channel under a variety of imperfect channel state information assumptions and show that a second order autoregressive model adequately represents the RFView channel effect.

Paper number 32:
Title: EdgeNavMamba: Mamba Optimized Object Detection for Energy Efficient Edge Devices
Authors: Romina Aalishah, Mozhgan Navardi, Tinoosh Mohsenin
Abstract: Deployment of efficient and accurate Deep Learning models has long been a challenge in autonomous navigation, particularly for real-time applications on resource-constrained edge devices. Edge devices are limited in computing power and memory, making model efficiency and compression essential. In this work, we propose EdgeNavMamba, a reinforcement learning-based framework for goal-directed navigation using an efficient Mamba object detection model. To train and evaluate the detector, we introduce a custom shape detection dataset collected in diverse indoor settings, reflecting visual cues common in real-world navigation. The object detector serves as a pre-processing module, extracting bounding boxes (BBOX) from visual input, which are then passed to an RL policy to control goal-oriented navigation. Experimental results show that the student model achieved a reduction of 67% in size, and up to 73% in energy per inference on edge devices of NVIDIA Jetson Orin Nano and Raspberry Pi 5, while keeping the same performance as the teacher model. EdgeNavMamba also maintains high detection accuracy in MiniWorld and IsaacLab simulators while reducing parameters by 31% compared to the baseline. In the MiniWorld simulator, the navigation policy achieves over 90% success across environments of varying complexity.

Paper number 33:
Title: Physics-Informed autoencoder for DSC-MRI Perfusion post-processing: application to glioma grading
Authors: Pierre Fayolle, Alexandre Bône, Noëlie Debs, Mathieu Naudin, Pascal Bourdon, Remy Guillevin, David Helbert
Abstract: DSC-MRI perfusion is a medical imaging technique for diagnosing and prognosing brain tumors and strokes. Its analysis relies on mathematical deconvolution, but noise or motion artifacts in a clinical environment can disrupt this process, leading to incorrect estimate of perfusion parameters. Although deep learning approaches have shown promising results, their calibration typically rely on third-party deconvolution algorithms to generate reference outputs and are bound to reproduce their limitations. To adress this problem, we propose a physics-informed autoencoder that leverages an analytical model to decode the perfusion parameters and guide the learning of the encoding network. This autoencoder is trained in a self-supervised fashion without any third-party software and its performance is evaluated on a database with glioma patients. Our method shows reliable results for glioma grading in accordance with other well-known deconvolution algorithms despite a lower computation time. It also achieved competitive performance even in the presence of high noise which is critical in a medical environment.

Paper number 34:
Title: Optical Computation-in-Communication enables low-latency, high-fidelity perception in telesurgery
Authors: Rui Yang, Jiaming Hu, Jian-Qing Zheng, Yue-Zhen Lu, Jian-Wei Cui, Qun Ren, Yi-Jie Yu, John Edward Wu, Zhao-Yu Wang, Xiao-Li Lin, Dandan Zhang, Mingchu Tang, Christos Masouros, Huiyun Liu, Chin-Pang Liu
Abstract: Artificial intelligence (AI) holds significant promise for enhancing intraoperative perception and decision-making in telesurgery, where physical separation impairs sensory feedback and control. Despite advances in medical AI and surgical robotics, conventional electronic AI architectures remain fundamentally constrained by the compounded latency from serial processing of inference and communication. This limitation is especially critical in latency-sensitive procedures such as endovascular interventions, where delays over 200 ms can compromise real-time AI reliability and patient safety. Here, we introduce an Optical Computation-in-Communication (OCiC) framework that reduces end-to-end latency significantly by performing AI inference concurrently with optical communication. OCiC integrates Optical Remote Computing Units (ORCUs) directly into the optical communication pathway, with each ORCU experimentally achieving up to 69 tera-operations per second per channel through spectrally efficient two-dimensional photonic convolution. The system maintains ultrahigh inference fidelity within 0.1% of CPU/GPU baselines on classification and coronary angiography segmentation, while intrinsically mitigating cumulative error propagation, a longstanding barrier to deep optical network scalability. We validated the robustness of OCiC through outdoor dark fibre deployments, confirming consistent and stable performance across varying environmental conditions. When scaled globally, OCiC transforms long-haul fibre infrastructure into a distributed photonic AI fabric with exascale potential, enabling reliable, low-latency telesurgery across distances up to 10,000 km and opening a new optical frontier for distributed medical intelligence.

Paper number 35:
Title: Laser Fault Injection in Memristor-Based Accelerators for AI/ML and Neuromorphic Computing
Authors: Muhammad Faheemur Rahman, Wayne Burleson
Abstract: Memristive crossbar arrays (MCA) are emerging as efficient building blocks for in-memory computing and neuromorphic hardware due to their high density and parallel analog matrix-vector multiplication capabilities. However, the physical properties of their nonvolatile memory elements introduce new attack surfaces, particularly under fault injection scenarios. This work explores Laser Fault Injection as a means of inducing analog perturbations in MCA-based architectures. We present a detailed threat model in which adversaries target memristive cells to subtly alter their physical properties or outputs using laser beams. Through HSPICE simulations of a large MCA on 45 nm CMOS tech. node, we show how laser-induced photocurrent manifests in output current distributions, enabling differential fault analysis to infer internal weights with up to 99.7% accuracy, replicate the model, and compromise computational integrity through targeted weight alterations by approximately 143%.

Paper number 36:
Title: Learning Wireless Interference Patterns: Decoupled GNN for Throughput Prediction in Heterogeneous Multi-Hop p-CSMA Networks
Authors: Faezeh Dehghan Tarzjani, Bhaskar Krishnamachari
Abstract: The p-persistent CSMA protocol is central to random-access MAC analysis, but predicting saturation throughput in heterogeneous multi-hop wireless networks remains a hard problem. Simplified models that assume a single, shared interference domain can underestimate throughput by 48--62\% in sparse topologies. Exact Markov-chain analyses are accurate but scale exponentially in computation time, making them impractical for large networks. These computational barriers motivate structural machine learning approaches like GNNs for scalable throughput prediction in general network topologies. Yet off-the-shelf GNNs struggle here: a standard GCN yields 63.94\% normalized mean absolute error (NMAE) on heterogeneous networks because symmetric normalization conflates a node's direct interference with higher-order, cascading effects that pertain to how interference propagates over the network graph. Building on these insights, we propose the Decoupled Graph Convolutional Network (D-GCN), a novel architecture that explicitly separates processing of a node's own transmission probability from neighbor interference effects. D-GCN replaces mean aggregation with learnable attention, yielding interpretable, per-neighbor contribution weights while capturing complex multihop interference patterns. D-GCN attains 3.3\% NMAE, outperforms strong baselines, remains tractable even when exact analytical methods become computationally infeasible, and enables gradient-based network optimization that achieves within 1\% of theoretical optima.

Paper number 37:
Title: Musical consonance: a review of theory and evidence on perception and preference of auditory roughness in humans and other animals
Authors: John M. McBride
Abstract: The origins of consonance in human music has long been contested, and today there are three primary hypotheses: aversion to roughness, preference for harmonicity, and learned preferences from cultural exposure. While the evidence is currently insufficient to disentangle the contributions of these hypotheses, I propose several reasons why roughness is an especially promising area for future study. The aim of this review is to summarize and critically evaluate roughness theory and models, experimental data, to highlight areas that deserve further research. I identify 2 key areas: There are fundamental issues with the definition and interpretation of results due to tautology in the definition of roughness, and the lack of independence in empirical measurements. Despite extensive model development, there are many duplications and models have issues with data quality and overfitting. Future theory development should aim for model simplicity, and extra assumptions, features and parameters should be evaluated systematically. Model evaluation should aim to maximise the breadth of stimuli that are predicted.

Paper number 38:
Title: Prescribed Performance Control of Deformable Object Manipulation in Spatial Latent Space
Authors: Ning Han, Gu Gong, Bin Zhang, Yuexuan Xu, Bohan Yang, Yunhui Liu, David Navarro-Alarcon
Abstract: Manipulating three-dimensional (3D) deformable objects presents significant challenges for robotic systems due to their infinite-dimensional state space and complex deformable dynamics. This paper proposes a novel model-free approach for shape control with constraints imposed on key points. Unlike existing methods that rely on feature dimensionality reduction, the proposed controller leverages the coordinates of key points as the feature vector, which are extracted from the deformable object's point cloud using deep learning methods. This approach not only reduces the dimensionality of the feature space but also retains the spatial information of the object. By extracting key points, the manipulation of deformable objects is simplified into a visual servoing problem, where the shape dynamics are described using a deformation Jacobian matrix. To enhance control accuracy, a prescribed performance control method is developed by integrating barrier Lyapunov functions (BLF) to enforce constraints on the key points. The stability of the closed-loop system is rigorously analyzed and verified using the Lyapunov method. Experimental results further demonstrate the effectiveness and robustness of the proposed method.

Paper number 39:
Title: Do Joint Language-Audio Embeddings Encode Perceptual Timbre Semantics?
Authors: Qixin Deng, Bryan Pardo, Thrasyvoulos N Pappas
Abstract: Understanding and modeling the relationship between language and sound is critical for applications such as music information retrieval,text-guided music generation, and audio captioning. Central to these tasks is the use of joint language-audio embedding spaces, which map textual descriptions and auditory content into a shared embedding space. While multimodal embedding models such as MS-CLAP, LAION-CLAP, and MuQ-MuLan have shown strong performance in aligning language and audio, their correspondence to human perception of timbre, a multifaceted attribute encompassing qualities such as brightness, roughness, and warmth, remains underexplored. In this paper, we evaluate the above three joint language-audio embedding models on their ability to capture perceptual dimensions of timbre. Our findings show that LAION-CLAP consistently provides the most reliable alignment with human-perceived timbre semantics across both instrumental sounds and audio effects.

Paper number 40:
Title: A Robust Classification Method using Hybrid Word Embedding for Early Diagnosis of Alzheimer's Disease
Authors: Yangyang Li
Abstract: Early detection of Alzheimer's Disease (AD) is greatly beneficial to AD patients, leading to early treatments that lessen symptoms and alleviating financial burden of health care. As one of the leading signs of AD, language capability changes can be used for early diagnosis of AD. In this paper, I develop a robust classification method using hybrid word embedding and fine-tuned hyperparameters to achieve state-of-the-art accuracy in the early detection of AD. Specifically, we create a hybrid word embedding based on word vectors from Doc2Vec and ELMo to obtain perplexity scores of the sentences. The scores identify whether a sentence is fluent or not and capture semantic context of the sentences. I enrich the word embedding by adding linguistic features to analyze syntax and semantics. Further, we input an embedded feature vector into logistic regression and fine tune hyperparameters throughout the pipeline. By tuning hyperparameters of the machine learning pipeline (e.g., model regularization parameter, learning rate and vector size of Doc2Vec, and vector size of ELMo), I achieve 91% classification accuracy and an Area Under the Curve (AUC) of 97% in distinguishing early AD from healthy subjects. Based on my knowledge, my model with 91% accuracy and 97% AUC outperforms the best existing NLP model for AD diagnosis with an accuracy of 88% [32]. I study the model stability through repeated experiments and find that the model is stable even though the training data is split randomly (standard deviation of accuracy = 0.0403; standard deviation of AUC = 0.0174). This affirms our proposed method is accurate and stable. This model can be used as a large-scale screening method for AD, as well as a complementary examination for doctors to detect AD.

Paper number 41:
Title: Revisit Modality Imbalance at the Decision Layer
Authors: Xiaoyu Ma, Hao Chen
Abstract: Multimodal learning integrates information from different modalities to enhance model performance, yet it often suffers from modality imbalance, where dominant modalities overshadow weaker ones during joint optimization. This paper reveals that such an imbalance not only occurs during representation learning but also manifests significantly at the decision layer. Experiments on audio-visual datasets (CREMAD and Kinetic-Sounds) show that even after extensive pretraining and balanced optimization, models still exhibit systematic bias toward certain modalities, such as audio. Further analysis demonstrates that this bias originates from intrinsic disparities in feature-space and decision-weight distributions rather than from optimization dynamics alone. We argue that aggregating uncalibrated modality outputs at the fusion stage leads to biased decision-layer weighting, hindering weaker modalities from contributing effectively. To address this, we propose that future multimodal systems should focus more on incorporate adaptive weight allocation mechanisms at the decision layer, enabling relative balanced according to the capabilities of each modality.

Paper number 42:
Title: RoboANKLE: Design, Development, and Functional Evaluation of a Robotic Ankle with a Motorized Compliant Unit
Authors: Baris Baysal, Omid Arfaie, Ramazan Unal
Abstract: This study presents a powered transtibial prosthesis with complete push-off assistance, RoboANKLE. The design aims to fulfill specific requirements, such as a sufficient range of motion (RoM) while providing the necessary torque for achieving natural ankle motion in daily activities. Addressing the challenges faced in designing active transtibial prostheses, such as maintaining energetic autonomy and minimizing weight, is vital for the study. With this aim, we try to imitate the human ankle by providing extensive push-off assistance to achieve a natural-like torque profile. Thus, Energy Store and Extended Release mechanism (ESER) is employed with a novel Extra Energy Storage (EES) mechanism. Kinematic and kinetic analyses are carried out to determine the design parameters and assess the design performance. Subsequently, a Computer-Aided Design (CAD) model is built and used in comprehensive dynamic and structural analyses. These analyses are used for the design performance evaluation and determine the forces and torques applied to the prosthesis, which aids in optimizing the design for minimal weight via structural analysis and topology optimization. The design of the prototype is then finalized and manufactured for experimental evaluation to validate the design and functionality. The prototype is realized with a mass of 1.92 kg and dimensions of 261x107x420 mm. The Functional evaluations of the RoboANKLE revealed that it is capable of achieving the natural maximum dorsi-flexion angle with 95% accuracy. Also, Thanks to the implemented mechanisms, the results show that RoboANKLE can generate 57% higher than the required torque for natural walking. The result of the power generation capacity of the RoboANKLE is 10% more than the natural power during the gait cycle.

Paper number 43:
Title: Big Data Approaches to Bovine Bioacoustics: A FAIR-Compliant Dataset and Scalable ML Framework for Precision Livestock Welfare
Authors: Mayuri Kate, Suresh Neethirajan
Abstract: The convergence of IoT sensing, edge computing, and machine learning is transforming precision livestock farming. Yet bioacoustic data streams remain underused because of computational complexity and ecological validity challenges. We present one of the most comprehensive bovine vocalization datasets to date, with 569 curated clips covering 48 behavioral classes, recorded across three commercial dairy farms using multiple microphone arrays and expanded to 2900 samples through domain informed augmentation. This FAIR compliant resource addresses major Big Data challenges - volume (90 hours of recordings, 65.6 GB), variety (multi farm and multi zone acoustics), velocity (real time processing), and veracity (noise robust feature extraction). Our distributed processing framework integrates advanced denoising using iZotope RX, multimodal synchronization through audio and video alignment, and standardized feature engineering with 24 acoustic descriptors generated from Praat, librosa, and openSMILE. Preliminary benchmarks reveal distinct class level acoustic patterns for estrus detection, distress classification, and maternal communication. The datasets ecological realism, reflecting authentic barn acoustics rather than controlled settings, ensures readiness for field deployment. This work establishes a foundation for animal centered AI, where bioacoustic data enable continuous and non invasive welfare assessment at industrial scale. By releasing standardized pipelines and detailed metadata, we promote reproducible research that connects Big Data analytics, sustainable agriculture, and precision livestock management. The framework supports UN SDG 9, showing how data science can turn traditional farming into intelligent, welfare optimized systems that meet global food needs while upholding ethical animal care.

Paper number 44:
Title: Stability Criteria and Motor Performance in Delayed Haptic Dyadic Interactions Mediated by Robots
Authors: Mingtian Du, Suhas Raghavendra Kulkarni, Simone Kager, Domenico Campolo
Abstract: This paper establishes analytical stability criteria for robot-mediated human-human (dyadic) interaction systems, focusing on haptic communication under network-induced time delays. Through frequency-domain analysis supported by numerical simulations, we identify both delay-independent and delay-dependent stability criteria. The delay-independent criterion guarantees stability irrespective of the delay, whereas the delay-dependent criterion is characterised by a maximum tolerable delay before instability occurs. The criteria demonstrate dependence on controller and robot dynamic parameters, where increasing stiffness reduces the maximum tolerable delay in a non-linear manner, thereby heightening system vulnerability. The proposed criteria can be generalised to a wide range of robot-mediated interactions and serve as design guidelines for stable remote dyadic systems. Experiments with robots performing human-like movements further illustrate the correlation between stability and motor performance. The findings of this paper suggest the prerequisites for effective delay-compensation strategies.

Paper number 45:
Title: AudioEval: Automatic Dual-Perspective and Multi-Dimensional Evaluation of Text-to-Audio-Generation
Authors: Hui Wang, Jinghua Zhao, Cheng Liu, Yuhang Jia, Haoqin Sun, Jiaming Zhou, Yong Qin
Abstract: Text-to-audio (TTA) is rapidly advancing, with broad potential in virtual reality, accessibility, and creative media. However, evaluating TTA quality remains difficult: human ratings are costly and limited, while existing objective metrics capture only partial aspects of perceptual quality. To address this gap, we introduce AudioEval, the first large-scale TTA evaluation dataset, containing 4,200 audio samples from 24 systems with 126,000 ratings across five perceptual dimensions, annotated by both experts and non-experts. Based on this resource, we propose Qwen-DisQA, a multimodal scoring model that jointly processes text prompts and generated audio to predict human-like quality ratings. Experiments show its effectiveness in providing reliable and scalable evaluation. The dataset will be made publicly available to accelerate future research.

Paper number 46:
Title: SpeechLLM-as-Judges: Towards General and Interpretable Speech Quality Evaluation
Authors: Hui Wang, Jinghua Zhao, Yifan Yang, Shujie Liu, Junyang Chen, Yanzhe Zhang, Shiwan Zhao, Jinyu Li, Jiaming Zhou, Haoqin Sun, Yan Lu, Yong Qin
Abstract: Generative speech technologies are progressing rapidly, but evaluating the perceptual quality of synthetic speech remains a core challenge. Existing methods typically rely on scalar scores or binary decisions, which lack interpretability and generalization across tasks and languages. We present SpeechLLM-as-Judges, a new paradigm for enabling large language models (LLMs) to conduct structured and explanation-based speech quality evaluation. To support this direction, we introduce SpeechEval, a large-scale dataset containing 32,207 multilingual speech clips and 128,754 annotations spanning four tasks: quality assessment, pairwise comparison, improvement suggestion, and deepfake detection. Based on this resource, we develop SQ-LLM, a speech-quality-aware LLM trained with chain-of-thought reasoning and reward optimization to improve capability. Experimental results show that SQ-LLM delivers strong performance across tasks and languages, revealing the potential of this paradigm for advancing speech quality evaluation. Relevant resources will be open-sourced.

Paper number 47:
Title: Camera Movement Classification in Historical Footage: A Comparative Study of Deep Video Models
Authors: Tingyu Lin, Armin Dadras, Florian Kleber, Robert Sablatnig
Abstract: Camera movement conveys spatial and narrative information essential for understanding video content. While recent camera movement classification (CMC) methods perform well on modern datasets, their generalization to historical footage remains unexplored. This paper presents the first systematic evaluation of deep video CMC models on archival film material. We summarize representative methods and datasets, highlighting differences in model design and label definitions. Five standard video classification models are assessed on the HISTORIAN dataset, which includes expert-annotated World War II footage. The best-performing model, Video Swin Transformer, achieves 80.25% accuracy, showing strong convergence despite limited training data. Our findings highlight the challenges and potential of adapting existing models to low-quality video and motivate future work combining diverse input modalities and temporal architectures.

Paper number 48:
Title: Exploiting Non-Diffracting Beams for Resilient Near-Field Millimeter-Wave Communications A Quantitative Roadmap
Authors: Yifeng Qin, Jing Chen, Zhi Hao Jiang, Zhining Chen, Yongming Huang, Lingyang Song
Abstract: Non diffracting (ND) beams are often cited as a promising solution to mitigate blockage in millimeter wave (mmWave) systems. However, a quantitative answer to the fundamental question, under what specific conditions do ND beams actually outperform conventional pencil beams, has remained elusive, especially in the emerging context of near-field communications. This paper provides the first systematic answer by mapping the performance advantage regimes of ND beams for blockage-resilient near-field links. We propose a unified holographic generator that synthesizes various structured beams (e.g., Bessel, Mathieu) under the physical constraints of a planar phased array, ensuring a fair comparison against a boresight baseline with identical EIRP and aperture. Through extensive, unbiased Monte Carlo simulations, we construct advantage regime maps that delineate the specific regions where ND beams offer a tangible link-level gain. Our key finding is that the advantage of ND beams is a powerful but conditional near field phenomenon. While offering a positive average gain, its performance is highly variable, with a 60-70% probability of outperforming the baseline in its optimal range. Crucially, this performance is strongly modulated by the obstacle's geometry, revealing a significant weakness against large blockers. These findings provide not just a practical roadmap for judiciously employing ND beams but also a clear motivation for future work in environment-aware, adaptively shaped structured beams.

Paper number 49:
Title: TRI-DEP: A Trimodal Comparative Study for Depression Detection Using Speech, Text, and EEG
Authors: Annisaa Fitri Nurfidausi, Eleonora Mancini, Paolo Torroni
Abstract: Depression is a widespread mental health disorder, yet its automatic detection remains challenging. Prior work has explored unimodal and multimodal approaches, with multimodal systems showing promise by leveraging complementary signals. However, existing studies are limited in scope, lack systematic comparisons of features, and suffer from inconsistent evaluation protocols. We address these gaps by systematically exploring feature representations and modelling strategies across EEG, together with speech and text. We evaluate handcrafted features versus pre-trained embeddings, assess the effectiveness of different neural encoders, compare unimodal, bimodal, and trimodal configurations, and analyse fusion strategies with attention to the role of EEG. Consistent subject-independent splits are applied to ensure robust, reproducible benchmarking. Our results show that (i) the combination of EEG, speech and text modalities enhances multimodal detection, (ii) pretrained embeddings outperform handcrafted features, and (iii) carefully designed trimodal models achieve state-of-the-art performance. Our work lays the groundwork for future research in multimodal depression detection.

Paper number 50:
Title: Architecture Is All You Need: Diversity-Enabled Sweet Spots for Robust Humanoid Locomotion
Authors: Blake Werner, Lizhi Yang, Aaron D. Ames
Abstract: Robust humanoid locomotion in unstructured environments requires architectures that balance fast low-level stabilization with slower perceptual decision-making. We show that a simple layered control architecture (LCA), a proprioceptive stabilizer running at high rate, coupled with a compact low-rate perceptual policy, enables substantially more robust performance than monolithic end-to-end designs, even when using minimal perception encoders. Through a two-stage training curriculum (blind stabilizer pretraining followed by perceptual fine-tuning), we demonstrate that layered policies consistently outperform one-stage alternatives in both simulation and hardware. On a Unitree G1 humanoid, our approach succeeds across stair and ledge tasks where one-stage perceptual policies fail. These results highlight that architectural separation of timescales, rather than network scale or complexity, is the key enabler for robust perception-conditioned locomotion.

Paper number 51:
Title: CBF-RL: Safety Filtering Reinforcement Learning in Training with Control Barrier Functions
Authors: Lizhi Yang, Blake Werner, Massimiliano de Sa Aaron D. Ames
Abstract: Reinforcement learning (RL), while powerful and expressive, can often prioritize performance at the expense of safety. Yet safety violations can lead to catastrophic outcomes in real-world deployments. Control Barrier Functions (CBFs) offer a principled method to enforce dynamic safety -- traditionally deployed \emph{online} via safety filters. While the result is safe behavior, the fact that the RL policy does not have knowledge of the CBF can lead to conservative behaviors. This paper proposes CBF-RL, a framework for generating safe behaviors with RL by enforcing CBFs \emph{in training}. CBF-RL has two key attributes: (1) minimally modifying a nominal RL policy to encode safety constraints via a CBF term, (2) and safety filtering of the policy rollouts in training. Theoretically, we prove that continuous-time safety filters can be deployed via closed-form expressions on discrete-time roll-outs. Practically, we demonstrate that CBF-RL internalizes the safety constraints in the learned policy -- both enforcing safer actions and biasing towards safer rewards -- enabling safe deployment without the need for an online safety filter. We validate our framework through ablation studies on navigation tasks and on the Unitree G1 humanoid robot, where CBF-RL enables safer exploration, faster convergence, and robust performance under uncertainty, enabling the humanoid robot to avoid obstacles and climb stairs safely in real-world settings without a runtime safety filter.

Paper number 52:
Title: RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks
Authors: Mingxuan Yan, Yuping Wang, Zechun Liu, Jiachen Li
Abstract: To tackle long-horizon tasks, recent hierarchical vision-language-action (VLAs) frameworks employ vision-language model (VLM)-based planners to decompose complex manipulation tasks into simpler sub-tasks that low-level visuomotor policies can easily handle. Typically, the VLM planner is finetuned to learn to decompose a target task. This finetuning requires target task demonstrations segmented into sub-tasks by either human annotation or heuristic rules. However, the heuristic subtasks can deviate significantly from the training data of the visuomotor policy, which degrades task performance. To address these issues, we propose a Retrieval-based Demonstration Decomposer (RDD) that automatically decomposes demonstrations into sub-tasks by aligning the visual features of the decomposed sub-task intervals with those from the training data of the low-level visuomotor policies. Our method outperforms the state-of-the-art sub-task decomposer on both simulation and real-world tasks, demonstrating robustness across diverse settings. Code and more results are available at this http URL.

Paper number 53:
Title: Hierarchical Fuel-Cell Airpath Control: an Efficiency-Aware MIMO Control Approach Combined with a Novel Constraint-Enforcing Reference Governor
Authors: Eli Bacher-Chong, Mostafa Ali Ayubirad, Zeng Qiu, Hao Wang, Alireza Goshtasbi, Hamid R. Ossareh
Abstract: This paper presents a hierarchical multivariable control and constraint management approach for an air supply system for a proton exchange membrane fuel cell (PEMFC) system. The control objectives are to track desired compressor mass airflow and cathode inlet pressure, maintain a minimum oxygen excess ratio (OER), and run the system at maximum net efficiency. A multi-input multi-output (MIMO) internal model controller (IMC) is designed and simulated to track flow and pressure set-points, which showed high performance despite strongly coupled plant dynamics. A new set-point map is generated to compute the most efficient cathode inlet pressure from the stack current load. To enforce OER constraints, a novel reference governor (RG) with the ability to govern multiple references (the cascade RG) and the ability to speed up as well as slow down a reference signal (the cross-section RG) is developed and tested. Compared with a single-input single-output (SISO) air-flow control approach, the proposed MIMO control approach shows up to 7.36 percent lower hydrogen fuel consumption. Compared to a traditional load governor, the novel cascaded cross-section RG (CC-RG) shows up to 3.68 percent less mean absolute percent error (MAPE) on net power tracking and greatly improved worst-case OER on realistic drive-cycle simulations. Control development and validations were conducted on two fuel cell system (FCS) models, a nonlinear open-source model and a proprietary Ford high-fidelity model

Paper number 54:
Title: Offline and Online Use of Interval and Set-Based Approaches for Control and State Estimation: A Selection of Methodological Approaches and Their Application
Authors: Andreas Rauh, Marit Lahme, Simon Rohou, Luc Jaulin, Thach Ngoc Dinh, Tarek Raissi, Mohamed Fnadi
Abstract: Control and state estimation procedures need to be robust against imprecisely known parameters, uncertainty in initial conditions, and external disturbances. Interval methods and other set-based techniques form the basis for the implementation of powerful approaches that can be used to identify parameters of dynamic system models in the presence of the aforementioned types of uncertainty. Moreover, they are applicable to a verified feasibility and stability analysis of controllers and state estimators. In addition to these approaches which are typically used offline for analysis of system models designed with classical floating point procedures, interval and set-based methods have also been developed in recent years, which allow to directly solve the associated design tasks and to implement reliable techniques that are applicable online, i.e., during system operation. The latter approaches include set-based model predictive control, online parameter adaptation techniques for nonlinear variable-structure and backstepping controllers, interval observers, and fault diagnosis techniques. This paper provides an overview of the methodological background and reviews numerous practical applications for which interval and other set-valued approaches have been employed successfully.

Paper number 55:
Title: TABSurfer: a Hybrid Deep Learning Architecture for Subcortical Segmentation
Authors: Aaron Cao, Vishwanatha M. Rao, Kejia Liu, Xinrui Liu, Andrew F. Laine, Jia Guo
Abstract: Subcortical segmentation remains challenging despite its important applications in quantitative structural analysis of brain MRI scans. The most accurate method, manual segmentation, is highly labor intensive, so automated tools like FreeSurfer have been adopted to handle this task. However, these traditional pipelines are slow and inefficient for processing large datasets. In this study, we propose TABSurfer, a novel 3D patch-based CNN-Transformer hybrid deep learning model designed for superior subcortical segmentation compared to existing state-of-the-art tools. To evaluate, we first demonstrate TABSurfer's consistent performance across various T1w MRI datasets with significantly shorter processing times compared to FreeSurfer. Then, we validate against manual segmentations, where TABSurfer outperforms FreeSurfer based on the manual ground truth. In each test, we also establish TABSurfer's advantage over a leading deep learning benchmark, FastSurferVINN. Together, these studies highlight TABSurfer's utility as a powerful tool for fully automated subcortical segmentation with high fidelity.

Paper number 56:
Title: Composite learning backstepping control with guaranteed exponential stability and robustness
Authors: Tian Shi, Shihua Li, Changyun Wen, Yongping Pan
Abstract: Adaptive backstepping control provides a feasible solution to achieve asymptotic tracking for mismatched uncertain nonlinear systems. However, the closed-loop stability depends on high-gain feedback generated by nonlinear damping terms, and closed-loop exponential stability with parameter convergence involves a stringent condition named persistent excitation (PE). This paper proposes a composite learning backstepping control (CLBC) strategy based on modular backstepping and high-order tuners to compensate for the transient process of parameter estimation and achieve closed-loop exponential stability without the nonlinear damping terms and the PE condition. A novel composite learning mechanism is designed to maximize the staged exciting strength for parameter estimation, such that parameter convergence can be achieved under a condition of interval excitation (IE) or even partial IE that is strictly weaker than PE. An extra prediction error is employed in the adaptive law to ensure the transient performance without nonlinear damping terms. The exponential stability of the closed-loop system is proved rigorously under the partial IE or IE condition. Simulations have demonstrated the effectiveness and superiority of the proposed method in both parameter estimation and control compared to state-of-the-art methods.

Paper number 57:
Title: Pruning Sparse Tensor Neural Networks Enables Deep Learning for 3D Ultrasound Localization Microscopy
Authors: Brice Rauby (1 and 2), Paul Xing (1), Jonathan Porée (1), Maxime Gasse (1, 2 and 3), Jean Provost (1 and 4) ((1) Polytechnique Montréal, (2) Mila - Quebec Artificial Intelligence Institute, (3) ServiceNow Inc., (4) Montreal Heart Institute)
Abstract: Ultrasound Localization Microscopy (ULM) is a non-invasive technique that allows for the imaging of micro-vessels in vivo, at depth and with a resolution on the order of ten microns. ULM is based on the sub-resolution localization of individual microbubbles injected in the bloodstream. Mapping the whole angioarchitecture requires the accumulation of microbubbles trajectories from thousands of frames, typically acquired over a few minutes. ULM acquisition times can be reduced by increasing the microbubble concentration, but requires more advanced algorithms to detect them individually. Several deep learning approaches have been proposed for this task, but they remain limited to 2D imaging, in part due to the associated large memory requirements. Herein, we propose to use sparse tensor neural networks to reduce memory usage in 2D and to improve the scaling of the memory requirement for the extension of deep learning architecture to 3D. We study several approaches to efficiently convert ultrasound data into a sparse format and study the impact of the associated loss of information. When applied in 2D, the sparse formulation reduces the memory requirements by a factor 2 at the cost of a small reduction of performance when compared against dense networks. In 3D, the proposed approach reduces memory requirements by two order of magnitude while largely outperforming conventional ULM in high concentration settings. We show that Sparse Tensor Neural Networks in 3D ULM allow for the same benefits as dense deep learning based method in 2D ULM i.e. the use of higher concentration in silico and reduced acquisition time.

Paper number 58:
Title: Strategy Templates for Almost-Sure and Positive Winning of Stochastic Parity Games towards Permissive and Resilient Control
Authors: Kittiphon Phalakarn, Sasinee Pruekprasert, Ichiro Hasuo
Abstract: Stochastic games are fundamental in various applications, including the control of cyber-physical systems (CPS), where both controller and environment are modeled as players. Traditional algorithms typically aim to determine a single winning strategy to develop a controller. However, in CPS control and other domains, permissive controllers are essential, as they enable the system to adapt when additional constraints arise and remain resilient to runtime changes. This work generalizes the concept of (permissive winning) strategy templates, originally introduced by Anand et al. at TACAS and CAV 2023 for deterministic games, to incorporate stochastic games. These templates capture an infinite number of winning strategies, allowing for efficient strategy adaptation to system changes. We focus on two winning criteria (almost-sure and positive winning) and five winning objectives (safety, reachability, Büchi, co-Büchi, and parity). Our contributions include algorithms for constructing templates for each winning criterion and objective and a novel approach for extracting a winning strategy from a given template. Discussions on comparisons between templates and between strategy extraction methods are provided.

Paper number 59:
Title: VoxelPrompt: A Vision Agent for End-to-End Medical Image Analysis
Authors: Andrew Hoopes, Neel Dey, Victor Ion Butoi, John V. Guttag, Adrian V. Dalca
Abstract: We present VoxelPrompt, an end-to-end image analysis agent that tackles free-form radiological tasks. Given any number of volumetric medical images and a natural language prompt, VoxelPrompt integrates a language model that generates executable code to invoke a jointly-trained, adaptable vision network. This code further carries out analytical steps to address practical quantitative aims, such as measuring the growth of a tumor across visits. The pipelines generated by VoxelPrompt automate analyses that currently require practitioners to painstakingly combine multiple specialized vision and statistical tools. We evaluate VoxelPrompt using diverse neuroimaging tasks and show that it can delineate hundreds of anatomical and pathological features, measure complex morphological properties, and perform open-language analysis of lesion characteristics. VoxelPrompt performs these objectives with an accuracy similar to that of specialist single-task models for image analysis, while facilitating a broad range of compositional biomedical workflows.

Paper number 60:
Title: VERITAS: Verifying the Performance of AI-native Transceiver Actions in Base-Stations
Authors: Nasim Soltani, Michael Loehning, Kaushik Chowdhury
Abstract: Artificial Intelligence (AI)-native receivers prove significant performance improvement in high noise regimes and can potentially reduce communication overhead compared to the traditional receiver. However, their performance highly depends on the representativeness of the training dataset. A major issue is the uncertainty of whether the training dataset covers all test environments and waveform configurations, and thus, whether the trained model is robust in practical deployment conditions. To this end, we propose a joint measurement-recovery framework for AI-native transceivers post deployment, called VERITAS, that continuously looks for distribution shifts in the received signals and triggers finite re-training spurts. VERITAS monitors the wireless channel using 5G pilots fed to an auxiliary neural network that detects out-of-distribution channel profile, transmitter speed, and delay spread. As soon as such a change is detected, a traditional (reference) receiver is activated, which runs for a period of time in parallel to the AI-native receiver. Finally, VERTIAS compares the bit probabilities of the AI-native and the reference receivers for the same received data inputs, and decides whether or not a retraining process needs to be initiated. Our evaluations reveal that VERITAS can detect changes in the channel profile, transmitter speed, and delay spread with 99%, 97%, and 69% accuracies, respectively, followed by timely initiation of retraining for 86%, 93.3%, and 94.8% of inputs in channel profile, transmitter speed, and delay spread test sets, respectively.

Paper number 61:
Title: Revolution-Spaced Output-Feedback Model Predictive Control for Station Keeping on Near-Rectilinear Halo Orbits
Authors: Yuri Shimane, Stefano Di Cairano, Koki Ho, Avishai Weiss
Abstract: We develop a model predictive control (MPC) policy for station keeping on a Near-Rectilinear Halo Orbit (NRHO). The proposed policy achieves full-state tracking of a reference NRHO via a multiple-maneuver control horizon, each spaced one revolution apart to abide by typical mission operation requirements. We prove that the proposed policy is recursively feasible, and perform numerical evaluation in an output-feedback setting by incorporating a navigation filter and realistic operational uncertainties, where the proposed MPC is compared against the state-of-the-art station-keeping algorithm adopted for the Gateway. Our approach successfully maintains the spacecraft in the vicinity of the reference NRHO at a similar cumulative cost as existing station-keeping methods without encountering phase deviation issues, a common drawback of existing methods with one maneuver per revolution.

Paper number 62:
Title: Non-invasive electromyographic speech neuroprosthesis: a geometric perspective
Authors: Harshavardhana T. Gowda, Lee M. Miller
Abstract: We present a high-bandwidth, egocentric neuromuscular speech interface that translates $silently$ voiced articulations directly into text. We record surface electromyographic (EMG) signals from multiple articulatory sites on the face and neck as participants $silently$ articulate speech, enabling direct EMG-to-text translation. Such an interface has the potential to restore communication for individuals who have lost the ability to produce intelligible speech due to laryngectomy, neuromuscular disease, stroke, or trauma-induced damage (e.g., radiotherapy toxicity) to the speech articulators. Prior work has largely focused on mapping EMG collected during $audible$ articulation to time-aligned audio targets or transferring these targets to $silent$ EMG recordings, which inherently requires audio and limits applicability to patients who can no longer speak. In contrast, we propose an efficient representation of high-dimensional EMG signals and demonstrate direct sequence-to-sequence EMG-to-text conversion at the phonemic level without relying on time-aligned audio. All data, code, and model checkpoints are open-sourced at The dataset and code are available at: this https URL .

Paper number 63:
Title: Electromagnetically Reconfigurable Fluid Antenna System for Wireless Communications: Design, Modeling, Algorithm, Fabrication, and Experiment
Authors: Ruiqi Wang, Pinjun Zheng, Vijith Varma Kotte, Sakandar Rauf, Yiming Yang, Muhammad Mahboob Ur Rahman, Tareq Y. Al-Naffouri, Atif Shamim
Abstract: This paper presents the concept, design, channel modeling, beamforming algorithm development, prototype fabrication, and experimental measurement of an electromagnetically reconfigurable fluid antenna system (ER-FAS), in which each FAS array element features electromagnetic (EM) reconfigurability. Unlike most existing FAS works that investigate spatial reconfigurability by adjusting the position and/or orientation of array elements, the proposed ER-FAS enables direct control over the EM characteristics of each element, allowing for dynamic radiation pattern reconfigurability. Specifically, a novel ER-FAS architecture leveraging software-controlled fluidics is proposed, and corresponding wireless channel models are established. Based on this ER-FAS channel model, a low-complexity greedy beamforming algorithm is developed to jointly optimize the analog phase shift and the radiation state of each array element. The accuracy of the ER-FAS channel model and the effectiveness of the beamforming algorithm are validated through (i) full-wave EM simulations and (ii) numerical spectral efficiency evaluations. These results confirm that the proposed ER-FAS significantly enhances spectral efficiency in both near-field and far-field scenarios compared to conventional antenna arrays. To further validate this design, we fabricate prototypes for both the ER-FAS element and array, using Galinstan liquid metal alloy, fluid silver paste, and software-controlled fluidic channels. The simulation results are experimentally validated through prototype measurements conducted in an anechoic chamber. Additionally, several indoor communication experiments using a pair of software-defined radios demonstrate the superior received power and bit error rate performance of the ER-FAS prototype.

Paper number 64:
Title: A Weighted Predict-and-Optimize Framework for Power System Operation Considering Varying Impacts of Uncertainty
Authors: Yingrui Zhuang, Lin Cheng, Can Wan, Rui Xie, Ning Qi, Yue Chen
Abstract: Prediction deviations of different uncertainties have varying impacts on downstream decision-making. Improving the prediction accuracy of critical uncertainties with significant impacts on decision-making quality yields better optimization results. Motivated by this observation, this paper proposes a novel weighted predict-and-optimize (WPO) framework for decision-making under multiple uncertainties. Specifically, we incorporate an uncertainty-aware weighting mechanism into the predictive model to capture the relative impact of each uncertainty on specific optimization tasks, and introduce a problem-driven prediction loss (PDPL) to quantify the suboptimality of the weighted predictions relative to perfect predictions in downstream optimization. By optimizing the uncertainty weights to minimize the PDPL, the proposed WPO framework enables adaptive assessment of uncertainty impacts and joint learning of prediction and optimization. Furthermore, to facilitate weight optimization, we develop a surrogate model that establishes a direct mapping between the uncertainty weights and the PDPL, where enhanced graph convolutional networks and multi-task learning are adopted for efficient surrogate model construction and training. Numerical experiments on the modified IEEE 33-bus and 123-bus systems demonstrate that the proposed WPO framework outperforms the traditional predict-then-optimize paradigm, reducing the PDPL by an average of 55% within acceptable computational time.

Paper number 65:
Title: No-Regret Learning in Stackelberg Games with an Application to Electric Ride-Hailing
Authors: Anna Maddux, Marko Maljkovic, Nikolas Geroliminis, Maryam Kamgarpour
Abstract: We consider the problem of efficiently learning to play single-leader multi-follower Stackelberg games when the leader lacks knowledge of the lower-level game. Such games arise in hierarchical decision-making problems involving self-interested agents. For example, in electric ride-hailing markets, a central authority aims to learn optimal charging prices to shape fleet distributions and charging patterns of ride-hailing companies. Existing works typically apply gradient-based methods to find the leader's optimal strategy. Such methods are impractical as they require that the followers share private utility information with the leader. Instead, we treat the lower-level game as a black box, assuming only that the followers' interactions approximate a Nash equilibrium while the leader observes the realized cost of the resulting approximation. Under kernel-based regularity assumptions on the leader's cost function, we develop a no-regret algorithm that converges to an $\epsilon$-Stackelberg equilibrium in $O(\sqrt{T})$ rounds. Finally, we validate our approach through a numerical case study on optimal pricing in electric ride-hailing markets.

Paper number 66:
Title: SPIRIT: Patching Speech Language Models against Jailbreak Attacks
Authors: Amirbek Djanibekov, Nurdaulet Mukhituly, Kentaro Inui, Hanan Aldarmaki, Nils Lukas
Abstract: Speech Language Models (SLMs) enable natural interactions via spoken instructions, which more effectively capture user intent by detecting nuances in speech. The richer speech signal introduces new security risks compared to text-based models, as adversaries can better bypass safety mechanisms by injecting imperceptible noise to speech. We analyze adversarial attacks and find that SLMs are substantially more vulnerable to jailbreak attacks, which can achieve a perfect 100% attack success rate in some instances. To improve security, we propose post-hoc patching defenses used to intervene during inference by modifying the SLM's activations that improve robustness up to 99% with (i) negligible impact on utility and (ii) without any re-training. We conduct ablation studies to maximize the efficacy of our defenses and improve the utility/security trade-off, validated with large-scale benchmarks unique to SLMs.

Paper number 67:
Title: EM-Based Channel Estimation for mMIMO LEO SATCOM Under Imperfect Doppler Compensation
Authors: Abdollah Masoud Darya, Saeed Abdallah
Abstract: Massive multiple-input multiple-output low-Earth-orbit communication channels are highly time-varying due to severe Doppler shifts and propagation delays. While satellite-mobility-induced Doppler shifts can be compensated using known ephemeris data, those caused by user mobility require accurate user positioning information; the absence of such information contributes to amplified channel aging in conventional channel estimators. To address this challenge, we propose a data-aided channel estimator based on the expectation-maximization (EM) algorithm, combined with a discrete Legendre polynomial basis expansion model (DLP-BEM), to estimate the channel under imperfect Doppler compensation. The EM algorithm iteratively exploits hidden data symbols for improved channel estimation, while DLP-BEM regularizes the process by projecting the channel estimate onto a lower-dimensional subspace that mitigates estimation errors. Simulation results demonstrate the superiority of the proposed framework over existing methods in terms of normalized mean square error and symbol error rate.

Paper number 68:
Title: Attention-Aided MMSE for OFDM Channel Estimation: Learning Linear Filters with Attention
Authors: TaeJun Ha, Chaehyun Jung, Hyeonuk Kim, Jeongwoo Park, Jeonghun Park
Abstract: In orthogonal frequency division multiplexing (OFDM), accurate channel estimation is crucial. Classical signal processing based approaches, such as minimum mean-squared error (MMSE) estimation, often require second-order statistics that are difficult to obtain in practice. Recent deep neural networks based methods have been introduced to address this; yet they often suffer from high inference complexity. This paper proposes an Attention-aided MMSE (A-MMSE), a novel model-based DNN framework that learns the optimal MMSE filter via the Attention Transformer. Once trained, the A-MMSE estimates the channel through a single linear operation for channel estimation, eliminating nonlinear activations during inference and thus reducing computational complexity. To enhance the learning efficiency of the A-MMSE, we develop a two-stage Attention encoder, designed to effectively capture the channel correlation structure. Additionally, a rank-adaptive extension of the proposed A-MMSE allows flexible trade-offs between complexity and channel estimation accuracy. Extensive simulations with 3GPP TDL channel models demonstrate that the proposed A-MMSE consistently outperforms other baseline methods in terms of normalized MSE across a wide range of signal-to-noise ratio (SNR) conditions. In particular, the A-MMSE and its rank-adaptive extension establish a new frontier in the performance-complexity trade-off, providing a powerful yet highly efficient solution for practical channel estimation

Paper number 69:
Title: SIM-Enabled Hybrid Digital-Wave Beamforming for Fronthaul-Constrained Cell-Free Massive MIMO Systems
Authors: Eunhyuk Park, Seok-Hwan Park, Osvaldo Simeone, Marco Di Renzo, Shlomo Shamai
Abstract: As the dense deployment of access points (APs) in cell-free massive multiple-input multiple-output (CF-mMIMO) systems presents significant challenges, per-AP coverage can be expanded using large-scale antenna arrays (LAAs). However, this approach incurs high implementation costs and substantial fronthaul demands due to the need for dedicated RF chains for all antennas. To address these challenges, we propose a hybrid beamforming framework that integrates wave-domain beamforming via stacked intelligent metasurfaces (SIM) with conventional digital processing. By dynamically manipulating electromagnetic waves, SIM-equipped APs enhance beamforming gains while significantly reducing RF chain requirements. We formulate a joint optimization problem for digital and wave-domain beamforming along with fronthaul compression to maximize the weighted sum-rate for both uplink and downlink transmission under finite-capacity fronthaul constraints. Given the high dimensionality and non-convexity of the problem, we develop alternating optimization-based algorithms that iteratively optimize digital and wave-domain variables. Numerical results demonstrate that the proposed hybrid schemes outperform conventional hybrid schemes, that rely on randomly set wave-domain beamformers or restrict digital beamforming to simple power control. Moreover, the proposed scheme employing sufficiently deep SIMs achieves near fully-digital performance with fewer RF chains in the high signal-to-noise ratios regime.

Paper number 70:
Title: A Clinically-Grounded Two-Stage Framework for Renal CT Report Generation
Authors: Renjie Liang, Zhengkang Fan, Jinqian Pan, Chenkun Sun, Bruce Daniel Steinberg, Russell Terry, Jie Xu
Abstract: Objective Renal cancer is a common malignancy and a major cause of cancer-related deaths. Computed tomography (CT) is central to early detection, staging, and treatment planning. However, the growing CT workload increases radiologists' burden and risks incomplete documentation. Automatically generating accurate reports remains challenging because it requires integrating visual interpretation with clinical reasoning. Advances in artificial intelligence (AI), especially large language and vision-language models, offer potential to reduce workload and enhance diagnostic quality. Methods We propose a clinically informed, two-stage framework for automatic renal CT report generation. In Stage 1, a multi-task learning model detects structured clinical features from each 2D image. In Stage 2, a vision-language model generates free-text reports conditioned on the image and the detected features. To evaluate clinical fidelity, generated clinical features are extracted from the reports and compared with expert-annotated ground truth. Results Experiments on an expert-labeled dataset show that incorporating detected features improves both report quality and clinical accuracy. The model achieved an average AUC of 0.75 for key imaging features and a METEOR score of 0.33, demonstrating higher clinical consistency and fewer template-driven errors. Conclusion Linking structured feature detection with conditioned report generation provides a clinically grounded approach to integrate structured prediction and narrative drafting for renal CT reporting. This method enhances interpretability and clinical faithfulness, underscoring the value of domain-relevant evaluation metrics for medical AI development.

Paper number 71:
Title: HANS-Net: Hyperbolic Convolution and Adaptive Temporal Attention for Accurate and Generalizable Liver and Tumor Segmentation in CT Imaging
Authors: Arefin Ittesafun Abian, Ripon Kumar Debnath, Md. Abdur Rahman, Mohaimenul Azam Khan Raiaan, Md Rafiqul Islam, Asif Karim, Reem E. Mohamed, Sami Azam
Abstract: Accurate liver and tumor segmentation on abdominal CT images is critical for reliable diagnosis and treatment planning, but remains challenging due to complex anatomical structures, variability in tumor appearance, and limited annotated data. To address these issues, we introduce Hyperbolic-convolutions Adaptive-temporal-attention with Neural-representation and Synaptic-plasticity Network (HANS-Net), a novel segmentation framework that synergistically combines hyperbolic convolutions for hierarchical geometric representation, a wavelet-inspired decomposition module for multi-scale texture learning, a biologically motivated synaptic plasticity mechanism for adaptive feature enhancement, and an implicit neural representation branch to model fine-grained and continuous anatomical boundaries. Additionally, we incorporate uncertainty-aware Monte Carlo dropout to quantify prediction confidence and lightweight temporal attention to improve inter-slice consistency without sacrificing efficiency. Extensive evaluations of the LiTS dataset demonstrate that HANS-Net achieves a mean Dice score of 93.26%, an IoU of 88.09%, an average symmetric surface distance (ASSD) of 0.72 mm, and a volume overlap error (VOE) of 11.91%. Furthermore, cross-dataset validation on the AMOS 2022 dataset obtains an average Dice of 85.09%, IoU of 76.66%, ASSD of 19.49 mm, and VOE of 23.34%, indicating strong generalization across different datasets. These results confirm the effectiveness and robustness of HANS-Net in providing anatomically consistent, accurate, and confident liver and tumor segmentation.

Paper number 72:
Title: Model-Driven Deep Learning Enhanced Joint Beamforming and Mode Switching for RDARS-Aided MIMO Systems
Authors: Chengwang Ji, Kehui Li, Haiquan Lu, Qiaoyan Peng, Jintao Wang, Feifei Gao, Shaodan Ma
Abstract: Reconfigurable distributed antenna and reflecting surface (RDARS) is a promising architecture for future sixth-generation (6G) wireless networks. In particular, the dynamic working mode configuration for the RDARS-aided system brings an extra selection gain compared to the existing reconfigurable intelligent surface (RIS)-aided system and distributed antenna system (DAS). In this paper, we consider the RDARS-aided downlink multiple-input multiple-output (MIMO) system and aim to maximize the weighted sum rate (WSR) by jointly optimizing the beamforming matrices at the based station (BS) and RDARS, as well as mode switching matrix at RDARS. The optimization problem is challenging to be solved due to the non-convex objective function and mixed integer binary constraint. To this end, a penalty term-based weight minimum mean square error (PWM) algorithm is proposed by integrating the majorization-minimization (MM) and weight minimum mean square error (WMMSE) methods. To further escape the local optimum point in the PWM algorithm, a model-driven DL method is integrated into this algorithm, where the key variables related to the convergence of PWM algorithm are trained to accelerate the convergence speed and improve the system performance. Simulation results are provided to show that the PWM-based beamforming network (PWM-BFNet) can reduce the number of iterations by half and achieve performance improvements of 26.53% and 103.2% at the scenarios of high total transmit power and a large number of RDARS transmit elements (TEs), respectively.

Paper number 73:
Title: A predictive modular approach to constraint satisfaction under uncertainty - with application to glycosylation in continuous monoclonal antibody biosimilar production
Authors: Yu Wang, Xiao Chen, Hubert Schwarz, Véronique Chotteau, Elling W. Jacobsen
Abstract: The paper proposes a modular-based approach to constraint handling in process optimization and control. This is partly motivated by the recent interest in learning-based methods, e.g., within bioproduction, for which constraint handling under uncertainty is a challenge. The proposed constraint handler, called predictive filter, is combined with an adaptive constraint margin and a constraint violation cost monitor to minimize the cost of violating soft constraints due to model uncertainty and disturbances. The module can be combined with any controller and is based on minimally modifying the controller output, in a least squares sense, such that constraints are satisfied within the considered horizon. The proposed method is computationally efficient and suitable for real-time applications. The effectiveness of the method is illustrated through a realistic simulation case study of glycosylation constraint satisfaction in continuous monoclonal antibody biosimilar production using Chinese hamster ovary cells, for which the metabolic network model consists of 23 extracellular metabolites and 126 reactions.

Paper number 74:
Title: Pinhole Effect on Linkability and Dispersion in Speaker Anonymization
Authors: Kong Aik Lee, Zeyan Liu, Liping Chen, Zhenhua Ling
Abstract: Speaker anonymization aims to conceal speaker-specific attributes in speech signals, making the anonymized speech unlinkable to the original speaker identity. Recent approaches achieve this by disentangling speech into content and speaker components, replacing the latter with pseudo speakers. The anonymized speech can be mapped either to a common pseudo speaker shared across utterances or to distinct pseudo speakers unique to each utterance. This paper investigates the impact of these mapping strategies on three key dimensions: speaker linkability, dispersion in the anonymized speaker space, and de-identification from the original identity. Our findings show that using distinct pseudo speakers increases speaker dispersion and reduces linkability compared to common pseudo-speaker mapping, thereby enhancing privacy preservation. These observations are interpreted through the proposed pinhole effect, a conceptual framework introduced to explain the relationship between mapping strategies and anonymization performance. The hypothesis is validated through empirical evaluation.

Paper number 75:
Title: NEFT: A Unified Transformer Framework for Efficient Near-Field CSI Feedback in XL-MIMO Systems
Authors: Haiyang Li, Tianqi Mao, Pengyu Wang, Ruiqi Liu, Shunyu Li, Zhaocheng Wang
Abstract: Extremely large-scale multiple-input multiple-output (XL-MIMO) systems, operating in the near-field region due to their massive antenna arrays, are key enablers of next-generation wireless communications but face significant challenges in channel state information (CSI) feedback. Deep learning has emerged as a powerful tool by learning compact CSI representations for feedback. However, existing methods struggle to capture the intricate structure of near-field CSI and incur prohibitive computational overhead on practical mobile devices. To overcome these limitations, we propose the Near-Field Efficient Feedback Transformer (NEFT) family for accurate and efficient near-field CSI feedback across diverse hardware platforms. Built on a hierarchical Vision Transformer backbone, NEFT is extended with lightweight variants to meet various deployment constraints: NEFT-Compact applies multi-level knowledge distillation (KD) to reduce complexity while maintaining accuracy, whereas NEFT-Hybrid and NEFT-Edge address encoder- and edge-constrained scenarios via attention-free encoding and KD. Extensive simulations show that NEFT achieves a 15--21 dB improvement in normalized mean-squared error (NMSE) over state-of-the-art methods, while NEFT-Compact and NEFT-Edge reduce total FLOPs by 25--36% with negligible accuracy loss. Moreover, NEFT-Hybrid reduces encoder-side complexity by up to 64%, enabling deployment in highly asymmetric device scenarios. These results establish NEFT as a practical and scalable solution for near-field CSI feedback in XL-MIMO systems.

Paper number 76:
Title: Sensing-Secure ISAC: Ambiguity Function Engineering for Impairing Unauthorized Sensing
Authors: Kawon Han, Kaitao Meng, Christos Masouros
Abstract: The deployment of integrated sensing and communication (ISAC) brings along unprecedented vulnerabilities to authorized sensing, necessitating the development of secure solutions. Sensing parameters are embedded within the target-reflected signal leaked to unauthorized passive radar sensing eavesdroppers (Eve), implying that they can silently extract sensory information without prior knowledge of the information data. To overcome this limitation, we propose a sensing-secure ISAC framework that ensures secure target detection and estimation for the legitimate system, while obfuscating unauthorized sensing without requiring any prior knowledge of Eve. By introducing artificial imperfections into the ambiguity function (AF) of ISAC signals, we introduce artificial targets into Eve's range profile which increase its range estimation ambiguity. In contrast, the legitimate sensing receiver (Alice) can suppress these AF artifacts using mismatched filtering, albeit at the expense of signal-to-noise ratio (SNR) loss. Employing an OFDM signal, a structured subcarrier power allocation scheme is designed to shape the secure autocorrelation function (ACF), inserting periodic peaks to mislead Eve's range estimation and degrade target detection performance. To quantify the sensing security, we introduce peak sidelobe level (PSL) and integrated sidelobe level (ISL) as key performance metrics. Then, we analyze the three-way trade-offs between communication, legitimate sensing, and sensing security, highlighting the impact of the proposed sensing-secure ISAC signaling on system performance. We formulate a convex optimization problem to maximize ISAC performance while guaranteeing a certain sensing security level. Numerical results validate the effectiveness of the proposed sensing-secure ISAC signaling, demonstrating its ability to degrade Eve's target estimation while preserving Alice's performance.

Paper number 77:
Title: Time-causal and time-recursive wavelets
Authors: Tony Lindeberg
Abstract: When to apply wavelet analysis to real-time temporal signals, where the future cannot be accessed, it is essential to base all the steps in the signal processing pipeline on computational mechanisms that are truly time-causal. This paper describes how a time-causal wavelet analysis can be performed based on concepts developed in the area of temporal scale-space theory, originating from a complete classification of temporal smoothing kernels that guarantee non-creation of new structures from finer to coarser temporal scale levels. By necessity, convolution with truncated exponential kernels in cascade constitutes the only permissable class of kernels, as well as their temporal derivatives as a natural complement to fulfil the admissibility conditions of wavelet representations. For a particular way of choosing the time constants in the resulting infinite convolution of truncated exponential kernels, to ensure temporal scale covariance and thus self-similarity over temporal scales, we describe how mother wavelets can be chosen as temporal derivatives of the resulting time-causal limit kernel. By developing connections between wavelet theory and scale-space theory, we characterize and quantify how the continuous scaling properties transfer to the discrete implementation, demonstrating how the proposed time-causal wavelet representation can reflect the duration of locally dominant temporal structures in the input signals. We propose that this notion of time-causal wavelet analysis could be a valuable tool for signal processing tasks, where streams of signals are to be processed in real time, specifically for signals that may contain local variations over a rich span of temporal scales, or more generally for analysing physical or biophysical temporal phenomena, where a fully time-causal analysis is called for to be physically realistic.

Paper number 78:
Title: Bit Allocation Transfer for Perceptual Quality Enhancement of VVC Intra Coding
Authors: Runyu Yang, Ivan V. Bajić
Abstract: Mainstream image and video coding standards -- including state-of-the-art codecs like H.266/VVC, AVS3, and AV1 -- adopt a block-based hybrid coding framework. While this framework facilitates straightforward optimization for Peak Signal-to-Noise Ratio (PSNR), it struggles to effectively optimize perceptually-aligned metrics such as Multi-Scale Structural Similarity (MS-SSIM). To address this challenge, this paper proposes a low-complexity method to enhance perceptual quality in VVC intra coding by transferring bit allocation knowledge from end-to-end image compression. We introduce a lightweight model trained with perceptual losses to generate a quantization step map. This map implicitly captures block-level perceptual importance, enabling efficient derivation of a QP map for VVC. Experiments on Kodak and CLIC datasets demonstrate significant advantages, both in execution time and perceptual metric performance, with more than 11% BD-rate reduction in terms of MS-SSIM. Our scheme provides an efficient, practical pathway for perceptual enhancement of traditional codecs.

Paper number 79:
Title: DiSTAR: Diffusion over a Scalable Token Autoregressive Representation for Speech Generation
Authors: Yakun Song, Xiaobin Zhuang, Jiawei Chen, Zhikang Niu, Guanrou Yang, Chenpeng Du, Dongya Jia, Zhuo Chen, Yuping Wang, Yuxuan Wang, Xie Chen
Abstract: Recent attempts to interleave autoregressive (AR) sketchers with diffusion-based refiners over continuous speech representations have shown promise, but they remain brittle under distribution shift and offer limited levers for controllability. We introduce DISTAR, a zero-shot text-to-speech framework that operates entirely in a discrete residual vector quantization (RVQ) code space and tightly couples an AR language model with a masked diffusion model, without forced alignment or a duration predictor. Concretely, DISTAR drafts block-level RVQ tokens with an AR language model and then performs parallel masked-diffusion infilling conditioned on the draft to complete the next block, yielding long-form synthesis with blockwise parallelism while mitigating classic AR exposure bias. The discrete code space affords explicit control at inference: DISTAR produces high-quality audio under both greedy and sample-based decoding using classifier-free guidance, supports trade-offs between robustness and diversity, and enables variable bit-rate and controllable computation via RVQ layer pruning at test time. Extensive experiments and ablations demonstrate that DISTAR surpasses state-of-the-art zero-shot TTS systems in robustness, naturalness, and speaker/style consistency, while maintaining rich output diversity. Audio samples are provided on this https URL.

Paper number 80:
Title: Symmetric Rank-$1$ Regularization for Iterative Inversion of Ill-Conditioned MIMO Channels
Authors: Jinfei Wang, Yi Ma, Rahim Tafazolli
Abstract: While iterative matrix inversion methods excel in computational efficiency, memory optimization, and support for parallel and distributed computing when managing large matrices, their limitations are also evident in multiple-input multiple-output (MIMO) fading channels. These methods encounter challenges related to slow convergence and diminished accuracy, especially in ill-conditioned scenarios, hindering their application in future MIMO networks such as extra-large aperture array. To address these challenges, this paper proposes a novel matrix regularization method termed symmetric rank-$1$ regularization (SR-$1$R). The proposed method functions by augmenting the channel matrix with a symmetric rank-$1$ matrix, with the primary goal of minimizing the condition number of the resultant regularized matrix. This significantly improves the matrix condition, enabling fast and accurate iterative inversion of the regularized matrix. Then, the inverse of the original channel matrix is obtained by applying the Sherman-Morrison transform on the outcome of iterative inversions. Our eigenvalue analysis unveils the best channel condition that can be achieved by an optimized SR-$1$R matrix. Moreover, a power iteration-assisted (PIA) approach is proposed to find the optimum SR-$1$R matrix without need of eigenvalue decomposition. The proposed approach exhibits logarithmic algorithm-depth in parallel computing for MIMO precoding. Finally, computer simulations demonstrate that SR-$1$R has the potential to reduce the required iteration by up to $35\%$ while achieving the performance of regularized zero-forcing.

Paper number 81:
Title: A Survey and Future Outlook on Indoor Location Fingerprinting Privacy Preservation
Authors: Amir Fathalizadeh, Vahideh Moghtadaiee, Mina Alishahi
Abstract: The pervasive integration of Indoor Positioning Systems (IPS) arises from the limitations of Global Navigation Satellite Systems (GNSS) in indoor environments, leading to the widespread adoption of Location-Based Services (LBS) in places such as shopping malls, airports, hospitals, museums, corporate campuses, and smart buildings. Specifically, indoor location fingerprinting (ILF) systems employ diverse signal fingerprints from user devices, enabling precise location identification by Location Service Providers (LSP). Despite its broad applications across various domains, ILF introduces a notable privacy risk, as both LSP and potential adversaries inherently have access to this sensitive information, compromising users' privacy. Consequently, concerns regarding privacy vulnerabilities in this context necessitate a focused exploration of privacy-preserving mechanisms. In response to these concerns, this survey presents a comprehensive review of Indoor Location Fingerprinting Privacy-Preserving Mechanisms (ILFPPM) based on cryptographic, anonymization, differential privacy (DP), and federated learning (FL) techniques. We also propose a distinctive and novel grouping of privacy vulnerabilities, adversary models, privacy attacks, and evaluation metrics specific to ILF systems. Given the identified limitations and research gaps in this survey, we highlight numerous prospective opportunities for future investigation, aiming to motivate researchers interested in advancing ILF systems. This survey constitutes a valuable reference for researchers and provides a clear overview for those beyond this specific research domain. To further help the researchers, we have created an online resource repository, which can be found at \href{this https URL}{this https URL}.

Paper number 82:
Title: Generating High Dimensional User-Specific Wireless Channels using Diffusion Models
Authors: Taekyun Lee, Juseong Park, Hyeji Kim, Jeffrey G. Andrews
Abstract: Deep neural network (DNN)-based algorithms are emerging as an important tool for many physical and MAC layer functions in future wireless communication systems, including for large multi-antenna channels. However, training such models typically requires a large dataset of high-dimensional channel measurements, which are very difficult and expensive to obtain. This paper introduces a novel method for generating synthetic wireless channel data using diffusion-based models to produce user-specific channels that accurately reflect real-world wireless environments. Our approach employs a conditional denoising diffusion implicit model (cDDIM) framework, effectively capturing the relationship between user location and multi-antenna channel characteristics. We generate synthetic high fidelity channel samples using user positions as conditional inputs, creating larger augmented datasets to overcome measurement scarcity. The utility of this method is demonstrated through its efficacy in training various downstream tasks such as channel compression and beam alignment. Our diffusion-based augmentation approach achieves over a 1-2 dB gain in NMSE for channel compression, and an 11dB SNR boost in beamforming compared to prior methods, such as noise addition or the use of generative adversarial networks (GANs).

Paper number 83:
Title: BlueME: Robust Underwater Robot-to-Robot Communication Using Compact Magnetoelectric Antennas
Authors: Mehron Talebi, Sultan Mahmud, Adam Khalifa, Md Jahidul Islam
Abstract: We present the design, development, and experimental validation of BlueME, a compact magnetoelectric (ME) antenna array system for underwater robot-to-robot communication. BlueME employs ME antennas operating at their natural mechanical resonance frequency to efficiently transmit and receive very-low-frequency (VLF) electromagnetic signals underwater. We outline the design, simulation, fabrication, and integration of the proposed system on low-power embedded platforms, focusing on portable and scalable applications. For performance evaluation, we deployed BlueME on an autonomous surface vehicle (ASV) and a remotely operated vehicle (ROV) in open-water field trials. Ocean trials demonstrate that BlueME maintains reliable signal transmission at distances beyond 700 meters while consuming only 10 watts of power. Field trials show that the system operates effectively in challenging underwater conditions such as turbidity, obstacles, and multipath interference -- conditions that generally affect acoustics and optics. Our analysis also examines the impact of complete submersion on system performance and identifies key deployment considerations. This work represents the first practical underwater deployment of ME antennas outside the laboratory and implements the largest VLF ME array system to date. BlueME demonstrates significant potential for marine robotics and automation in multi-robot cooperative systems and remote sensor networks.

Paper number 84:
Title: An AI-Driven Multimodal Smart Home Platform for Continuous Monitoring and Assistance in Post-Stroke Motor Impairment
Authors: Chenyu Tang, Ruizhi Zhang, Shuo Gao, Zihe Zhao, Zibo Zhang, Jiaqi Wang, Cong Li, Junliang Chen, Yanning Dai, Shengbo Wang, Ruoyu Juan, Qiaoying Li, Ruimou Xie, Xuhang Chen, Xinkai Zhou, Yunjia Xia, Jianan Chen, Fanghao Lu, Xin Li, Ninglli Wang, Peter Smielewski, Yu Pan, Hubin Zhao, Luigi G. Occhipinti
Abstract: At-home rehabilitation for post-stroke patients presents significant challenges, as continuous, personalized care is often limited outside clinical settings. Moreover, the lack of integrated solutions capable of simultaneously monitoring motor recovery and providing intelligent assistance in home environments hampers rehabilitation outcomes. Here, we present a multimodal smart home platform designed for continuous, at-home rehabilitation of post-stroke patients, integrating wearable sensing, ambient monitoring, and adaptive automation. A plantar pressure insole equipped with a machine learning pipeline classifies users into motor recovery stages with up to 94\% accuracy, enabling quantitative tracking of walking patterns during daily activities. An optional head-mounted eye-tracking module, together with ambient sensors such as cameras and microphones, supports seamless hands-free control of household devices with a 100\% success rate and sub-second response time. These data streams are fused locally via a hierarchical Internet of Things (IoT) architecture, ensuring low latency and data privacy. An embedded large language model (LLM) agent, Auto-Care, continuously interprets multimodal data to provide real-time interventions -- issuing personalized reminders, adjusting environmental conditions, and notifying caregivers. Implemented in a post-stroke context, this integrated smart home platform increased mean user satisfaction from 3.9 $\pm$ 0.8 in conventional home environments to 8.4 $\pm$ 0.6 with the full system ($n=20$). Beyond stroke, the system offers a scalable, patient-centered framework with potential for long-term use in broader neurorehabilitation and aging-in-place applications.

Paper number 85:
Title: Inferring Foresightedness in Dynamic Noncooperative Games
Authors: Cade Armstrong, Ryan Park, Xinjie Liu, Kushagra Gupta, David Fridovich-Keil
Abstract: Dynamic game theory is an increasingly popular tool for modeling multi-agent, e.g. human-robot, interactions. Game-theoretic models presume that each agent wishes to minimize a private cost function that depends on others' actions. These games typically evolve over a fixed time horizon, specifying how far into the future each agent plans. In practical settings, however, decision-makers may vary in foresightedness, or how much they care about their current cost in relation to their past and future costs. We conjecture that quantifying and estimating each agent's foresightedness from online data will enable safer and more efficient interactions with other agents. To this end, we frame this inference problem as an inverse dynamic game. We consider a specific objective function parametrization that smoothly interpolates myopic and farsighted planning. Games of this form are readily transformed into parametric mixed complementarity problems; we exploit the directional differentiability of solutions to these problems with respect to their hidden parameters to solve for agents' foresightedness. We conduct three experiments: one with synthetically generated delivery robot motion, one with real-world data involving people walking, biking, and driving vehicles, and one using high-fidelity simulators. The results of these experiments demonstrate that explicitly inferring agents' foresightedness enables game-theoretic models to make 33% more accurate models for agents' behavior.

Paper number 86:
Title: Tokenizing Single-Channel EEG with Time-Frequency Motif Learning
Authors: Jathurshan Pradeepkumar, Xihao Piao, Zheng Chen, Jimeng Sun
Abstract: Foundation models are reshaping EEG analysis, yet an important problem of EEG tokenization remains a challenge. This paper presents TFM-Tokenizer, a novel tokenization framework that learns a vocabulary of time-frequency motifs from single-channel EEG signals and encodes them into discrete tokens. We propose a dual-path architecture with time-frequency masking to capture robust motif representations, and it is model-agnostic, supporting both lightweight transformers and existing foundation models for downstream tasks. Our study demonstrates three key benefits: Accuracy: Experiments on four diverse EEG benchmarks demonstrate consistent performance gains across both single- and multi-dataset pretraining settings, achieving up to 17% improvement in Cohen's Kappa over strong baselines. Generalization: Moreover, as a plug-and-play component, it consistently boosts the performance of diverse foundation models, including BIOT and LaBraM. Scalability: By operating at the single-channel level rather than relying on the strict 10-20 EEG system, our method has the potential to be device-agnostic. Experiments on ear-EEG sleep staging, which differs from the pretraining data in signal format, channel configuration, recording device, and task, show that our tokenizer outperforms baselines by 14%. A comprehensive token analysis reveals strong class-discriminative, frequency-aware, and consistent structure, enabling improved representation quality and interpretability. Code is available at this https URL.

Paper number 87:
Title: Offline Reinforcement Learning via Inverse Optimization
Authors: Ioannis Dimanidis, Tolga Ok, Peyman Mohajerin Esfahani
Abstract: Inspired by the recent successes of Inverse Optimization (IO) across various application domains, we propose a novel offline Reinforcement Learning (ORL) algorithm for continuous state and action spaces, leveraging the convex loss function called ``sub-optimality loss" from the IO literature. To mitigate the distribution shift commonly observed in ORL problems, we further employ a robust and non-causal Model Predictive Control (MPC) expert steering a nominal model of the dynamics using in-hindsight information stemming from the model mismatch. Unlike the existing literature, our robust MPC expert enjoys an exact and tractable convex reformulation. In the second part of this study, we show that the IO hypothesis class, trained by the proposed convex loss function, enjoys ample expressiveness and achieves competitive performance comparing with the state-of-the-art (SOTA) methods in the low-data regime of the MuJoCo benchmark while utilizing three orders of magnitude fewer parameters, thereby requiring significantly fewer computational resources. To facilitate the reproducibility of our results, we provide an open-source package implementing the proposed algorithms and the experiments.

Paper number 88:
Title: MetaQAP - A Meta-Learning Approach for Quality-Aware Pretraining in Image Quality Assessment
Authors: Nisar Ahmed, Gulshan Saleem, Nazik Alturki, Nada Alasbali
Abstract: Image Quality Assessment (IQA) is a critical task in a wide range of applications but remains challenging due to the subjective nature of human perception and the complexity of real-world image distortions. This study proposes MetaQAP, a novel no-reference IQA model designed to address these challenges by leveraging quality-aware pre-training and meta-learning. The model performs three key contributions: pre-training Convolutional Neural Networks (CNNs) on a quality-aware dataset, implementing a quality-aware loss function to optimize predictions, and integrating a meta-learner to form an ensemble model that effectively combines predictions from multiple base models. Experimental evaluations were conducted on three benchmark datasets: LiveCD, KonIQ-10K, and BIQ2021. The proposed MetaQAP model achieved exceptional performance with Pearson Linear Correlation Coefficient (PLCC) and Spearman Rank Order Correlation Coefficient (SROCC) scores of 0.9885/0.9812 on LiveCD, 0.9702/0.9658 on KonIQ-10K, and 0.884/0.8765 on BIQ2021, outperforming existing IQA methods. Cross-dataset evaluations further demonstrated the generalizability of the model, with PLCC and SROCC scores ranging from 0.6721 to 0.8023 and 0.6515 to 0.7805, respectively, across diverse datasets. The ablation study confirmed the significance of each model component, revealing substantial performance degradation when critical elements such as the meta-learner or quality-aware loss function were omitted. MetaQAP not only addresses the complexities of authentic distortions but also establishes a robust and generalizable framework for practical IQA applications. By advancing the state-of-the-art in no-reference IQA, this research provides valuable insights and methodologies for future improvements and extensions in the field.

Paper number 89:
Title: Towards Inclusive Communication: A Unified Framework for Generating Spoken Language from Sign, Lip, and Audio
Authors: Jeong Hun Yeo, Hyeongseop Rha, Sungjune Park, Junil Won, Yong Man Ro
Abstract: Audio is the primary modality for human communication and has driven the success of Automatic Speech Recognition (ASR) technologies. However, such audio-centric systems inherently exclude individuals who are deaf or hard of hearing. Visual alternatives such as sign language and lip reading offer effective substitutes, and recent advances in Sign Language Translation (SLT) and Visual Speech Recognition (VSR) have improved audio-less communication. Yet, these modalities have largely been studied in isolation, and their integration within a unified framework remains underexplored. In this paper, we propose the first unified framework capable of handling diverse combinations of sign language, lip movements, and audio for spoken-language text generation. We focus on three main objectives: (i) designing a unified, modality-agnostic architecture capable of effectively processing heterogeneous inputs; (ii) exploring the underexamined synergy among modalities, particularly the role of lip movements as non-manual cues in sign language comprehension; and (iii) achieving performance on par with or superior to state-of-the-art models specialized for individual tasks. Building on this framework, we achieve performance on par with or better than task-specific state-of-the-art models across SLT, VSR, ASR, and Audio-Visual Speech Recognition. Furthermore, our analysis reveals a key linguistic insight: explicitly modeling lip movements as a distinct modality significantly improves SLT performance by capturing critical non-manual cues.

Paper number 90:
Title: Differentiable-by-design Nonlinear Optimization for Model Predictive Control
Authors: Riccardo Zuliani, Efe Balta, John Lygeros
Abstract: Nonlinear optimization-based control policies, such as those those arising in nonlinear Model Predictive Control, have seen remarkable success in recent years. These policies require solving computationally demanding nonlinear optimization programs online at each time-step. The resulting solution map, viewed as a function of the measured state of the system and design parameters, may not be differentiable, which poses significant challenges if the control policy is embedded in a gradient-based policy optimization scheme. We propose a principled way to regularize the nonlinear optimization problem, obtaining a surrogate derivative even if when the original problem is not differentiable. The surrogate problem is differentiable by design and its solution map coincides with the solution of the unregularized problem. We demonstrate the effectiveness of our approach in a free-final-time optimal control problem and a receding-horizon nonlinear MPC example.

Paper number 91:
Title: A Faster and More Reliable Middleware for Autonomous Driving Systems
Authors: Yuankai He, Weisong Shi
Abstract: Ensuring safety in high-speed autonomous vehicles requires rapid control loops and tightly bounded delays from perception to actuation. Many open-source autonomy systems rely on ROS 2 middleware; when multiple sensor and control nodes share one compute unit, ROS 2 and its DDS transports add significant (de)serialization, copying, and discovery overheads, shrinking the available time budget. We present Sensor-in-Memory (SIM), a shared-memory transport designed for intra-host pipelines in autonomous vehicles. SIM keeps sensor data in native memory layouts (e.g., cv::Mat, PCL), uses lock-free bounded double buffers that overwrite old data to prioritize freshness, and integrates into ROS 2 nodes with four lines of code. Unlike traditional middleware, SIM operates beside ROS 2 and is optimized for applications where data freshness and minimal latency outweigh guaranteed completeness. SIM provides sequence numbers, a writer heartbeat, and optional checksums to ensure ordering, liveness, and basic integrity. On an NVIDIA Jetson Orin Nano, SIM reduces data-transport latency by up to 98% compared to ROS 2 zero-copy transports such as FastRTPS and Zenoh, lowers mean latency by about 95%, and narrows 95th/99th-percentile tail latencies by around 96%. In tests on a production-ready Level 4 vehicle running this http URL, SIM increased localization frequency from 7.5 Hz to 9.5 Hz. Applied across all latency-critical modules, SIM cut average perception-to-decision latency from 521.91 ms to 290.26 ms, reducing emergency braking distance at 40 mph (64 km/h) on dry concrete by 13.6 ft (4.14 m).
    