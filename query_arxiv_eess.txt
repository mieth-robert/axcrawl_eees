
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: The establishment of static digital humans and the integration with spinal models
Authors: Fujiao Ju, Yuxuan Wang, Shuo Wang, Chengyin Wang, Yinbo Chen, Jianfeng Li, Mingjie Dong, Bin Fang, Qianyu Zhuang
Abstract: Adolescent idiopathic scoliosis (AIS), a prevalent spinal deformity, significantly affects individuals' health and quality of life. Conventional imaging techniques, such as X - rays, computed tomography (CT), and magnetic resonance imaging (MRI), offer static views of the spine. However, they are restricted in capturing the dynamic changes of the spine and its interactions with overall body motion. Therefore, developing new techniques to address these limitations has become extremely important. Dynamic digital human modeling represents a major breakthrough in digital medicine. It enables a three - dimensional (3D) view of the spine as it changes during daily activities, assisting clinicians in detecting deformities that might be missed in static imaging. Although dynamic modeling holds great potential, constructing an accurate static digital human model is a crucial initial step for high - precision simulations. In this study, our focus is on constructing an accurate static digital human model integrating the spine, which is vital for subsequent dynamic digital human research on AIS. First, we generate human point - cloud data by combining the 3D Gaussian method with the Skinned Multi - Person Linear (SMPL) model from the patient's multi - view images. Then, we fit a standard skeletal model to the generated human model. Next, we align the real spine model reconstructed from CT images with the standard skeletal model. We validated the resulting personalized spine model using X - ray data from six AIS patients, with Cobb angles (used to measure the severity of scoliosis) as evaluation metrics. The results indicate that the model's error was within 1 degree of the actual measurements. This study presents an important method for constructing digital humans.

Paper number 2:
Title: Automatic Prostate Volume Estimation in Transabdominal Ultrasound Images
Authors: Tiziano Natali, Liza M. Kurucz, Matteo Fusaglia, Laura S. Mertens, Theo J.M. Ruers, Pim J. van Leeuwen, Behdad Dashtbozorg
Abstract: Prostate cancer is a leading health concern among men, requiring accurate and accessible methods for early detection and risk stratification. Prostate volume (PV) is a key parameter in multivariate risk stratification for early prostate cancer detection, commonly estimated using transrectal ultrasound (TRUS). While TRUS provides precise prostate volume measurements, its invasive nature often compromises patient comfort. Transabdominal ultrasound (TAUS) provides a non-invasive alternative but faces challenges such as lower image quality, complex interpretation, and reliance on operator expertise. This study introduces a new deep-learning-based framework for automatic PV estimation using TAUS, emphasizing its potential to enable accurate and non-invasive prostate cancer risk stratification. A dataset of TAUS videos from 100 individual patients was curated, with manually delineated prostate boundaries and calculated diameters by an expert clinician as ground truth. The introduced framework integrates deep-learning models for prostate segmentation in both axial and sagittal planes, automatic prostate diameter estimation, and PV calculation. Segmentation performance was evaluated using Dice correlation coefficient (%) and Hausdorff distance (mm). Framework's volume estimation capabilities were evaluated on volumetric error (mL). The framework demonstrates that it can estimate PV from TAUS videos with a mean volumetric error of -5.5 mL, which results in an average relative error between 5 and 15%. The introduced framework for automatic PV estimation from TAUS images, utilizing deep learning models for prostate segmentation, shows promising results. It effectively segments the prostate and estimates its volume, offering potential for reliable, non-invasive risk stratification for early prostate detection.

Paper number 3:
Title: Design and Implementation of Scalable Communication Interfaces for Reliable and Stable Real-time Co-Simulation of Power Systems
Authors: Qi Xiao, Jongha Woo, Lidong Song, Ning Lu, Victor Paduani
Abstract: Co-simulation offers an integrated approach for modeling the large-scale integration of inverter-based resources (IBRs) into transmission and distribution grids. This paper presents a scalable communication interface design and implementation to enable reliable and stable real-time co-simulation of power systems with high IBR penetration. The communication interface is categorized into two types: local and remote. In local scenarios, where subsystems are connected within a single local area network (LAN), low-latency communication facilitates the seamless integration of electromagnetic transient (EMT) and phasor-domain models, enabling efficient interactions with power and energy management algorithms. For remote scenarios, data exchange is achieved via internet-based file sharing or VPN-enabled communication. The performance of both methods is evaluated using OPAL-RT as a real-time simulator, demonstrating scalability, effectiveness, and challenges specific to real-time co-simulation applications. To mitigate instability arising from data resolution mismatches in time-sensitive co-simulations, a real-time data extrapolation method is proposed. This approach significantly enhances stability and reliability, ensuring more accurate simulation outcomes. The implementation code is available on GitHub, providing researchers the tools to replicate and expand upon this work.

Paper number 4:
Title: Performance Analysis of Infrastructure Sharing Techniques in Cellular Networks: A Percolation Theory Approach
Authors: Hao Lin, Mustafa A. Kishk, Mohamed-Slim Alouini
Abstract: In the context of 5G, infrastructure sharing has been identified as a potential solution to reduce the investment costs of cellular networks. In particular, it can help low-income regions build 5G networks more affordably and further bridge the digital divide. There are two main kinds of infrastructure sharing: passive sharing (i.e. site sharing) and active sharing (i.e. access sharing), which require mobile network operators (MNOs) to share their non-electronic elements or electronic elements, respectively. Because co-construction and sharing can achieve broader coverage with lower investment, through percolation theory, we investigate how different sharing strategies can deliver large-scale continuous services. First, we examine the percolation characteristics in signal-to-interference-plus-noise ratio (SINR) coverage graphs and the necessary conditions for percolation. Second, we propose an 'average coverage radius' to approximate the SINR graph with a low base station (BS) density based on the Gilbert disk model. Finally, we estimate the critical conditions of BS densities of MNOs for different sharing strategies and compare the percolation probabilities under different infrastructure sharing strategies.

Paper number 5:
Title: Global Convergence of ESPRIT with Preconditioned First-Order Methods for Spike Deconvolution
Authors: Joseph Gabet, Meghna Kalra, Maxime Ferreira Da Costa, Kiryung Lee
Abstract: Spike deconvolution is the problem of recovering point sources from their convolution with a known point spread function, playing a fundamental role in many sensing and imaging applications. This paper proposes a novel approach combining ESPRIT with Preconditioned Gradient Descent (PGD) to estimate the amplitudes and locations of the point sources by a non-linear least squares. The preconditioning matrices are adaptively designed to account for variations in the learning process, ensuring a proven super-linear convergence rate. We provide local convergence guarantees for PGD and performance analysis of ESPRIT reconstruction, leading to global convergence guarantees for our method in one-dimensional settings with multiple snapshots, demonstrating its robustness and effectiveness. Numerical simulations corroborate the performance of the proposed approach for spike deconvolution.

Paper number 6:
Title: Continuous-Aperture Array Based OAM High-Capacity Communication For Metaverse
Authors: Hongyun Jin, Wenchi Cheng, Jingqing Wang, Wei Zhang
Abstract: The extensive data interaction demands of an immersive metaverse necessitate the adoption of emerging technologies to enable high-capacity communication. Vortex electromagnetic waves with different orbital angular momentum (OAM) modes are spatially orthogonal, providing a novel spatial multiplexing dimension to achieve high-capacity communication. However, the number of orthogonal OAM modes based on a discrete uniform circular array (UCA) is limited by the number of array elements in the UCA, and traditional discrete channel models are unable to accurately capture the physical properties of vortex electromagnetic wave propagation. The continuous-aperture array (CAPA) is composed of densely packed electromagnetic excitation elements, capable of flexibly and efficiently generating the desired surface currents to produce an arbitrary number of mutually orthogonal OAM modes. From the perspective of electromagnetic information theory (EIT), we propose a CAPA-based OAM orthogonal transmission scheme to realize high-capacity communication. We design the surface currents of the CAPA using Fourier basis functions, derive the electromagnetic channel for vortex electromagnetic waves, and investigate the upper bound of the spectrum efficiency for CAPA-based OAM orthogonal transmission. This paper establishes a theoretical foundation for applying EIT to the orthogonal transmission of vortex electromagnetic waves, offering a novel solution for achieving CAPA-based efficient and high-capacity communication.

Paper number 7:
Title: Control Barrier Function-Based Quadratic Programming for SafeOperation of Tethered UAVs
Authors: Samuel O. Folorunsho, Maggi Ni, William R. Norris
Abstract: Consider an unmanned aerial vehicle (UAV) physically connected to the ground station with a tether operating in a space, tasked with performing precise maneuvers while constrained by the physical limitation of its tether, which prevents it from flying beyond a maximum allowable length. Violating this tether constraint could lead to system failure or operational hazards, making it essential to enforce safety constraints dynamically while ensuring the drone can track desired trajectories accurately. This paper presents a Control Barrier Function Quadratic Programming Framework (CBF-QP) for ensuring the safe and efficient operation of tethered unmanned aerial vehicles (TUAVs). The framework leverages nominal backstepping control to achieve trajectory tracking, augmented with control barrier functions to ensure compliance with the tether constraint. In this proposed method, the tether constraint is directly embedded in the control design and therefore guarantees the TUAV remains within a predefined operational region defined by the maximum tether length while achieving precise trajectory tracking. The effectiveness of the proposed framework is validated through simulations involving set-point tracking, dynamic trajectory following, and disturbances such as incorrect user inputs. The results demonstrate that the TUAV respects the tether constraint ||x(t)||</= Lmax, with tracking errors converging to zero and the control input remaining bounded.

Paper number 8:
Title: Can TDD Be Employed in LEO SatCom Systems? Challenges and Potential Approaches
Authors: Hyunwoo Lee, Ian P. Roberts, Jehyun Heo, Joohyun Son, Hanwoong Kim, Yunseo Lee, Daesik Hong
Abstract: Frequency-division duplexing (FDD) remains the de facto standard in modern low Earth orbit (LEO) satellite communication (SatCom) systems, such as SpaceX's Starlink, OneWeb, and Amazon's Project Kuiper. While time-division duplexing (TDD) is often regarded as superior in today's terrestrial networks, its viability in future LEO SatCom systems remains unclear. This article details how the long propagation delays and high orbital velocities exhibited by LEO SatCom systems impedes the adoption of TDD, due to challenges involving the frame structure and synchronization. We then present potential approaches to overcome these challenges, which vary in terms of resource efficiency and operational/device complexity and thus would likely be application-specific. We conclude by assessing the performance of these proposed approaches, putting into perspective the tradeoff between complexity and performance gains over FDD. Overall, this article aims to motivate future investigation into the prospects of TDD in LEO SatCom systems and solutions to enable such, with the goal of enhancing future systems and unifying them with terrestrial networks.

Paper number 9:
Title: Sparse wavefield reconstruction and denoising with boostlets
Authors: Elias Zea, Marco Laudato, Joakim andén
Abstract: Boostlets are spatiotemporal functions that decompose nondispersive wavefields into a collection of localized waveforms parametrized by dilations, hyperbolic rotations, and translations. We study the sparsity properties of boostlets and find that the resulting decompositions are significantly sparser than those of other state-of-the-art representation systems, such as wavelets and shearlets. This translates into improved denoising performance when hard-thresholding the boostlet coefficients. The results suggest that boostlets offer a natural framework for sparsely decomposing wavefields in unified space-time.

Paper number 10:
Title: MovISAC: Coherent Imaging of Moving Targets with Distributed Asynchronous ISAC Devices
Authors: Jacopo Pegoraro, Dario Tagliaferri, Joerg Widmer
Abstract: Distributed integrated sensing and communication (ISAC) devices can overcome the traditional resolution limitations imposed by the signal bandwidth, cooperating to produce high-resolution images of the environment. However, existing phase-coherent imaging approaches are not suited to imaging multiple moving targets, since the Doppler effect causes a phase rotation that degrades the image focus and biases the targets' locations. In this paper, we propose MovISAC, the first coherent imaging method for moving targets using distributed asynchronous ISAC devices. Our approach obtains a set of high-resolution images of the environment, in which each image represents only targets moving with a selected velocity. To achieve this, MovISAC performs over-the-air (OTA) synchronization to compensate for timing, frequency, and phase offsets among distributed ISAC devices. Then, to solve the prohibitive complexity of an exhaustive search over the targets' velocities, we introduce a new association algorithm to match the Doppler shifts observed by each ISAC device pair to the corresponding spatial peaks obtained by standard imaging methods. This gives MovISAC the unique capability of pre-compensating the Doppler shift for each target before forming the images, thus recasting it from an undesired impairment to image formation to an additional means for resolving the targets. We perform extensive numerical simulations showing that our approach achieves extremely high resolution, superior robustness to clutter thanks to the additional target separation in the Doppler domain, and obtains cm- and cm/s-level target localization and velocity estimation errors. MovISAC significantly outperforms existing imaging methods that do not compensate for the Doppler shift, demonstrating up to 18 times lower localization error and enabling velocity estimation.

Paper number 11:
Title: Principles and Framework for the Operationalisation of Meaningful Human Control over Autonomous Systems
Authors: Simeon C. Calvert
Abstract: This paper proposes an alignment for the operationalisation of Meaningful Human Control (MHC) for autonomous systems by proposing operational principles for MHC and introducing a generic framework for its application. With a plethora of different seemingly diverging expansions for use of MHC in practice, this work aims to bring alignment and convergence use in practice. The increasing integration of autonomous systems in various domains emphasises a critical need to maintain human control to ensure responsible safety, accountability, and ethical operation of these systems. The concept of MHC offers an ideal concept for the design and evaluation of human control over autonomous systems, while considering human and technology capabilities. Through analysis of existing literature and investigation across various domains and related concepts, principles for the operationalisation of MHC are set out to provide tangible guidelines for researchers and practitioners aiming to implement MHC in their systems. The proposed framework dissects generic components of systems and their subsystems aligned with different agents, stakeholders and processes at different levels of proximity to an autonomous technology. The framework is domain-agnostic, emphasizing the universal applicability of the MHC principles irrespective of the technological context, paving the way for safer and more responsible autonomous systems.

Paper number 12:
Title: Higher-order Laplacian dynamics on hypergraphs with cooperative and antagonistic interactions
Authors: Shaoxuan Cui, Chencheng Zhang, Bin Jiang, Hildeberto Jardón Kojakhmetov, Ming Cao
Abstract: Laplacian dynamics on a signless graph characterize a class of linear interactions, where pairwise cooperative interactions between all agents lead to the convergence to a common state. On a structurally balanced signed graph, the agents converge to values of the same magnitude but opposite signs (bipartite consensus), as illustrated by the well-known Altafini model. These interactions have been modeled using traditional graphs, where the relationships between agents are always pairwise. In comparison, higher-order networks (such as hypergraphs), offer the possibility to capture more complex, group-wise interactions among agents. This raises a natural question: can collective behavior be analyzed by using hypergraphs? The answer is affirmative. In this paper, higher-order Laplacian dynamics on signless hypergraphs are first introduced and various collective convergence behaviors are investigated, in the framework of homogeneous and non-homogeneous polynomial systems. Furthermore, by employing gauge transformations and leveraging tensor similarities, we extend these dynamics to signed hypergraphs, drawing parallels to the Altafini model. Moreover, we explore non-polynomial interaction functions within this framework. The theoretical results are demonstrated through several numerical examples.

Paper number 13:
Title: CRISP: A Framework for Cryo-EM Image Segmentation and Processing with Conditional Random Field
Authors: Szu-Chi Chung, Po-Cheng Chou
Abstract: Differentiating signals from the background in micrographs is a critical initial step for cryogenic electron microscopy (cryo-EM), yet it remains laborious due to low signal-to-noise ratio (SNR), the presence of contaminants and densely packed particles of varying sizes. Although image segmentation has recently been introduced to distinguish particles at the pixel level, the low SNR complicates the automated generation of accurate annotations for training supervised models. Moreover, platforms for systematically comparing different design choices in pipeline construction are lacking. Thus, a modular framework is essential to understand the advantages and limitations of this approach and drive further development. To address these challenges, we present a pipeline that automatically generates high-quality segmentation maps from cryo-EM data to serve as ground truth labels. Our modular framework enables the selection of various segmentation models and loss functions. We also integrate Conditional Random Fields (CRFs) with different solvers and feature sets to refine coarse predictions, thereby producing fine-grained segmentation. This flexibility facilitates optimal configurations tailored to cryo-EM datasets. When trained on a limited set of micrographs, our approach achieves over 90% accuracy, recall, precision, Intersection over Union (IoU), and F1-score on synthetic data. Furthermore, to demonstrate our framework's efficacy in downstream analyses, we show that the particles extracted by our pipeline produce 3D density maps with higher resolution than those generated by existing particle pickers on real experimental datasets, while achieving performance comparable to that of manually curated datasets from experts.

Paper number 14:
Title: Exploiting Non-uniform Quantization for Enhanced ILC in Wideband Digital Pre-distortion
Authors: Jinfei Wang, Yi Ma, Fei Tong, Ziming He
Abstract: In this paper, it is identified that lowering the reference level at the vector signal analyzer can significantly improve the performance of iterative learning control (ILC). We present a mathematical explanation for this phenomenon, where the signals experience logarithmic transform prior to analogue-to-digital conversion, resulting in non-uniform quantization. This process reduces the quantization noise of low-amplitude signals that constitute a substantial portion of orthogonal frequency division multiplexing (OFDM) signals, thereby improving ILC performance. Measurement results show that compared to setting the reference level to the peak amplitude, lowering the reference level achieves 3 dB improvement on error vector magnitude (EVM) and 15 dB improvement on normalized mean square error (NMSE) for 320 MHz WiFi OFDM signals.

Paper number 15:
Title: A crayfish-optimized wavelet filter and its application to fault diagnosis
Authors: Sumika Chauhan, Govind Vashishtha, Radoslaw Zimroz, Rajesh Kumar
Abstract: Industrial machine fault diagnosis ensures the reliability and functionality of the system, but identifying informative frequency bands in vibration signals can be challenging due to low signal-to-noise ratio (SNR), background noise, and random interferences. The wavelet filter is commonly used for this purpose, but its parameters are crucial for locating the informative frequency band to extract repetitive transients. This study utilizes a crayfish optimization algorithm (COA) to optimize the wavelet filter adaptively for extracting fault characteristics. COA uses correlated kurtosis (CK) as a fitness function while addressing issues related to inaccurate CK period through an updation process. The proposed methodology is applied to different industrial cases and compared with existing methods, demonstrating its superiority in extracting informative frequencies.

Paper number 16:
Title: Local damage detection in rolling element bearings based on a Single Ensemble Empirical Mode Decomposition
Authors: Yaakoub Berrouche, Govind Vashishtha, Sumika Chauhan, Radoslaw Zimroz
Abstract: A Single Ensemble Empirical Mode Decomposition (SEEMD) is proposed for locating the damage in rolling element bearings. The SEEMD does not require a number of ensembles from the addition or subtraction of noise every time while processing the signals. The SEEMD requires just a single sifting process of a modified raw signal to reduce the computation time significantly. The other advantage of the SEEMD method is its success in dealing with non-Gaussian or non-stationary perturbing signals. In SEEMD, initially, a fractional Gaussian noise (FGN) is added to the raw signal to emphasize on high frequencies of the signal. Then, a convoluted white Gaussian noise is multiplied to the resulting signal which changes the spectral content of the signal which helps in extraction of the weak periodic signal. Finally, the obtained signal is decomposed by using a single sifting process. The proposed methodology is applied to the raw signals obtained from the mining industry. These signals are difficult to analyze since cyclic impulsive components are obscured by noise and other interference. Based on the results, the proposed method can effectively detect the fault where the signal of interest (SOI) has been extracted with good quality.

Paper number 17:
Title: A Generalized Converted Measurement Kalman Filter
Authors: Steven V. Bordonaro, Tod E. Luginbuhl, Michael J. Walsh
Abstract: This report derives a generalized, converted measurement Kalman filter for the class of filtering problems with a linear state equation and nonlinear measurement equation, for which a bijective mapping exists between the state and measurement coordinate systems. For these problems, a procedure is developed for mapping the observed measurements and their covariance matrices from measurement coordinates to state coordinates, such that the converted measurements are unbiased and the converted measurement covariance matrices are independent of the states and observed measurements. In cases where not all measurement coordinates are observed, predicted measurements of these coordinates are introduced as substitutes, and the impact of these measurements on the filter is mitigated by an information zeroing operation on the corresponding rows and columns of the converted measurement inverse-covariance matrix. Filter performance is demonstrated on two well-known target-tracking problems and is compared with the performance of the standard extended and unscented Kalman filters for these problems. These examples show the proposed filter obtains lower mean squared error, better consistency, and less track loss than either the extended Kalman filter or the unscented Kalman filter.

Paper number 18:
Title: Conveyor Line Color Object Sorting using A Monochrome Camera, Colored Light and RGB Filters
Authors: Mason Petersen, Brendon Lakenen, Krishna Chavan, Pratik Waghmare, Aleksandr Sergeyev, Nathir A. Rawashdeh
Abstract: This paper tests the ability of a machine vision system with a monochrome camera to differentiate colored objects. The system is designed to autonomously and continuously sort colored objects of which the user specifies the desired color(s). The system uses camera color light filters and red-green-blue (RGB) color light emitting diode (LED) lights to aid the machine vision system in recognizing part contrast. Additionally the system is controlled by a Programmable Logic Controller (PLC) which is integrated with a Robot that is used to remove parts. The parts are fed into the workcell via a conveyor belt that is controlled by the PLC. The user has the ability to select the desired acceptable colors on both the HMI and the physical pushbuttons.

Paper number 19:
Title: Semantic Learning for Molecular Communication in Internet of Bio-Nano Things
Authors: Hanlin Cai, Ozgur B. Akan
Abstract: Molecular communication (MC) provides a foundational framework for information transmission in the Internet of Bio-Nano Things (IoBNT), where efficiency and reliability are crucial. However, the inherent limitations of molecular channels, such as low transmission rates, noise, and inter-symbol interference (ISI), limit their ability to support complex data transmission. This paper proposes an end-to-end semantic learning framework designed to optimize task-oriented molecular communication, with a focus on biomedical diagnostic tasks under resource-constrained conditions. The proposed framework employs a deep encoder-decoder architecture to efficiently extract, quantize, and decode semantic features, prioritizing task-relevant semantic information to enhance diagnostic classification performance. Additionally, a probabilistic channel network is introduced to approximate molecular propagation dynamics, enabling gradient-based optimization for end-to-end learning. Experimental results demonstrate that the proposed semantic framework improves diagnostic accuracy by at least 25% compared to conventional JPEG compression with LDPC coding methods under resource-constrained communication scenarios.

Paper number 20:
Title: Dynamic Power Allocation in OFDM ISAC for Time of Arrival Estimation
Authors: Ali Al Khansa, Giyyarpuram Madhusudan, Guillaume Larue, Louis-Adrien Dufrene
Abstract: Resource allocation in Integrated Sensing and Communication (ISAC) systems is critical for balancing communication and sensing performance. This paper introduces a novel dynamic power allocation strategy for Orthogonal Frequency Division Multiplexing (OFDM) ISAC systems, optimizing communication capacity while adhering to Peak Side-lobe Level (PSL) and sensing accuracy constraints, particularly for Time of Arrival (ToA) estimation. Unlike conventional methods that address either PSL or accuracy in isolation, our approach dynamically allocates power to satisfy both constraints. Additionally, it prioritizes communication when sensing performance is insufficient, avoiding any loss in communication capacity. Numerical results validate the importance of considering both sensing constraints and demonstrate the effectiveness of the proposed dynamic power allocation strategy.

Paper number 21:
Title: Bistatic Micro-Doppler Analysis of a Vertical Takeoff and Landing (VTOL) Drone in ICAS Framework
Authors: Heraldo Cesar Alves Costa, Saw James Myint, Carsten Andrich, Sebastian W. Giehl, Dieter Novotny, Julia Beuster, Christian Schneider, Reiner S. Thomä
Abstract: Integrated Communication and Sensing (ICAS) is a key technology that enables sensing functionalities within the next-generation mobile communication (6G). Joint design and optimization of both functionalities could allow coexistence, therefore it advances toward joint signal processing and using the same hardware platform and common spectrum. Contributing to ICAS sensing, this paper presents the measurement and analysis of the micro-Doppler signature of Vertical Takeoff and Landing (VTOL) drones. Measurement is performed with an OFDM-like communication signal and bistatic constellation, which is a typical case in ICAS scenarios. This work shows that micro-Doppler signatures can be used to precisely distinguish flight modes, such as take-off, landing, hovering, transition, and cruising.

Paper number 22:
Title: LoRa Fine Synchronization with Two-Pass Time and Frequency Offset Estimation
Authors: Joachim Tapparel, Andreas Burg
Abstract: LoRa is currently one of the most widely used low-power wide-area network (LPWAN) technologies. The physical layer leverages a chirp spread spectrum modulation to achieve long-range communication with low power consumption. Synchronization at long distances is a challenging task as the spread signal can lie multiple orders of magnitude below the thermal noise floor. Multiple research works have proposed synchronization algorithms for LoRa under different hardware impairments. However, the impact of sampling frequency offset (SFO) has mostly either been ignored or tracked only during the data phase, but it often harms synchronization. In this work, we extend existing synchronization algorithms for LoRa to estimate and compensate SFO already in the preamble and show that this early compensation has a critical impact on the estimation of other impairments such as carrier frequency offset and sampling time offset. Therefore it is critical to recover long-range signals.

Paper number 23:
Title: Flat-Top Beamforming with Efficient Array-Fed RIS
Authors: Krishan Kumar Tiwari, Giuseppe Caire
Abstract: Flat-top beam designs are essential for uniform power distribution over a wide angular sector for applications such as 5G/6G networks, satellite communications, radar systems, etc. Low sidelobe levels with steep transitions allow negligible cross sector illumination. Active array designs requiring amplitude taper suffer from poor power amplifier utilization. Phase only designs, e.g., Zadoff-Chu or generalized step chirp polyphase sequence methods, often require large active antenna arrays which in turns increases the hardware complexity and reduces the energy efficiency. In our recently proposed novel array-fed reflective intelligent surface (RIS) architecture, the small ($2 \times 2$) active array has uniform (principal eigenmode) amplitude weighting. We now present a pragmatic flat-top pattern design method for practical array (RIS) sizes, which outperforms current state-of-the-art in terms of design superiority, energy efficiency, and deployment feasibility. This novel design holds promise for advancing sustainable wireless technologies in next-generation communication systems while mitigating the environmental impact of high-energy antenna arrays.

Paper number 24:
Title: Causal Analysis of ASR Errors for Children: Quantifying the Impact of Physiological, Cognitive, and Extrinsic Factors
Authors: Vishwanath Pratap Singh, Md. Sahidullah, Tomi Kinnunen
Abstract: The increasing use of children's automatic speech recognition (ASR) systems has spurred research efforts to improve the accuracy of models designed for children's speech in recent years. The current approach utilizes either open-source speech foundation models (SFMs) directly or fine-tuning them with children's speech data. These SFMs, whether open-source or fine-tuned for children, often exhibit higher word error rates (WERs) compared to adult speech. However, there is a lack of systemic analysis of the cause of this degraded performance of SFMs. Understanding and addressing the reasons behind this performance disparity is crucial for improving the accuracy of SFMs for children's speech. Our study addresses this gap by investigating the causes of accuracy degradation and the primary contributors to WER in children's speech. In the first part of the study, we conduct a comprehensive benchmarking study on two self-supervised SFMs (Wav2Vec2.0 and Hubert) and two weakly supervised SFMs (Whisper and MMS) across various age groups on two children speech corpora, establishing the raw data for the causal inference analysis in the second part. In the second part of the study, we analyze the impact of physiological factors (age, gender), cognitive factors (pronunciation ability), and external factors (vocabulary difficulty, background noise, and word count) on SFM accuracy in children's speech using causal inference. The results indicate that physiology (age) and particular external factor (number of words in audio) have the highest impact on accuracy, followed by background noise and pronunciation ability. Fine-tuning SFMs on children's speech reduces sensitivity to physiological and cognitive factors, while sensitivity to the number of words in audio persists. Keywords: Children's ASR, Speech Foundational Models, Causal Inference, Physiology, Cognition, Pronunciation

Paper number 25:
Title: Direction Finding for Software Defined Radios with Switched Uniform Circular Arrays
Authors: Lennart Werner, Markus Gardill, Marco Hutter
Abstract: Accurate Direction of Arrival (DoA) estimation is critical for applications in robotics and communication, but high costs and complexity of coherent multi-channel receivers hinder accessibility. This work proposes a cost-effective DoA estimation system for continuous wave (CW) signals in the 2.4 GHz ISM band. A two-channel software-defined radio (SDR) with time-division multiplexing (TDM) enables pseudo-coherent sampling of an eight-element uniform circular array (UCA) with low hardware complexity. A central reference antenna mitigates phase jitter and sampling errors. The system applies an enhanced MUSIC algorithm with spatial smoothing to handle light multipath interference in indoor and outdoor environments. Experiments in an anechoic chamber validate accuracy under ideal conditions, while real-world tests confirm robust performance in multipath-prone scenarios. With 5 Hz DoA updates and post-processing to enhance tracking, the system provides an accessible and reliable solution for DoA estimation in real-world environments.

Paper number 26:
Title: Rapid Whole Brain Mesoscale In-vivo MR Imaging using Multi-scale Implicit Neural Representation
Authors: Jun Lyu, Lipeng Ning, William Consagra, Qiang Liu, Richard J. Rushmore, Berkin Bilgic, Yogesh Rathi
Abstract: Purpose: To develop and validate a novel image reconstruction technique using implicit neural representations (INR) for multi-view thick-slice acquisitions while reducing the scan time but maintaining high signal-to-noise ratio (SNR). Methods: We propose Rotating-view super-resolution (ROVER)-MRI, an unsupervised neural network-based algorithm designed to reconstruct MRI data from multi-view thick slices, effectively reducing scan time by 2-fold while maintaining fine anatomical details. We compare our method to both bicubic interpolation and the current state-of-the-art regularized least-squares super-resolution reconstruction (LS-SRR) technique. Validation is performed using ground-truth ex-vivo monkey brain data, and we demonstrate superior reconstruction quality across several in-vivo human datasets. Notably, we achieve the reconstruction of a whole human brain in-vivo T2-weighted image with an unprecedented 180{\mu}m isotropic spatial resolution, accomplished in just 17 minutes of scan time on a 7T MRI scanner. Results: ROVER-MRI outperformed LS-SRR method in terms of reconstruction quality with 22.4% lower relative error (RE) and 7.5% lower full-width half maximum (FWHM) indicating better preservation of fine structural details in nearly half the scan time. Conclusion: ROVER-MRI offers an efficient and robust approach for mesoscale MR imaging, enabling rapid, high-resolution whole-brain scans. Its versatility holds great promise for research applications requiring anatomical details and time-efficient imaging.

Paper number 27:
Title: Joint Transmit and Pinching Beamforming for PASS: Optimization-Based or Learning-Based?
Authors: Xiaoxia Xu, Xidong Mu, Yuanwei Liu, Arumugam Nallanathan
Abstract: A novel pinching antenna system (PASS)-enabled downlink multi-user multiple-input single-output (MISO) framework is proposed. PASS consists of multiple waveguides spanning over thousands of wavelength, which equip numerous low-cost dielectric particles, named pinching antennas (PAs), to radiate signals into free space. The positions of PAs can be reconfigured to change both the large-scale path losses and phases of signals, thus facilitating the novel pinching beamforming design. A sum rate maximization problem is formulated, which jointly optimizes the transmit and pinching beamforming to adaptively achieve constructive signal enhancement and destructive interference mitigation. To solve this highly coupled and nonconvex problem, both optimization-based and learning-based methods are proposed. 1) For the optimization-based method, a majorization-minimization and penalty dual decomposition (MM-PDD) algorithm is developed, which handles the nonconvex complex exponential component using a Lipschitz surrogate function and then invokes PDD for problem decoupling. 2) For the learning-based method, a novel Karush-Kuhn-Tucker (KKT)-guided dual learning (KDL) approach is proposed, which enables KKT solutions to be reconstructed in a data-driven manner by learning dual variables. Following this idea, a KDL-Tranformer algorithm is developed, which captures both inter-PA/inter-user dependencies and channel-state-information (CSI)-beamforming dependencies by attention mechanisms. Simulation results demonstrate that: i) The proposed PASS framework significantly outperforms conventional massive multiple input multiple output (MIMO) system even with a few PAs. ii) The proposed KDL-Transformer can improve over 30% system performance than MM-PDD algorithm, while achieving a millisecond-level response on modern GPUs.

Paper number 28:
Title: Decoding Neuronal Networks: A Reservoir Computing Approach for Predicting Connectivity and Functionality
Authors: Ilya Auslender, Giorgio Letti, Yasaman Heydari, Clara Zaccaria, Lorenzo Pavesi
Abstract: In this study, we address the challenge of analyzing electrophysiological measurements in neuronal networks. Our computational model, based on the Reservoir Computing Network (RCN) architecture, deciphers spatio-temporal data obtained from electrophysiological measurements of neuronal cultures. By reconstructing the network structure on a macroscopic scale, we reveal the connectivity between neuronal units. Notably, our model outperforms common methods like Cross-Correlation and Transfer-Entropy in predicting the network's connectivity map. Furthermore, we experimentally validate its ability to forecast network responses to specific inputs, including localized optogenetic stimuli.

Paper number 29:
Title: neuro2voc: Decoding Vocalizations from Neural Activity
Authors: Fei Gao
Abstract: Accurate decoding of neural spike trains and relating them to motor output is a challenging task due to the inherent sparsity and length in neural spikes and the complexity of brain circuits. This master project investigates experimental methods for decoding zebra finch motor outputs (in both discrete syllables and continuous spectrograms), from invasive neural recordings obtained from Neuropixels. There are three major achievements: (1) XGBoost with SHAP analysis trained on spike rates revealed neuronal interaction patterns crucial for syllable classification. (2) Novel method (tokenizing neural data with GPT2) and architecture (Mamba2) demonstrated potential for decoding of syllables using spikes. (3) A combined contrastive learning-VAE framework successfully generated spectrograms from binned neural data. This work establishes a promising foundation for neural decoding of complex motor outputs and offers several novel methodological approaches for processing sparse neural data.

Paper number 30:
Title: Deep Learning in Automated Power Line Inspection: A Review
Authors: Md. Ahasan Atick Faisal, Imene Mecheter, Yazan Qiblawey, Javier Hernandez Fernandez, Muhammad E. H. Chowdhury, Serkan Kiranyaz
Abstract: In recent years, power line maintenance has seen a paradigm shift by moving towards computer vision-powered automated inspection. The utilization of an extensive collection of videos and images has become essential for maintaining the reliability, safety, and sustainability of electricity transmission. A significant focus on applying deep learning techniques for enhancing power line inspection processes has been observed in recent research. A comprehensive review of existing studies has been conducted in this paper, to aid researchers and industries in developing improved deep learning-based systems for analyzing power line data. The conventional steps of data analysis in power line inspections have been examined, and the body of current research has been systematically categorized into two main areas: the detection of components and the diagnosis of faults. A detailed summary of the diverse methods and techniques employed in these areas has been encapsulated, providing insights into their functionality and use cases. Special attention has been given to the exploration of deep learning-based methodologies for the analysis of power line inspection data, with an exposition of their fundamental principles and practical applications. Moreover, a vision for future research directions has been outlined, highlighting the need for advancements such as edge-cloud collaboration, and multi-modal analysis among others. Thus, this paper serves as a comprehensive resource for researchers delving into deep learning for power line analysis, illuminating the extent of current knowledge and the potential areas for future investigation.

Paper number 31:
Title: A Cooperative Bearing-Rate Approach for Observability-Enhanced Target Motion Estimation
Authors: Canlun Zheng, Hanqing Guo, Shiyu Zhao
Abstract: Vision-based target motion estimation is a fundamental problem in many robotic tasks. The existing methods have the limitation of low observability and, hence, face challenges in tracking highly maneuverable targets. Motivated by the aerial target pursuit task where a target may maneuver in 3D space, this paper studies how to further enhance observability by incorporating the \emph{bearing rate} information that has not been well explored in the literature. The main contribution of this paper is to propose a new cooperative estimator called STT-R (Spatial-Temporal Triangulation with bearing Rate), which is designed under the framework of distributed recursive least squares. This theoretical result is further verified by numerical simulation and real-world experiments. It is shown that the proposed STT-R algorithm can effectively generate more accurate estimations and effectively reduce the lag in velocity estimation, enabling tracking of more maneuverable targets.

Paper number 32:
Title: Learning-Based Design of LQG Controllers in Quantum Coherent Feedback
Authors: Chunxiang Song, Yanan Liu, Guofeng Zhang, Huadong Mo, Daoyi Dong
Abstract: In this paper, we propose a differential evolution (DE) algorithm specifically tailored for the design of Linear-Quadratic-Gaussian (LQG) controllers in quantum systems. Building upon the foundational DE framework, the algorithm incorporates specialized modules, including relaxed feasibility rules, a scheduled penalty function, adaptive search range adjustment, and the ``bet-and-run'' initialization strategy. These enhancements improve the algorithm's exploration and exploitation capabilities while addressing the unique physical realizability requirements of quantum systems. The proposed method is applied to a quantum optical system, where three distinct controllers with varying configurations relative to the plant are designed. The resulting controllers demonstrate superior performance, achieving lower LQG performance indices compared to existing approaches. Additionally, the algorithm ensures that the designs comply with physical realizability constraints, guaranteeing compatibility with practical quantum platforms. The proposed approach holds significant potential for application to other linear quantum systems in performance optimization tasks subject to physically feasible constraints.

Paper number 33:
Title: DualStream Contextual Fusion Network: Efficient Target Speaker Extraction by Leveraging Mixture and Enrollment Interactions
Authors: Ke Xue, Rongfei Fan, Shanping Yu, Chang Sun, Jianping An
Abstract: Target speaker extraction focuses on extracting a target speech signal from an environment with multiple speakers by leveraging an enrollment. Existing methods predominantly rely on speaker embeddings obtained from the enrollment, potentially disregarding the contextual information and the internal interactions between the mixture and enrollment. In this paper, we propose a novel DualStream Contextual Fusion Network (DCF-Net) in the time-frequency (T-F) domain. Specifically, DualStream Fusion Block (DSFB) is introduced to obtain contextual information and capture the interactions between contextualized enrollment and mixture representation across both spatial and channel dimensions, and then rich and consistent representations are utilized to guide the extraction network for better extraction. Experimental results demonstrate that DCF-Net outperforms state-of-the-art (SOTA) methods, achieving a scale-invariant signal-to-distortion ratio improvement (SI-SDRi) of 21.6 dB on the benchmark dataset, and exhibits its robustness and effectiveness in both noise and reverberation scenarios. In addition, the wrong extraction results of our model, called target confusion problem, reduce to 0.4%, which highlights the potential of DCF-Net for practical applications.

Paper number 34:
Title: Hierarchical Multi-Agent Framework for Carbon-Efficient Liquid-Cooled Data Center Clusters
Authors: Soumyendu Sarkar, Avisek Naug, Antonio Guillen, Vineet Gundecha, Ricardo Luna Gutierrez, Sahand Ghorbanpour, Sajad Mousavi, Ashwin Ramesh Babu, Desik Rengarajan, Cullen Bash
Abstract: Reducing the environmental impact of cloud computing requires efficient workload distribution across geographically dispersed Data Center Clusters (DCCs) and simultaneously optimizing liquid and air (HVAC) cooling with time shift of workloads within individual data centers (DC). This paper introduces Green-DCC, which proposes a Reinforcement Learning (RL) based hierarchical controller to optimize both workload and liquid cooling dynamically in a DCC. By incorporating factors such as weather, carbon intensity, and resource availability, Green-DCC addresses realistic constraints and interdependencies. We demonstrate how the system optimizes multiple data centers synchronously, enabling the scope of digital twins, and compare the performance of various RL approaches based on carbon emissions and sustainability metrics while also offering a framework and benchmark simulation for broader ML research in sustainability.

Paper number 35:
Title: Enhanced Load Forecasting with GAT-LSTM: Leveraging Grid and Temporal Features
Authors: Ugochukwu Orji, Çiçek Güven, Dan Stowell
Abstract: Accurate power load forecasting is essential for the efficient operation and planning of electrical grids, particularly given the increased variability and complexity introduced by renewable energy sources. This paper introduces GAT-LSTM, a hybrid model that combines Graph Attention Networks (GAT) and Long Short-Term Memory (LSTM) networks. A key innovation of the model is the incorporation of edge attributes, such as line capacities and efficiencies, into the attention mechanism, enabling it to dynamically capture spatial relationships grounded in grid-specific physical and operational constraints. Additionally, by employing an early fusion of spatial graph embeddings and temporal sequence features, the model effectively learns and predicts complex interactions between spatial dependencies and temporal patterns, providing a realistic representation of the dynamics of power grids. Experimental evaluations on the Brazilian Electricity System dataset demonstrate that the GAT-LSTM model significantly outperforms state-of-the-art models, achieving reductions of 21. 8% in MAE, 15. 9% in RMSE and 20. 2% in MAPE. These results underscore the robustness and adaptability of the GAT-LSTM model, establishing it as a powerful tool for applications in grid management and energy planning.

Paper number 36:
Title: Resilient Quantized Consensus in Multi-Hop Relay Networks
Authors: Liwei Yuan, Hideaki Ishii
Abstract: We study resilient quantized consensus in multi-agent systems, where some agents may malfunction. The network consists of agents taking integer-valued states, and the agents' communication is subject to asynchronous updates and time delays. We utilize the quantized weighted mean subsequence reduced algorithm where agents communicate with others through multi-hop relays. We prove necessary and sufficient conditions for our algorithm to achieve the objective under the malicious and Byzantine attack models. Our approach has tighter graph conditions compared to the one-hop algorithm and the flooding-based algorithms for binary consensus. Numerical examples verify the efficacy of our algorithm.

Paper number 37:
Title: Testbed Development: An Intelligent O-RAN based Cell-Free MIMO Network
Authors: Yi Chu, Mostafa Rahmani, Josh Shackleton, David Grace, Kanapathippillai Cumanan, Hamed Ahmadi, Alister Burr
Abstract: Cell-free multiple input multiple output (CF-MIMO) systems improve spectral and energy efficiencies using distributed access points (APs) to provide reliable service across an area equivalent to multiple conventional cells. This paper presents a novel design and implementation of a CF-MIMO network leveraging the open radio access network (O-RAN) architecture based testbed to enhance the performance of interference-prone user. The proposed prototype is developed based on open source software components and unlike many other prototypes, our testbed is able to serve commercial 5G user equipment (UE). The RAN intelligent controller (RIC) allows the cell-free (CF) network to access the embedded artificial intelligence and benefit from the network optimisation techniques that O-RAN brings. The testbed includes an intelligent antenna association xApp which determines the antenna group that serves each UE based on the live key performance measurements. The paper demonstrates the deployment and operation of the CF network and the xApp and discusses how the CF networks can benefit from the O-RAN architecture.

Paper number 38:
Title: Falsification of Cyber-Physical Systems using Bayesian Optimization
Authors: Zahra Ramezani, Kenan Šehić, Luigi Nardi, Knut Åkesson
Abstract: Cyber-physical systems (CPSs) are often complex and safety-critical, making it both challenging and crucial to ensure that the system's specifications are met. Simulation-based falsification is a practical testing technique for increasing confidence in a CPS's correctness, as it only requires that the system be simulated. Reducing the number of computationally intensive simulations needed for falsification is a key concern. In this study, we investigate Bayesian optimization (BO), a sample-efficient approach that learns a surrogate model to capture the relationship between input signal parameterization and specification evaluation. We propose two enhancements to the basic BO for improving falsification: (1) leveraging local surrogate models, and (2) utilizing the user's prior knowledge. Additionally, we address the formulation of acquisition functions for falsification by proposing and evaluating various alternatives. Our benchmark evaluation demonstrates significant improvements when using local surrogate models in BO for falsifying challenging benchmark examples. Incorporating prior knowledge is found to be especially beneficial when the simulation budget is constrained. For some benchmark problems, the choice of acquisition function noticeably impacts the number of simulations required for successful falsification.

Paper number 39:
Title: Characterization of full-scale denial-of-service
Authors: Anindya Basu, Indrani Kar
Abstract: This article investigates the resilient control problem for Cyber-Physical Systems (CPSs) with multiple sensors, where both sides of the communication channels are affected by Denial-of-Service (DoS) attacks. While previous work focused on characterizing Multi-Channel DoS (MCDoS), this study emphasizes the characterization of Full-Scale DoS (FSDoS). First, a partial observer technique is proposed to address the MCDoS condition. Then, an event-triggered control strategy is designed to handle FSDoS. Finally, the frequency and duration of FSDoS are analyzed to ensure the Input-to-State Stability (ISS) of the closed-loop system.

Paper number 40:
Title: DISC: a Dataset for Integrated Sensing and Communication in mmWave Systems
Authors: Jacopo Pegoraro, Pablo Saucedo, Jesus Omar Lacruz, Michele Rossi, Joerg Widmer
Abstract: This paper presents DISC, a dataset of millimeter-wave channel impulse response measurements for integrated human activity sensing and communication. This is the first dataset collected with a software-defined radio testbed that transmits 60 GHz IEEE 802-11ay-compliant packets and estimates the channel response including scattered signals off the moving body parts of subjects moving in an indoor environment. The provided data consists of three parts, for more than 2 hours of channel measurements with high temporal resolution (0.27 ms inter-packet time). DISC contains the contribution of 7 subjects performing 5 different activities, and includes data collected from two distinct environments. Unlike available radar-based millimeter-wave sensing datasets, our measurements are collected using uniform packet transmission times and sparse traffic patterns from real Wi-Fi deployments. We develop, train, and release open-source baseline algorithms based on DISC to perform human sensing tasks. Our results demonstrate that DISC can serve as a multi-purpose benchmarking tool for machine learning-based human activity recognition, radio frequency gait analysis, and sparse sensing algorithms for next-generation integrated sensing and communications.

Paper number 41:
Title: Testing Correctness, Fairness, and Robustness of Speech Emotion Recognition Models
Authors: Anna Derington, Hagen Wierstorf, Ali Özkil, Florian Eyben, Felix Burkhardt, Björn W. Schuller
Abstract: Machine learning models for speech emotion recognition (SER) can be trained for different tasks and are usually evaluated based on a few available datasets per task. Tasks could include arousal, valence, dominance, emotional categories, or tone of voice. Those models are mainly evaluated in terms of correlation or recall, and always show some errors in their predictions. The errors manifest themselves in model behaviour, which can be very different along different dimensions even if the same recall or correlation is achieved by the model. This paper introduces a testing framework to investigate behaviour of speech emotion recognition models, by requiring different metrics to reach a certain threshold in order to pass a test. The test metrics can be grouped in terms of correctness, fairness, and robustness. It also provides a method for automatically specifying test thresholds for fairness tests, based on the datasets used, and recommendations on how to select the remaining test thresholds. We evaluated a xLSTM-based and nine transformer-based acoustic foundation models against a convolutional baseline model, testing their performance on arousal, valence, dominance, and emotional category classification. The test results highlight, that models with high correlation or recall might rely on shortcuts -- such as text sentiment --, and differ in terms of fairness.

Paper number 42:
Title: A New Framework for Bounding Reachability Probabilities of Continuous-time Stochastic Systems
Authors: Bai Xue
Abstract: This manuscript presents an innovative framework for constructing barrier functions to bound reachability probabilities for continuous-time stochastic systems described by stochastic differential equations (SDEs). The reachability probabilities considered in this paper encompass two aspects: the probability of reaching a set of specified states within a predefined finite time horizon, and the probability of reaching a set of specified states at a particular time instant. The barrier functions presented in this manuscript are developed either by relaxing a parabolic partial differential equation that characterizes the exact reachability probability or by applying the Grönwall's inequality. In comparison to the prevailing construction method, which relies on Doob's non-negative supermartingale inequality (or Ville's inequality), the proposed barrier functions provide stronger alternatives, complement existing methods, or fill gaps.

Paper number 43:
Title: Deep Spatiotemporal Clutter Filtering of Transthoracic Echocardiographic Images: Leveraging Contextual Attention and Residual Learning
Authors: Mahdi Tabassian, Somayeh Akbari, Sandro Queirós, Jan D'hooge
Abstract: This study presents a deep convolutional autoencoder network for filtering reverberation clutter from transthoracic echocardiographic (TTE) image sequences. Given the spatiotemporal nature of this type of clutter, the filtering network employs 3D convolutional layers to suppress it throughout the cardiac cycle. The design of the network incorporates two key features that contribute to the effectiveness of the filter: 1) an attention mechanism for focusing on cluttered regions and leveraging contextual information, and 2) residual learning for preserving fine image structures. To train the network, a diverse set of artifact patterns was simulated and superimposed onto ultra-realistic synthetic TTE sequences from six ultrasound vendors, generating input for the filtering network. The artifact-free sequences served as ground-truth. Performance of the filtering network was evaluated using unseen synthetic and in vivo artifactual sequences. Results from the in vivo dataset confirmed the network's strong generalization capabilities, despite being trained solely on synthetic data and simulated artifacts. The suitability of the filtered sequences for downstream processing was assessed by computing segmental strain curves. A significant reduction in the discrepancy between strain profiles computed from cluttered and clutter-free segments was observed after filtering the cluttered sequences with the proposed network. The trained network processes a TTE sequence in a fraction of a second, enabling real-time clutter filtering and potentially improving the precision of clinically relevant indices derived from TTE sequences. The source code of the proposed method and example video files of the filtering results are available at: \href{this https URL}{this https URL}.

Paper number 44:
Title: Graph Neural Networks in EEG-based Emotion Recognition: A Survey
Authors: Chenyu Liu, Xinliang Zhou, Yihao Wu, Ruizhi Yang, Zhongruo Wang, Liming Zhai, Ziyu Jia, Yang Liu
Abstract: Compared to other modalities, EEG-based emotion recognition can intuitively respond to the emotional patterns in the human brain and, therefore, has become one of the most concerning tasks in the brain-computer interfaces field. Since dependencies within brain regions are closely related to emotion, a significant trend is to develop Graph Neural Networks (GNNs) for EEG-based emotion recognition. However, brain region dependencies in emotional EEG have physiological bases that distinguish GNNs in this field from those in other time series fields. Besides, there is neither a comprehensive review nor guidance for constructing GNNs in EEG-based emotion recognition. In the survey, our categorization reveals the commonalities and differences of existing approaches under a unified framework of graph construction. We analyze and categorize methods from three stages in the framework to provide clear guidance on constructing GNNs in EEG-based emotion recognition. In addition, we discuss several open challenges and future directions, such as Temporal full-connected graph and Graph condensation.

Paper number 45:
Title: X-Diffusion: Generating Detailed 3D MRI Volumes From a Single Image Using Cross-Sectional Diffusion Models
Authors: Emmanuelle Bourigault, Abdullah Hamdi, Amir Jamaludin
Abstract: Magnetic Resonance Imaging (MRI) is a crucial diagnostic tool, but high-resolution scans are often slow and expensive due to extensive data acquisition requirements. Traditional MRI reconstruction methods aim to expedite this process by filling in missing frequency components in the K-space, performing 3D-to-3D reconstructions that demand full 3D scans. In contrast, we introduce X-Diffusion, a novel cross-sectional diffusion model that reconstructs detailed 3D MRI volumes from extremely sparse spatial-domain inputs, achieving 2D-to-3D reconstruction from as little as a single 2D MRI slice or few slices. A key aspect of X-Diffusion is that it models MRI data as holistic 3D volumes during the cross-sectional training and inference, unlike previous learning approaches that treat MRI scans as collections of 2D slices in standard planes (coronal, axial, sagittal). We evaluated X-Diffusion on brain tumor MRIs from the BRATS dataset and full-body MRIs from the UK Biobank dataset. Our results demonstrate that X-Diffusion not only surpasses state-of-the-art methods in quantitative accuracy (PSNR) on unseen data but also preserves critical anatomical features such as tumor profiles, spine curvature, and brain volume. Remarkably, the model generalizes beyond the training domain, successfully reconstructing knee MRIs despite being trained exclusively on brain data. Medical expert evaluations further confirm the clinical relevance and fidelity of the generated this http URL our knowledge, X-Diffusion is the first method capable of producing detailed 3D MRIs from highly limited 2D input data, potentially accelerating MRI acquisition and reducing associated costs. The code is available on the project website this https URL .

Paper number 46:
Title: Fault Detection and Monitoring using a Data-Driven Information-Based Strategy: Method, Theory, and Application
Authors: Camilo Ramírez, Jorge F. Silva, Ferhat Tamssaouet, Tomás Rojas, Marcos E. Orchard
Abstract: The ability to detect when a system undergoes an incipient fault is of paramount importance in preventing a critical failure. Classic methods for fault detection (including model-based and data-driven approaches) rely on thresholding error statistics or simple input-residual dependencies but face difficulties with non-linear or non-Gaussian systems. Behavioral methods (e.g., those relying on digital twins) address these difficulties but still face challenges when faulty data is scarce, decision guarantees are required, or working with already-deployed models is required. In this work, we propose an information-driven fault detection method based on a novel concept drift detector, addressing these challenges. The method is tailored to identifying drifts in input-output relationships of additive noise models (i.e., model drifts) and is based on a distribution-free mutual information (MI) estimator. Our scheme does not require prior faulty examples and can be applied distribution-free over a large class of system models. Our core contributions are twofold. First, we demonstrate the connection between fault detection, model drift detection, and testing independence between two random variables. Second, we prove several theoretical properties of the proposed MI-based fault detection scheme: (i) strong consistency, (ii) exponentially fast detection of the non-faulty case, and (iii) control of both significance levels and power of the test. To conclude, we validate our theory with synthetic data and the benchmark dataset N-CMAPSS of aircraft turbofan engines. These empirical results support the usefulness of our methodology in many practical and realistic settings, and the theoretical results show performance guarantees that other methods cannot offer.

Paper number 47:
Title: Similarity and Quality Metrics for MR Image-To-Image Translation
Authors: Melanie Dohmen, Mark A. Klemens, Ivo M. Baltruschat, Tuan Truong, Matthias Lenga
Abstract: Image-to-image translation can create large impact in medical imaging, as images can be synthetically transformed to other modalities, sequence types, higher resolutions or lower noise levels. To ensure patient safety, these methods should be validated by human readers, which requires a considerable amount of time and costs. Quantitative metrics can effectively complement such studies and provide reproducible and objective assessment of synthetic images. If a reference is available, the similarity of MR images is frequently evaluated by SSIM and PSNR metrics, even though these metrics are not or too sensitive regarding specific distortions. When reference images to compare with are not available, non-reference quality metrics can reliably detect specific distortions, such as blurriness. To provide an overview on distortion sensitivity, we quantitatively analyze 11 similarity (reference) and 12 quality (non-reference) metrics for assessing synthetic images. We additionally include a metric on a downstream segmentation task. We investigate the sensitivity regarding 11 kinds of distortions and typical MR artifacts, and analyze the influence of different normalization methods on each metric and distortion. Finally, we derive recommendations for effective usage of the analyzed similarity and quality metrics for evaluation of image-to-image translation models.

Paper number 48:
Title: Real-time Tracking in a Status Update System with an Imperfect Feedback Channel
Authors: Saeid Sadeghi Vilni, Abolfazl Zakeri, Mohammad Moltafet, Marian Codreanu
Abstract: We consider a status update system consisting of a finite-state Markov source, an energy-harvesting-enabled transmitter, and a sink. The forward and feedback channels between the transmitter and the sink are error-prone. We study the problem of minimizing the long-term time average of a (generic) distortion function subject to an energy causality constraint. Since the feedback channel is error-prone, the transmitter has only partial knowledge about the transmission results and, consequently, about the estimate of the source state at the sink. Therefore, we model the problem as a partially observable Markov decision process (POMDP), which is then cast as a belief-MDP problem. The infinite belief space makes solving the belief-MDP difficult. Thus, by exploiting a specific property of the belief evolution, we truncate the state space and formulate a finite-state MDP problem, which is then solved using the relative value iteration algorithm (RVIA). Furthermore, we propose a low-complexity transmission policy in which the belief-MDP problem is transformed into a sequence of per-slot optimization problems. Simulation results show the effectiveness of the proposed policies and their superiority compared to a baseline policy. Moreover, we numerically show that the proposed policies have switching-type structures.

Paper number 49:
Title: Interference-Free Backscatter Communications for OFDM-Based Symbiotic Radio
Authors: Muhammad Bilal Janjua, Alphan Şahin, Hüseyin Arslan
Abstract: This study proposes an orthogonal frequency division multiplexing (OFDM) based scheme to achieve interference-free backscatter communications (BC) in a symbiotic radio system. In specific, we propose three frequency shift keying (FSK) based backscatter modulation schemes to shift the primary signal, i.e., the OFDM symbols transmitted from a base station (BS), in the frequency domain to transmit its information. Symbiotically, the BS empties specific subcarriers within the band so that the received frequency-shifted signals from the backscatter device and the primary signal are always orthogonal. The first scheme relies on the combination of on-off keying (OOK) within the FSK modulation while the second and the third schemes are based on the conventional FSK modulation with different in-band null-subcarrier allocation. These schemes allow the use of non-coherent detection at the receiver which addresses the channel estimation challenge for the signals arriving from a backscatter device. We derive the bit-error rate performance of the detector theoretically. The comprehensive simulations show that the proposed approach achieves a lower bit-error rate up to 10-4 at 30 dB with BC by eliminating direct link interference.

Paper number 50:
Title: Joint 9D Receiver Localization and Ephemeris Correction with LEO and $5$G Base Stations
Authors: Don-Roberts Emenonye, Wasif J. Hussain, Harpreet S. Dhillon, R. Michael Buehrer
Abstract: This paper leverages Fisher information to examine the interaction between low-Earth orbit (LEO) satellites and 5G base stations (BSs) in enabling 9D receiver localization and refining LEO ephemeris. First, we propose a channel model that incorporates all relevant links: LEO-receiver, LEO-BS, and this http URL, we utilize the Fisher information matrix (FIM) to quantify the information available about the channel parameters in these links. By transforming these FIMs, we derive the FIM for 9D receiver localization parameters-comprising 3D position, 3D orientation, and 3D velocity-along with LEO position and velocity offsets. We present closed-form expressions for the FIM entries corresponding to these localization parameters. Our identifiability analysis based on the FIM reveals that: i) With a single LEO, three BSs, and three time slots are required to estimate the 9D localization parameters and correct the LEO position and velocity. ii) With two LEOs, the same configuration (three BSs and three time slots) suffices for both tasks. iii) With three LEOs, three BSs and four time slots are needed to achieve the same goal. A key insight from the Cramer-Rao lower bound (CRLB) analysis is that, under the configuration of one LEO, three BSs, and three time slots, the estimated errors for receiver positioning, velocity, and orientation, as well as LEO position and velocity offsets, are 0.1 cm, 1 mm/s, 0.001 rad, 0.01 m, and 1 m/s, respectively. The receiver localization parameters are estimated after 1 s while the LEO offset parameters are estimated after 20 s. Additionally, our CRLB analysis indicates that operating frequency has minimal impact on receiver orientation estimation accuracy, and the number of receive antennas has a negligible effect on LEO velocity estimation accuracy.

Paper number 51:
Title: Janssen 2.0: Audio Inpainting in the Time-frequency Domain
Authors: Ondřej Mokrý, Peter Balušík, Pavel Rajmic
Abstract: The paper focuses on inpainting missing parts of an audio signal spectrogram. The autoregression-based Janssen algorithm, the state-of-the-art for the time-domain audio inpainting, is adapted for the time-frequency setting. This novel method, termed Janssen-TF, is compared to the deep-prior neural network approach using both objective metrics and a~subjective listening test, proving Janssen-TF to be superior in all the considered measures.

Paper number 52:
Title: Sketched Equivariant Imaging Regularization and Deep Internal Learning for Inverse Problems
Authors: Guixian Xu, Jinglai Li, Junqi Tang
Abstract: Equivariant Imaging (EI) regularization has become the de-facto technique for unsupervised training of deep imaging networks, without any need of ground-truth data. Observing that the EI-based unsupervised training paradigm currently has significant computational redundancy leading to inefficiency in high-dimensional applications, we propose a sketched EI regularization which leverages the randomized sketching techniques for acceleration. We then extend our sketched EI regularization to develop an accelerated deep internal learning framework, Sketched Equivariant Deep Image Prior (Sk-EI-DIP), which can be efficiently applied for single-image and task-adapted reconstruction. Additionally, for network adaptation tasks, we propose a parameter-efficient approach for accelerating both EI-DIP and Sk-EI-DIP via optimizing only the normalization layers. Our numerical study on X-ray CT and multi-coil MRI image reconstruction tasks demonstrate that our approach can achieve significant computational acceleration over standard EI-based counterpart in single-input setting and network adaptation at test time.

Paper number 53:
Title: Graph-based Simulation Framework for Power Resilience Estimation and Enhancement
Authors: Xuesong Wang, Shuo Yuan, Sharaf K. Magableh, Oraib Dawaghreh, Caisheng Wang, Le Yi Wang
Abstract: The increasing frequency of extreme weather events poses significant risks to power distribution systems, leading to widespread outages and severe economic and social consequences. This paper presents a novel simulation framework for assessing and enhancing the resilience of power distribution networks under such conditions. Resilience is estimated through Monte Carlo simulations, which simulate extreme weather scenarios and evaluate the impact on infrastructure fragility. Due to the proprietary nature of power network topology, a distribution network is synthesized using publicly available data. To generate the weather scenarios, an extreme weather generation method is developed. To enhance resilience, renewable resources such as solar panels and energy storage systems (batteries in this study) are incorporated. A customized Genetic Algorithm is proposed to determine the optimal locations and capacities for solar panels and battery installations, maximizing resilience while balancing cost constraints. Experiment results demonstrate that on a large-scale synthetic distribution network with more than 300,000 nodes and 300,000 edges, the proposed framework can efficiently evaluate the resilience, and enhance the resilience through the installations of distributed energy resources (DERs), providing utilities with valuable insights for community-level power system resilience estimation and enhancement.

Paper number 54:
Title: Arbitrarily Fast Multivariable Least-squares MRAC
Authors: Liu Hsu, Ramon R. Costa, Fernando Lizarralde, Alessandro Jacoud Peixoto
Abstract: A novel least-squares model-reference direct adaptive control (LS-MRAC) algorithm for multivariable (MIMO) plants is presented. The controller parameters are directly updated based on the output tracking error. The control law is crucially modified to reduce the relative degree of the error model to zero. A complete Lyapunov-based stability analysis as well as a tracking error convergence characterization is provided demonstrating that the LS-MRAC can achieve arbitrarily fast tracking while maintaining satisfactory parameter convergence for appropriate adaptation gains. Simulation results show a significant improvement in tracking performance compared to previous methods.

Paper number 55:
Title: Frequency Diverse Array OFDM System for Joint Communication and Sensing
Authors: Marcin Wachowiak, André Bourdoux, Sofie Pollin
Abstract: The frequency-diverse array (FDA) offers a time-varying beamforming capability without the use of phase shifters. The autoscanning property is achieved by applying a frequency offset between the antennas. This paper analyzes the performance of an FDA joint communication and sensing system with the orthogonal frequency-division multiplexing (OFDM) modulation. The performance of the system is evaluated against the scanning frequency, number of antennas and number of subcarriers. The utilized metrics; integrated sidelobe level (ISL) and error vector magnitude (EVM) allow for straightforward comparison with a standard single-input single-output (SISO) OFDM system.

Paper number 56:
Title: Beamforming with Oversampled Time-Modulated Arrays
Authors: Marcin Wachowiak, André Bourdoux, Sofie Pollin
Abstract: The time-modulated array (TMA) is a simple array architecture in which each antenna is connected via a multi-throw switch. The switch acts as a modulator switching state faster than the symbol rate. The phase shifting and beamforming is achieved by a cyclic shift of the periodical modulating signal across antennas. In this paper, the TMA mode of operation is proposed to improve the resolution of a conventional phase shifter. The TMAs are analyzed under constrained switching frequency being a small multiple of the symbol rate. The presented generic signal model gives insight into the magnitude, phase and spacing of the harmonic components generated by the quantized modulating sequence. It is shown that the effective phase-shifting resolution can be improved multiplicatively by the oversampling factor ($O$) at the cost of introducing harmonics. Finally, the array tapering with an oversampled modulating signal is proposed. The oversampling provides $O+1$ uniformly distributed tapering amplitudes.

Paper number 57:
Title: A Novel Phenomenological Model of Equalization-enhanced Phase Noise
Authors: Benedikt Geiger, Fred Buchali, Vahid Aref, Laurent Schmalen
Abstract: We show that equalization-enhanced phase noise manifests as a time-varying, frequency-dependent phase error, which can be modeled and reversed by a time-varying all-pass finite impulse response filter.

Paper number 58:
Title: Continuous-Time Zeroth-Order Dynamics with Projection Maps: Model-Free Feedback Optimization with Safety Guarantees
Authors: Xin Chen, Jorge I. Poveda, Na Li
Abstract: This paper introduces a class of model-free feedback methods for solving generic constrained optimization problems where the specific mathematical forms of the objective and constraint functions are not available. The proposed methods, termed Projected Zeroth-Order (P-ZO) dynamics, incorporate projection maps into a class of continuous-time model-free dynamics that make use of periodic dithering for the purpose of gradient learning. In particular, the proposed P-ZO algorithms can be interpreted as new extremum-seeking algorithms that autonomously drive an unknown system toward a neighborhood of the set of solutions of an optimization problem using only output feedback, while systematically guaranteeing that the input trajectories remain in a feasible set for all times. In this way, the P-ZO algorithms can properly handle hard and asymptotical constraints in model-free optimization problems without using penalty terms or barrier functions. Moreover, the proposed dynamics have suitable robustness properties with respect to small bounded additive disturbances on the states and dynamics, a property that is fundamental for practical real-world implementations. Additional tracking results for time-varying and switching cost functions are also derived under stronger convexity and smoothness assumptions and using tools from hybrid dynamical systems. Numerical examples are presented throughout the paper to illustrate the above results.

Paper number 59:
Title: Absorption-Based, Passive Range Imaging from Hyperspectral Thermal Measurements
Authors: Unay Dorken Gallastegi, Hoover Rueda-Chacon, Martin J. Stevens, Vivek K Goyal
Abstract: Passive hyperspectral longwave infrared measurements are remarkably informative about the surroundings. Remote object material and temperature determine the spectrum of thermal radiance, and range, air temperature, and gas concentrations determine how this spectrum is modified by propagation to the sensor. We introduce a passive range imaging method based on computationally separating these phenomena. Previous methods assume hot and highly emitting objects; ranging is more challenging when objects' temperatures do not deviate greatly from air temperature. Our method jointly estimates range and intrinsic object properties, with explicit consideration of air emission, though reflected light is assumed negligible. Inversion being underdetermined is mitigated by using a parametric model of atmospheric absorption and regularizing for smooth emissivity estimates. To assess where our estimate is likely accurate, we introduce a technique to detect which scene pixels are significantly influenced by reflected downwelling. Monte Carlo simulations demonstrate the importance of regularization, temperature differentials, and availability of many spectral bands. We apply our method to longwave infrared (8--13 $\mu$m) hyperspectral image data acquired from natural scenes with no active illumination. Range features from 15m to 150m are recovered, with good qualitative match to lidar data for pixels classified as having negligible reflected downwelling.

Paper number 60:
Title: FlexRDZ: Autonomous Mobility Management for Radio Dynamic Zones
Authors: Aashish Gottipati, Jacobus Van der Merwe
Abstract: FlexRDZ is an online, autonomous manager for radio dynamic zones (RDZ) that seeks to enable the safe operation of RDZs through real-time control of deployed test transmitters. FlexRDZ leverages Hierarchical Task Networks and digital twin modeling to plan and resolve RDZ violations in near real-time. We prototype FlexRDZ with GTPyhop and the Terrain Integrated Rough Earth Model (TIREM). We deploy and evaluate FlexRDZ within a simulated version of the Salt Lake City POWDER testbed, a potential urban RDZ environment. Our simulations show that FlexRDZ enables up to a 20 dBm reduction in mobile interference and a significant reduction in the total power of leaked transmissions while preserving the overall communication capabilities and uptime of test transmitters. To our knowledge, FlexRDZ is the first autonomous system for RDZ management.

Paper number 61:
Title: Assessment of the Sparsity-Diversity Trade-offs in Active Users Detection for mMTC with the Orthogonal Matching Pursuit
Authors: Gabriel Martins de Jesus, Onel Luis Alcaraz Lopez, Richard Demo Souza, Nurul Huda Mahmood, Markku Juntti, Matti Latva-Aho
Abstract: Wireless communication systems must increasingly support a multitude of machine-type communications (MTC) devices, thus calling for advanced strategies for active user detection (AUD). Recent literature has delved into AUD techniques based on compressed sensing, highlighting the critical role of signal sparsity. This study investigates the relationship between frequency diversity and signal sparsity in the AUD problem. Single-antenna users transmit multiple copies of non-orthogonal pilots across multiple frequency channels and the base station independently performs AUD in each channel using the orthogonal matching pursuit algorithm. We note that, although frequency diversity may improve the likelihood of successful reception of the signals, it may also damage the channel sparsity level, leading to important trade-offs. We show that a sparser signal significantly benefits AUD, surpassing the advantages brought by frequency diversity in scenarios with limited temporal resources and/or high numbers of receive antennas. Conversely, with longer pilots and fewer receive antennas, investing in frequency diversity becomes more impactful, resulting in a tenfold AUD performance improvement.

Paper number 62:
Title: Distributed Discrete-time Dynamic Outer Approximation of the Intersection of Ellipsoids
Authors: Eduardo Sebastián, Rodrigo Aldana-López, Rosario Aragüés, Eduardo Montijano, Carlos Sagüés
Abstract: This paper presents the first discrete-time distributed algorithm to track the tightest ellipsoids that outer approximates the global dynamic intersection of ellipsoids. Given an undirected network, we consider a setup where each node measures an ellipsoid, defined as a time-varying positive semidefinite matrix. The goal is to devise a distributed algorithm to track the tightest outer approximation of the intersection of all the ellipsoids. The solution is based on a novel distributed reformulation of the original centralized semi-definite outer Löwner-John program, characterized by a non-separable objective function and global constraints. We prove finite-time convergence to the global minima of the centralized problem in the static case and finite-time bounded tracking error in the dynamic case. Moreover, we prove boundedness of estimation in the tracking of the global optimum and robustness in the estimation against time-varying inputs. We illustrate the properties of the algorithm with different simulated examples, including a distributed estimation showcase where our proposal is integrated into a distributed Kalman filter to surpass the state-of-the-art in mean square error performance.

Paper number 63:
Title: Predicting Parkinson's disease trajectory using clinical and functional MRI features: a reproduction and replication study
Authors: Elodie Germani (EMPENN, LACODAM), Nikhil Baghwat, Mathieu Dugré (CSE), Rémi Gau, Albert Montillo, Kevin Nguyen, Andrzej Sokolowski (CSE), Madeleine Sharp, Jean-Baptiste Poline, Tristan Glatard (CSE)
Abstract: Parkinson's disease (PD) is a common neurodegenerative disorder with a poorly understood physiopathology and no established biomarkers for the diagnosis of early stages and for prediction of disease progression. Several neuroimaging biomarkers have been studied recently, but these are susceptible to several sources of variability related for instance to cohort selection or image analysis. In this context, an evaluation of the robustness of such biomarkers to variations in the data processing workflow is essential. This study is part of a larger project investigating the replicability of potential neuroimaging biomarkers of PD. Here, we attempt to reproduce (re-implementing the experiments with the same data, same method) and replicate (different data and/or method) the models described in [1] to predict individual's PD current state and progression using demographic, clinical and neuroimaging features (fALFF and ReHo extracted from resting-state fMRI). We use the Parkinson's Progression Markers Initiative dataset (PPMI, this http URL), as in [1] and aim to reproduce the original cohort, imaging features and machine learning models as closely as possible using the information available in the paper and the code. We also investigated methodological variations in cohort selection, feature extraction pipelines and sets of input features. Different criteria were used to evaluate the reproduction and compare the reproduced results with the original ones. Notably, we obtained significantly better than chance performance using the analysis pipeline closest to that in the original study (R2 \&gt; 0), which is consistent with its findings. Moreover, using derived data provided by the authors of the original study, we were able to make an exact reproduction and managed to obtain results that were close to the original ones. The challenges encountered while reproducing and replicating the original work are likely explained by the complexity of neuroimaging studies, in particular in clinical settings. We provide recommendations to further facilitate the reproducibility of such studies in the future.

Paper number 64:
Title: A Comprehensive Study on Ziv-Zakai Lower Bounds on the MMSE
Authors: Minoh Jeong, Alex Dytso, Martina Cardone
Abstract: This paper explores Bayesian lower bounds on the minimum mean squared error (MMSE) that belong to the Ziv-Zakai (ZZ) family. The ZZ technique relies on connecting the bound to an M-ary hypothesis testing problem. Three versions of the ZZ bound (ZZB) exist: the first relies on the so-called valley-filling function (VFF), the second omits the VFF, and the third, i.e., the single-point ZZB (SZZB), uses a single point maximization. The first part of this paper provides the most general version of the bounds. First, it is shown that these bounds hold without any assumption on the distribution of the estimand. Second, the SZZB bound is extended to an M-ary setting and a version of it for the multivariate case is provided. In the second part, general properties of the bounds are provided. First, it is shown that all the bounds tensorize. Second, a complete characterization of the high-noise asymptotic is provided, which is used to argue about the tightness of the bounds. Third, the low-noise asymptotic is provided for mixed-input distributions and Gaussian additive noise channels. Specifically, in the low-noise, it is shown that the SZZB is not always tight. In the third part, the tightness of the bounds is evaluated. First, it is shown that in the low-noise regime the ZZB bound without the VFF is tight for mixed-input distributions and Gaussian additive noise channels. Second, for discrete inputs, the ZZB with the VFF is shown to be always sub-optimal, and equal to zero without the VFF. Third, unlike for the ZZB, an example is shown for which the SZZB is tight to the MMSE for discrete inputs. Fourth, sufficient and necessary conditions for the tightness of the bounds are provided. Finally, some examples are shown in which the bounds in the ZZ family outperform other well-known Bayesian bounds, i.e., the Cramér-Rao bound and the maximum entropy bound.

Paper number 65:
Title: Multiple-Target Detection in Cell-Free Massive MIMO-Assisted ISAC
Authors: Mohamed Elfiatoure, Mohammadali Mohammadi, Hien Quoc Ngo, Hyundong Shin, Michail Matthaiou
Abstract: We propose a distributed implementation for integrated sensing and communication (ISAC) backed by a massive multiple input multiple output (CF-mMIMO) architecture without cells. Distributed multi-antenna access points (APs) simultaneously serve communication users (UEs) and emit probing signals towards multiple specified zones for sensing. The APs can switch between communication and sensing modes, and adjust their transmit power based on the network settings and sensing and communication operations' requirements. By considering local partial zero-forcing and maximum-ratio-transmit precoding at the APs for communication and sensing, respectively, we first derive closed-form expressions for the spectral efficiency (SE) of the UEs and the mainlobe-to-average-sidelobe ratio (MASR) of the sensing zones. Then, a joint operation mode selection and power control design problem is formulated to maximize the SE fairness among the UEs, while ensuring specific levels of MASR for sensing zones. The complicated mixed-integer problem is relaxed and solved via successive convex approximation approach. We further propose a low-complexity design, where AP mode selection is designed through a greedy algorithm and then power control is designed based on this chosen mode. Our findings reveal that the proposed scheme can consistently ensure a sensing success rate of $100\%$ for different network setups with a satisfactory fairness among all UEs.

Paper number 66:
Title: EnvId: A Metric Learning Approach for Forensic Few-Shot Identification of Unseen Environments
Authors: Denise Moussa, Germans Hirsch, Christian Riess
Abstract: Audio recordings may provide important evidence in criminal investigations. One such case is the forensic association of a recorded audio to its recording location. For example, a voice message may be the only investigative cue to narrow down the candidate sites for a crime. Up to now, several works provide supervised classification tools for closed-set recording environment identification under relatively clean recording conditions. However, in forensic investigations, the candidate locations are case-specific. Thus, supervised learning techniques are not applicable without retraining a classifier on a sufficient amount of training samples for each case and respective candidate set. In addition, a forensic tool has to deal with audio material from uncontrolled sources with variable properties and quality. In this work, we therefore attempt a major step towards practical forensic application scenarios. We propose a representation learning framework called EnvId, short for environment identification. EnvId avoids case-specific retraining by modeling the task as a few-shot classification problem. We demonstrate that EnvId can handle forensically challenging material. It provides good quality predictions even under unseen signal degradations, out-of-distribution reverberation characteristics or recording position mismatches.

Paper number 67:
Title: An Exact Theory of Causal Emergence for Linear Stochastic Iteration Systems
Authors: Kaiwei Liu, Bing Yuan, Jiang Zhang
Abstract: After coarse-graining a complex system, the dynamics of its macro-state may exhibit more pronounced causal effects than those of its micro-state. This phenomenon, known as causal emergence, is quantified by the indicator of effective information. However, two challenges confront this theory: the absence of well-developed frameworks in continuous stochastic dynamical systems and the reliance on coarse-graining methodologies. In this study, we introduce an exact theoretic framework for causal emergence within linear stochastic iteration systems featuring continuous state spaces and Gaussian noise. Building upon this foundation, we derive an analytical expression for effective information across general dynamics and identify optimal linear coarse-graining strategies that maximize the degree of causal emergence when the dimension averaged uncertainty eliminated by coarse-graining has an upper bound. Our investigation reveals that the maximal causal emergence and the optimal coarse-graining methods are primarily determined by the principal eigenvalues and eigenvectors of the dynamic system's parameter matrix, with the latter not being unique. To validate our propositions, we apply our analytical models to three simplified physical systems, comparing the outcomes with numerical simulations, and consistently achieve congruent results.

Paper number 68:
Title: Converse Theorems for Certificates of Safety and Stability
Authors: Pol Mestres, Jorge Cortés
Abstract: Motivated by the key role of control barrier functions (CBFs) in assessing safety and enabling the synthesis of safe controllers in nonlinear control systems, this paper presents a suite of converse results on CBFs. Given any safe set, we first identify a set of general sufficient conditions which guarantee the existence of a CBF. Our technical analysis also enables us to define an extended notion of CBF which is always guaranteed to exist if the set is safe. We next turn our attention to the problem of joint safety and stability, and give conditions under which the notions of control Lyapunov-barrier function (CLBF) and compatible control Lyapunov function (CLF) and CBF pair are guaranteed to exist. Finally, we identify conditions under which a CLBF and a compatible CLF-CBF pair can be constructed from a non-compatible CLF-CBF pair. Throughout the paper, we intersperse different examples and counterexamples to motivate our results and position them within the state of the art.

Paper number 69:
Title: Regression coefficient estimation from remote sensing maps
Authors: Kerri Lu, Dan M. Kluger, Stephen Bates, Sherrie Wang
Abstract: Remote sensing map products are used to estimate regression coefficients relating environmental variables, such as the effect of conservation zones on deforestation. However, the quality of map products varies, and -- because maps are outputs of complex machine learning algorithms that take in a variety of remotely sensed variables as inputs -- errors are difficult to characterize. Thus, population-level estimates from such maps may be biased. In this paper, we apply prediction-powered inference (PPI) to regression coefficient estimation. PPI generates unbiased estimates by using a small amount of randomly sampled ground truth data to correct for bias in large-scale remote sensing map products. Applying PPI across multiple remote sensing use cases in regression coefficient estimation, we find that it results in estimates that are (1) more reliable than using the map product as if it were 100% accurate and (2) have lower uncertainty than using only the ground truth and ignoring the map product. Empirically, we observe effective sample size increases of up to 17-fold using PPI compared to only using ground truth data. This is the first work to estimate remote sensing regression coefficients without assumptions on the structure of map product errors. Data and code are available at this https URL.

Paper number 70:
Title: Characterization of point-source transient events with a rolling-shutter compressed sensing system
Authors: Frank Qiu, Joshua Michalenko, Lilian K. Casias, Cameron J. Radosevich, Jon Slater, Eric A. Shields
Abstract: Point-source transient events (PSTEs) - optical events that are both extremely fast and extremely small - pose several challenges to an imaging system. Due to their speed, accurately characterizing such events often requires detectors with very high frame rates. Due to their size, accurately detecting such events requires maintaining coverage over an extended field-of-view, often through the use of imaging focal plane arrays (FPA) with a global shutter readout. Traditional imaging systems that meet these requirements are costly in terms of price, size, weight, power consumption, and data bandwidth, and there is a need for cheaper solutions with adequate temporal and spatial coverage. To address these issues, we develop a novel compressed sensing algorithm adapted to the rolling shutter readout of an imaging system. This approach enables reconstruction of a PSTE signature at the sampling rate of the rolling shutter, offering a 1-2 order of magnitude temporal speedup and a proportional reduction in data bandwidth. We present empirical results demonstrating accurate recovery of PSTEs using measurements that are spatially undersampled by a factor of 25, and our simulations show that, relative to other compressed sensing algorithms, our algorithm is both faster and yields higher quality reconstructions. We also present theoretical results characterizing our algorithm and corroborating simulations. The potential impact of our work includes the development of much faster, cheaper sensor solutions for PSTE detection and characterization.

Paper number 71:
Title: A New Twist on Low-Complexity Digital Backpropagation
Authors: Stella Civelli, Debi Pada Jana, Enrico Forestieri, Marco Secondini
Abstract: This work proposes a novel low-complexity digital backpropagation (DBP) method, with the goal of optimizing the trade-off between backpropagation accuracy and complexity. The method combines a split step Fourier method (SSFM)-like structure with a simplified logarithmic perturbation method to obtain a high accuracy with a small number of DBP steps. Subband processing and asymmetric steps with optimized splitting ratio are also employed to further reduce the number of steps required to achieve a prescribed performance. The first part of the manuscript is dedicated to the derivation of a simplified logarithmic-perturbation model for the propagation of signal in an optical fiber, which serves for the development of the proposed coupled-band enhanced split step Fourier method (CB-ESSFM) and for the analytical calculation of the model coefficients. Next, the manuscript presents a DSP algorithm for the implementation of DBP based on a discrete-time version of the model and an overlap-and-save processing strategy. Practical approaches for the optimization of the coefficients used in the algorithm and of the splitting ratio of the asymmetric steps are also discussed. A detailed analysis of the computational complexity is presented. Finally, the performance and complexity of the proposed DBP method are investigated through simulations. In a five-channel 100 GHz-spaced wavelength division multiplexing system over a 15x80 km single-mode-fiber link, the proposed CB-ESSFM achieves a gain of about 1dB over simple dispersion compensation with only 15 steps (corresponding to 681 real multiplications per 2D symbol), with an improvement of 0.9 dB over conventional SSFM and almost 0.4dB over our previously proposed ESSFM. Significant gains and improvements are obtained also at lower complexity. A similar analysis is performed also for longer links, confirming the good performance of the proposed method.

Paper number 72:
Title: Machine Learning-Based Estimation Of Wave Direction For Unmanned Surface Vehicles
Authors: Manele Ait Habouche, Mickaël Kerboeuf, Goulven Guillou, Jean-Philippe Babau
Abstract: Unmanned Surface Vehicles (USVs) have become critical tools for marine exploration, environmental monitoring, and autonomous navigation. Accurate estimation of wave direction is essential for improving USV navigation and ensuring operational safety, but traditional methods often suffer from high costs and limited spatial resolution. This paper proposes a machine learning-based approach leveraging LSTM (Long Short-Term Memory) networks to predict wave direction using sensor data collected from USVs. Experimental results show the capability of the LSTM model to learn temporal dependencies and provide accurate predictions, outperforming simpler baselines.

Paper number 73:
Title: Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment
Authors: Zuyan Liu, Yuhao Dong, Jiahui Wang, Ziwei Liu, Winston Hu, Jiwen Lu, Yongming Rao
Abstract: Recent advances in large language models, particularly following GPT-4o, have sparked increasing interest in developing omni-modal models capable of understanding more modalities. While some open-source alternatives have emerged, there is still a notable lag behind specialized single-modality models in performance. In this paper, we present Ola, an Omni-modal language model that achieves competitive performance across image, video, and audio understanding compared to specialized counterparts. The core design of Ola lies in its progressive modality alignment strategy that extends the supporting modality of the language model progressively. Our training pipeline begins with the most distinct modalities: image and text, then gradually expands the skill sets of the model using speech data that connects language and audio knowledge, and video data that connects all modalities. The progressive learning pipeline also enables us to maintain a relatively small size of the cross-modal alignment data, making developing omni-modal from existing vision-language models easy and less costly. Moreover, to unlock an advanced interactive experience like GPT-4o, we further design a sentence-wise decoding solution for streaming speech generation. Extensive experiments demonstrate that Ola surpasses existing open omni-modal LLMs across all modalities while achieving highly competitive performance compared to state-of-the-art specialized models of similar sizes. We aim to make Ola a fully open omni-modal understanding solution to advance future research in this emerging field. Model weights, code, and data are open-sourced at this https URL.

Paper number 74:
Title: Explainable and Class-Revealing Signal Feature Extraction via Scattering Transform and Constrained Zeroth-Order Optimization
Authors: Naoki Saito, David Weber
Abstract: We propose a new method to extract discriminant and explainable features from a particular machine learning model, i.e., a combination of the scattering transform and the multiclass logistic regression. Although this model is well-known for its ability to learn various signal classes with high classification rate, it remains elusive to understand why it can generate such successful classification, mainly due to the nonlinearity of the scattering transform. In order to uncover the meaning of the scattering transform coefficients selected by the multiclass logistic regression (with the Lasso penalty), we adopt zeroth-order optimization algorithms to search an input pattern that maximizes the class probability of a class of interest given the learned model. In order to do so, it turns out that imposing sparsity and smoothness of input patterns is important. We demonstrate the effectiveness of our proposed method using a couple of synthetic time-series classification problems.

Paper number 75:
Title: Adaptive Grasping of Moving Objects in Dense Clutter via Global-to-Local Detection and Static-to-Dynamic Planning
Authors: Hao Chen, Takuya Kiyokawa, Weiwei Wan, Kensuke Harada
Abstract: Robotic grasping is facing a variety of real-world uncertainties caused by non-static object states, unknown object properties, and cluttered object arrangements. The difficulty of grasping increases with the presence of more uncertainties, where commonly used learning-based approaches struggle to perform consistently across varying conditions. In this study, we integrate the idea of similarity matching to tackle the challenge of grasping novel objects that are simultaneously in motion and densely cluttered using a single RGBD camera, where multiple uncertainties coexist. We achieve this by shifting visual detection from global to local states and operating grasp planning from static to dynamic scenes. Notably, we introduce optimization methods to enhance planning efficiency for this time-sensitive task. Our proposed system can adapt to various object types, arrangements and movement speeds without the need for extensive training, as demonstrated by real-world experiments. Videos are available at this https URL.
    