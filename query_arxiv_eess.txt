
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Raspberry Pi Pico as a Radio Transmitter
Authors: M. Andrecut
Abstract: In this paper we discuss several surprisingly simple methods for transforming the Raspberry Pi Pico (RP2) microcontroller into a radio transmitter, by using only cheap off the shelf electronic components, and open source software. While initially this transformation may look as a harmless curiosity, in some extreme cases it can also pose security risks, since it can be used to open a large number of local stealth radio communication channels.

Paper number 2:
Title: A Federated Fine-Tuning Paradigm of Foundation Models in Heterogenous Wireless Networks
Authors: Jingyi Wang, Zhongyuan Zhao, Qingtian Wang, Zexu Li, Yue Wang, Tony Q. S. Quek
Abstract: Edge intelligence has emerged as a promising strategy to deliver low-latency and ubiquitous services for mobile devices. Recent advances in fine-tuning mechanisms of foundation models have enabled edge intelligence by integrating low-rank adaptation (LoRA) with federated learning. However, in wireless networks, the device heterogeneity and resource constraints on edge devices pose great threats to the performance of federated fine-tuning. To tackle these issues, we propose to optimize federated fine-tuning in heterogenous wireless networks via online learning. First, the framework of switching-based federated fine-tuning in wireless networks is provided. The edge devices switches to LoRA modules dynamically for federated fine-tuning with base station to jointly mitigate the impact of device heterogeneity and transmission unreliability. Second, a tractable upper bound on the inference risk gap is derived based on theoretical analysis. To improve the generalization capability, we formulate a non-convex mixed-integer programming problem with long-term constraints, and decouple it into model switching, transmit power control, and bandwidth allocation subproblems. An online optimization algorithm is developed to solve the problems with polynomial computational complexity. Finally, the simulation results on the SST-2 and QNLI data sets demonstrate the performance gains in test accuracy and energy efficiency.

Paper number 3:
Title: Bandwidth of Gamma-Distribution-Shaped Functions via Lambert W Function
Authors: Anthony LoPrete, Johannes Burge
Abstract: The full width at half maximum (FWHM) is a useful quantity for characterizing the bandwidth of unimodal functions. However, a closed-form expression for the FWHM of gamma-shaped functions-i.e. functions that are shaped like the gamma distribution probability density function (PDF)-is not widely available. Here, we derive and present just such an expression. To do so, we use the Lambert W function to compute the inverse of the gamma PDF. We use this inverse to derive an exact analytic expression for the width of a gamma distribution at an arbitrary proportion of the maximum, from which the FWHM follows trivially. (An expression for the octave bandwidth of gamma-shaped functions is also provided.) The FWHM is then compared to the Gaussian approximation of gamma-shaped functions. A few other related issues are discussed.

Paper number 4:
Title: Graph-Based Spatio-temporal Attention and Multi-Scale Fusion for Clinically Interpretable, High-Fidelity Fetal ECG Extraction
Authors: Chang Wang, Ming Zhu, Shahram Latifi, Buddhadeb Dawn, Shengjie Zhai
Abstract: Congenital Heart Disease (CHD) is the most common neonatal anomaly, highlighting the urgent need for early detection to improve outcomes. Yet, fetal ECG (fECG) signals in abdominal ECG (aECG) are often masked by maternal ECG and noise, challenging conventional methods under low signal-to-noise ratio (SNR) conditions. We propose FetalHealthNet (FHNet), a deep learning framework that integrates Graph Neural Networks with a multi-scale enhanced transformer to dynamically model spatiotemporal inter-lead correlations and extract clean fECG signals. On benchmark aECG datasets, FHNet consistently outperforms long short-term memory (LSTM) models, standard transformers, and state-of-the-art models, achieving R2>0.99 and RMSE = 0.015 even under severe noise. Interpretability analyses highlight physiologically meaningful temporal and lead contributions, supporting model transparency and clinical trust. FHNet illustrates the potential of AI-driven modeling to advance fetal monitoring and enable early CHD screening, underscoring the transformative impact of next-generation biomedical signal processing.

Paper number 5:
Title: A Novel Two-Dimensional Wigner Distribution Framework via the Quadratic Phase Fourier Transform with a Non-Separable Kernel
Authors: Mukul Chauhan, Waseem Z. Lone, Amit K. Verma
Abstract: This paper introduces a novel time-frequency distribution, referred to as the Two-Dimensional Non-Separable Quadratic Phase Wigner Distribution (2D-NSQPWD), formulated within the framework of the Two-Dimensional Non-Separable Quadratic Phase Fourier Transform (2D-NSQPFT). By replacing the classical Fourier kernel with the NSQPFT kernel, the proposed distribution generalizes the classical Wigner distribution and effectively captures complex, non-separable signal structures. We rigorously establish several key properties of the 2D-NSQPWD, including time and frequency shift invariance, marginal behavior, conjugate symmetry, convolution relations, and Moyal's identity. Furthermore, the connection between the 2D-NSQPWD and the two-dimensional short-time Fourier transform (2D-STFT) is explored. The distribution's effectiveness is demonstrated through its application to single-, bi-, and tri-component two-dimensional linear frequency modulated (2D-LFM) signals, where it shows superior performance in cross-term suppression and signal localization.

Paper number 6:
Title: E2E Learning Massive MIMO for Multimodal Semantic Non-Orthogonal Transmission and Fusion
Authors: Minghui Wu, Zhen Gao
Abstract: Massive multiple-input multiple-output (MIMO) promises high spectral efficiency but also leads to high-dimensional downlink channel state information (CSI), which complicates real-time channel acquisition and precoding. To address this, we propose an end-to-end (E2E) uplink-downlink CSI fusion precoding network that jointly models downlink CSI reference signal (CSI-RS) design, CSI feedback, and base-station (BS) precoding within a single E2E neural architecture. Concretely, a projection network built on the MAXIM architecture takes uplink sounding reference signals (SRS) as input and outputs frequency-, beam-, and port-domain projection matrices for designing downlink CSI-RS. User equipment (UE) then compresses/quantizes the resulting CSI-RS observations and feeds back a compact representation. At the base station (BS), two complementary branches produce candidate precoders: one is a feedback-only precoding network driven by quantized downlink observations, and the other is an SRS-only precoding network driven by uplink SRS. These candidate precoders are subsequently combined by a fusion precoding network to yield the final transmit precoder. All the modules are trained with a spectral-efficiency-oriented loss under a three-stage schedule. Simulation results show that the proposed approach effectively harnesses both SRS-derived information and UE feedback, achieving markedly better performance than conventional baselines.

Paper number 7:
Title: STL-FFT-STFT-TCN-LSTM: An Effective Wave Height High Accuracy Prediction Model Fusing Time-Frequency Domain Features
Authors: Huipeng Liu, Zhichao Zhu, Yuan Zhou, Changlu Li
Abstract: As the consumption of traditional energy sources intensifies and their adverse environmental impacts become more pronounced, wave energy stands out as a highly promising member of the renewable energy family due to its high energy density, stability, widespread distribution, and environmental friendliness. The key to its development lies in the precise prediction of Significant Wave Height (WVHT). However, wave energy signals exhibit strong nonlinearity, abrupt changes, multi-scale periodicity, data sparsity, and high-frequency noise interference; additionally, physical models for wave energy prediction incur extremely high computational costs. To address these challenges, this study proposes a hybrid model combining STL-FFT-STFT-TCN-LSTM. This model exploits the Seasonal-Trend Decomposition Procedure based on Loess (STL), Fast Fourier Transform (FFT), Short-Time Fourier Transform (STFT), Temporal Convolutional Network (TCN), and Long Short-Term Memory (LSTM) technologies. The model aims to optimize multi-scale feature fusion, capture extreme wave heights, and address issues related to high-frequency noise and periodic signals, thereby achieving efficient and accurate prediction of significant wave height. Experiments were conducted using hourly data from NOAA Station 41008 and 41047 spanning 2019 to 2022. The results showed that compared with other single models and hybrid models, the STL-FFT-STFT-TCN-LSTM model achieved significantly higher prediction accuracy in capturing extreme wave heights and suppressing high-frequency noise, with MAE reduced by 15.8\%-40.5\%, SMAPE reduced by 8.3\%-20.3\%, and R increased by 1.31\%-2.9\%; in ablation experiments, the model also demonstrated the indispensability of each component step, validating its superiority in multi-scale feature fusion.

Paper number 8:
Title: Advancing Few-Shot Pediatric Arrhythmia Classification with a Novel Contrastive Loss and Multimodal Learning
Authors: Yiqiao Chen, Zijian Huang, Zhenghui Feng
Abstract: Pediatric arrhythmias are a major risk factor for disability and sudden cardiac death, yet their automated classification remains challenging due to class imbalance, few-shot categories, and complex signal characteristics, which severely limit the efficiency and reliability of early screening and clinical intervention. To address this problem, we propose a multimodal end-to-end deep learning framework that combines dual-branch convolutional encoders for ECG and IEGM, semantic attention for cross-modal feature alignment, and a lightweight Transformer encoder for global dependency modeling. In addition, we introduce a new contrastive loss fucntion named Adaptive Global Class-Aware Contrastive Loss (AGCACL) to enhance intra-class compactness and inter-class separability through class prototypes and a global similarity matrix. To the best of our knowledge, this is the first systematic study based on the Leipzig Heart Center pediatric/congenital ECG+IEGM dataset, for which we also provide a complete and reproducible preprocessing pipeline. Experimental results demonstrate that the proposed method achieves the overall best performance on this dataset, including 97.76\% Top-1 Accuracy, 94.08\% Macro Precision, 91.97\% Macro Recall, 92.97\% Macro F1, and 92.36\% Macro F2, with improvements of +13.64, +15.96, +19.82, and +19.44 percentage points over the strongest baseline in Macro Precision/Recall/F1/F2, respectively. These findings indicate that the framework significantly improves the detectability and robustness for minority arrhythmia classes, offering potential clinical value for rhythm screening, pre-procedural assessment, and postoperative follow-up in pediatric and congenital heart disease populations.

Paper number 9:
Title: Electric Vehicle Identification from Behind Smart Meter Data
Authors: Ammar Kamoona, Hui Song, Ali Moradi Amani, Mahdi Jalili, Xinghuo Yu, Peter McTaggart
Abstract: Electric vehicle (EV) charging loads identification from behind smart meter recordings is an indispensable aspect that enables effective decision-making for energy distributors to reach an informed and intelligent decision about the power grid's reliability. When EV charging happens behind the meter (BTM), the charging occurs on the customer side of the meter, which measures the overall electricity consumption. In other words, the charging of the EV is considered part of the customer's load and not separately measured by the Distribution Network Operators (DNOs). DNOs require complete knowledge about the EV presence in their network. Identifying the EV charging demand is essential to better plan and manage the distribution grid. Unlike supervised methods, this paper addresses the problem of EV charging load identification in a non-nonintrusive manner from low-frequency smart meter using an unsupervised learning approach based on anomaly detection technique. Our approach does not require prior knowledge of EV charging profiles. It only requires real power consumption data of non-EV users, which are abundant in practice. We propose a deep temporal convolution encoding decoding (TAE) network. The TAE is applied to power consumption from smart BTM from Victorian households in Australia, and the TAE shows superior performance in identifying households with EVs.

Paper number 10:
Title: Scensory: Automated Real-Time Fungal Identification and Spatial Mapping
Authors: Yanbaihui Liu, Erica Babusci, Claudia K. Gunsch, Boyuan Chen
Abstract: Indoor fungal contamination poses significant risks to public health, yet existing detection methods are slow, costly, and lack spatial resolution. Conventional approaches rely on laboratory analysis or high-concentration sampling, making them unsuitable for real-time monitoring and scalable deployment. We introduce \textbf{\textit{Scensory}}, a robot-enabled olfactory system that simultaneously identifies fungal species and localizes their spatial origin using affordable volatile organic compound (VOC) sensor arrays and deep learning. Our key idea is that temporal VOC dynamics encode both chemical and spatial signatures, which we decode through neural architectures trained on robot-automated data collection. We demonstrate two operational modes: a passive multi-array configuration for environmental monitoring, and a mobile single-array configuration for active source tracking. Across five fungal species, our system achieves up to 89.85\% accuracy in species detection and 87.31\% accuracy in localization under ambient conditions, where each prediction only takes 3--7\,s sensor inputs. Additionally, by computationally analyzing model behavior, we can uncover key biochemical signatures without additional laboratory experiments. Our approach enables real-time, spatially aware fungal monitoring and establishes a scalable and affordable framework for autonomous environmental sensing.

Paper number 11:
Title: Human Activity Recognition Based on Electrocardiogram Data Only
Authors: Sina Montazeri, Waltenegus Dargie, Yunhe Feng, Kewei Sha
Abstract: Human activity recognition is critical for applications such as early intervention and health analytics. Traditional activity recognition relies on inertial measurement units (IMUs), which are resource intensive and require calibration. Although electrocardiogram (ECG)-based methods have been explored, these have typically served as supplements to IMUs or have been limited to broad categorical classification such as fall detection or active vs. inactive in daily activities. In this paper, we advance the field by demonstrating, for the first time, robust recognition of activity only with ECG in six distinct activities, which is beyond the scope of previous work. We design and evaluate three new deep learning models, including a CNN classifier with Squeeze-and-Excitation blocks for channel-wise feature recalibration, a ResNet classifier with dilated convolutions for multiscale temporal dependency capture, and a novel CNNTransformer hybrid combining convolutional feature extraction with attention mechanisms for long-range temporal relationship modeling. Tested on data from 54 subjects for six activities, all three models achieve over 94% accuracy for seen subjects, while CNNTransformer hybrid reaching the best accuracy of 72% for unseen subjects, a result that can be further improved by increasing the training population. This study demonstrates the first successful ECG-only activity classification in multiple physical activities, offering significant potential for developing next-generation wearables capable of simultaneous cardiac monitoring and activity recognition without additional motion sensors.

Paper number 12:
Title: LibEMER: A novel benchmark and algorithms library for EEG-based Multimodal Emotion Recognition
Authors: Zejun Liu, Yunshan Chen, Chengxi Xie, Huan Liu
Abstract: EEG-based multimodal emotion recognition(EMER) has gained significant attention and witnessed notable advancements, the inherent complexity of human neural systems has motivated substantial efforts toward multimodal approaches. However, this field currently suffers from three critical limitations: (i) the absence of open-source implementations. (ii) the lack of standardized and transparent benchmarks for fair performance analysis. (iii) in-depth discussion regarding main challenges and promising research directions is a notable scarcity. To address these challenges, we introduce LibEMER, a unified evaluation framework that provides fully reproducible PyTorch implementations of curated deep learning methods alongside standardized protocols for data preprocessing, model realization, and experimental setups. This framework enables unbiased performance assessment on three widely-used public datasets across two learning tasks. The open-source library is publicly accessible at: this https URL

Paper number 13:
Title: Holographic Transformers for Complex-Valued Signal Processing: Integrating Phase Interference into Self-Attention
Authors: Enhao Huang, Zhiyu Zhang, Tianxiang Xu, Chunshu Xia, Kaichun Hu, Yuchen Yang, Tongtong Pan, Dong Dong, Zhan Qin
Abstract: Complex-valued signals encode both amplitude and phase, yet most deep models treat attention as real-valued correlation, overlooking interference effects. We introduce the Holographic Transformer, a physics-inspired architecture that incorporates wave interference principles into self-attention. Holographic attention modulates interactions by relative phase and coherently superimposes values, ensuring consistency between amplitude and phase. A dual-headed decoder simultaneously reconstructs the input and predicts task outputs, preventing phase collapse when losses prioritize magnitude over phase. We demonstrate that holographic attention implements a discrete interference operator and maintains phase consistency under linear mixing. Experiments on PolSAR image classification and wireless channel prediction show strong performance, achieving high classification accuracy and F1 scores, low regression error, and increased robustness to phase perturbations. These results highlight that enforcing physical consistency in attention leads to generalizable improvements in complex-valued learning and provides a unified, physics-based framework for coherent signal modeling. The code is available at this https URL.

Paper number 14:
Title: A Spatio-Temporal Feature Fusion EEG Virtual Channel Signal Generation Network and Its Application in Anxiety Assessment
Authors: Shangqing Yuan, Wenshuang Zhai, Shengwen Guo
Abstract: To address the issue of limited channels and insufficient information collection in portable EEG devices, this study explores an EEG virtual channel signal generation network using a novel spatio-temporal feature fusion strategy. Based on the EEG signals from four frontal lobe channels, the network aims to generate virtual channel EEG signals for other 13 important brain regions. The architecture of the network is a two-dimensional convolutional neural network and it includes a parallel module for temporal and spatial domain feature extraction, followed by a feature fusion module. The public PRED+CT database, which includes multi-channel EEG signals from 119 subjects, was selected to verify the constructed network. The results showed that the average correlation coefficient between the generated virtual channel EEG signals and the original real signals was 0.6724, with an average absolute error of 3.9470. Furthermore, the 13 virtual channel EEG signals were combined with the original EEG signals of four brain regions and then used for anxiety classification with a support vector machine. The results indicate that the virtual EEG signals generated by the constructed network not only have a high degree of consistency with the real channel EEG signals but also significantly enhance the performance of machine learning algorithms for anxiety classification. This study effectively alleviates the problem of insufficient information acquisition by portable EEG devices with few channels.

Paper number 15:
Title: CSIYOLO: An Intelligent CSI-based Scatter Sensing Framework for Integrated Sensing and Communication Systems
Authors: Xudong Zhang, Jingbo Tan, Zhizhen Ren, Jintao Wang, Yihua Ma, Jian Song
Abstract: ISAC is regarded as a promising technology for next-generation communication systems, enabling simultaneous data transmission and target sensing. Among various tasks in ISAC, scatter sensing plays a crucial role in exploiting the full potential of ISAC and supporting applications such as autonomous driving and low-altitude economy. However, most existing methods rely on either waveform and hardware modifications or traditional signal processing schemes, leading to poor compatibility with current communication systems and limited sensing accuracy. To address these challenges, we propose CSIYOLO, a framework that performs scatter localization only using estimated CSI from a single base station-user equipment pair. This framework comprises two main components: anchor-based scatter parameter detection and CSI-based scatter localization. First, by formulating scatter parameter extraction as an image detection problem, we propose an anchor-based scatter parameter detection method inspired by You Only Look Once architectures. After that, a CSI-based localization algorithm is derived to determine scatter locations with extracted parameters. Moreover, to improve localization accuracy and implementation efficiency, we design an extendable network structure with task-oriented optimizations, enabling multi-scale anchor detection and better adaptation to CSI characteristics. A noise injection training strategy is further designed to enhance robustness against channel estimation errors. Since the proposed framework operates solely on estimated CSI without modifying waveforms or signal processing pipelines, it can be seamlessly integrated into existing communication systems as a plugin. Experiments show that our proposed method can significantly outperform existing methods in scatter localization accuracy with relatively low complexities under varying numbers of scatters and estimation errors.

Paper number 16:
Title: Joint Channel Estimation and Computation Offloading in Fluid Antenna-assisted MEC Networks
Authors: Ying Ju, Mingdong Li, Haoyu Wang, Lei Liu, Youyang Qu, Mianxiong Dong, Victor C. M. Leung, Chau Yuen
Abstract: With the emergence of fluid antenna (FA) in wireless communications, the capability to dynamically adjust port positions offers substantial benefits in spatial diversity and spectrum efficiency, which are particularly valuable for mobile edge computing (MEC) systems. Therefore, we propose an FA-assisted MEC offloading framework to minimize system delay. This framework faces two severe challenges, which are the complexity of channel estimation due to dynamic port configuration and the inherent non-convexity of the joint optimization problem. Firstly, we propose Information Bottleneck Metric-enhanced Channel Compressed Sensing (IBM-CCS), which advances FA channel estimation by integrating information relevance into the sensing process and capturing key features of FA channels effectively. Secondly, to address the non-convex and high-dimensional optimization problem in FA-assisted MEC systems, which includes FA port selection, beamforming, power control, and resource allocation, we propose a game theory-assisted Hierarchical Twin-Dueling Multi-agent Algorithm (HiTDMA) based offloading scheme, where the hierarchical structure effectively decouples and coordinates the optimization tasks between the user side and the base station side. Crucially, the game theory effectively reduces the dimensionality of power control variables, allowing deep reinforcement learning (DRL) agents to achieve improved optimization efficiency. Numerical results confirm that the proposed scheme significantly reduces system delay and enhances offloading performance, outperforming benchmarks. Additionally, the IBM-CCS channel estimation demonstrates superior accuracy and robustness under varying port densities, contributing to efficient communication under imperfect CSI.

Paper number 17:
Title: A Measurement Report Data-Driven Framework for Localized Statistical Channel Modeling
Authors: Xinyu Qin, Ye Xue, Qi Yan, Shutao Zhang, Bingsheng Peng, Tsung-Hui Chang
Abstract: Localized statistical channel modeling (LSCM) is crucial for effective performance evaluation in digital twin-assisted network optimization. Solely relying on the multi-beam reference signal receiving power (RSRP), LSCM aims to model the localized statistical propagation environment by estimating the channel angular power spectrum (APS). However, existing methods rely heavily on drive test data with high collection costs and limited spatial coverage. In this paper, we propose a measurement report (MR) data-driven framework for LSCM, exploiting the low-cost and extensive collection of MR data. The framework comprises two novel modules. The MR localization module addresses the issue of missing locations in MR data by introducing a semi-supervised method based on hypergraph neural networks, which exploits multi-modal information via distance-aware hypergraph modeling and hypergraph convolution for location extraction. To enhance the computational efficiency and solution robustness, LSCM operates at the grid level. Compared to independently constructing geographically uniform grids and estimating channel APS, the joint grid construction and channel APS estimation module enhances robustness in complex environments with spatially non-uniform data by exploiting their correlation. This module alternately optimizes grid partitioning and APS estimation using clustering and improved sparse recovery for the ill-conditioned measurement matrix and incomplete observations. Through comprehensive experiments on a real-world MR dataset, we demonstrate the superior performance and robustness of our framework in localization and channel modeling.

Paper number 18:
Title: Frequency-Aware Ensemble Learning for BraTS 2025 Pediatric Brain Tumor Segmentation
Authors: Yuxiao Yi, Qingyao Zhuang, Zhi-Qin John Xu
Abstract: Pediatric brain tumor segmentation presents unique challenges due to the rarity and heterogeneity of these malignancies, yet remains critical for clinical diagnosis and treatment planning. We propose an ensemble approach integrating nnU-Net, Swin UNETR, and HFF-Net for the BraTS-PED 2025 challenge. Our method incorporates three key extensions: adjustable initialization scales for optimal nnU-Net complexity control, transfer learning from BraTS 2021 pre-trained models to enhance Swin UNETR's generalization on pediatric dataset, and frequency domain decomposition for HFF-Net to separate low-frequency tissue contours from high-frequency texture details. Our final ensemble combines nnU-Net ($\gamma=0.7$), fine-tuned Swin UNETR, and HFF-Net, achieving Dice scores of 72.3% (ET), 95.6% (NET), 68.9% (CC), 89.5% (ED), 92.3% (TC), and 92.3% (WT), respectively.

Paper number 19:
Title: Low-Cost Sensor Fusion Framework for Organic Substance Classification and Quality Control Using Classification Methods
Authors: Borhan Uddin Chowdhury, Damian Valles, Md Raf E Ul Shougat
Abstract: We present a sensor-fusion framework for rapid, non-destructive classification and quality control of organic substances, built on a standard Arduino Mega 2560 microcontroller platform equipped with three commercial environmental and gas sensors. All data used in this study were generated in-house: sensor outputs for ten distinct classes - including fresh and expired samples of apple juice, onion, garlic, and ginger, as well as cinnamon and cardamom - were systematically collected and labeled using this hardware setup, resulting in a unique, application-specific dataset. Correlation analysis was employed as part of the preprocessing pipeline for feature selection. After preprocessing and dimensionality reduction (PCA/LDA), multiple supervised learning models - including Support Vector Machine (SVM), Decision Tree (DT), and Random Forest (RF), each with hyperparameter tuning, as well as an Artificial Neural Network (ANN) and an ensemble voting classifier - were trained and cross-validated on the collected dataset. The best-performing models, including tuned Random Forest, ensemble, and ANN, achieved test accuracies in the 93 to 94 percent range. These results demonstrate that low-cost, multisensory platforms based on the Arduino Mega 2560, combined with advanced machine learning and correlation-driven feature engineering, enable reliable identification and quality control of organic compounds.

Paper number 20:
Title: Short-Term Regional Electricity Demand Forecasting in Argentina Using LSTM Networks
Authors: Oscar A. Oviedo
Abstract: This study presents the development and optimization of a deep learning model based on Long Short-Term Memory (LSTM) networks to predict short-term hourly electricity demand in Córdoba, Argentina. Integrating historical consumption data with exogenous variables (climatic factors, temporal cycles, and demographic statistics), the model achieved high predictive precision, with a mean absolute percentage error of 3.20\% and a determination coefficient of 0.95. The inclusion of periodic temporal encodings and weather variables proved crucial to capture seasonal patterns and extreme consumption events, enhancing the robustness and generalizability of the model. In addition to the design and hyperparameter optimization of the LSTM architecture, two complementary analyses were carried out: (i) an interpretability study using Random Forest regression to quantify the relative importance of exogenous drivers, and (ii) an evaluation of model performance in predicting the timing of daily demand maxima and minima, achieving exact-hour accuracy in more than two-thirds of the test days and within abs(1) hour in over 90\% of cases. Together, these results highlight both the predictive accuracy and operational relevance of the proposed framework, providing valuable insights for grid operators seeking optimized planning and control strategies under diverse demand scenarios.

Paper number 21:
Title: Neural Network Based Framework for Passive Intermodulation Cancellation in MIMO Systems
Authors: Xiaolong Li, Zhi-qin John Xu, Peiting You, Yifei Zhu
Abstract: Passive intermodulation (PIM) has emerged as a critical source of self-interference in modern MIMO-OFDM systems, especially under the stringent requirements of 5G and beyond. Conventional cancellation methods often rely on complex nonlinear models with limited scalability and high computational cost. In this work, we propose a lightweight deep learning framework for PIM cancellation that leverages depthwise separable convolutions and dilated convolutions to efficiently capture nonlinear dependencies across antennas and subcarriers. To further enhance convergence, we adopt a cyclic learning rate schedule and gradient clipping. In a controlled MIMO experimental setup, the method effectively suppresses third-order passive intermodulation (PIM) distortion, achieving up to 29dB of average power error (APE) with only 11k trainable parameters. These results highlight the potential of compact neural architectures for scalable interference mitigation in future wireless communication systems.

Paper number 22:
Title: Impact of RHIs and ipSIC on Active RIS-NOMA Systems with Low-Precision ADCs
Authors: Qianqian Li, Hua Li, Shiya Hao, Lintao Li, Xiaoming Dai
Abstract: This study evaluates the performance of an active reconfigurable intelligent surface (ARIS)-assisted non-orthogonal multiple access (NOMA) system employing low-precision analog-to-digital converters (ADCs). Analytical approximations for the outage probability (OP) are derived, considering residual hardware impairments (RHIs) and imperfect successive interference cancellation (ipSIC). Additionally, we analyze the asymptotic OP, system throughput, and diversity order at high signal-to-noise ratios (SNRs). Simulation results demonstrate that the proposed quantized ARIS-NOMA system outperforms its passive counterpart (PRIS-NOMA), achieving lower OP and higher throughput with reduced transmit power requirements and fewer reflecting elements. Moreover, the outage performance of both quantized ARIS-NOMA and PRIS-NOMA systems demonstrates significant improvement as the number of reflecting elements increases. The negative impacts of low-precision ADCs can be effectively mitigated by optimizing transmit power and scaling the number of reflecting elements.

Paper number 23:
Title: Data-Driven Reconstruction of Significant Wave Heights from Sparse Observations
Authors: Hongyuan Shi, Yilin Zhai, Ping Dong, Zaijin You, Chao Zhan, Qing Wang
Abstract: Reconstructing high-resolution regional significant wave height fields from sparse and uneven buoy observations remains a core challenge for ocean monitoring and risk-aware operations. We introduce AUWave, a hybrid deep learning framework that fuses a station-wise sequence encoder (MLP) with a multi-scale U-Net enhanced by a bottleneck self-attention layer to recover 32$\times$32 regional SWH fields. A systematic Bayesian hyperparameter search with Optuna identifies the learning rate as the dominant driver of generalization, followed by the scheduler decay and the latent dimension. Using NDBC buoy observations and ERA5 reanalysis over the Hawaii region, AUWave attains a minimum validation loss of 0.043285 and a slightly right-skewed RMSE distribution. Spatial errors are lowest near observation sites and increase with distance, reflecting identifiability limits under sparse sampling. Sensitivity experiments show that AUWave consistently outperforms a representative baseline in data-richer configurations, while the baseline is only marginally competitive in the most underdetermined single-buoy cases. The architecture's multi-scale and attention components translate into accuracy gains when minimal but non-trivial spatial anchoring is available. Error maps and buoy ablations reveal key anchor stations whose removal disproportionately degrades performance, offering actionable guidance for network design. AUWave provides a scalable pathway for gap filling, high-resolution priors for data assimilation, and contingency reconstruction.

Paper number 24:
Title: A Statistical Mixture-of-Experts Framework for EMG Artifact Removal in EEG: Empirical Insights and a Proof-of-Concept Application
Authors: Benjamin J. Choi, Griffin Milsap, Clara A. Scholl, Francesco Tenore, Mattson Ogg
Abstract: Effective control of neural interfaces is limited by poor signal quality. While neural network-based electroencephalography (EEG) denoising methods for electromyogenic (EMG) artifacts have improved in recent years, current state-of-the-art (SOTA) models perform suboptimally in settings with high noise. To address the shortcomings of current machine learning (ML)-based denoising algorithms, we present a signal filtration algorithm driven by a new mixture-of-experts (MoE) framework. Our algorithm leverages three new statistical insights into the EEG-EMG denoising problem: (1) EMG artifacts can be partitioned into quantifiable subtypes to aid downstream MoE classification, (2) local experts trained on narrower signal-to-noise ratio (SNR) ranges can achieve performance increases through specialization, and (3) correlation-based objective functions, in conjunction with rescaling algorithms, can enable faster convergence in a neural network-based denoising context. We empirically demonstrate these three insights into EMG artifact removal and use our findings to create a new downstream MoE denoising algorithm consisting of convolutional (CNN) and recurrent (RNN) neural networks. We tested all results on a major benchmark dataset (EEGdenoiseNet) collected from 67 subjects. We found that our MoE denoising model achieved competitive overall performance with SOTA ML denoising algorithms and superior lower bound performance in high noise settings. These preliminary results highlight the promise of our MoE framework for enabling advances in EMG artifact removal for EEG processing, especially in high noise settings. Further research and development will be necessary to assess our MoE framework on a wider range of real-world test cases and explore its downstream potential to unlock more effective neural interfaces.

Paper number 25:
Title: Hybrid Pipeline SWD Detection in Long-Term EEG Signals
Authors: Antonio Quintero Rincon, Nicolas Masino, Veronica Marsico, Hadj Batatia
Abstract: Spike-and-wave discharges (SWDs) are the electroencephalographic hallmark of absence epilepsy, yet their manual identification in multi-day recordings remains labour-intensive and error-prone. We present a lightweight hybrid pipeline that couples analytical features with a shallow artificial neural network (ANN) for accurate, patient-specific SWD detection in long-term, monopolar EEG. A two-sided moving-average (MA) filter first suppresses the high-frequency components of normal background activity. The residual signal is then summarised by the mean and the standard deviation of its normally distributed samples, yielding a compact, two-dimensional feature vector for every 20s window. These features are fed to a single-hidden-layer ANN trained via back-propagation to classify each window as SWD or non-SWD. The method was evaluated on 780 channels sampled at 256 Hz from 12 patients, comprising 392 annotated SWD events. It correctly detected 384 events (sensitivity: 98%) while achieving a specificity of 96.2 % and an overall accuracy of 97.2%. Because feature extraction is analytic, and the classifier is small, the pipeline runs in real-time and requires no manual threshold tuning. These results indicate that normal-distribution descriptors combined with a modest ANN provide an effective and computationally inexpensive solution for automated SWD screening in extended EEG recordings.

Paper number 26:
Title: Self-Alignment Learning to Improve Myocardial Infarction Detection from Single-Lead ECG
Authors: Jiarui Jin, Xiaocheng Fang, Haoyu Wang, Jun Li, Che Liu, Donglin Xie, Hongyan Li, Shenda Hong
Abstract: Myocardial infarction is a critical manifestation of coronary artery disease, yet detecting it from single-lead electrocardiogram (ECG) remains challenging due to limited spatial information. An intuitive idea is to convert single-lead into multiple-lead ECG for classification by pre-trained models, but generative methods optimized at the signal level in most cases leave a large latent space gap, ultimately degrading diagnostic performance. This naturally raises the question of whether latent space alignment could help. However, most prior ECG alignment methods focus on learning transformation invariance, which mismatches the goal of single-lead detection. To address this issue, we propose SelfMIS, a simple yet effective alignment learning framework to improve myocardial infarction detection from single-lead ECG. Discarding manual data augmentations, SelfMIS employs a self-cutting strategy to pair multiple-lead ECG with their corresponding single-lead segments and directly align them in the latent space. This design shifts the learning objective from pursuing transformation invariance to enriching the single-lead representation, explicitly driving the single-lead ECG encoder to learn a representation capable of inferring global cardiac context from the local signal. Experimentally, SelfMIS achieves superior performance over baseline models across nine myocardial infarction types while maintaining a simpler architecture and lower computational overhead, thereby substantiating the efficacy of direct latent space alignment. Our code and checkpoint will be publicly available after acceptance.

Paper number 27:
Title: SpellerSSL: Self-Supervised Learning with P300 Aggregation for Speller BCIs
Authors: Jiazhen Hong, Geoff Mackellar, Soheila Ghane
Abstract: Electroencephalogram (EEG)-based P300 speller brain-computer interfaces (BCIs) face three main challenges: low signal-to-noise ratio (SNR), poor generalization, and time-consuming calibration. We propose SpellerSSL, a framework that combines self-supervised learning (SSL) with P300 aggregation to address these issues. First, we introduce an aggregation strategy to enhance SNR. Second, to achieve generalization in training, we employ a customized 1D U-Net backbone and pretrain the model on both cross-domain and in-domain EEG data. The pretrained model is subsequently fine-tuned with a lightweight ERP-Head classifier for P300 detection, which adapts the learned representations to subject-specific data. Our evaluations on calibration time demonstrate that combining the aggregation strategy with SSL significantly reduces the calibration burden per subject and improves robustness across subjects. Experimental results show that SSL learns effective EEG representations in both in-domain and cross-domain, with in-domain achieving a state-of-the-art character recognition rate of 94% with only 7 repetitions and the highest information transfer rate (ITR) of 21.86 bits/min on the public II-B dataset. Moreover, in-domain SSL with P300 aggregation reduces the required calibration size by 60% while maintaining a comparable character recognition rate. To the best of our knowledge, this is the first study to apply SSL to P300 spellers, highlighting its potential to improve both efficiency and generalization in speller BCIs and paving the way toward an EEG foundation model for P300 speller BCIs.

Paper number 28:
Title: Online Adaptation via Dual-Stage Alignment and Self-Supervision for Fast-Calibration Brain-Computer Interfaces
Authors: Sheng-Bin Duan, Jian-Long Hao, Tian-Yu Xiang, Xiao-Hu Zhou, Mei-Jiang Gui, Xiao-Liang Xie, Shi-Qi Liu, Zeng-Guang Hou
Abstract: Individual differences in brain activity hinder the online application of electroencephalogram (EEG)-based brain computer interface (BCI) systems. To overcome this limitation, this study proposes an online adaptation algorithm for unseen subjects via dual-stage alignment and self-supervision. The alignment process begins by applying Euclidean alignment in the EEG data space and then updates batch normalization statistics in the representation space. Moreover, a self-supervised loss is designed to update the decoder. The loss is computed by soft pseudo-labels derived from the decoder as a proxy for the unknown ground truth, and is calibrated by Shannon entropy to facilitate self-supervised training. Experiments across five public datasets and seven decoders show the proposed algorithm can be integrated seamlessly regardless of BCI paradigm and decoder architecture. In each iteration, the decoder is updated with a single online trial, which yields average accuracy gains of 4.9% on steady-state visual evoked potentials (SSVEP) and 3.6% on motor imagery. These results support fast-calibration operation and show that the proposed algorithm has great potential for BCI applications.

Paper number 29:
Title: Automatic and Scalable Safety Verification using Interval Reachability with Subspace Sampling
Authors: Brendan Gould, Akash Harapanahalli, Samuel Coogan
Abstract: Interval refinement is a technique for reducing the conservatism of traditional interval based reachability methods by lifting the system to a higher dimension using new auxiliary variables and exploiting the introduced structure through a refinement procedure. We present a novel, efficiently scaling, automatic refinement strategy based on a subspace sampling argument and motivated by reducing the number of interval operations through sparsity. Unlike previous methods, we guarantee that refined bounds shrink as additional auxiliary variables are added. This additionally encourages automation of the lifting phase by allowing larger groups of auxiliary variables to be considered. We implement our strategy in JAX, a high-performance computational toolkit for Python and demonstrate its efficacy on several examples, including regulating a multi-agent platoon to the origin while avoiding an obstacle.

Paper number 30:
Title: Robust Near-Optimal Nonlinear Target Enclosing Guidance
Authors: Abhinav Sinha, Rohit V. Nanavati
Abstract: This paper proposes a nonlinear optimal guidance law that enables a pursuer to enclose a target within arbitrary geometric patterns, which extends beyond conventional circular encirclement. The design operates using only relative state measurements and formulates a target enclosing guidance law in which the vehicle's lateral acceleration serves as the steering control, making it well-suited for aerial vehicles with turning constraints. Our approach generalizes and extends existing guidance strategies that are limited to target encirclement and provides a degree of optimality. At the same time, the exact information of the target's maneuver is unnecessary during the design. The guidance law is developed within the framework of a state-dependent Riccati equation (SDRE), thereby providing a systematic way to handle nonlinear dynamics through a pseudo-linear representation to design locally optimal feedback guidance commands through state-dependent weighting matrices. While SDRE ensures near-optimal performance in the absence of strong disturbances, we further augment the design to incorporate an integral sliding mode manifold to compensate when disturbances push the system away from the nominal trajectory, and demonstrate that the design provides flexibility in the sense that the (possibly time-varying) stand-off curvature could also be treated as unknown. Simulations demonstrate the efficacy of the proposed approach.

Paper number 31:
Title: linrax: A JAX Compatible, Simplex Method Linear Program Solver
Authors: Brendan Gould, Akash Harapanahalli, Samuel Coogan
Abstract: We present linrax, the first simplex based linear program (LP) solver compatible with the JAX ecosystem. In many control algorithms, LPs are often automatically generated and frequently solved either offline or online in the control loop. This motivates the design of linrax, which is especially suited for compilation into a complex JAX-based pipeline as a subroutine. We discuss the challenges associated with implementing a general purpose LP solver under strict design requirements from JAX. Notably, we can solve general problems which may include dependent constraints-something not possible with existing JAX-compatible LP solvers that use first-order techniques and may fail to converge. We demonstrate the utility of linrax through several examples, including a robust control synthesis pipeline for a nonlinear vehicle model using automatic differentiation through a LP-based reachable set framework.

Paper number 32:
Title: Four-Transistor Bipolar Series-Parallel Module Structure for Cascaded Bridge and Modular Multilevel Circuits
Authors: Jinshui Zhang, Stefan M Goetz
Abstract: With their great scalability and flexibility, cascaded-bridge and modular multilevel converters have enabled a variety of energy applications, such as offshore wind power, high-voltage dc power transmission, power-quality management, and cutting-edge medical instrumentation. The incorporation of parallel connectivity between modules equips systems with advantages such as sensorless balancing, switched-capacitor energy exchange, and reduced impedance. However, existing topologies require many individual switches -- eight transistors per module. Efforts to use fewer switches, instead, have previously compromised their functionality. We propose a new module topology, named the direction-selective parallel (DiSeP) structure, which requires only four transistors per module -- the same as an H bridge -- but can achieve bidirectional equilibration, bipolar module output, and inter-module switched-capacitor features. This topology is highly attractive for existing converters with cascaded bridge elements, as the addition of only four diodes enables key features such as sensorless balancing and inter-module energy exchange. Thus, the module can outcompete H bridges in their applications, as it adds parallel modes without any additional transistors. Compared to double-H bridges (CH2B), it saves as many as half of the transistors. We elaborate on its working principles and key design considerations. We validate our theories on an experimental prototype with six modules. This prototype attains a total voltage harmonic distortion plus noise (THD+N) of 10.3% and a peak efficiency of 96.3%. Furthermore, the modules achieve autonomous sensorless balancing under open-loop control.

Paper number 33:
Title: Insights into Xona Pulsar LEO PNT: Constellation, Signals, and Receiver Design
Authors: Jérôme Leclère, Thyagaraja Marathe, Tyler G. R. Reid
Abstract: The landscape of global navigation satellite systems (GNSS) is expanding with the emergence of low Earth orbit (LEO) constellations such as Pulsar, which are expected to play a key role in the future of positioning, navigation, and timing (PNT). LEO-based systems provide advantages including stronger signals for greater robustness, faster dynamics that aid convergence and multipath mitigation, and shorter time to first fix (TTFF) enabled by high data rates. These benefits, however, come with changes in signal behavior and constellation geometry that require careful consideration in receiver design. This paper investigates Pulsar properties using a GNSS simulator, analyzing parameters such as satellite pass duration, elevation, Doppler shift, Doppler rate, range, and number of satellites in view. Comparisons with GPS highlight the differences introduced by LEO operation. The analysis examines temporal evolution, statistical distributions, and maximum and minimum values. Beyond these statistical insights, the study explores interdependencies between parameters and differences across satellites, providing additional perspective. Evaluations are performed at multiple latitudes to ensure a worldwide perspective, and the impact of applying different elevation masks is discussed where relevant. Building on these findings, the paper assesses Pulsar's impact on receiver design from two standpoints: design considerations, addressing expanded Doppler ranges, higher Doppler rates, and unique constellation structure; and design optimizations, exploiting parameter analyses and interdependencies (e.g., Doppler rate vs Doppler) to refine acquisition strategies and applying prediction and prioritization techniques to avoid unnecessary computations. Together, these optimizations can reduce acquisition time and lower receiver power consumption.

Paper number 34:
Title: Frame-Stacked Local Transformers For Efficient Multi-Codebook Speech Generation
Authors: Roy Fejgin, Paarth Neekhara, Xuesong Yang, Edresson Casanova, Ryan Langman Jaehyeon Kim, Subhankar Ghosh, Shehzeen Hussain, Jason Li
Abstract: Speech generation models based on large language models (LLMs) typically operate on discrete acoustic codes, which differ fundamentally from text tokens due to their multicodebook structure. At each timestep, models must predict N codebook entries jointly, introducing dependencies that challenge simple parallel prediction approaches. Parallel prediction assumes independence among codebooks, yielding efficient decoding but often at the cost of reduced fidelity. To address this, hierarchical strategies employ a local transformer (LT) to refine predictions and capture intra-timestep dependencies. In this work, we systematically investigate two LT architectures: an autoregressive transformer that generates codebooks sequentially, and a MaskGIT-based transformer that performs iterative masked prediction. Both designs further enable frame stacking, where the primary transformer predicts multiple frames jointly, and the LT decodes their codebooks, offering improvements in speed without compromising perceptual quality. Through extensive analysis, we characterize the tradeoffs between parallel and iterative sampling strategies across different throughput and quality regimes. Finally, we propose practical guidelines for selecting decoding strategies based on deployment priorities such as computational efficiency and synthesis fidelity.

Paper number 35:
Title: DNN-Based Nulling Control Beam Focusing for Near-Field Multi-User Interference Mitigation
Authors: Mohammadhossein Karimi, Yuanzhe Gong, Tho Le-Ngoc
Abstract: This paper proposes a deep learning-based framework for near-field nulling control beam focusing (NCBF) in extra-large MIMO (XL-MIMO) systems to mitigate multi-user interference (MUI). A dual-estimator architecture comprising two fully connected deep neural networks (FCDNNs) is developed to separately predict the phase and magnitude components of NCBF weights, using locations of both desired and interfering users. The models are trained on a large dataset generated via a Linearly Constrained Minimum Variance (LCMV) beamforming algorithm to accommodate diverse user configurations, including both collinear and non-collinear scenarios. Illustrative results demonstrate that the proposed DNN models achieve high prediction accuracy, with test errors of only 0.067 radians for phase estimation and 0.206 dB for magnitude estimation. Full-wave simulations incorporating realistic element radiation patterns and inter-element coupling confirm the close agreement between the beam patterns produced by the DNN-predicted and LCMV-based NCBF schemes under practical deployment conditions. An average MUI suppression of 36.7 dB is achieved, with interference mitigation exceeding 17.5 dB across all tested cases. The proposed approach enables scalable and real-time beam focusing with effective interference suppression, offering a promising solution for future near-field multi-user wireless communications.

Paper number 36:
Title: Federated Aggregation of Demand Flexibility
Authors: Yifan Dong, Ge Chen, Junjie Qin
Abstract: This paper proposes a federated framework for demand flexibility aggregation to support grid operations. Unlike existing geometric methods that rely on a static, pre-defined base set as the geometric template for aggregation, our framework establishes a true federated process by enabling the collaborative optimization of this base set without requiring the participants sharing sensitive data with the aggregator. Specifically, we first formulate the base set optimization problem as a bilevel program. Using optimal solution functions, we then reformulate the bilevel program into a single-level, unconstrained learning task. By exploiting the decomposable structure of the overall gradient, we further design a decentralized gradient-based algorithm to solve this learning task. The entire framework, encompassing base set optimization, aggregation, and disaggregation, operates by design without exchanging raw user data. Numerical results demonstrate that our proposed framework unlocks substantially more flexibility than the approaches with static base sets, thus providing a promising framework for efficient and privacy-enhanced approaches to coordinate demand flexibility at scale.

Paper number 37:
Title: BALANCE: Bitrate-Adaptive Limit-Aware Netcast Content Enhancement Utilizing QUBO and Quantum Annealing
Authors: Animesh Rajpurohit, Michael Kelley, Wei Wang, Krishna Murthy Kattiyan Ramamoorthy
Abstract: In an era of increasing data cap constraints, optimizing video streaming quality while adhering to user-defined data caps remains a significant challenge. This paper introduces Bitrate-Adaptive Limit-Aware Netcast Content Enhancement (BALANCE), a novel Quantum framework aimed at addressing this issue. BALANCE intelligently pre-selects video segments based on visual complexity and anticipated data consumption, utilizing the Video Multimethod Assessment Fusion (VMAF) metric to enhance Quality of Experience (QoE). We compare our method against traditional bitrate ladders used in Adaptive Bitrate (ABR) streaming, demonstrating a notable improvement in QoE under equivalent data constraints. We compare the Slack variable approach with the Dynamic Penalization Approach (DPA) by framing the bitrate allocation problem through Quadratic Unconstrained Binary Optimization (QUBO) to effectively enforce data limits. Our results indicate that the DPA consistently outperforms the Slack Variable Method, delivering more valid and optimal solutions as data limits increase. This new quantum approach significantly enhances streaming satisfaction for users with limited data plans.

Paper number 38:
Title: Advancing Speech Summarization in Multi-modal LLMs with Reinforcement Learning
Authors: Shaoshi Ling, Gang Liu, Guoli Ye, Jinyu Li
Abstract: Speech summarization is a critical component of spoken content understanding, particularly in the era of rapidly growing spoken and audiovisual data. Recent advances in multi-modal large language models (MLLMs), leveraging the power of LLMs, enable generating textual summaries directly from speech without intermediate transcriptions, while supporting controllable styles and zero-shot generalization. However, open-source MLLMs continue to lag behind the state-of-the-art text-based LLMs, limiting their practical deployment for speech summarization. In this work, we present a novel multi-stage reinforcement learning training framework to enhance the speech summarization capabilities in MLLMs. Our model delivers substantial improvements over strong baselines, outperforms much larger MLLMs, and significantly narrows the gap with state-of-the-art text-based LLMs.

Paper number 39:
Title: Selective Classifier-free Guidance for Zero-shot Text-to-speech
Authors: John Zheng, Farhad Maleki
Abstract: In zero-shot text-to-speech, achieving a balance between fidelity to the target speaker and adherence to text content remains a challenge. While classifier-free guidance (CFG) strategies have shown promising results in image generation, their application to speech synthesis are underexplored. Separating the conditions used for CFG enables trade-offs between different desired characteristics in speech synthesis. In this paper, we evaluate the adaptability of CFG strategies originally developed for image generation to speech synthesis and extend separated-condition CFG approaches for this domain. Our results show that CFG strategies effective in image generation generally fail to improve speech synthesis. We also find that we can improve speaker similarity while limiting degradation of text adherence by applying standard CFG during early timesteps and switching to selective CFG only in later timesteps. Surprisingly, we observe that the effectiveness of a selective CFG strategy is highly text-representation dependent, as differences between the two languages of English and Mandarin can lead to different results even with the same model.

Paper number 40:
Title: Non-locally averaged pruned reassigned spectrograms: a tool for glottal pulse visualization and analysis
Authors: Gabriel J. Griswold, Mark A. Griswold
Abstract: Reassigned spectrograms have shown advantages in precise formant measuring and inter-speaker differentiation. However, reassigned spectrograms suffer from their inability to visualize larger amounts of data in an easily comprehensible and reproducible manner. Utilizing the techniques and tools developed by Fulop and Fitz, a variation of the reassigned spectrogram is proposed. Non-locally Averaged Pruned Reassigned Spectrograms (NAPReS) provide a simplified view into the characteristics of a speaker's glottal pulsation patterns throughout the centroid of a vowel through the stacking, summing, and pruning of large numbers of glottal pulses. In this exploratory study, NAPReS has been shown to display a large amount of data in an easily comprehensible and quantifiable manner, while also making the observation of low-amplitude cyclical structures more accessible. NAPReS also allows for alternative formant fitting methods such as Gaussian mixture modeling. In this study, NAPReS with GMM was compared against conventional LPC fitting of formant values and was shown to be more reproducible than conventional LPC fitting in high-noise situations.

Paper number 41:
Title: Short-Segment Speaker Verification with Pre-trained Models and Multi-Resolution Encoder
Authors: Jisoo Myoung, Sangwook Han, Kihyuk Kim, Jong Won Shin
Abstract: Speaker verification (SV) utilizing features obtained from models pre-trained via self-supervised learning has recently demonstrated impressive performances. However, these pre-trained models (PTMs) usually have a temporal resolution of 20 ms, which is lower than typical filterbank features. It may be problematic especially for short-segment SV with an input segment shorter than 2 s, in which we need to extract as much information as possible from the input with a limited length. Although there have been approaches to utilize multi-resolution features from the HuBERT models, the window shifts were 320, 640, and 1600 samples when the sampling rate was 16 kHz and thus only lower resolution features were considered. In this study, we propose an SV system which utilizes PTM features along with filterbank features and those from the multi-resolution time domain encoder with window shifts of 25, 50, 100, and 200 samples. Experimental results on the VoxCeleb dataset with various input lengths showed consistent improvements over systems with various combinations of input features.

Paper number 42:
Title: Timeliness-Aware Joint Source and Channel Coding for Adaptive Image Transmission
Authors: Xiaolei Yang, Zijing Wang, Zhijin Qin, Xiaoming Tao
Abstract: Accurate and timely image transmission is critical for emerging time-sensitive applications such as remote sensing in satellite-assisted Internet of Things. However, the bandwidth limitation poses a significant challenge in existing wireless systems, making it difficult to fulfill the requirements of both high-fidelity and low-latency image transmission. Semantic communication is expected to break through the performance bottleneck by focusing on the transmission of goal-oriented semantic information rather than raw data. In this paper, we employ a new timeliness metric named the value of information (VoI) and propose an adaptive joint source and channel coding (JSCC) method for image transmission that simultaneously considers both reconstruction quality and timeliness. Specifically, we first design a JSCC framework for image transmission with adaptive code length. Next, we formulate a VoI maximization problem by optimizing the transmission code length of the adaptive JSCC under the reconstruction quality constraint. Then, a deep reinforcement learning-based algorithm is proposed to solve the optimization problem efficiently. Experimental results show that the proposed method significantly outperforms baseline schemes in terms of reconstruction quality and timeliness, particularly in low signal-to-noise ratio conditions, offering a promising solution for efficient and robust image transmission in time-sensitive wireless networks.

Paper number 43:
Title: Dispersion Formation Control: from Geometry to Distribution
Authors: Jin Chen, Jesus Bautista Villar, Bayu Jayawardhana, Hector Garcia de Marina
Abstract: We introduce and develop the concept of dispersion formation control, bridging a gap between shape-assembly studies in physics and biology and formation control theory. In current formation control studies, the control objectives typically focus on achieving desired local geometric properties, such as inter-agent distances, bearings, or relative positions. In contrast, our dispersion formation control approach enables agents to directly regulate the dispersion of their spatial distribution, a global variable associated with a covariance matrix. Specifically, we introduce the notion of covariance similarity to define the target spatial dispersion of agents. Building on this framework, we propose two control strategies: a centralized approach to illustrate the key ideas, and a distributed approach that enables agents to control the global dispersion but using only local information. Our stability analysis demonstrates that both strategies ensure exponential convergence of the agents' distribution to the desired dispersion. Notably, controlling a global variable rather than multiple local ones enhances the resiliency of the system, particularly against malfunctioning agents. Simulations validate the effectiveness of the proposed dispersion formation control.

Paper number 44:
Title: Electromagnetics-Compliant Optimization of Dynamic Metasurface Antennas for Bistatic Sensing
Authors: Ioannis Gavras, George C. Alexandropoulos
Abstract: Dynamic Metasurface Antennas (DMAs) are recently attracting considerable research interests due to their potential to enable low-cost, reconfigurable, and highly scalable antenna array architectures for next generation wireless systems. However, most of the existing literature relies on idealized models for the DMA operation, often overlooking critical structural and physical constraints inherent to their constituent metamaterials. In this paper, leveraging a recently proposed model for this antenna architecture incorporating physically consistent modeling of mutual coupling and waveguide propagation losses, we optimize DMA-based transmission for bistatic sensing. A tractable approximation for the DMA response is first presented, which enables efficient optimization of the dynamically reconfigurable Lorentzian-constrained responses of the array's metamaterials. In particular, we formulate a robust beamforming optimization problem with the objective to minimize the worst-case position error bound, in the presence of spatial uncertainties for the environment's scatterers as well as synchronization uncertainties at the analog combining multi-antenna receiver. To address the resulting high computational complexity due to the possibly excessive number of metamaterial-based antennas and their operation constraints, two low complexity beamforming design approaches are presented that perform offline searching over a novel beam codebook. The accuracy of all presented DMA designs is assessed by means of Monte Carlo simulations for various system parameters, confirming that accurately modeling mutual coupling is essential for maintaining increased localization performance. It is also shown that, even under positioning and synchronization uncertainties, the proposed designs yield accuracy comparable to their fully digital and analog counterparts, while adhering to the structural DMA constraints.

Paper number 45:
Title: MMedFD: A Real-world Healthcare Benchmark for Multi-turn Full-Duplex Automatic Speech Recognition
Authors: Hongzhao Chen, XiaoYang Wang, Jing Lan, Hexiao Ding, Yufeng Jiang MingHui Yang, DanHui Xu, Jun Luo, Nga-Chun Ng, Gerald W.Y. Cheng, Yunlin Mao, Jung Sun Yoo
Abstract: Automatic speech recognition (ASR) in clinical dialogue demands robustness to full-duplex interaction, speaker overlap, and low-latency constraints, yet open benchmarks remain scarce. We present MMedFD, the first real-world Chinese healthcare ASR corpus designed for multi-turn, full-duplex settings. Captured from a deployed AI assistant, the dataset comprises 5,805 annotated sessions with synchronized user and mixed-channel views, RTTM/CTM timing, and role labels. We introduce a model-agnostic pipeline for streaming segmentation, speaker attribution, and dialogue memory, and fine-tune Whisper-small on role-concatenated audio for long-context recognition. ASR evaluation includes WER, CER, and HC-WER, which measures concept-level accuracy across healthcare settings. LLM-generated responses are assessed using rubric-based and pairwise protocols. MMedFD establishes a reproducible framework for benchmarking streaming ASR and end-to-end duplex agents in healthcare deployment. The dataset and related resources are publicly available at this https URL

Paper number 46:
Title: Zonotope-Based Elastic Tube Model Predictive Control
Authors: Sabin Diaconescu, Florin Stoican, Bogdan D. Ciubotaru, Sorin Olaru
Abstract: Tube-based Model Predictive Control (MPC) is a widely adopted robust control framework for constrained linear systems under additive disturbance. The paper is focused on reducing the numerical complexity associated with the tube parameterization, described as a sequence of elastically-scaled zonotopic sets. A new class of scaled-zonotope inclusion conditions is proposed, alleviating the need for a priori specification of certain set-containment constraints and achieving significant reductions in complexity. A comprehensive complexity analysis is provided for both the polyhedral and the zonotopic setting, illustrating the trade-off between an enlarged domain of attraction and the required computational effort. The proposed approach is validated through extensive numerical experiments.

Paper number 47:
Title: SCORE: Scaling audio generation using Standardized COmposite REwards
Authors: Jaemin Jung, Jaehun Kim, Inkyu Shin, Joon Son Chung
Abstract: The goal of this paper is to enhance Text-to-Audio generation at inference, focusing on generating realistic audio that precisely aligns with text prompts. Despite the rapid advancements, existing models often fail to achieve a reliable balance between perceptual quality and textual alignment. To address this, we adopt Inference-Time Scaling, a training-free method that improves performance by increasing inference computation. We establish its unexplored application to audio generation and propose a novel multi-reward guidance that equally signifies each component essential in perception. By normalizing each reward value into a common scale and combining them with a weighted summation, the method not only enforces stable guidance but also enables explicit control to reach desired aspects. Moreover, we introduce a new audio-text alignment metric using an audio language model for more robust evaluation. Empirically, our method improves both semantic alignment and perceptual quality, significantly outperforming naive generation and existing reward guidance techniques. Synthesized samples are available on our demo page: this https URL

Paper number 48:
Title: An early termination strategy for the distributed biased min-consensus protocol under disturbances
Authors: Zicheng Huang, Wangzhi Zhou, Yuanqiu Mo
Abstract: The distributed biased min-consensus (DBMC) protocol is an iterative scheme that solves the shortest path problem asymptotically, requiring only local information exchange between neighboring nodes. By appropriately designing the gain function, prior work [1] proposed a DBMC-based system that ensures convergence within a pre-specified time interval. However, this guarantee assumes the absence of disturbances. In this paper, we study the DBMC-based system under disturbances affecting the edge weights. We first establish rigorous error bounds on the resulting state estimates. Building on this analysis, we then propose a practical early termination strategy to prevent potential singularities, specifically, unbounded gain, that may arise in the presence of disturbances, while still ensuring that the shortest paths are correctly this http URL are performed to validate and illustrate the theoretical results.

Paper number 49:
Title: CollaPipe: Adaptive Segment-Optimized Pipeline Parallelism for Collaborative LLM Training in Heterogeneous Edge Networks
Authors: Jiewei Chen, Xiumei Deng, Zehui Xiong, Shaoyong Guo, Xuesong Qiu, Ping Wang, Dusit Niyato
Abstract: The increasing demand for intelligent mobile applications has made multi-agent collaboration with Transformer-based large language models (LLMs) essential in mobile edge computing (MEC) networks. However, training LLMs in such environments remains challenging due to heavy computation, high end-to-end latency, and limited model generalization. We introduce CollaPipe, a hybrid distributed learning framework that integrates collaborative pipeline parallelism with federated aggregation to support self-evolving intelligent networks. In CollaPipe, the encoder part is adaptively partitioned into variable-sized segments and deployed across mobile devices for pipeline-parallel training, while the decoder is deployed on edge servers to handle generative tasks. Then we perform global model update via federated aggregation. To enhance training efficiency, we formulate a joint optimization problem that adaptively allocates model segments, micro-batches, bandwidth, and transmission power. We derive and use a closed-form convergence bound to design an Dynamic Segment Scheduling and Resource Allocation (DSSDA) algorithm based on Lyapunov optimization, ensuring system stability under long-term constraints. Extensive experiments on downstream tasks with Transformer and BERT models show that CollaPipe improves computation efficiency by up to 15.09%, reduces end-to-end latency by at least 48.98%, and cuts single device memory usage by more than half, enabling online learning in heterogeneous and dynamic communication environments.

Paper number 50:
Title: Scalable and Approximation-free Symbolic Control for Unknown Euler-Lagrange Systems
Authors: Ratnangshu Das, Shubham Sawarkar, Pushpak Jagtap
Abstract: We propose a novel symbolic control framework for enforcing temporal logic specifications in Euler-Lagrange systems that addresses the key limitations of traditional abstraction-based approaches. Unlike existing methods that require exact system models and provide guarantees only at discrete sampling instants, our approach relies only on bounds on system parameters and input constraints, and ensures correctness for the full continuous-time trajectory. The framework combines scalable abstraction of a simplified virtual system with a closed-form, model-free controller that guarantees trajectories satisfy the original specification while respecting input bounds and remaining robust to unknown but bounded disturbances. We provide feasibility conditions for the construction of confinement regions and analyze the trade-off between efficiency and conservatism. Case studies on pendulum dynamics, a two-link manipulator, and multi-agent systems, including hardware experiments, demonstrate that the proposed approach ensures both correctness and safety while significantly reducing computational time and memory requirements. These results highlight its scalability and practicality for real-world robotic systems where precise models are unavailable and continuous-time guarantees are essential.

Paper number 51:
Title: Modeling and Control of Deep Sign-Definite Dynamics with Application to Hybrid Powertrain Control
Authors: Teruki Kato, Ryotaro Shima, Kenji Kashima
Abstract: Deep learning is increasingly used for complex, large-scale systems where first-principles modeling is difficult. However, standard deep learning models often fail to enforce physical structure or preserve convexity in downstream control, leading to physically inconsistent predictions and discontinuous inputs owing to nonconvexity. We introduce sign constraints--sign restrictions on Jacobian entries--that unify monotonicity, positivity, and sign-definiteness; additionally, we develop model-construction methods that enforce them, together with a control-synthesis procedure. In particular, we design exactly linearizable deep models satisfying these constraints and formulate model predictive control as a convex quadratic program, which yields a unique optimizer and a Lipschitz continuous control law. On a two-tank system and a hybrid powertrain, the proposed approach improves prediction accuracy and produces smoother control inputs than existing methods.

Paper number 52:
Title: Weakly Supervised Phonological Features for Pathological Speech Analysis
Authors: Jenthe Thienpondt, Geoffroy Vanderreydt, Abdessalem Hammami, Kris Demuynck
Abstract: Paralinguistic properties of speech are essential in analyzing and choosing optimal treatment options for patients with speech disorders. However, automatic modeling of these characteristics is difficult due to the lack of labeled speech datasets describing paralinguistic properties, especially at the frame-level. In this paper, we propose a weakly supervised training method which exploits the known acoustic properties of phonemes by training an ASR model with an interpretable frame-level phonological feature bottleneck layer. Subsequently, we assess the viability of these phonological features in speech pathology analysis by developing corresponding models for intelligibility prediction and speech pathology classification. Models using our proposed phonological features perform similar to other state-of-the-art acoustic features on both tasks with a classification accuracy of 75% and a 8.43 RMSE on speech intelligibility prediction. In contrast to others, our phonological features are text-independent and highly interpretable, providing potentially useful insights for speech therapists.

Paper number 53:
Title: MAGE: A Coarse-to-Fine Speech Enhancer with Masked Generative Model
Authors: The Hieu Pham, Tan Dat Nguyen, Phuong Thanh Tran, Joon Son Chun, Duc Dung Nguyen
Abstract: Speech enhancement remains challenging due to the trade-off between efficiency and perceptual quality. In this paper, we introduce MAGE, a Masked Audio Generative Enhancer that advances generative speech enhancement through a compact and robust design. Unlike prior masked generative models with random masking, MAGE employs a scarcity-aware coarse-to-fine masking strategy that prioritizes frequent tokens in early steps and rare tokens in later refinements, improving efficiency and generalization. We also propose a lightweight corrector module that further stabilizes inference by detecting low-confidence predictions and re-masking them for refinement. Built on BigCodec and finetuned from Qwen2.5-0.5B, MAGE is reduced to 200M parameters through selective layer retention. Experiments on DNS Challenge and noisy LibriSpeech show that MAGE achieves state-of-the-art perceptual quality and significantly reduces word error rate for downstream recognition, outperforming larger baselines. Audio examples are available at this https URL.

Paper number 54:
Title: Generalized Nonnegative Structured Kruskal Tensor Regression
Authors: Xinjue Wang, Esa Ollila, Sergiy A. Vorobyov, Ammar Mian
Abstract: This paper introduces Generalized Nonnegative Structured Kruskal Tensor Regression (NS-KTR), a novel tensor regression framework that enhances interpretability and performance through mode-specific hybrid regularization and nonnegativity constraints. Our approach accommodates both linear and logistic regression formulations for diverse response variables while addressing the structural heterogeneity inherent in multidimensional tensor data. We integrate fused LASSO, total variation, and ridge regularizers, each tailored to specific tensor modes, and develop an efficient alternating direction method of multipliers (ADMM) based algorithm for parameter estimation. Comprehensive experiments on synthetic signals and real hyperspectral datasets demonstrate that NS-KTR consistently outperforms conventional tensor regression methods. The framework's ability to preserve distinct structural characteristics across tensor dimensions while ensuring physical interpretability makes it especially suitable for applications in signal processing and hyperspectral image analysis.

Paper number 55:
Title: Voice Privacy Preservation with Multiple Random Orthogonal Secret Keys: Attack Resistance Analysis
Authors: Kohei Tanaka, Hitoshi Kiya, Sayaka Shiota
Abstract: Recently, opportunities to transmit speech data to deep learning models executed in the cloud have increased. This has led to growing concerns about speech privacy, including both speaker-specific information and the linguistic content of utterances. As an approach to preserving speech privacy, a speech privacy-preserving method based on encryption using a secret key with a random orthogonal matrix has been proposed. This method enables cloud-based model inference while concealing both the speech content and the speaker identity. However, the method has limited attack resistance and is constrained in terms of the deep learning models to which the encryption can be applied. In this work, we propose a method that enhances the attack resistance of the conventional speech privacy-preserving technique by employing multiple random orthogonal matrices as secret keys. We also introduce approaches to relax the model constraints, enabling the application of our method to a broader range of deep learning models. Furthermore, we investigate the robustness of the proposed method against attacks using extended attack scenarios based on the scenarios employed in the Voice Privacy Challenge. Our experimental results confirmed that the proposed method maintains privacy protection performance for speaker concealment, even under more powerful attack scenarios not considered in prior work.

Paper number 56:
Title: Rotatable Antenna Enabled Spectrum Sharing: Joint Antenna Orientation and Beamforming Design
Authors: Xingxiang Peng, Qingqing Wu, Ziyuan Zheng, Wen Chen, Yanze Zhu, Ying Gao
Abstract: Conventional antenna arrays rely primarily on digital beamforming for spatial control. While adding more elements can narrow beamwidth and suppress interference, such scaling incurs prohibitive hardware and power costs. Rotatable antennas (RAs), which allow mechanical or electronic adjustment of element orientations, introduce a new degree of freedom to exploit spatial flexibility without enlarging the array. By dynamically optimizing orientations, RAs can substantially improve desired link alignment and interference suppression. This paper investigates RA-enabled multiple-input single-output (MISO) interference channels under co-channel spectrum sharing and formulates a weighted sum-rate maximization problem that jointly optimizes transmit beamforming and antenna orientations. To tackle this nonconvex problem, we develop an alternating optimization (AO) framework that integrates weighted minimum mean-square error (WMMSE)-based beamforming with Frank-Wolfe-based orientation updates. To reduce complexity, we further study orientation optimization under maximum-ratio transmission (MRT) and zero-forcing (ZF) beamforming schemes. For finite-resolution actuators, we construct spherical Fibonacci codebooks and design a cross-entropy method (CEM)-based algorithm for discrete orientation selection. Simulations show that integrating RAs with conventional beamforming markedly increases weighted sum-rate, with gains rising with element directivity. Under discrete orientation control, the proposed CEM algorithm consistently outperforms the nearest-projection baseline.

Paper number 57:
Title: Measuring Prosody Diversity in Zero-Shot TTS: A New Metric, Benchmark, and Exploration
Authors: Yifan Yang, Bing Han, Hui Wang, Long Zhou, Wei Wang, Mingyu Cui, Xu Tan, Xie Chen
Abstract: Prosody diversity is essential for achieving naturalness and expressiveness in zero-shot text-to-speech (TTS). However, frequently used acoustic metrics capture only partial views of prosodic variation and correlate poorly with human perception, leaving the problem of reliably quantifying prosody diversity underexplored. To bridge this gap, we introduce ProsodyEval, a prosody diversity assessment dataset that provides Prosody Mean Opinion Score (PMOS) alongside conventional acoustic metrics. ProsodyEval comprises 1000 speech samples derived from 7 mainstream TTS systems, with 2000 human ratings. Building on this, we propose the Discretized Speech Weighted Edit Distance (DS-WED), a new objective diversity metric that quantifies prosodic variation via weighted edit distance over semantic tokens. Experiments on ProsodyEval show that DS-WED achieves substantially higher correlation with human judgments than existing acoustic metrics, while remaining highly robust in speech tokenization from HuBERT and WavLM. Leveraging DS-WED, we benchmark state-of-the-art open-source TTS systems on LibriSpeech test-clean and Seed-TTS test-en, and further explorations uncover several factors that influence prosody diversity, including generative modeling paradigms, duration control, and reinforcement learning. Moreover, we find that current large audio language models (LALMs) remain limited in capturing prosodic variations. Audio samples are available at this https URL.

Paper number 58:
Title: Evaluating pretrained speech embedding systems for dysarthria detection across heterogenous datasets
Authors: Lovisa Wihlborg, Jemima Goodall, David Wheatley, Jacob J. Webber, Johnny Tam, Christine Weaver, Suvankar Pal, Siddharthan Chandran, Sohan Seth, Oliver Watts, Cassia Valentini-Botinhao
Abstract: We present a comprehensive evaluation of pretrained speech embedding systems for the detection of dysarthric speech using existing accessible data. Dysarthric speech datasets are often small and can suffer from recording biases as well as data imbalance. To address these we selected a range of datasets covering related conditions and adopt the use of several cross-validations runs to estimate the chance level. To certify that results are above chance, we compare the distribution of scores across these runs against the distribution of scores of a carefully crafted null hypothesis. In this manner, we evaluate 17 publicly available speech embedding systems across 6 different datasets, reporting the cross-validation performance on each. We also report cross-dataset results derived when training with one particular dataset and testing with another. We observed that within-dataset results vary considerably depending on the dataset, regardless of the embedding used, raising questions about which datasets should be used for benchmarking. We found that cross-dataset accuracy is, as expected, lower than within-dataset, highlighting challenges in the generalization of the systems. These findings have important implications for the clinical validity of systems trained and tested on the same dataset.

Paper number 59:
Title: Control and Navigation of a 2-D Electric Rocket
Authors: André Fonte, Pedro Santos, Paulo Oliveira
Abstract: This work addresses the control and navigation of a simulated two-dimensional electric rocket. The model provides a simplified framework that neglects actuator dynamics and aerodynamic effects while capturing the complexities of underactuation and state coupling. Trajectory tracking is achieved through a modularized and layered control architecture, with employement of a Linear Quadratic Regulator (LQR) and Lyapunov theory. Full-state estimation is achieved through Kalman filtering techniques, part of the navigation module. The solutions are thoroughly evaluated in a custom-built MATLAB/Simulink testbed, simulating real-world conditions while maintaining a simplified setup. The results reveal limitations along the lateral axis, whose resolution is suggested for future work.

Paper number 60:
Title: On the Invariance of Cross-Correlation Peak Positions Under Monotonic Signal Transformations, with Application to Fast Time Difference Estimation
Authors: Natsuki Ueno, Ryotaro Sato, Nobutaka Ono
Abstract: We present a theorem concerning the invariance of cross-correlation peak positions, which provides a foundation for a new method for time difference estimation that is potentially faster than the conventional fast Fourier transform (FFT) approach for real/complex sequences. This theoretical result shows that the peak position of the cross-correlation function between two shifted discrete-time signals remains unchanged under arbitrary monotonic transformations of the input signals. By exploiting this property, we design an efficient estimation algorithm based on the cross-correlation function between signals quantized into low-bit integers. The proposed method requires only integer arithmetic instead of real-valued operations, and further computational efficiency can be achieved through number-theoretic algorithms. Numerical experiments demonstrate that the proposed method achieves a shorter processing time than conventional FFT-based approaches.

Paper number 61:
Title: Ensuring Reliable Participation in Subjective Video Quality Tests Across Platforms
Authors: Babak Naderi, Ross Cutler
Abstract: Subjective video quality assessment (VQA) is the gold standard for measuring end-user experience across communication, streaming, and UGC pipelines. Beyond high-validity lab studies, crowdsourcing offers accurate, reliable, faster, and cheaper evaluation-but suffers from unreliable submissions by workers who ignore instructions or game rewards. Recent tests reveal sophisticated exploits of video metadata and rising use of remote-desktop (RD) connections, both of which bias results. We propose objective and subjective detectors for RD users and compare two mainstream crowdsourcing platforms on their susceptibility and mitigation under realistic test conditions and task designs.

Paper number 62:
Title: Near-field Spatial-domain Channel Extrapolation for XL-MIMO Systems
Authors: Jiayi Lu, Jiayi Zhang, Hao Lei, Huahua Xiao, Bo Ai, Derrick Wing Kwan Ng
Abstract: Extremely large-scale multiple-input multiple-output (XL-MIMO) systems are pivotal to next-generation wireless communications, where dynamic RF chain architectures offer enhanced performance. However, efficient precoding in such systems requires accurate channel state information (CSI) obtained with low complexity. To address this challenge, spatial-domain channel extrapolation has attracted growing interest. Existing methods often overlook near-field spherical wavefronts or rely heavily on sparsity priors, leading to performance degradation. In this paper, we propose an adaptive near-field channel extrapolation framework for multi-subcarrier XL-MIMO systems, leveraging a strategically selected subset of antennas. Subsequently, we develop both on-grid and off-grid algorithms, where the latter refines the former's estimates for improved accuracy. To further reduce complexity, a cross-validation (CV)-based scheme is introduced. Additionally, we analytically formulate the mutual coherence of the sensing matrix and propose a coherence-minimizing-based random pattern to ensure robust extrapolation. Numerical results validate that the proposed algorithms significantly outperform existing methods in both extrapolation accuracy and achievable rate, while maintaining low computational complexity. In particular, our proposed CV ratio offers a flexible trade-off between accuracy and efficiency, and the corresponding off-grid algorithm achieves high accuracy with complexity comparable to conventional on-grid methods.

Paper number 63:
Title: Multi-Stage CD-Kennedy Receiver for QPSK Modulated CV-QKD in Turbulent Channels
Authors: Renzhi Yuan, Zhixing Wang, Shouye Miao, Mufei Zhao, Haifeng Yao, Bin Cao, Mugen Peng
Abstract: Continuous variable-quantum key distribution (CV-QKD) protocols attract increasing attentions in recent years because they enjoy high secret key rate (SKR) and good compatibility with existing optical communication infrastructure. Classical coherent receivers are widely employed in coherent states based CV-QKD protocols, whose detection performance is bounded by the standard quantum limit (SQL). Recently, quantum receivers based on displacement operators are experimentally demonstrated with detection performance outperforming the SQL in various practical conditions. However, potential applications of quantum receivers in CV-QKD protocols under turbulent channels are still not well explored, while practical CV-QKD protocols must survive from the atmospheric turbulence in satellite-to-ground optical communication links. In this paper, we consider the possibility of using a quantum receiver called multi-stage CD-Kennedy receiver to enhance the SKR performance of a quadrature phase shift keying (QPSK) modulated CV-QKD protocol in turbulent channels. We first derive the error probability of the multi-stage CD-Kennedy receiver for detecting QPSK signals in turbulent channels and further propose three types of multi-stage CD-Kennedy receiver with different displacement choices, i.e., the Type-I, Type-II, and Type-III receivers. Then we derive the SKR of a QPSK modulated CV-QKD protocol using the multi-stage CD-Kennedy receiver and post-selection strategy in turbulent channels. Numerical results show that the multi-stage CD-Kennedy receiver can outperform the classical coherent receiver in turbulent channels in terms of both error probability and SKR performance and the Type-II receiver can tolerate worse channel conditions compared with Type-I and Type-III receivers in terms of error probability performance.

Paper number 64:
Title: Reproduction Number and Spatial Connectivity Structure Estimation via Graph Sparsity-Promoting Penalized Functional
Authors: Etienne Lasalle, Barbara Pascal
Abstract: During an epidemic outbreak, decision makers crucially need accurate and robust tools to monitor the pathogen propagation. The effective reproduction number, defined as the expected number of secondary infections stemming from one contaminated individual, is a state-of-the-art indicator quantifying the epidemic intensity. Numerous estimators have been developed to precisely track the reproduction number temporal evolution. Yet, COVID-19 pandemic surveillance raised unprecedented challenges due to the poor quality of worldwide reported infection counts. When monitoring the epidemic in different territories simultaneously, leveraging the spatial structure of data significantly enhances both the accuracy and robustness of reproduction number estimates. However, this requires a good estimate of the spatial structure. To tackle this major limitation, the present work proposes a joint estimator of the reproduction number and connectivity structure. The procedure is assessed through intensive numerical simulations on carefully designed synthetic data and illustrated on real COVID-19 spatiotemporal infection counts.

Paper number 65:
Title: A dual bistatic optical forward transceiver configuration for determining the position of an acoustic communication source detected by optical communication fibers
Authors: Knut H. Grythe, Jan Erik Håkegård
Abstract: Optical fibers have long been employed as sensors in a wide range of commercial systems. Distributed Acoustic Sensing (DAS) extends this concept by enabling the detection and localization of acoustic sources along the fiber, using backscattered light from small segments to achieve spatial resolution on the order of meters. Recently, DAS has also been explored as a component in underwater acoustic communication systems. Emerging interest in bidirectional configurations where both transmitter and receiver are placed at opposite ends of the fiber has opened new possibilities. However, in such setups, source localization is not inherently integrated into the signal decoding process. For scenarios where source positioning is valuable, we propose an approach inspired by bi-static radar principles. This configuration utilizes acoustic signals received at both ends of the fiber to estimate source position based on propagation delay differences. Although the localization accuracy is lower than that of DAS due to reduced sampling rates, the method offers a viable alternative for integrated communication and positioning. We present the system topology and configuration for a dual-fiber layout, each end equipped with optical transmitters and receivers. The position estimation is derived from the time difference of arrival (TDOA) between the two receivers. The Cramér-Rao Bound is derived to characterize the theoretical limits of localization accuracy, highlighting dependencies on system parameters such as optical power loss. Our analysis shows that increased acoustic bandwidth and higher carrier frequencies enhance spatial resolution. We formulate the Cross Ambiguity Function as a maximum likelihood estimator for TDOA and provide simulation results illustrating its performance under varying system conditions. Finally, we discuss key challenges that must be addressed for practical implementation.

Paper number 66:
Title: Joint Ex-Post Location Calibration and Radio Map Construction under Biased Positioning Errors
Authors: Koki Kanzaki (1), Koya Sato (1) ((1) The University of Electro-Communications)
Abstract: This paper proposes a high-accuracy radio map construction method tailored for environments where location information is affected by bursty errors. Radio maps are an effective tool for visualizing wireless environments. Although extensive research has been conducted on accurate radio map construction, most existing approaches assume noise-free location information during sensing. In practice, however, positioning errors ranging from a few to several tens of meters can arise due to device-based positioning systems (e.g., GNSS). Ignoring such errors during inference can lead to significant degradation in radio map accuracy. This study highlights that these errors often tend to be biased when using mobile devices as sensors. We introduce a novel framework that models these errors together with spatial correlation in radio propagation by embedding them as tunable parameters in the marginal log-likelihood function. This enables ex-post calibration of location uncertainty during radio map construction. Numerical results based on practical human mobility data demonstrate that the proposed method can limit RMSE degradation to approximately 0.25-0.29 dB, compared with Gaussian process regression using noise-free location data, whereas baseline methods suffer performance losses exceeding 1 dB.

Paper number 67:
Title: Discrete Diffusion for Generative Modeling of Text-Aligned Speech Tokens
Authors: Pin-Jui Ku, He Huang, Jean-Marie Lemercier, Subham Sekhar Sahoo, Zhehuai Chen, Ante Jukić
Abstract: This paper introduces a discrete diffusion model (DDM) framework for text-aligned speech tokenization and reconstruction. By replacing the auto-regressive speech decoder with a discrete diffusion counterpart, our model achieves significantly better reconstruction quality, stronger ASR performance, and faster inference. We provide a comprehensive analysis of applying DDMs to speech reconstruction, examining sampler choices, inference steps, and robustness to length-scale estimation errors. Furthermore, we improve the original TASTE by systematically comparing vector quantization modules, showing that FSQ yields up to a 35% relative WER reduction and +0.14 UT-MOS improvement over RVQ for AR models, while also enhancing DDM performance. Our model generates speech in just 10 denoising steps and even supports single-step generation with only minor quality degradation.

Paper number 68:
Title: Distributed Koopman Operator Learning from Sequential Observations
Authors: Ali Azarbahram, Shenyu Liu, Gian Paolo Incremona
Abstract: This paper presents a distributed Koopman operator learning framework for modeling unknown nonlinear dynamics using sequential observations from multiple agents. Each agent estimates a local Koopman approximation based on lifted data and collaborates over a communication graph to reach exponential consensus on a consistent distributed approximation. The approach supports distributed computation under asynchronous and resource-constrained sensing. Its performance is demonstrated through simulation results, validating convergence and predictive accuracy under sensing-constrained scenarios and limited communication.

Paper number 69:
Title: Koopman-Operator-Based Model Predictive Control for Drag-free Satellite
Authors: Yankai Wang, Ti Chen
Abstract: This paper presents a data-driven modelling method for nonlinear dynamics of drag-free satellite based on Koopman operator theory, and a model predictive controller is designed based on the identified model. The nonlinear dynamics of drag-free satellite are identified and controlled based on Sparse Identification of Nonlinear Dynamics (SINDy). Using the manually constructed nonlinear function dictionary as observables, the system approximation is obtained by SINDy algorithm, and a linear Model Predictive Control (MPC) controller is designed for test mass capture based on the SINDy model. Finally, the effectiveness of MPC control is verified by numerical examples.

Paper number 70:
Title: Reciprocal Beyond-Diagonal Reconfigurable Intelligent Surface (BD-RIS): Scattering Matrix Design via Manifold Optimization
Authors: Marko Fidanovski, Iván Alexander Morales Sandoval, Hyeon Seok Rou, Giuseppe Thadeu Freitas de Abreu, Emil Björnson
Abstract: Beyond-diagonal reconfigurable intelligent surfaces (BD-RISs) are emerging as a transformative technology in wireless communications, enabling enhanced performance and quality of service (QoS) of wireless systems in harsh urban environments due to their relatively low cost and advanced signal processing capabilities. Generally, BD-RIS systems are employed to improve robustness, increase achievable rates, and enhance energy efficiency of wireless systems in both direct and indirect ways. The direct way is to produce a favorable propagation environment via the design of optimized scattering matrices, while the indirect way is to reap additional improvements via the design of multiple-input multiple-output (MIMO) beamformers that further exploit the latter "engineered" medium. In this article, the problem of sum-rate maximization via BD-RIS is examined, with a focus on feasibility, namely low-complexity physical implementation, by enforcing reciprocity in the BD-RIS design. We begin by outlining the system model and formulating an optimization problem that aims to enhance the system's sum-rate by designing a symmetric scattering matrix. In particular, the approach leverages a manifold optimization framework, where a penalty term is added to the objective function to ensure that the symmetry constraint is upheld, with reciprocity further enforced by projecting the obtained solution onto a set of feasible scattering matrices. Simulation results demonstrate the effectiveness of the proposed method in outperforming current state-of-the-art (SotA) approaches in terms of sum-rate maximization.

Paper number 71:
Title: Geometric Port Selection in CUMA Systems
Authors: Chenguang Rao, Kai-Kit Wong, Mohd Hamza Naim Shaikh, Hanjiang Hong, Hyundong Shin, Yangyang Zhang
Abstract: Compact ultra-massive antenna-array (CUMA) is a novel multiple access technology built on the fluid antenna system (FAS) concept, offering an improved scheme over fluid antenna multiple access (FAMA) that can support massive connectivity on the same physical channel without the need of precoding and interference cancellation. By employing a simple port-selection mechanism that leverages random channel superposition, CUMA can suppress inter-user interference while keeping hardware costs low. Nevertheless, its ad-hoc port-selection strategy leaves considerable room for optimization. In this work, we revisit CUMA and propose two adaptive single-RF port-selection schemes that retain its simplicity while significantly enhancing performance. The first one, referred to as exact optimal half-space (EOHS), dynamically selects the projection direction that maximizes the instantaneous signal build-up across active ports. To reduce complexity while preserving most of the gains, we furthermore introduce a principal component analysis (PCA)-based scheme, which aligns port partitioning with the dominant statistical direction of per-port channel vectors. This method yields a closed-form low-complexity solution, complemented by a tractable analytical framework that provides a closed-form expression for the signal-to-interference ratio (SIR) probability density function (PDF). Simulation results corroborate the analysis, demonstrating that both EOHS and PCA consistently outperform conventional CUMA across diverse user densities, port counts, and FAS aperture sizes. Notably, PCA achieves performance close to EOHS at a fraction of the computational cost. The proposed schemes scale effectively to large-user regimes, offering a compelling complexity-performance trade-off for next-generation multiple access systems.

Paper number 72:
Title: Certified Learning-Enabled Noise-Aware Motion Planning for Urban Air Mobility
Authors: Jaejeong Park, Mahmoud Elfar, Cody Fleming, Yasser Shoukry
Abstract: Urban Air Mobility (UAM) has emerged as a promising solution to alleviate urban congestion and transportation challenges. Nevertheless, the noise generated by eVTOL aircrafts poses a significant barrier to public acceptance and regulatory approval, potentially limiting the operational scope and scalability of UAM systems. Hence, the successful adoption of UAM systems hinges on the ability to predict generated noise levels, and further develop motion planning strategies that comply with community-level noise regulations while maintaining operational efficiency. To this end, this paper proposes a novel noise-aware motion planning framework for UAM systems that ensures compliance with noise regulations. We first develop a certifiable neural network model to accurately predict eVTOL noise propagation patterns in urban environments, providing provable bounds on its correctness. To achieve a desired level of accuracy, we propose an active sampling strategy to efficiently build the dataset used to train and test the noise model. Next, we develop a noise-aware motion planning algorithm that utilizes the noise model to generate eVTOL trajectories that guarantee compliance with community noise regulations. The algorithm exploits the monotonic structure of the noise model to efficiently sample the configuration space, ensuring that the generated trajectories are both noise-compliant and operationally efficient. We demonstrate the effectiveness of the proposed framework through a number of experiments for Vahana eVTOLs. The results show that the framework can generate noise-compliant flight plans for a fleet of eVTOLs that adhere to community noise regulations while optimizing operational efficiency.

Paper number 73:
Title: On Robustness of Consensus over Pseudo-Undirected Path Graphs
Authors: Abhinav Sinha, Dwaipayan Mukherjee, Shashi Ranjan Kumar
Abstract: Consensus over networked agents is typically studied using undirected or directed communication graphs. Undirected graphs enforce symmetry in information exchange, leading to convergence to the average of initial states, while directed graphs permit asymmetry but make consensus dependent on root nodes and their influence. Both paradigms impose inherent restrictions on achievable consensus values and network robustness. This paper introduces a theoretical framework for achieving consensus over a class of network topologies, termed pseudo-undirected graphs, which retains bidirectional connectivity between node pairs but allows the corresponding edge weights to differ, including the possibility of negative values under bounded conditions. The resulting Laplacian is generally non-symmetric, yet it guarantees consensus under connectivity assumptions, to expand the solution space, which enables the system to achieve a stable consensus value that can lie outside the convex hull of the initial state set. We derive admissibility bounds for negative weights for a pseudo-undirected path graph, and show an application in the simultaneous interception of a moving target.

Paper number 74:
Title: Adversarial Pursuits in Cislunar Space
Authors: Filippos Fotiadis, Quentin Rommel, Gregory Falco, Ufuk Topcu
Abstract: Cislunar space is becoming a critical domain for future lunar and interplanetary missions, yet its remoteness, sparse infrastructure, and unstable dynamics create single points of failure. Adversaries in cislunar orbits can exploit these vulnerabilities to pursue and jam co-located communication relays, potentially severing communications between lunar missions and the Earth. We study a pursuit-evasion scenario between two spacecraft in a cislunar orbit, where the evader must avoid a pursuer-jammer while remaining close to its nominal trajectory. We model the evader-pursuer interaction as a zero-sum adversarial differential game cast in the circular restricted three-body problem. This formulation incorporates critical aspects of cislunar orbital dynamics, including autonomous adjustment of the reference orbit phasing to enable aggressive evading maneuvers, and shaping of the evader's cost with the orbit's stable and unstable manifolds. We solve the resulting nonlinear game locally using a continuous-time differential dynamic programming variant, which iteratively applies linear-quadratic approximations to the Hamilton-Jacobi-Isaacs equation. We simulate the evader's behavior against both a worst-case and a linear-quadratic pursuer. Our results pave the way for securing future missions in cislunar space against emerging cyber threats.

Paper number 75:
Title: Adaptive Event-Triggered Policy Gradient for Multi-Agent Reinforcement Learning
Authors: Umer Siddique, Abhinav Sinha, Yongcan Cao
Abstract: Conventional multi-agent reinforcement learning (MARL) methods rely on time-triggered execution, where agents sample and communicate actions at fixed intervals. This approach is often computationally expensive and communication-intensive. To address this limitation, we propose ET-MAPG (Event-Triggered Multi-Agent Policy Gradient reinforcement learning), a framework that jointly learns an agent's control policy and its event-triggering policy. Unlike prior work that decouples these mechanisms, ET-MAPG integrates them into a unified learning process, enabling agents to learn not only what action to take but also when to execute it. For scenarios with inter-agent communication, we introduce AET-MAPG, an attention-based variant that leverages a self-attention mechanism to learn selective communication patterns. AET-MAPG empowers agents to determine not only when to trigger an action but also with whom to communicate and what information to exchange, thereby optimizing coordination. Both methods can be integrated with any policy gradient MARL algorithm. Extensive experiments across diverse MARL benchmarks demonstrate that our approaches achieve performance comparable to state-of-the-art, time-triggered baselines while significantly reducing both computational load and communication overhead.

Paper number 76:
Title: Approximately Optimal Toll Design for Efficiency and Equity in Arc-Based Traffic Assignment Models
Authors: Chih-Yuan Chiu
Abstract: Congestion pricing policies have emerged as promising traffic management tools to alleviate traffic congestion caused by travelers' selfish routing behaviors. The core principle behind deploying tolls is to impose monetary costs on frequently overcrowded routes, to incentivize self-interested travelers to select less easily congested routes. Recent literature has focused on toll design based on arc-based traffic assignment models (TAMs), which characterize commuters as traveling through a traffic network by successively selecting an outgoing arc from every intermediate node along their journey. However, existing tolling mechanisms predicated on arc-based TAMs often target the design of a single congestion-minimizing toll, ignoring crucial fairness considerations, such as the financial impact of high congestion fees on low-income travelers. To address these shortcomings, in this paper, we pose the dual considerations of efficiency and equity in traffic routing as bilevel optimization problems. Since such problems are in general computationally intractable to solve precisely, we construct a linear program approximation by introducing a polytope approximation for the set of all tolls that induce congestion-minimizing traffic flow patterns. Finally, we provide numerical results that validate our theoretical conclusions.

Paper number 77:
Title: Qompiler: A Traceable Quantum Circuit Synthesizer for Arbitrary Hamiltonians
Authors: Shoupu Wan
Abstract: We present a quantum compiler framework that bridges the gap between physics modeling and quantum software development. At the core of this framework is a versatile quantum circuit synthesizer capable of decomposing arbitrary Hamiltonians into quantum circuits, represented using a platform-independent B-Tree-based intermediate representation. The B-Tree structure encodes information for gate lineage, enabling detailed tracing information of quantum circuit gates and facilitating circuit verification. The intermediate representation serves as a universal, hardware-agnostic carrier of compiled code, allowing it to be readily rendered on most quantum hardware backends and transpiled into other quantum circuit languages. We demonstrate rendering the intermediate representation into executable quantum circuits in Qiskit and Cirq. We can also transpile the intermediate representation into OpenQASM for broader compatibility.

Paper number 78:
Title: Wavelet Fourier Diffuser: Frequency-Aware Diffusion Model for Reinforcement Learning
Authors: Yifu Luo, Yongzhe Chang, Xueqian Wang
Abstract: Diffusion probability models have shown significant promise in offline reinforcement learning by directly modeling trajectory sequences. However, existing approaches primarily focus on time-domain features while overlooking frequency-domain features, leading to frequency shift and degraded performance according to our observation. In this paper, we investigate the RL problem from a new perspective of the frequency domain. We first observe that time-domain-only approaches inadvertently introduce shifts in the low-frequency components of the frequency domain, which results in trajectory instability and degraded performance. To address this issue, we propose Wavelet Fourier Diffuser (WFDiffuser), a novel diffusion-based RL framework that integrates Discrete Wavelet Transform to decompose trajectories into low- and high-frequency components. To further enhance diffusion modeling for each component, WFDiffuser employs Short-Time Fourier Transform and cross attention mechanisms to extract frequency-domain features and facilitate cross-frequency interaction. Extensive experiment results on the D4RL benchmark demonstrate that WFDiffuser effectively mitigates frequency shift, leading to smoother, more stable trajectories and improved decision-making performance over existing methods.

Paper number 79:
Title: Vision-Based Perception for Autonomous Vehicles in Off-Road Environment Using Deep Learning
Authors: Nelson Alves Ferreira Neto
Abstract: Low-latency intelligent systems are required for autonomous driving on non-uniform terrain in open-pit mines and developing countries. This work proposes a perception system for autonomous vehicles on unpaved roads and off-road environments, capable of navigating rough terrain without a predefined trail. The Configurable Modular Segmentation Network (CMSNet) framework is proposed, facilitating different architectural arrangements. CMSNet configurations were trained to segment obstacles and trafficable ground on new images from unpaved/off-road scenarios with adverse conditions (night, rain, dust). We investigated applying deep learning to detect drivable regions without explicit track boundaries, studied algorithm behavior under visibility impairment, and evaluated field tests with real-time semantic segmentation. A new dataset, Kamino, is presented with almost 12,000 images from an operating vehicle with eight synchronized cameras. The Kamino dataset has a high number of labeled pixels compared to similar public collections and includes images from an off-road proving ground emulating a mine under adverse visibility. To achieve real-time inference, CMSNet CNN layers were methodically removed and fused using TensorRT, C++, and CUDA. Empirical experiments on two datasets validated the proposed system's effectiveness.

Paper number 80:
Title: Crater Observing Bio-inspired Rolling Articulator (COBRA)
Authors: Adarsh Salagame, Henry Noyes, Alireza Ramezani, Eric Sihite, Arash Kalantari
Abstract: NASA aims to establish a sustainable human basecamp on the Moon as a stepping stone for future missions to Mars and beyond. The discovery of water ice on the Moon's craters located in permanently shadowed regions, which can provide drinking water, oxygen, and rocket fuel, is therefore of critical importance. However, current methods to access lunar ice deposits are limited. While rovers have been used to explore the lunar surface for decades, they face significant challenges in navigating harsh terrains, such as permanently shadowed craters, due to the high risk of immobilization. This report introduces COBRA (Crater Observing Bio-inspired Rolling Articulator), a multi-modal snake-style robot designed to overcome mobility challenges in Shackleton Crater's rugged environment. COBRA combines slithering and tumbling locomotion to adapt to various crater terrains. In snake mode, it uses sidewinding to traverse flat or low inclined surfaces, while in tumbling mode, it forms a circular barrel by linking its head and tail, enabling rapid movement with minimal energy on steep slopes. Equipped with an onboard computer, stereo camera, inertial measurement unit, and joint encoders, COBRA facilitates real-time data collection and autonomous operation. This paper highlights COBRAs robustness and efficiency in navigating extreme terrains through both simulations and experimental validation.

Paper number 81:
Title: Metriplectic Conditional Flow Matching for Dissipative Dynamics
Authors: Ali Baheri, Lars Lindemann
Abstract: Metriplectic conditional flow matching (MCFM) learns dissipative dynamics without violating first principles. Neural surrogates often inject energy and destabilize long-horizon rollouts; MCFM instead builds the conservative-dissipative split into both the vector field and a structure preserving sampler. MCFM trains via conditional flow matching on short transitions, avoiding long rollout adjoints. In inference, a Strang-prox scheme alternates a symplectic update with a proximal metric step, ensuring discrete energy decay; an optional projection enforces strict decay when a trusted energy is available. We provide continuous and discrete time guarantees linking this parameterization and sampler to conservation, monotonic dissipation, and stable rollouts. On a controlled mechanical benchmark, MCFM yields phase portraits closer to ground truth and markedly fewer energy-increase and positive energy rate events than an equally expressive unconstrained neural flow, while matching terminal distributional fit.

Paper number 82:
Title: Retrieval Augmented Generation based context discovery for ASR
Authors: Dimitrios Siskos, Stavros Papadopoulos, Pablo Peso Parada, Jisi Zhang, Karthikeyan Saravanan, Anastasios Drosou
Abstract: This work investigates retrieval augmented generation as an efficient strategy for automatic context discovery in context-aware Automatic Speech Recognition (ASR) system, in order to improve transcription accuracy in the presence of rare or out-of-vocabulary terms. However, identifying the right context automatically remains an open challenge. This work proposes an efficient embedding-based retrieval approach for automatic context discovery in ASR. To contextualize its effectiveness, two alternatives based on large language models (LLMs) are also evaluated: (1) large language model (LLM)-based context generation via prompting, and (2) post-recognition transcript correction using LLMs. Experiments on the TED-LIUMv3, Earnings21 and SPGISpeech demonstrate that the proposed approach reduces WER by up to 17% (percentage difference) relative to using no-context, while the oracle context results in a reduction of up to 24.1%.

Paper number 83:
Title: From Space to Time: Enabling Adaptive Safety with Learned Value Functions via Disturbance Recasting
Authors: Sander Tonkens, Nikhil Uday Shinde, Azra Begzadić, Michael C. Yip, Jorge Cortés, Sylvia L. Herbert
Abstract: The widespread deployment of autonomous systems in safety-critical environments such as urban air mobility hinges on ensuring reliable, performant, and safe operation under varying environmental conditions. One such approach, value function-based safety filters, minimally modifies a nominal controller to ensure safety. Recent advances leverage offline learned value functions to scale these safety filters to high-dimensional systems. However, these methods assume detailed priors on all possible sources of model mismatch, in the form of disturbances in the environment -- information that is rarely available in real world settings. Even in well-mapped environments like urban canyons or industrial sites, drones encounter complex, spatially-varying disturbances arising from payload-drone interaction, turbulent airflow, and other environmental factors. We introduce SPACE2TIME, which enables safe and adaptive deployment of offline-learned safety filters under unknown, spatially-varying disturbances. The key idea is to reparameterize spatial variations in disturbance as temporal variations, enabling the use of precomputed value functions during online operation. We validate SPACE2TIME on a quadcopter through extensive simulations and hardware experiments, demonstrating significant improvement over baselines.

Paper number 84:
Title: Modular Machine Learning with Applications to Genetic Circuit Composition
Authors: Jichi Wang, Eduardo D. Sontag, Domitilla Del Vecchio
Abstract: In several applications, including in synthetic biology, one often has input/output data on a system composed of many modules, and although the modules' input/output functions and signals may be unknown, knowledge of the composition architecture can significantly reduce the amount of training data required to learn the system's input/output mapping. Learning the modules' input/output functions is also necessary for designing new systems from different composition architectures. Here, we propose a modular learning framework, which incorporates prior knowledge of the system's compositional structure to (a) identify the composing modules' input/output functions from the system's input/output data and (b) achieve this by using a reduced amount of data compared to what would be required without knowledge of the compositional structure. To achieve this, we introduce the notion of modular identifiability, which allows recovery of modules' input/output functions from a subset of the system's input/output data, and provide theoretical guarantees on a class of systems motivated by genetic circuits. We demonstrate the theory on computational studies showing that a neural network (NNET) that accounts for the compositional structure can learn the composing modules' input/output functions and predict the system's output on inputs outside of the training set distribution. By contrast, a neural network that is agnostic of the structure is unable to predict on inputs that fall outside of the training set distribution. By reducing the need for experimental data and allowing module identification, this framework offers the potential to ease the design of synthetic biological circuits and of multi-module systems more generally.

Paper number 85:
Title: Minimalistic Autonomous Stack for High-Speed Time-Trial Racing
Authors: Mahmoud Ali, Hassan Jardali, Youwei Yu, Durgakant Pushp, Lantao Liu
Abstract: Autonomous racing has seen significant advancements, driven by competitions such as the Indy Autonomous Challenge (IAC) and the Abu Dhabi Autonomous Racing League (A2RL). However, developing an autonomous racing stack for a full-scale car is often constrained by limited access to dedicated test tracks, restricting opportunities for real-world validation. While previous work typically requires extended development cycles and significant track time, this paper introduces a minimalistic autonomous racing stack for high-speed time-trial racing that emphasizes rapid deployment and efficient system integration with minimal on-track testing. The proposed stack was validated on real speedways, achieving a top speed of 206 km/h within just 11 hours' practice run on the track with 325 km in total. Additionally, we present the system performance analysis, including tracking accuracy, vehicle dynamics, and safety considerations, offering insights for teams seeking to rapidly develop and deploy an autonomous racing stack with limited track access.

Paper number 86:
Title: SoK: A Systematic Review of Malware Ontologies and Taxonomies and Implications for the Quantum Era
Authors: Dehinde Molade, Dave Ormrod, Mamello Thinyane, Nalin Arachchilage, Jill Slay
Abstract: The threat of quantum malware is real and a growing security concern that will have catastrophic scientific and technological impacts, if not addressed early. If weaponised or exploited especially by the wrong hands, malware will undermine highly sophisticated critical systems supported by next-generation quantum architectures, for example, in defence, communications, energy, and space. This paper explores the fundamental nature and implications of quantum malware to enable the future development of appropriate mitigations and defences, thereby protecting critical infrastructure. By conducting a systematic literature review (SLR) that draws on knowledge frameworks such as ontologies and taxonomies to explore malware, this provides insights into how malicious behaviours can be translated into attacks on quantum technologies, thereby providing a lens to analyse the severity of malware against quantum technologies. This study employs the European Competency Framework for Quantum Technologies (CFQT) as a guide to map malware behaviour to several competency layers, creating a foundation in this emerging field.

Paper number 87:
Title: Thinking While Listening: Simple Test Time Scaling For Audio Classification
Authors: Prateek Verma, Mert Pilanci
Abstract: We propose a framework that enables neural models to "think while listening" to everyday sounds, thereby enhancing audio classification performance. Motivated by recent advances in the reasoning capabilities of large language models, we address two central questions: (i) how can thinking be incorporated into existing audio classification pipelines to enable reasoning in the category space and improve performance, and (ii) can a new architecture be designed from the ground up to support both thinking and test-time scaling? We demonstrate that in both settings, our models exhibit improved classification accuracy. Leveraging test-time scaling, we observe consistent gains as the number of sampled traces increases. Furthermore, we evaluate two open-source reasoning models, GPT-OSS-20B and Qwen3-14B, showing that while such models are capable of zero-shot reasoning, a lightweight approach--retraining only the embedding matrix of a frozen, smaller model like GPT-2--can surpass the performance of billion-parameter text-based reasoning models.

Paper number 88:
Title: Formal Safety Verification and Refinement for Generative Motion Planners via Certified Local Stabilization
Authors: Devesh Nath, Haoran Yin, Glen Chou
Abstract: We present a method for formal safety verification of learning-based generative motion planners. Generative motion planners (GMPs) offer advantages over traditional planners, but verifying the safety and dynamic feasibility of their outputs is difficult since neural network verification (NNV) tools scale only to a few hundred neurons, while GMPs often contain millions. To preserve GMP expressiveness while enabling verification, our key insight is to imitate the GMP by stabilizing references sampled from the GMP with a small neural tracking controller and then applying NNV to the closed-loop dynamics. This yields reachable sets that rigorously certify closed-loop safety, while the controller enforces dynamic feasibility. Building on this, we construct a library of verified GMP references and deploy them online in a way that imitates the original GMP distribution whenever it is safe to do so, improving safety without retraining. We evaluate across diverse planners, including diffusion, flow matching, and vision-language models, improving safety in simulation (on ground robots and quadcopters) and on hardware (differential-drive robot).

Paper number 89:
Title: Can Audio Large Language Models Verify Speaker Identity?
Authors: Yiming Ren, Xuenan Xu, Baoxiang Li, Shuai Wang, Chao Zhang
Abstract: This paper investigates adapting Audio Large Language Models (ALLMs) for speaker verification (SV). We reformulate SV as an audio question-answering task and conduct comprehensive zero-shot evaluations on public benchmarks, showing that current ALLMs have limited zero-shot SV capability and often struggle in diverse acoustic conditions. To address this challenge, we perform supervised fine-tuning on speaker verification data. A rule-based hard pair sampling strategy is proposed to construct more challenging training pairs. Lightweight fine-tuning substantially improves the performance, though there is still a gap between ALLMs and conventional models. Then, we extend to text-dependent SV by jointly querying ALLMs to verify speaker identity and spoken content, yielding results competitive with cascaded ASR-SV systems. Our findings demonstrate that with proper adaptation, ALLMs hold substantial potential as a unified model for robust speaker verification systems, while maintaining the general audio understanding capabilities.

Paper number 90:
Title: PPGFlowECG: Latent Rectified Flow with Cross-Modal Encoding for PPG-Guided ECG Generation and Cardiovascular Disease Detection
Authors: Xiaocheng Fang, Jiarui Jin, Haoyu Wang, Che Liu, Jieyi Cai, Guangkun Nie, Jun Li, Hongyan Li, Shenda Hong
Abstract: In clinical practice, electrocardiography (ECG) remains the gold standard for cardiac monitoring, providing crucial insights for diagnosing a wide range of cardiovascular diseases (CVDs). However, its reliance on specialized equipment and trained personnel limits feasibility for continuous routine monitoring. Photoplethysmography (PPG) offers accessible, continuous monitoring but lacks definitive electrophysiological information, preventing conclusive diagnosis. Generative models present a promising approach to translate PPG into clinically valuable ECG signals, yet current methods face substantial challenges, including the misalignment of physiological semantics in generative models and the complexity of modeling in high-dimensional signals. To this end, we propose PPGFlowECG, a two-stage framework that aligns PPG and ECG in a shared latent space via the CardioAlign Encoder and employs latent rectified flow to generate ECGs with high fidelity and interpretability. To the best of our knowledge, this is the first study to experiment on MCMED, a newly released clinical-grade dataset comprising over 10 million paired PPG-ECG samples from more than 118,000 emergency department visits with expert-labeled cardiovascular disease annotations. Results demonstrate the effectiveness of our method for PPG-to-ECG translation and cardiovascular disease detection. Moreover, cardiologist-led evaluations confirm that the synthesized ECGs achieve high fidelity and improve diagnostic reliability, underscoring our method's potential for real-world cardiovascular screening.

Paper number 91:
Title: Sparse Regularization by Smooth Non-separable Non-convex Penalty Function Based on Ultra-discretization Formula
Authors: Natsuki Akaishi, Koki Yamada, Kohei Yatabe
Abstract: In sparse optimization, the $\ell_{1}$ norm is widely adopted for its convexity, yet it often yields solutions with smaller magnitudes than expected. To mitigate this drawback, various non-convex sparse penalties have been proposed. Some employ non-separability, with ordered weighting as an effective example, to retain large components while suppressing small ones. Motivated by these approaches, we propose ULPENS, a non-convex, non-separable sparsity-inducing penalty function that enables control over the suppression of elements. Derived from the ultra-discretization formula, ULPENS can continuously interpolate between the $\ell_{1}$ norm and a non-convex selective suppressing function by adjusting parameters inherent to the formula. With the formula, ULPENS is smooth, allowing the use of efficient gradient-based optimization algorithms. We establish key theoretical properties of ULPENS and demonstrate its practical effectiveness through numerical experiments.

Paper number 92:
Title: Voltage-sensitive distribution factors for contingency analysis and topology optimization
Authors: Maurizio Titz, Dirk Witthaut, Joost van Dijk, Benjamin Petrick, Nico Westerbeck
Abstract: Topology optimization is a promising approach for mitigating congestion and managing changing grid conditions, but it is computationally challenging and requires approximations. Conventional distribution factors like PTDFs and LODFs, based on DC power flow, fail to capture voltage variations, reactive power, and losses - limiting their use in detailed optimization tasks such as busbar splitting. This paper introduces generalized distribution factors derived from a voltage-sensitive linearization of the full AC power flow equations. The proposed formulation accurately reflects reactive power flows, Ohmic losses, and voltage deviations while remaining computationally efficient. We derive and evaluate generalized PTDFs, LODFs, and topology modification factors using matrix identities. We discuss potential applications including voltage-aware N-1 security analysis, and topology optimization with a focus on busbar splitting. Numerical experiments demonstrate close agreement with full AC solutions, significantly outperforming the traditional DC approximation.

Paper number 93:
Title: Diffusion-Augmented Contrastive Learning: A Noise-Robust Encoder for Biosignal Representations
Authors: Rami Zewail
Abstract: Learning robust representations for biosignals is often hampered by the challenge of designing effective data this http URL methods can fail to capture the complex variations inherent in physiological data. Within this context, we propose a novel hybrid framework, Diffusion-Augmented Contrastive Learning (DACL), that fuses concepts from diffusion models and supervised contrastive learning. The DACL framework operates on a latent space created by a lightweight Variational Autoencoder (VAE) trained on our novel Scattering Transformer (ST) features [12]. It utilizes the diffusion forward process as a principled data augmentation technique to generate multiple noisy views of these latent embeddings. A U-Net style encoder is then trained with a supervised contrastive objective to learn a representation that balances class discrimination with robustness to noise across various diffusion time steps. We evaluated this proof-of-concept method on the PhysioNet 2017 ECG dataset, achieving a competitive AUROC of 0.7815. This work establishes a new paradigm for representation learning by using the diffusion process itself to drive the contrastive objective, creating noise-invariant embeddings that demonstrate a strong foundation for class separability.

Paper number 94:
Title: Orbital Stabilization and Time Synchronization of Unstable Periodic Motions in Underactuated Robots
Authors: Surov Maksim
Abstract: This paper presents a control methodology for achieving orbital stabilization with simultaneous time synchronization of periodic trajectories in underactuated robotic systems. The proposed approach extends the classical transverse linearization framework to explicitly incorporate time-desynchronization dynamics. To stabilize the resulting extended transverse dynamics, we employ a combination of time-varying LQR and sliding-mode control. The theoretical results are validated experimentally through the implementation of both centralized and decentralized control strategies on a group of six Butterfly robots.

Paper number 95:
Title: Digital Signal Processing from Classical Coherent Systems to Continuous-Variable QKD: A Review of Cross-Domain Techniques, Applications, and Challenges
Authors: Davi Juvêncio Gomes de Sousa, Caroline da Silva Morais Alves, Valéria Loureiro da Silva, Nelson Alves Ferreira Neto
Abstract: This systematic review investigates the application of digital signal processing (DSP) techniques -- originally developed for coherent optical communication systems to continuous-variable quantum key distribution (CV-QKD). The convergence of these domains has enabled significant advances in CV-QKD performance, particularly in phase synchronization, polarization tracking, and excess noise mitigation. To provide a comprehensive and reproducible synthesis of this emerging field, we employed the APISSER methodology, a task-oriented framework adapted from the PRISMA protocol. A structured search across IEEE Xplore and Web of Science databases (2021-2025) yielded 220 relevant publications, which were screened, classified, and analyzed to address six research questions. Our findings highlight that many classical DSP algorithms, such as Kalman filtering, carrier recovery, adaptive equalization, and machine-learning-assisted signal estimation, have been successfully adapted to the quantum regime, often requiring modifications to meet security and noise constraints. We also identify a range of recent DSP innovations in coherent optical communication systems with high potential for future CV-QKD integration, including neural equalization, probabilistic shaping, and joint retiming-equalization filters. Despite these advances, challenges remain in achieving robust phase tracking under ultra-low Signal-to-Noise Ratio (SNR) conditions, real-time polarization compensation, and secure co-existence with classical channels. This review maps current trends, technical barriers, and emerging opportunities at the intersection of signal processing for quantum and classical communication, supporting the development of scalable and resilient CV-QKD systems.

Paper number 96:
Title: Choose Your Battles: Distributed Learning Over Multiple Tug of War Games
Authors: Siddharth Chandak, Ilai Bistritz, Nicholas Bambos
Abstract: Consider N players and K games taking place simultaneously. Each of these games is modeled as a Tug-of-War (ToW) game where increasing the action of one player decreases the reward for all other players. Each player participates in only one game at any given time. At each time step, a player decides the game in which they wish to participate in and the action they take in that game. Their reward depends on the actions of all players that are in the same game. This system of K games is termed `Meta Tug-of-War' (Meta-ToW) game. These games can model scenarios such as power control, distributed task allocation, and activation in sensor networks. We propose the Meta Tug-of-Peace algorithm, a distributed algorithm where the action updates are done using a simple stochastic approximation algorithm, and the decision to switch games is made using an infrequent 1-bit communication between the players. We prove that in Meta-ToW games, our algorithm converges to an equilibrium that satisfies a target Quality of Service reward vector for the players. We then demonstrate the efficacy of our algorithm through simulations for the scenarios mentioned above.

Paper number 97:
Title: Z-Scores: A Metric for Linguistically Assessing Disfluency Removal
Authors: Maria Teleki, Sai Janjur, Haoran Liu, Oliver Grabner, Ketan Verma, Thomas Docog, Xiangjue Dong, Lingfeng Shi, Cong Wang, Stephanie Birkelbach, Jason Kim, Yin Zhang, James Caverlee
Abstract: Evaluating disfluency removal in speech requires more than aggregate token-level scores. Traditional word-based metrics such as precision, recall, and F1 (E-Scores) capture overall performance but cannot reveal why models succeed or fail. We introduce Z-Scores, a span-level linguistically-grounded evaluation metric that categorizes system behavior across distinct disfluency types (EDITED, INTJ, PRN). Our deterministic alignment module enables robust mapping between generated text and disfluent transcripts, allowing Z-Scores to expose systematic weaknesses that word-level metrics obscure. By providing category-specific diagnostics, Z-Scores enable researchers to identify model failure modes and design targeted interventions -- such as tailored prompts or data augmentation -- yielding measurable performance improvements. A case study with LLMs shows that Z-Scores uncover challenges with INTJ and PRN disfluencies hidden in aggregate F1, directly informing model refinement strategies.

Paper number 98:
Title: DRES: Benchmarking LLMs for Disfluency Removal
Authors: Maria Teleki, Sai Janjur, Haoran Liu, Oliver Grabner, Ketan Verma, Thomas Docog, Xiangjue Dong, Lingfeng Shi, Cong Wang, Stephanie Birkelbach, Jason Kim, Yin Zhang, James Caverlee
Abstract: Disfluencies -- such as "um," "uh," interjections, parentheticals, and edited statements -- remain a persistent challenge for speech-driven systems, degrading accuracy in command interpretation, summarization, and conversational agents. We introduce DRES (Disfluency Removal Evaluation Suite), a controlled text-level benchmark that establishes a reproducible semantic upper bound for this task. DRES builds on human-annotated Switchboard transcripts, isolating disfluency removal from ASR errors and acoustic variability. We systematically evaluate proprietary and open-source LLMs across scales, prompting strategies, and architectures. Our results reveal that (i) simple segmentation consistently improves performance, even for long-context models; (ii) reasoning-oriented models tend to over-delete fluent tokens; and (iii) fine-tuning achieves near state-of-the-art precision and recall but harms generalization abilities. We further present a set of LLM-specific error modes and offer nine practical recommendations (R1-R9) for deploying disfluency removal in speech-driven pipelines. DRES provides a reproducible, model-agnostic foundation for advancing robust spoken-language systems.

Paper number 99:
Title: Infrared Image Super-Resolution: Systematic Review, and Future Trends
Authors: Yongsong Huang, Tomo Miyazaki, Xiaofeng Liu, Shinichiro Omachi
Abstract: Image Super-Resolution (SR) is essential for a wide range of computer vision and image processing tasks. Investigating infrared (IR) image (or thermal images) super-resolution is a continuing concern within the development of deep learning. This survey aims to provide a comprehensive perspective of IR image super-resolution, including its applications, hardware imaging system dilemmas, and taxonomy of image processing methodologies. In addition, the datasets and evaluation metrics in IR image super-resolution tasks are also discussed. Furthermore, the deficiencies in current technologies and possible promising directions for the community to explore are highlighted. To cope with the rapid development in this field, we intend to regularly update the relevant excellent work at this https URL.

Paper number 100:
Title: To Fold or Not to Fold: Graph Regularized Tensor Train for Visual Data Completion
Authors: Le Xu, Lei Cheng, Ngai Wong, Yik-Chung Wu
Abstract: Tensor train (TT) representation has achieved tremendous success in visual data completion tasks, especially when it is combined with tensor folding. However, folding an image or video tensor breaks the original data structure, leading to local information loss as nearby pixels may be assigned into different dimensions and become far away from each other. In this paper, to fully preserve the local information of the original visual data, we explore not folding the data tensor, and at the same time adopt graph information to regularize local similarity between nearby entries. To overcome the high computational complexity introduced by the graph-based regularization in the TT completion problem, we propose to break the original problem into multiple sub-problems with respect to each TT core fiber, instead of each TT core as in traditional methods. Furthermore, to avoid heavy parameter tuning, a sparsity promoting probabilistic model is built based on the generalized inverse Gaussian (GIG) prior, and an inference algorithm is derived under the mean-field approximation. Experiments on both synthetic data and real-world visual data show the superiority of the proposed methods.

Paper number 101:
Title: Coordination Control of Discrete Event Systems under Cyber Attacks
Authors: Fei Wang, Jan Komenda, Feng Lin
Abstract: In this paper, coordination control of discrete event systems under joint sensor and actuator attacks is investigated. Sensor attacks are described by a set of attack languages using a proposed ALTER model. Several local supervisors are used to control the system. The goal is to design local supervisors to ensure safety of the system even under cyber attacks (CA). The necessary and sufficient conditions for the existence of such supervisors are derived in terms of conditional decomposability, CA-controllability and CA-observability. A method is developed to calculate local state estimates under sensor attacks. Two methods are also developed to design local supervisors, one for discrete event systems satisfying conditional decomposability, CA-controllability and CA-observability, and one for discrete event systems satisfying conditional decomposability only. The approach works for both stealthy and non-stealthy attacks. A practical example is given to illustrate the results.

Paper number 102:
Title: Decentralized Learning Strategies for Estimation Error Minimization with Graph Neural Networks
Authors: Xingran Chen, Navid NaderiAlizadeh, Alejandro Ribeiro, Shirin Saeedi Bidokhti
Abstract: We address the challenge of sampling and remote estimation for autoregressive Markovian processes in a multi-hop wireless network with statistically-identical agents. Agents cache the most recent samples from others and communicate over wireless collision channels governed by an underlying graph topology. Our goal is to minimize time-average estimation error and/or age of information with decentralized scalable sampling and transmission policies, considering both oblivious (where decision-making is independent of the physical processes) and non-oblivious policies (where decision-making depends on physical processes). We prove that in oblivious policies, minimizing estimation error is equivalent to minimizing the age of information. The complexity of the problem, especially the multi-dimensional action spaces and arbitrary network topologies, makes theoretical methods for finding optimal transmission policies intractable. We optimize the policies using a graphical multi-agent reinforcement learning framework, where each agent employs a permutation-equivariant graph neural network architecture. Theoretically, we prove that our proposed framework exhibits desirable transferability properties, allowing transmission policies trained on small- or moderate-size networks to be executed effectively on large-scale topologies. Numerical experiments demonstrate that (i) Our proposed framework outperforms state-of-the-art baselines; (ii) The trained policies are transferable to larger networks, and their performance gains increase with the number of agents; (iii) The training procedure withstands non-stationarity even if we utilize independent learning techniques; and, (iv) Recurrence is pivotal in both independent learning and centralized training and decentralized execution, and improves the resilience to non-stationarity in independent learning.

Paper number 103:
Title: ctPuLSE: Close-Talk, and Pseudo-Label Based Far-Field, Speech Enhancement
Authors: Zhong-Qiu Wang
Abstract: The current dominant approach for neural speech enhancement is via purely-supervised deep learning on simulated pairs of far-field noisy-reverberant speech (i.e., mixtures) and clean speech. The trained models, however, often exhibit limited generalizability to real-recorded mixtures. To deal with this, this paper investigates training enhancement models directly on real mixtures. However, a major difficulty challenging this approach is that, since the clean speech of real mixtures is unavailable, there lacks a good supervision for real mixtures. In this context, assuming that a training set consisting of real-recorded pairs of close-talk and far-field mixtures is available, we propose to address this difficulty via close-talk speech enhancement, where an enhancement model is first trained on simulated mixtures to enhance real-recorded close-talk mixtures and the estimated close-talk speech can then be utilized as a supervision (i.e., pseudo-label) for training far-field speech enhancement models directly on the paired real-recorded far-field mixtures. We name the proposed system ctPuLSE. Evaluation results on the popular CHiME-4 dataset show that ctPuLSE can derive high-quality pseudo-labels and yield far-field speech enhancement models with strong generalizability to real data.

Paper number 104:
Title: Minimum Time Consensus of Multi-agent System under Fuel Constraints
Authors: Akansha Rautela, Deepak Patil, Ameer Mulla, Indra Narayan Kar
Abstract: This work addresses the problem of finding minimum time consensus point in the state space for a set of $N$ identical double integrator agents with bounded inputs and fixed fuel budget constraint. To address the problem, characterization of the attainable set for each agent subject to bounded inputs and fixed fuel budget constraints is done. Such attainable set is shown to be a convex set. The minimum time to consensus is the least time when the attainable sets of all agents intersect and the corresponding consensus state is the point of intersection. Using Helly's theorem, it is shown that the intersection is not empty at the time when all triplets of agents exhibit a non-empty intersection. Thus, a closed-form expression for the minimum time to consensus for a triplet of agents is obtained. The calculation of minimum time consensus for each of the triplets is performed independently and is distributed evenly among $N$ agents. The overall minimum time to consensus of $N$ agents is then given by the triplet that has the greatest minimum time to consensus. In the process, the set of initial conditions for agents from which consensus is possible under these input and fuel budget constraints is also characterized.

Paper number 105:
Title: A GEN AI Framework for Medical Note Generation
Authors: Hui Yi Leong, Yi Fan Gao, Shuai Ji, Bora Kalaycioglu, Uktu Pamuksuz
Abstract: The increasing administrative burden of medical documentation, particularly through Electronic Health Records (EHR), significantly reduces the time available for direct patient care and contributes to physician burnout. To address this issue, we propose MediNotes, an advanced generative AI framework designed to automate the creation of SOAP (Subjective, Objective, Assessment, Plan) notes from medical conversations. MediNotes integrates Large Language Models (LLMs), Retrieval-Augmented Generation (RAG), and Automatic Speech Recognition (ASR) to capture and process both text and voice inputs in real time or from recorded audio, generating structured and contextually accurate medical notes. The framework also incorporates advanced techniques like Quantized Low-Rank Adaptation (QLoRA) and Parameter-Efficient Fine-Tuning (PEFT) for efficient model fine-tuning in resource-constrained environments. Additionally, MediNotes offers a query-based retrieval system, allowing healthcare providers and patients to access relevant medical information quickly and accurately. Evaluations using the ACI-BENCH dataset demonstrate that MediNotes significantly improves the accuracy, efficiency, and usability of automated medical documentation, offering a robust solution to reduce the administrative burden on healthcare professionals while improving the quality of clinical workflows.

Paper number 106:
Title: TuneS: Patient-specific model-based optimization of contact configuration in deep brain stimulation
Authors: Anna Franziska Frigge, Lina Uggla, Elena Jiltsova, Markus Fahlström, Dag Nyholm, Alexander Medvedev
Abstract: Objective: The objective of this study is to develop and evaluate a systematic approach to optimize Deep Brain Stimulation (DBS) parameters, addressing the challenge of identifying patient-specific settings and optimal stimulation targets for various neurological and mental disorders. Methods: TuneS, a novel pipeline to predict clinically optimal DBS contact configurations based on predefined targets and constraints, is introduced. The method relies upon patient-specific models of stimulation spread and extends optimization beyond traditional neural structures to include automated, model-based targeting of streamlines. Results: Initial findings show that both the STN motor subdivision and STN motor streamlines are consistently engaged under clinical settings, while regions of avoidance receive minimal stimulation. Given these findings, the value of model-based contact predictions for assessing stimulation targets while observing anatomical constraints is demonstrated at the example of a small cohort of Parkinson's disease patients. The predicted settings were generally found to achieve higher target coverages while providing a better trade-off between maximizing target coverage and minimizing stimulation of regions associated with side effects. Conclusion: TuneS shows promise as a research tool, enabling systematic assessment of DBS target effectiveness and facilitating constraint-aware optimization of stimulation parameters. Significance: The presented pipeline offers a pathway to improve patient-specific DBS therapies and contributes to the broader understanding of effective DBS targeting strategies.

Paper number 107:
Title: Joint Communications and Sensing for 6G Satellite Networks: Use Cases and Challenges
Authors: Chandan Kumar Sheemar, Prabhu Thiruvasagam, Wali Ullah Khan, Sourabh Solanki, George C. Alexandropoulos, Jorge Querol, Jan Plachy, Oliver Holschke, Symeon Chatzinotas
Abstract: Satellite networks (SN) have long provided two fundamental services: global communications and Earth-oriented sensing, supporting applications from connectivity and navigation to disaster management and environmental monitoring. Yet, the accelerating demand for data and the emergence of new applications render the independent evolution of communication and sensing payloads increasingly unsustainable. Joint communications and sensing (JCAS) has emerged as a transformative paradigm, integrating both functions within a unified payload to enhance spectral efficiency, reduce operational costs, and minimize hardware redundancy. Beyond efficiency, this integration creates opportunities for novel services that are infeasible under separate payload designs. This paper motivates the role of JCAS in shaping the sixth-generation (6G) of satellite networks, explores a representative use case to assess its feasibility, and discusses key challenges that must be addressed to unlock its full potential. By highlighting these opportunities inherent to the space environment, we aim to stimulate the development of JCAS as a cornerstone technology for the next-generation space era

Paper number 108:
Title: Scan-Adaptive MRI Undersampling Using Neighbor-based Optimization (SUNO)
Authors: Siddhant Gautam, Angqi Li, Nicole Seiberlich, Jeffrey A. Fessler, Saiprasad Ravishankar
Abstract: Accelerated MRI involves collecting partial $k$-space measurements to reduce acquisition time, patient discomfort, and motion artifacts, and typically uses regular undersampling patterns or human-designed schemes. Recent works have studied population-adaptive sampling patterns learned from a group of patients (or scans). However, such patterns can be sub-optimal for individual scans, as they may fail to capture scan or slice-specific details, and their effectiveness can depend on the size and composition of the population. To overcome this issue, we propose a framework for jointly learning scan-adaptive Cartesian undersampling patterns and a corresponding reconstruction model from a training set. We use an alternating algorithm for learning the sampling patterns and the reconstruction model where we use an iterative coordinate descent (ICD) based offline optimization of scan-adaptive $k$-space sampling patterns for each example in the training set. A nearest neighbor search is then used to select the scan-adaptive sampling pattern at test time from initially acquired low-frequency $k$-space information. We applied the proposed framework (dubbed SUNO) to the fastMRI multi-coil knee and brain datasets, demonstrating improved performance over the currently used undersampling patterns at both $4\times$ and $8\times$ acceleration factors in terms of both visual quality and quantitative metrics. The code for the proposed framework is available at this https URL.

Paper number 109:
Title: Unsupervised Estimation of Nonlinear Audio Effects: Comparing Diffusion-Based and Adversarial approaches
Authors: Eloi Moliner, Michal Švento, Alec Wright, Lauri Juvela, Pavel Rajmic, Vesa Välimäki
Abstract: Accurately estimating nonlinear audio effects without access to paired input-output signals remains a challenging problem. This work studies unsupervised probabilistic approaches for solving this task. We introduce a method, novel for this application, based on diffusion generative models for blind system identification, enabling the estimation of unknown nonlinear effects using black- and gray-box models. This study compares this method with a previously proposed adversarial approach, analyzing the performance of both methods under different parameterizations of the effect operator and varying lengths of available effected recordings. Through experiments on guitar distortion effects, we show that the diffusion-based approach provides more stable results and is less sensitive to data availability, while the adversarial approach is superior at estimating more pronounced distortion effects. Our findings contribute to the robust unsupervised blind estimation of audio effects, demonstrating the potential of diffusion models for system identification in music technology.

Paper number 110:
Title: Scalable Two-Stage Stochastic Optimal Power Flow via Separable Approximation
Authors: Shishir Lamichhane, Abodh Poudyal, Nicholas R. Jones, Bala Krishnamoorthy, Anamika Dubey
Abstract: This paper proposes a Separable Projective Approximation Routine-Optimal Power Flow (SPAR-OPF) framework for solving two-stage stochastic optimization problems in power systems. The framework utilizes a separable piecewise linear approximation of the value function and learns the function based on sample sub-gradient information. We present two formulations to model the learned value function, and compare their effectiveness. Additionally, an efficient statistical method is introduced to assess the quality of the obtained solutions. The effectiveness of the proposed framework is validated using distributed generation siting and sizing problem in three-phase unbalanced power distribution systems as an example. Results show that the framework approximates the value function with over 98% accuracy and provides high-quality solutions with an optimality gap of less than 1%. The framework scales efficiently with system size, generating high-quality solutions in a short time when applied to a 9500-node distribution system with 1200 scenarios, while the extensive formulations and progressive hedging failed to solve the problem.

Paper number 111:
Title: Imaging Biomarkers for Neurodegenerative Diseases from Detailed Segmentation of Medial Temporal Lobe Subregions on in vivo Brain MRI Using Upsampling Strategy Guided by High-resolution ex vivo MRI
Authors: Yue Li, Pulkit Khandelwal, Long Xie, Laura E. M. Wisse, Amanda E. Denning, Christopher A. Brown, Emily McGrew, Sydney A. Lim, Niyousha Sadeghpour, Sadhana Ravikumar, Ranjit Ittyerah, Eunice Chung, Daniel T. Ohm, Nidhi S. Mundada, María Mercedes Íñiguez de Onzoño Martín, María del Mar Arroyo Jiménez, Monica Mũnoz, Maria del Pilar Marcos Rabal, David J. Irwin, Edward B. Lee, Ricardo Insausti, Sandhitsu R. Das, David A. Wolk, Paul A. Yushkevich
Abstract: The medial temporal lobe (MTL) is a region impacted extensively and non-uniformly in early stages of Alzheimer's disease (AD). Regional MTL morphometric measures extracted from magnetic resonance imaging (MRI) are supportive features for the diagnosis of AD and related disorders (ADRD). Different MRI modalities have distinct advantages for MTL morphometry. Anisotropic T2-weighted (T2w) MRI is preferred for hippocampal subfields due to its higher contrast between hippocampal layers. Isotropic T1-weighted (T1w) MRI is beneficial for thickness calculation of extra-hippocampal subregions due to its stable image quality and isotropic resolution. We propose a multi-modality MTL segmentation algorithm that bridges the T1w and T2w modalities by bringing both to a nearly isotropic voxel space. Guided by high-resolution ex vivo 9.4T MRI, an upsampling model was designed for the ground truth segmentations. Combined with non-local means upsampling, this model was used to construct a nearly iso-tropic T1w and T2w MTL subregion segmentation training set, which was used to train a nnUNet model. Morphometric biomarkers extracted by this model were compared to those extracted using conventional models operating in anisotropic spaces on downstream tasks. Biomarkers extracted using the proposed model had greater ability to discriminate between individuals with mild cognitive impairment and cognitively unimpaired; and had great-er longitudinal stability. These findings suggest that the biomarkers derived from T1w and T2w MRI unsampled to nearly isotropic resolution have sig-nificant potential for improving disease diagnosis and monitoring disease progression in ADRD.

Paper number 112:
Title: Exploring Noncommutative Polynomial Equation Methods for Discrete-Time Quaternionic Control
Authors: Michael Sebek
Abstract: We present new polynomial-based methods for discrete-time quaternionic systems, highlighting how noncommutative multiplication modifies classical control approaches. Defining quaternionic polynomials via a backward-shift operator, we examine left and right fraction representations of transfer functions, showing that right zeros correspond to similarity classes of quaternionic matrix right eigenvalues. We then propose a feedback design procedure that generalizes pole placement to quaternions - a first approach using a genuine quaternionic polynomial equation.

Paper number 113:
Title: Probability-One Optimization of Generalized Rayleigh Quotient Sum For Multi-Source Generalized Total Least-Squares
Authors: Dominik Friml, Pavel Václavek
Abstract: This paper addresses the global optimization of the sum of the Rayleigh quotient and the generalized Rayleigh quotient on the unit sphere. While various methods have been proposed for this problem, they fail to reliably converge to the global maximizer. To overcome this limitation, we propose an extension of the Riemannian Trust Region algorithm based on the probability-one homotopy optimization method, which enhances convergence to a global maximizer and, under certain conditions, ensures convergence to the global maximizer. In addition to the proposed method, existing state-of-the-art approaches are also presented, along with an explanation of their limitations and their connection to the proposed method. The proposed method is evaluated alongside the state-of-the-art approaches through numerical experiments, assessing convergence speed, success in reaching the global maximizer, and scalability with increasing problem dimension. Furthermore, we demonstrate how this ties in with the multi-source Bayesian Generalized Total Least-Squares (B-GTLS) problem, illustrating its applicability.

Paper number 114:
Title: HAZEMATCHING: Dehazing Light Microscopy Images with Guided Conditional Flow Matching
Authors: Anirban Ray, Ashesh, Florian Jug
Abstract: Fluorescence microscopy is a major driver of scientific progress in the life sciences. Although high-end confocal microscopes are capable of filtering out-of-focus light, cheaper and more accessible microscopy modalities, such as widefield microscopy, can not, which consequently leads to hazy image data. Computational dehazing is trying to combine the best of both worlds, leading to cheap microscopy but crisp-looking images. The perception-distortion trade-off tells us that we can optimize either for data fidelity, e.g. low MSE or high PSNR, or for data realism, measured by perceptual metrics such as LPIPS or FID. Existing methods either prioritize fidelity at the expense of realism, or produce perceptually convincing results that lack quantitative accuracy. In this work, we propose HazeMatching, a novel iterative method for dehazing light microscopy images, which effectively balances these objectives. Our goal was to find a balanced trade-off between the fidelity of the dehazing results and the realism of individual predictions (samples). We achieve this by adapting the conditional flow matching framework by guiding the generative process with a hazy observation in the conditional velocity field. We evaluate HazeMatching on 5 datasets, covering both synthetic and real data, assessing both distortion and perceptual quality. Our method is compared against 7 baselines, achieving a consistent balance between fidelity and realism on average. Additionally, with calibration analysis, we show that HazeMatching produces well-calibrated predictions. Note that our method does not need an explicit degradation operator to exist, making it easily applicable on real microscopy data. All data used for training and evaluation and our code will be publicly available under a permissive license.

Paper number 115:
Title: Unlocking Transmission Flexibility under Uncertainty: Getting Dynamic Line Ratings into Electricity Markets
Authors: Zhiyi Zhou, Christoph Graf, Yury Dvorkin
Abstract: Static transmission line ratings may lead to underutilization of line capacity due to overly conservative assumptions. Grid-enhancing technologies (GETs) such as dynamic line ratings (DLRs), which adjust line capacity based on real-time conditions, are a techno-economically viable alternative to increase the utilization of existing power lines. Nonetheless, their adoption has been slow, partly due to the absence of operational tools that effectively account for simultaneous impacts on dispatch and pricing. In this paper, we represent transmission capacity with DLRs as a stock-like resource with time-variant interdependency, which is modeled via an approximation of line temperature evolution process, decoupling the impacts of ambient weather conditions and power flow on transmission line temperature and thus capacity. We integrate DLRs into a multi-period DC optimal power flow problem, with chance constrains addressing correlated uncertainty in DLRs and renewable generation. This yields non-convex problems that we transform into a tractable convex form by linearization. We derive locational marginal energy and ancillary services prices consistent with a competitive equilibrium. Numerical experiments on the 11-zone and 1814-node NYISO systems demonstrate its performance, including impacts on dispatch, pricing, and marginal carbon emissions.

Paper number 116:
Title: High-Availability Integrity Monitoring for Multi-Constellation GNSS Navigation with Non-Gaussian Errors
Authors: Penggao Yan, Ronghe Jin, Junyi Zhang, Cheng-Wei Wang, Li-Ta Hsu
Abstract: Global navigation satellite systems (GNSS) are essential for aviation, requiring strict integrity monitoring to alert users to hazardously misleading information. Conventional receiver autonomous integrity monitoring (RAIM) and advanced RAIM (ARAIM) rely heavily on Gaussian models in bounding nominal errors, which can be overly conservative with real-world non-Gaussian errors with heavy tails, such as the satellite clock and orbit errors. This paper proposes an extended jackknife detector capable of detecting multiple simultaneous faults with non-Gaussian nominal errors. Furthermore, an integrity monitoring algorithm, jackknife ARAIM, is developed by systematically exploiting the properties of the jackknife detector in the range domain. A tight bound of the integrity risk is derived by quantifying the impacts of hypothetical fault vectors on the position solution. The proposed method is examined in worldwide simulations, with the nominal measurement error simulated based on authentic experimental data, which reveals different findings in existing research. In a setting of a single Global Positioning System (GPS) constellation, the proposed method reduces the 99.5 percentile vertical protection level (VPL) 45m, where the VPL of the baseline ARAIM is larger than 50m in most user locations. For dual-constellation (GPS-Galileo) settings, baseline ARAIM suffers VPL inflation over 60m due to the over-conservatism induced by the heavy-tailed Galileo signal-in-space range errors, whereas the proposed jackknife ARAIM retains VPL below 40m, achieving over 92% normal operations for a 35m Vertical Alert Limit. These improvements have promising potential to support localizer performance with vertical guidance (LPV) with a decision height of 200 ft, enhancing integrity and availability for multi-constellation GNSS applications.

Paper number 117:
Title: A Remark on the AAA Method for Secret-Key Generation in Mobile Networks
Authors: Yingbo Hua
Abstract: A broadly applicable method for secret-key generation is named for its accumulative, adaptable and additive (AAA) properties. This paper first shows a robustness of its performance. Namely, even if there is an inter correlation or a leakage caused intra correlation among the superimposed packets, provided there is a nonzero probability for each packet to be missed in full or in part by Eve, then the equivocation of the key generated by the AAA method always becomes perfect as the number of superpositions becomes infinite. Also shown in this paper is a comparison between the AAA method and an ideal method based on reciprocal channel estimation, which reveals several advantages of the AAA method.

Paper number 118:
Title: Low-Complexity Equalization of Zak-OTFS in the Frequency Domain
Authors: Sandesh Rao Mattu, Nishant Mehrotra, Saif Khan Mohammed, Venkatesh Khammammetti, Robert Calderbank
Abstract: 4G/5G wireless standards use orthogonal frequency division multiplexing (OFDM) which is robust to frequency selectivity. Equalization is possible with a single tap filter, and low-complexity equalization makes OFDM an attractive physical layer. However the performance of OFDM degrades with mobility, since Doppler spreads introduce inter-carrier interference (ICI) between subcarriers and they are no longer orthogonal. Zak-transform based orthogonal time frequency space (Zak-OTFS) modulation has been shown to be robust to doubly selective channels. Zak-OTFS signals are formed in the delay-Doppler (DD) domain, converted to time domain (TD) for transmission and reception, then returned to the DD domain for processing. The received signal is a superposition of many attenuated copies since the doubly selective channel introduces delay and Doppler shifts. The received symbols are more difficult to equalize since they are subject to interference along both delay and Doppler axes. In this paper, we propose a new low-complexity method of equalizing Zak-OTFS in the frequency domain (FD). We derive the FD system model and show that it is unitarily equivalent to the DD system model. We show that the channel matrix in the FD is banded, making it possible to apply conjugate gradient methods to reduce the complexity of equalization. We show that complexity of FD equalization is linear in the dimension of a Zak-OTFS frame. For comparison the complexity of naive MMSE equalization is cubic in the frame dimension. Through numerical simulations we show that FD equalization of Zak-OTFS achieves similar performance as equalization in DD domain.

Paper number 119:
Title: Interference-Asymmetric UAV Remote Control Links: Measurements and Performance Evaluation
Authors: Donggu Lee, Sung Joon Maeng, Ozgur Ozdemir, Mani Bharathi Pandian, Ismail Guvenc
Abstract: Reliable and secure connectivity is crucial for remote control (RC) and uncrewed aerial vehicles (UAVs) links. A major problem for UAV RC links is that interference sources within the coverage may degrade the link quality. Such interference problems are a higher concern for the UAV than the RC unit on the ground due to the UAV being in line of sight (LoS) with a larger number of interference sources. As a result, lost hybrid automatic repeat request (HARQ) indicators (ACK/NACK) feedback in the uplink (UL, RC to UAV) may degrade the downlink (DL, UAV to RC) throughput. To get physical evidence for our interference asymmetry argument, we first conducted a measurement campaign using a helikite platform at the Main Campus area of NC State University during the 2024 Packapalooza festival. Subsequently, we evaluated the throughput impact of the loss of HARQ indicator feedback caused by UL asymmetry using MATLAB long-term-evolution (LTE) and fifth-generation (5G) toolboxes. Our numerical results confirm that UL interference asymmetry substantially degrades the throughput performance due to the loss of HARQ indicator feedback.

Paper number 120:
Title: EAI-Avatar: Emotion-Aware Interactive Talking Head Generation
Authors: Haijie Yang, Zhenyu Zhang, Hao Tang, Jianjun Qian, Jian Yang
Abstract: Generative models have advanced rapidly, enabling impressive talking head generation that brings AI to life. However, most existing methods focus solely on one-way portrait animation. Even the few that support bidirectional conversational interactions lack precise emotion-adaptive capabilities, significantly limiting their practical applicability. In this paper, we propose EAI-Avatar, a novel emotion-aware talking head generation framework for dyadic interactions. Leveraging the dialogue generation capability of large language models (LLMs, e.g., GPT-4), our method produces temporally consistent virtual avatars with rich emotional variations that seamlessly transition between speaking and listening states. Specifically, we design a Transformer-based head mask generator that learns temporally consistent motion features in a latent mask space, capable of generating arbitrary-length, temporally consistent mask sequences to constrain head motions. Furthermore, we introduce an interactive talking tree structure to represent dialogue state transitions, where each tree node contains information such as child/parent/sibling nodes and the current character's emotional state. By performing reverse-level traversal, we extract rich historical emotional cues from the current node to guide expression synthesis. Extensive experiments demonstrate the superior performance and effectiveness of our method.

Paper number 121:
Title: Data-fused Model Predictive Control with Guarantees: Application to Flying Humanoid Robots
Authors: Davide Gorbani, Mohamed Elobaid, Giuseppe L'Erario, Hosameldin Awadalla Omer Mohamed, Daniele Pucci
Abstract: This paper introduces a Data-Fused Model Predictive Control (DFMPC) framework that combines physics-based models with data-driven representations of unknown dynamics. Leveraging Willems' Fundamental Lemma and an artificial equilibrium formulation, the method enables tracking of changing, potentially unreachable setpoints while explicitly handling measurement noise through slack variables and regularization. We provide guarantees of recursive feasibility and practical stability under input-output constraints for a specific class of reference signals. The approach is validated on the iRonCub flying humanoid robot, integrating analytical momentum models with data-driven turbine dynamics. Simulations show improved tracking and robustness compared to a purely model-based MPC, while maintaining real-time feasibility.

Paper number 122:
Title: Meta Fluid Antenna: Architecture Design, Performance Analysis, Experimental Examination
Authors: Baiyang Liu, Jiewei Huang, Tuo Wu, Huan Meng, Fengcheng Mei, Lei Ning, Kai-Kit Wong, Hang Wong, Kin-Fai Tong, Kwai-Man Luk
Abstract: Fluid antenna systems (FAS) have recently emerged as a promising solution for sixth-generation (6G) ultra-dense connectivity. These systems utilize dynamic radiating and/or shaping techniques to mitigate interference and improve spectral efficiency without relying on channel state information (CSI). The reported improvements achieved by employing a single dynamically activated radiating position in fluid antenna multiple access (FAMA) are significant. To fully realize the potential of FAMA in multi-user multiplexing, we propose leveraging the unique fast-switching capabilities of a single radio-frequency (RF)-chain meta-fluid antenna structure to achieve multi-activation. This allows for a significantly larger set of independent radiating states without requiring additional signal processing. Simulations demonstrate that multi-activation FAMA enables robust multi-user multiplexing with a higher signal-to-interference ratio (SIR) under various Rayleigh-fading environments compared to other single RF-chain technologies. We further show that the SIR can be optimized within a 15~$\mu s$ timeframe under a multi-user Rayleigh-fading channel, making the proposed scheme highly suitable for fast-changing wireless environments. Verified through the theoretical Jakes' model, full three-dimensional (3D) electromagnetic (EM) simulations and experimental validation, multi-activation FAMA enables effective CSI-free, multi-user communication, offering a scalable solution for high-capacity wireless networks.

Paper number 123:
Title: Robust Audio-Visual Target Speaker Extraction with Emotion-Aware Multiple Enrollment Fusion
Authors: Zhan Jin, Bang Zeng, Peijun Yang, Jiarong Du, Juan Liu, Ming Li
Abstract: Target Speaker Extraction (TSE) is a critical challenge in cocktail party scenarios. While leveraging multiple modalities, such as voice, lip, face, and expression embeddings, can enhance performance, real-world applications often suffer from intermittent modality dropout. This paper presents a comprehensive study on the interactions and robustness of various multimodal fusion strategies under varying degrees of modality dropout. We build upon a state-of-the-art audio-visual speech enhancement system and integrate four distinct speaker identity cues: lip embeddings for synchronized contextual information, a voice speaker embedding extracted via cross-attention for acoustic consistency, a static face embedding for speaker identity, and a novel dynamic expression embedding for frame-wise emotional features. We systematically evaluate different combinations of these modalities under two key training regimes: zero dropout and 80% modality dropout. Extensive experiments demonstrate that while a full multimodal ensemble achieves optimal performance under ideal (zero dropout) conditions, its effectiveness diminishes significantly when test-time dropout occurs without prior exposure during training. Crucially, we show that training with a high (80%) modality dropout rate dramatically enhances model robustness, enabling the system to maintain superior performance even under severe test-time missing modalities. Our findings highlight that voice embeddings exhibit consistent robustness, while the proposed expression embedding provides valuable complementary information. This work underscores the importance of training strategies that account for real-world imperfection, moving beyond pure performance maximization to achieve practical reliability in multimodal speech enhancement systems.

Paper number 124:
Title: MAPPO for Edge Server Monitoring
Authors: Samuel Chamoun, Christian McDowell, Robin Buchanan, Kevin Chan, Eric Graves, Yin Sun
Abstract: In this paper, we consider a goal-oriented communication problem for edge server monitoring, where jobs arrive intermittently at multiple dispatchers and must be assigned to shared edge servers with finite queues and time-varying availability. Accurate knowledge of server status is critical for sustaining high throughput, yet remains challenging under dynamic workloads and partial observability. To address this challenge, each dispatcher maintains server knowledge through two complementary mechanisms: (i) active status queries that provide instantaneous updates at a communication cost, and (ii) job execution feedback that reveals server conditions opportunistically. We formulate a cooperative multi-agent distributed decision-making problem in which dispatchers jointly optimize query scheduling to balance throughput against communication overhead. To solve this problem, we propose a Multi-Agent Proximal Policy Optimization (MAPPO)-based algorithm that leverages centralized training with decentralized execution (CTDE) to learn distributed query-and-dispatch policies under partial and stale observations. Numerical evaluations show that MAPPO achieves superior throughput-cost tradeoffs and significantly outperforms baseline strategies, achieving on average a 30% improvement over the closest baseline.

Paper number 125:
Title: On-device Internet of Sounds Sonification with Wavetable Synthesis Techniques for Soil Moisture Monitoring in Water Scarcity Contexts
Authors: Stephen Roddy
Abstract: Sonification, the mapping of data to sound to communicate information about the original data source, is becoming a viable strategy for the sonic representation and communication of information derived from the complex flows of data exchanged across Internet of Sounds (IoS) networks. This paper presents an IoS sonification implementation for monitoring soil moisture levels within the broader context of the globally increasing water scarcity. While previous work has focused on sonifications operating on the applications and services level of the IoS network infrastructure, this paper explores device-level sonification using wavetable synthesis techniques to map sensor data to acoustic parameters. An approach to on-device wavetable sonification is formalized, and a prototype implementation is presented and explored before the approach is contextualised with regard to the soil moisture monitoring tasks.

Paper number 126:
Title: An on-chip Pixel Processing Approach with 2.4μs latency for Asynchronous Read-out of SPAD-based dToF Flash LiDARs
Authors: Yiyang Liu, Rongxuan Zhang, Istvan Gyongy, Alistair Gorman, Sarrah M. Patanwala, Filip Taneski, Robert K. Henderson
Abstract: We propose a fully asynchronous peak detection approach for SPAD-based direct time-of-flight (dToF) flash LiDAR, enabling pixel-wise event-driven depth acquisition without global synchronization. By allowing pixels to independently report depth once a sufficient signal-to-noise ratio is achieved, the method reduces latency, mitigates motion blur, and increases effective frame rate compared to frame-based systems. The framework is validated under two hardware implementations: an offline 256$\times$128 SPAD array with PC based processing and a real-time FPGA proof-of-concept prototype with 2.4$\upmu$s latency for on-chip integration. Experiments demonstrate robust depth estimation, reflectivity reconstruction, and dynamic event-based representation under both static and dynamic conditions. The results confirm that asynchronous operation reduces redundant background data and computational load, while remaining tunable via simple hyperparameters. These findings establish a foundation for compact, low-latency, event-driven LiDAR architectures suited to robotics, autonomous driving, and consumer applications. In addition, we have derived a semi-closed-form solution for the detection probability of the raw-peak finding based LiDAR systems that could benefit both conventional frame-based and proposed asynchronous LiDAR systems.

Paper number 127:
Title: MOIS-SAM2: Exemplar-based Segment Anything Model 2 for multilesion interactive segmentation of neurofibromas in whole-body MRI
Authors: Georgii Kolokolnikov, Marie-Lena Schmalhofer, Sophie Goetz, Lennart Well, Said Farschtschi, Victor-Felix Mautner, Inka Ristow, Rene Werner
Abstract: Background and Objectives: Neurofibromatosis type 1 is a genetic disorder characterized by the development of numerous neurofibromas (NFs) throughout the body. Whole-body MRI (WB-MRI) is the clinical standard for detection and longitudinal surveillance of NF tumor growth. Existing interactive segmentation methods fail to combine high lesion-wise precision with scalability to hundreds of lesions. This study proposes a novel interactive segmentation model tailored to this challenge. Methods: We introduce MOIS-SAM2, a multi-object interactive segmentation model that extends the state-of-the-art, transformer-based, promptable Segment Anything Model 2 (SAM2) with exemplar-based semantic propagation. MOIS-SAM2 was trained and evaluated on 119 WB-MRI scans from 84 NF1 patients acquired using T2-weighted fat-suppressed sequences. The dataset was split at the patient level into a training set and four test sets (one in-domain and three reflecting different domain shift scenarios, e.g., MRI field strength variation, low tumor burden, differences in clinical site and scanner vendor). Results: On the in-domain test set, MOIS-SAM2 achieved a scan-wise DSC of 0.60 against expert manual annotations, outperforming baseline 3D nnU-Net (DSC: 0.54) and SAM2 (DSC: 0.35). Performance of the proposed model was maintained under MRI field strength shift (DSC: 0.53) and scanner vendor variation (DSC: 0.50), and improved in low tumor burden cases (DSC: 0.61). Lesion detection F1 scores ranged from 0.62 to 0.78 across test sets. Preliminary inter-reader variability analysis showed model-to-expert agreement (DSC: 0.62-0.68), comparable to inter-expert agreement (DSC: 0.57-0.69). Conclusions: The proposed MOIS-SAM2 enables efficient and scalable interactive segmentation of NFs in WB-MRI with minimal user input and strong generalization, supporting integration into clinical workflows.

Paper number 128:
Title: Explicit Steady-State Approximations for Parallel Server Systems with Heterogeneous Servers
Authors: Yaosheng Xu
Abstract: We study the steady-state performance of parallel-server systems under an immediate routing architecture with two sources of heterogeneity: servers and job classes, subject to compatibility constraints. We focus on the weighted-workload-task-allocation (WWTA) policy, a load-balancing scheme known to be throughput-optimal for such systems. Under a relaxed complete-resource-pooling (CRP) condition, we prove a "strong form" of state-space collapse in heavy traffic and that the scaled workload of each server converges in distribution to an exponential random variable, whose parameter is explicitly given by system primitives. Our analysis yields three main insights. First, the conventional heavy-traffic requirement of a unique static allocation plan can be dropped; a relaxed CRP condition suffices. Second, the limiting workload distribution is shown to be independent of local scheduling policy on server side, allowing substantial flexibility. Third, the inefficient (non-basic) activities prescribed by static allocation plan is proved to receive an asymptotically negligible fraction of routing and service, even though WWTA has no prior knowledge of which activities are basic, highlighting its robustness to changing arrival rates.

Paper number 129:
Title: Unifying Symbolic Music Arrangement: Track-Aware Reconstruction and Structured Tokenization
Authors: Longshen Ou, Jingwei Zhao, Ziyu Wang, Gus Xia, Qihao Liang, Torin Hopkins Ye Wang
Abstract: We present a unified framework for automatic multitrack music arrangement that enables a single pre-trained symbolic music model to handle diverse arrangement scenarios, including reinterpretation, simplification, and additive generation. At its core is a segment-level reconstruction objective operating on token-level disentangled content and style, allowing for flexible any-to-any instrumentation transformations at inference time. To support track-wise modeling, we introduce REMI-z, a structured tokenization scheme for multitrack symbolic music that enhances modeling efficiency and effectiveness for both arrangement tasks and unconditional generation. Our method outperforms task-specific state-of-the-art models on representative tasks in different arrangement scenarios -- band arrangement, piano reduction, and drum arrangement, in both objective metrics and perceptual evaluations. Taken together, our framework demonstrates strong generality and suggests broader applicability in symbolic music-to-music transformation.

Paper number 130:
Title: Survey of Deep Learning and Physics-Based Approaches in Computational Wave Imaging
Authors: Youzuo Lin, Shihang Feng, James Theiler, Yinpeng Chen, Umberto Villa, Jing Rao, John Greenhall, Cristian Pantea, Mark A. Anastasio, Brendt Wohlberg
Abstract: Computational wave imaging (CWI) extracts hidden structure and physical properties of a volume of material by analyzing wave signals that traverse that volume. Applications include seismic exploration of the Earth's subsurface, acoustic imaging and non-destructive testing in material science, and ultrasound computed tomography in medicine. Current approaches for solving CWI problems can be divided into two categories: those rooted in traditional physics, and those based on deep learning. Physics-based methods stand out for their ability to provide high-resolution and quantitatively accurate estimates of acoustic properties within the medium. However, they can be computationally intensive and are susceptible to ill-posedness and nonconvexity typical of CWI problems. Machine learning-based computational methods have recently emerged, offering a different perspective to address these challenges. Diverse scientific communities have independently pursued the integration of deep learning in CWI. This review discusses how contemporary scientific machine-learning (ML) techniques, and deep neural networks in particular, have been developed to enhance and integrate with traditional physics-based methods for solving CWI problems. We present a structured framework that consolidates existing research spanning multiple domains, including computational imaging, wave physics, and data science. This study concludes with important lessons learned from existing ML-based methods and identifies technical hurdles and emerging trends through a systematic analysis of the extensive literature on this topic.

Paper number 131:
Title: Stylus: Repurposing Stable Diffusion for Training-Free Music Style Transfer on Mel-Spectrograms
Authors: Heehwan Wang, Joonwoo Kwon, Sooyoung Kim, Jungwoo Seo, Shinjae Yoo, Yuewei Lin, Jiook Cha
Abstract: Music style transfer enables personalized music creation by blending the structure of a source with the stylistic attributes of a reference. Existing text-conditioned and diffusion-based approaches show promise but often require paired datasets, extensive training, or detailed annotations. We present Stylus, a training-free framework that repurposes a pre-trained Stable Diffusion model for music style transfer in the mel-spectrogram domain. Stylus manipulates self-attention by injecting style key-value features while preserving source queries to maintain musical structure. To improve fidelity, we introduce a phase-preserving reconstruction strategy that avoids artifacts from Griffin-Lim reconstruction, and we adopt classifier-free-guidance-inspired control for adjustable stylization and multi-style blending. In extensive evaluations, Stylus outperforms state-of-the-art baselines, achieving 34.1% higher content preservation and 25.7% better perceptual quality without any additional training.

Paper number 132:
Title: RG-Attn: Radian Glue Attention for Multi-modality Multi-agent Cooperative Perception
Authors: Lantao Li, Kang Yang, Wenqi Zhang, Xiaoxue Wang, Chen Sun
Abstract: Cooperative perception enhances autonomous driving by leveraging Vehicle-to-Everything (V2X) communication for multi-agent sensor fusion. However, most existing methods rely on single-modal data sharing, limiting fusion performance, particularly in heterogeneous sensor settings involving both LiDAR and cameras across vehicles and roadside units (RSUs). To address this, we propose Radian Glue Attention (RG-Attn), a lightweight and generalizable cross-modal fusion module that unifies intra-agent and inter-agent fusion via transformation-based coordinate alignment and a unified sampling/inversion strategy. RG-Attn efficiently aligns features through a radian-based attention constraint, operating column-wise on geometrically consistent regions to reduce overhead and preserve spatial coherence, thereby enabling accurate and robust fusion. Building upon RG-Attn, we propose three cooperative architectures. The first, Paint-To-Puzzle (PTP), prioritizes communication efficiency but assumes all agents have LiDAR, optionally paired with cameras. The second, Co-Sketching-Co-Coloring (CoS-CoCo), offers maximal flexibility, supporting any sensor setup (e.g., LiDAR-only, camera-only, or both) and enabling strong cross-modal generalization for real-world deployment. The third, Pyramid-RG-Attn Fusion (PRGAF), aims for peak detection accuracy with the highest computational overhead. Extensive evaluations on simulated and real-world datasets show our framework delivers state-of-the-art detection accuracy with high flexibility and efficiency. GitHub Link: this https URL

Paper number 133:
Title: Benefits of Mutual Coupling in Dynamic Metasurface Antennas
Authors: Hugo Prod'homme, Jean Tapie, Luc Le Magoarou, Philipp del Hougne
Abstract: Dynamic metasurface antennas (DMAs) are a promising embodiment of next-generation reconfigurable antenna technology to realize base stations and access points with reduced cost and power consumption. A DMA is a thin structure patterned on its front with reconfigurable radiating metamaterial elements (meta-atoms) that are excited by waveguides or cavities. Mutual coupling between the meta-atoms can result in a strongly non-linear dependence of the DMA's radiation pattern on the configuration of its meta-atoms. However, besides the obvious algorithmic challenges of working with physics-compliant DMA models, it remains unclear how mutual coupling in DMAs influences the ability to achieve a desired wireless functionality. In this paper, we provide theoretical, numerical and experimental evidence that strong mutual coupling in DMAs increases the radiation pattern sensitivity to the DMA configuration and thereby boosts the available control over the radiation pattern, improving the ability to tailor the radiation pattern to the requirements of a desired wireless functionality. Counterintuitively, we hence encourage next-generation DMA implementations to enhance (rather than suppress) mutual coupling, in combination with suitable physics-compliant modeling and optimization. We expect the unveiled mechanism by which mutual coupling boosts the radiation pattern control to also apply to other reconfigurable antenna systems based on tunable lumped elements.

Paper number 134:
Title: GaussianSeal: Rooting Adaptive Watermarks for 3D Gaussian Generation Model
Authors: Runyi Li, Xuanyu Zhang, Chuhan Tong, Zhipei Xu, Jian Zhang
Abstract: With the advancement of AIGC technologies, the modalities generated by models have expanded from images and videos to 3D objects, leading to an increasing number of works focused on 3D Gaussian Splatting (3DGS) generative models. Existing research on copyright protection for generative models has primarily concentrated on watermarking in image and text modalities, with little exploration into the copyright protection of 3D object generative models. In this paper, we propose the first bit watermarking framework for 3DGS generative models, named GaussianSeal, to enable the decoding of bits as copyright identifiers from the rendered outputs of generated 3DGS. By incorporating adaptive bit modulation modules into the generative model and embedding them into the network blocks in an adaptive way, we achieve high-precision bit decoding with minimal training overhead while maintaining the fidelity of the model's outputs. Experiments demonstrate that our method outperforms post-processing watermarking approaches for 3DGS objects, achieving superior performance of watermark decoding accuracy and preserving the quality of the generated results.

Paper number 135:
Title: Uncertainty-aware Latent Safety Filters for Avoiding Out-of-Distribution Failures
Authors: Junwon Seo, Kensuke Nakamura, Andrea Bajcsy
Abstract: Recent advances in generative world models have enabled classical safe control methods, such as Hamilton-Jacobi (HJ) reachability, to generalize to complex robotic systems operating directly from high-dimensional sensor observations. However, obtaining comprehensive coverage of all safety-critical scenarios during world model training is extremely challenging. As a result, latent safety filters built on top of these models may miss novel hazards and even fail to prevent known ones, overconfidently misclassifying risky out-of-distribution (OOD) situations as safe. To address this, we introduce an uncertainty-aware latent safety filter that proactively steers robots away from both known and unseen failures. Our key idea is to use the world model's epistemic uncertainty as a proxy for identifying unseen potential hazards. We propose a principled method to detect OOD world model predictions by calibrating an uncertainty threshold via conformal prediction. By performing reachability analysis in an augmented state space-spanning both the latent representation and the epistemic uncertainty-we synthesize a latent safety filter that can reliably safeguard arbitrary policies from both known and unseen safety hazards. In simulation and hardware experiments on vision-based control tasks with a Franka manipulator, we show that our uncertainty-aware safety filter preemptively detects potential unsafe scenarios and reliably proposes safe, in-distribution actions. Video results can be found on the project website at this https URL

Paper number 136:
Title: Multi-Modal Artificial Intelligence of Embryo Grading and Pregnancy Prediction in Assisted Reproductive Technology: A Review
Authors: Xueqiang Ouyang, Jia Wei
Abstract: Infertility, a pressing global health concern, affects a substantial proportion of individuals worldwide. While advancements in assisted reproductive technology (ART) have offered effective interventions, conventional in vitro fertilization-embryo transfer (IVF-ET) procedures still encounter significant hurdles in enhancing pregnancy success rates. Key challenges include the inherent subjectivity in embryo grading and the inefficiency of multi-modal data integration. Against this backdrop, the adoption of AI-driven technologies has emerged as a pivotal strategy to address these issues. This article presents a comprehensive review of the progress in AI applications for embryo grading and pregnancy prediction from a novel perspective, with a specific focus on the utilization of different modal data, such as static images, time-lapse videos, and structured tabular data. The reason for this perspective is that reorganizing tasks based on data sources can not only more accurately depict the essence of the problem but also help clarify the rationality and limitations of model design. Furthermore, this review critically examines the core challenges in contemporary research, encompassing the intricacies of multi-modal feature fusion, constraints imposed by data scarcity, limitations in model generalization capabilities, and the dynamically evolving legal and regulatory frameworks. On this basis, it explicitly identifies potential avenues for future research, aiming to provide actionable guidance for advancing the application of multi-modal AI in the field of ART.

Paper number 137:
Title: Latent Wavelet Diffusion For Ultra-High-Resolution Image Synthesis
Authors: Luigi Sigillo, Shengfeng He, Danilo Comminiello
Abstract: High-resolution image synthesis remains a core challenge in generative modeling, particularly in balancing computational efficiency with the preservation of fine-grained visual detail. We present Latent Wavelet Diffusion (LWD), a lightweight training framework that significantly improves detail and texture fidelity in ultra-high-resolution (2K-4K) image synthesis. LWD introduces a novel, frequency-aware masking strategy derived from wavelet energy maps, which dynamically focuses the training process on detail-rich regions of the latent space. This is complemented by a scale-consistent VAE objective to ensure high spectral fidelity. The primary advantage of our approach is its efficiency: LWD requires no architectural modifications and adds zero additional cost during inference, making it a practical solution for scaling existing models. Across multiple strong baselines, LWD consistently improves perceptual quality and FID scores, demonstrating the power of signal-driven supervision as a principled and efficient path toward high-resolution generative modeling.

Paper number 138:
Title: Energy Management for Renewable-Colocated Artificial Intelligence Data Centers
Authors: Siying Li, Lang Tong, Timothy D. Mount
Abstract: We develop an energy management system (EMS) for artificial intelligence (AI) data centers with colocated renewable generation. Under a cost-minimizing framework, the EMS of renewable-colocated data center (RCDC) co-optimizes AI workload scheduling, on-site renewable utilization, and electricity market participation. Within both wholesale and retail market participation models, the economic benefit of the RCDC operation is maximized. Empirical evaluations using real-world traces of electricity prices, data center power consumption, and renewable generation demonstrate significant electricity cost reduction from renewable and AI data center colocations.

Paper number 139:
Title: Embedding Alignment in Code Generation for Audio
Authors: Sam Kouteili, Hiren Madhu, George Typaldos, Mark Santolucito
Abstract: LLM-powered code generation has the potential to revolutionize creative coding endeavors, such as live-coding, by enabling users to focus on structural motifs over syntactic details. In such domains, when prompting an LLM, users may benefit from considering multiple varied code candidates to better realize their musical intentions. Code generation models, however, struggle to present unique and diverse code candidates, with no direct insight into the code's audio output. To better establish a relationship between code candidates and produced audio, we investigate the topology of the mapping between code and audio embedding spaces. We find that code and audio embeddings do not exhibit a simple linear relationship, but supplement this with a constructed predictive model that shows an embedding alignment map could be learned. Supplementing the aim for musically diverse output, we present a model that given code predicts output audio embedding, constructing a code-audio embedding alignment map.
    