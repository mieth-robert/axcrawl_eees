
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: An AI-driven EDA Algorithm-Empowered VCO and LDO Co-Design Method
Authors: Yijia Hao, Maarten Strackx, Miguel Gandara, Sandy Cochran, Bo Liu
Abstract: Traditionally, the output noise and power supply rejection of low-dropout regulators (LDOs) are optimized to minimize power supply fluctuations, reducing their impact on the low-frequency noise of target voltage-controlled oscillators (VCOs). However, this sequential design approach does not fully address the trade-offs between high-frequency and LDO-induced low-frequency phase noise. To overcome this limitation, this paper presents a co-design method for low phase-noise LC-tank VCOs powered by LDOs. It is difficult to carry out the co-design using traditional manual design techniques. Hence, an efficient AI-driven EDA algorithm is used. To validate the proposed method, a 5.6 GHz LC-tank VCO with an integrated LDO is designed using a 65 nm CMOS process. Simulations show that the co-design method improves phase noise by 1.2 dB at a 1 MHz offset and reduces dynamic power consumption by 28.8%, with FoM increased by 2.4 dBc/Hz compared to the conventional sequential design method.

Paper number 2:
Title: On Improving PPG-Based Sleep Staging: A Pilot Study
Authors: Jiawei Wang, Yu Guan, Chen Chen, Ligang Zhou, Laurence T. Yang, Sai Gu
Abstract: Sleep monitoring through accessible wearable technology is crucial to improving well-being in ubiquitous computing. Although photoplethysmography(PPG) sensors are widely adopted in consumer devices, achieving consistently reliable sleep staging using PPG alone remains a non-trivial challenge. In this work, we explore multiple strategies to enhance the performance of PPG-based sleep staging. Specifically, we compare conventional single-stream model with dual-stream cross-attention strategies, based on which complementary information can be learned via PPG and PPG-derived modalities such as augmented PPG or synthetic ECG. To study the effectiveness of the aforementioned approaches in four-stage sleep monitoring task, we conducted experiments on the world's largest sleep staging dataset, i.e., the Multi-Ethnic Study of Atherosclerosis(MESA). We found that substantial performance gain can be achieved by combining PPG and its auxiliary information under the dual-stream cross-attention architecture. Source code of this project can be found at this https URL

Paper number 3:
Title: Federated Learning in Active STARS-Aided Uplink Networks
Authors: Xinwei Yue, Xinning Guo, Xidong Mu, Jingjing Zhao, Peng Yang, Junsheng Mu, Zhiping Lu
Abstract: Active simultaneously transmitting and reflecting surfaces (ASTARS) have attracted growing research interest due to its ability to alleviate multiplicative fading and reshape the electromagnetic environment across the entire space. In this paper, we utilise ASTARS to assist the federated learning (FL) uplink model transfer and further reduce the number of uploaded parameter counts through over-the-air (OTA) computing techniques. The impact of model aggregation errors on ASTARS-aided FL uplink networks is characterized. We derive an upper bound on the aggregation error of the OTA-FL model and quantify the training loss due to communication errors. Then, we define the performance of OTA-FL as a joint optimization problem that encompasses both the assignment of received beams and the phase shifting of ASTARS, aiming to achieve the maximum learning efficiency and high-quality signal transmission. Numerical results demonstrate that: i) The FL accuracy in ASTARS uplink networks are enhanced compared to that in state-of-the-art networks; ii) The ASTARS enabled FL system achieves the better learning accuracy using fewer active units than other baseline, especially when the dataset is more discrete; and iii) FL accuracy improves with higher amplification power, but excessive amplification makes thermal noise the dominant source of error.

Paper number 4:
Title: A Completely Blind Channel Estimation Technique for OFDM Using Constellation Splitting
Authors: Sameera Bharadwaja H., D. K. Mehra
Abstract: The problem of second-order statistics (SOS)-based blind channel estimation in OFDM systems is addressed in this paper. Almost all SOS-based methods proposed so far suffer from a complex-scalar estimation ambiguity, which is resolved by using pilots or reference symbols. We propose an algorithm to resolve this ambiguity in blind manner using frequency-domain linear non-redundant precoding and constellation-splitting among the alternate subcarriers. The performance of the proposed scheme is evaluated via numerical simulations in MATLAB environment. Simulation results show that the proposed approach performs as good as its semi-blind counterpart for M-ary PAM systems.

Paper number 5:
Title: Measuring Dependencies between Biological Signals with Temporal Self-supervision, and its Limitations
Authors: Evangelos Sariyanidi, John D. Herrington, Lisa Yankowitz, Pratik Chaudhari, Theodore D. Satterthwaite, Casey J. Zampella, Robert T. Schultz, Russell T. Shinohara, Birkan Tunc
Abstract: Measuring the statistical dependence between observed signals is a primary tool for scientific discovery. However, biological systems often exhibit complex non-linear interactions that currently cannot be captured without a priori knowledge regarding the nature of dependence. We introduce a self-supervised approach, concurrence, which is inspired by the observation that if two signals are dependent, then one should be able to distinguish between temporally aligned vs. misaligned segments extracted from them. Experiments with fMRI, physiological and behavioral signals show that, to our knowledge, concurrence is the first approach that can expose relationships across such a wide spectrum of signals and extract scientifically relevant differences without ad-hoc parameter tuning or reliance on a priori information, providing a potent tool for scientific discoveries across fields. However, depencencies caused by extraneous factors remain an open problem, thus researchers should validate that exposed relationships truely pertain to the question(s) of interest.

Paper number 6:
Title: Evaluation of Deep Learning Models for LBBB Classification in ECG Signals
Authors: Beatriz Macas Ordóñez, Diego Vinicio Orellana Villavicencio, José Manuel Ferrández, Paula Bonomini
Abstract: This study explores different neural network architectures to evaluate their ability to extract spatial and temporal patterns from electrocardiographic (ECG) signals and classify them into three groups: healthy subjects, Left Bundle Branch Block (LBBB), and Strict Left Bundle Branch Block (sLBBB). Clinical Relevance, Innovative technologies enable the selection of candidates for Cardiac Resynchronization Therapy (CRT) by optimizing the classification of subjects with Left Bundle Branch Block (LBBB).

Paper number 7:
Title: Physics-guided denoiser network for enhanced additive manufacturing data quality
Authors: Pallock Halder, Satyajit Mojumder
Abstract: Modern engineering systems are increasingly equipped with sensors for real-time monitoring and decision-making. However, the data collected by these sensors is often noisy and difficult to interpret, limiting its utility for control and diagnostics. In this work, we propose a physics-informed denoising framework that integrates energy-based model and Fisher score regularization to jointly reduce data noise and enforce physical consistency with a physics-based model. The approach is first validated on benchmark problems, including the simple harmonic oscillator, Burgers' equation, and Laplace's equation, across varying noise levels. We then apply the denoising framework to real thermal emission data from laser powder bed fusion (LPBF) additive manufacturing experiments, using a trained Physics-Informed Neural Network (PINN) surrogate model of the LPBF process to guide denoising. Results show that the proposed method outperforms baseline neural network denoisers, effectively reducing noise under a range of LPBF processing conditions. This physics-guided denoising strategy enables robust, real-time interpretation of low-cost sensor data, facilitating predictive control and improved defect mitigation in additive manufacturing.

Paper number 8:
Title: Precoder Design for User-Centric Network Massive MIMO: A Symplectic Optimization Approach
Authors: Pengxu Lin, An-An Lu, Xiqi Gao
Abstract: In this paper, we utilize symplectic optimization to design a precoder for user-centric network (UCN) massive multiple-input multiple-output (MIMO) systems, where a subset of base stations (BSs) serves each user terminal (UT) instead of using all BSs. In UCN massive MIMO systems, the dimension of the precoders is reduced compared to conventional network massive MIMO. It simplifies the implementation of precoders in practical systems. However, the matrix inversion in traditional linear precoders still requires high computational complexity. To avoid the matrix inversion, we employ the symplectic optimization framework, where optimization problems are solved based on dissipative Hamiltonian dynamical systems. To better fit symplectic optimization, we transform the received model into the real field and reformulate the weighted sum-rate (WSR) maximization problem. The objective function of the optimization problem is viewed as the potential energy of the dynamical system. Due to energy dissipation, the continuous dynamical system always converges to a state with minimal potential energy. By discretizing the continuous system while preserving the symplectic structure, we obtain an iterative method for the precoder design. The complexity analysis of the proposed symplectic method is also provided to show its high computational efficiency. Simulation results demonstrate that the proposed precoder design based on symplectic optimization outperforms the weighted minimum mean-square error (WMMSE) precoder in the UCN massive MIMO system.

Paper number 9:
Title: SleepLiteCNN: Energy-Efficient Sleep Apnea Subtype Classification with 1-Second Resolution Using Single-Lead ECG
Authors: Zahra Mohammadi, Siamak Mohammadi
Abstract: Apnea is a common sleep disorder characterized by breathing interruptions lasting at least ten seconds and occurring more than five times per hour. Accurate, high-temporal-resolution detection of sleep apnea subtypes - Obstructive, Central, and Mixed - is crucial for effective treatment and management. This paper presents an energy-efficient method for classifying these subtypes using a single-lead electrocardiogram (ECG) with high temporal resolution to address the real-time needs of wearable devices. We evaluate a wide range of classical machine learning algorithms and deep learning architectures on 1-second ECG windows, comparing their accuracy, complexity, and energy consumption. Based on this analysis, we introduce SleepLiteCNN, a compact and energy-efficient convolutional neural network specifically designed for wearable platforms. SleepLiteCNN achieves over 95% accuracy and a 92% macro-F1 score, while requiring just 1.8 microjoules per inference after 8-bit quantization. Field Programmable Gate Array (FPGA) synthesis further demonstrates significant reductions in hardware resource usage, confirming its suitability for continuous, real-time monitoring in energy-constrained environments. These results establish SleepLiteCNN as a practical and effective solution for wearable device sleep apnea subtype detection.

Paper number 10:
Title: Veli: Unsupervised Method and Unified Benchmark for Low-Cost Air Quality Sensor Correction
Authors: Yahia Dalbah, Marcel Worring, Yen-Chia Hsu
Abstract: Urban air pollution is a major health crisis causing millions of premature deaths annually, underscoring the urgent need for accurate and scalable monitoring of air quality (AQ). While low-cost sensors (LCS) offer a scalable alternative to expensive reference-grade stations, their readings are affected by drift, calibration errors, and environmental interference. To address these challenges, we introduce Veli (Reference-free Variational Estimation via Latent Inference), an unsupervised Bayesian model that leverages variational inference to correct LCS readings without requiring co-location with reference stations, eliminating a major deployment barrier. Specifically, Veli constructs a disentangled representation of the LCS readings, effectively separating the true pollutant reading from the sensor noise. To build our model and address the lack of standardized benchmarks in AQ monitoring, we also introduce the Air Quality Sensor Data Repository (AQ-SDR). AQ-SDR is the largest AQ sensor benchmark to date, with readings from 23,737 LCS and reference stations across multiple regions. Veli demonstrates strong generalization across both in-distribution and out-of-distribution settings, effectively handling sensor drift and erratic sensor behavior. Code for model and dataset will be made public when this paper is published.

Paper number 11:
Title: MPCA-based Domain Adaptation for Transfer Learning in Ultrasonic Guided Waves
Authors: Lucio Pinello, Francesco Cadini, Luca Lomazzi
Abstract: Ultrasonic Guided Waves (UGWs) represent a promising diagnostic tool for Structural Health Monitoring (SHM) in thin-walled structures, and their integration with machine learning (ML) algorithms is increasingly being adopted to enable real-time monitoring capabilities. However, the large-scale deployment of UGW-based ML methods is constrained by data scarcity and limited generalisation across different materials and sensor configurations. To address these limitations, this work proposes a novel transfer learning (TL) framework based on Multilinear Principal Component Analysis (MPCA). First, a Convolutional Neural Network (CNN) for regression is trained to perform damage localisation for a plated structure. Then, MPCA and fine-tuning are combined to have the CNN work for a different plate. By jointly applying MPCA to the source and target domains, the method extracts shared latent features, enabling effective domain adaptation without requiring prior assumptions about dimensionality. Following MPCA, fine-tuning enables adapting the pre-trained CNN to a new domain without the need for a large training dataset. The proposed MPCA-based TL method was tested against 12 case studies involving different composite materials and sensor arrays. Statistical metrics were used to assess domains alignment both before and after MPCA, and the results demonstrate a substantial reduction in localisation error compared to standard TL techniques. Hence, the proposed approach emerges as a robust, data-efficient, and statistically based TL framework for UGW-based SHM.

Paper number 12:
Title: SpectrumFM: A New Paradigm for Spectrum Cognition
Authors: Chunyu Liu, Hao Zhang, Wei Wu, Fuhui Zhou, Qihui Wu, Derrick Wing Kwan Ng, Chan-Byoung Chae
Abstract: The enhancement of spectrum efficiency and the realization of secure spectrum utilization are critically dependent on spectrum cognition. However, existing spectrum cognition methods often exhibit limited generalization and suboptimal accuracy when deployed across diverse spectrum environments and tasks. To overcome these challenges, we propose a spectrum foundation model, termed SpectrumFM, which provides a new paradigm for spectrum cognition. An innovative spectrum encoder that exploits the convolutional neural networks and the multi-head self attention mechanisms is proposed to effectively capture both fine-grained local signal structures and high-level global dependencies in the spectrum data. To enhance its adaptability, two novel self-supervised learning tasks, namely masked reconstruction and next-slot signal prediction, are developed for pre-training SpectrumFM, enabling the model to learn rich and transferable representations. Furthermore, low-rank adaptation (LoRA) parameter-efficient fine-tuning is exploited to enable SpectrumFM to seamlessly adapt to various downstream spectrum cognition tasks, including spectrum sensing (SS), anomaly detection (AD), and wireless technology classification (WTC). Extensive experiments demonstrate the superiority of SpectrumFM over state-of-the-art methods. Specifically, it improves detection probability in the SS task by 30% at -4 dB signal-to-noise ratio (SNR), boosts the area under the curve (AUC) in the AD task by over 10%, and enhances WTC accuracy by 9.6%.

Paper number 13:
Title: Extracting Range-Doppler Information of Moving Targets from Wi-Fi Channel State Information
Authors: Jessica Sanson, Rahul C. Shah, Maximilian Pinaroc, Valerio Frascolla
Abstract: This paper presents, for the first time, a method to extract both range and Doppler information from commercial Wi-Fi Channel State Information (CSI) using a monostatic (single transceiver) setup. Utilizing the CSI phase in Wi-Fi sensing from a Network Interface Card (NIC) not designed for full-duplex operation is challenging due to (1) Hardware asynchronization, which introduces significant phase errors, and (2) Proximity of transmit (Tx) and receive (Rx) antennas, which creates strong coupling that overwhelms the motion signal of interest. We propose a new signal processing approach that addresses both challenges via three key innovations: Time offset cancellation, Phase alignment correction, and Tx/Rx coupling mitigation. Our method achieves cm-level accuracy in range and Doppler estimation for moving targets, validated using a commercial Intel Wi-Fi AX211 NIC. Our results show successful detection and tracking of moving objects in realistic environments, establishing the feasibility of high-precision sensing using standard Wi-Fi packet communications and off-the-shelf hardware without requiring any modification or specialized full-duplex capabilities.

Paper number 14:
Title: Spatial-Temporal-Spectral Mamba with Sparse Deformable Token Sequence for Enhanced MODIS Time Series Classification
Authors: Zack Dewis, Zhengsen Xu, Yimin Zhu, Motasem Alkayid, Mabel Heffring, Lincoln Linlin Xu
Abstract: Although MODIS time series data are critical for supporting dynamic, large-scale land cover land use classification, it is a challenging task to capture the subtle class signature information due to key MODIS difficulties, e.g., high temporal dimensionality, mixed pixels, and spatial-temporal-spectral coupling effect. This paper presents a novel spatial-temporal-spectral Mamba (STSMamba) with deformable token sequence for enhanced MODIS time series classification, with the following key contributions. First, to disentangle temporal-spectral feature coupling, a temporal grouped stem (TGS) module is designed for initial feature learning. Second, to improve Mamba modeling efficiency and accuracy, a sparse, deformable Mamba sequencing (SDMS) approach is designed, which can reduce the potential information redundancy in Mamba sequence and improve the adaptability and learnability of the Mamba sequencing. Third, based on SDMS, to improve feature learning, a novel spatial-temporal-spectral Mamba architecture is designed, leading to three modules, i.e., a sparse deformable spatial Mamba module (SDSpaM), a sparse deformable spectral Mamba module (SDSpeM), and a sparse deformable temporal Mamba module (SDTM) to explicitly learn key information sources in MODIS. The proposed approach is tested on MODIS time series data in comparison with many state-of-the-art approaches, and the results demonstrate that the proposed approach can achieve higher classification accuracy with reduced computational complexity.

Paper number 15:
Title: State dimension reduction of recurrent equilibrium networks with contraction and robustness preservation
Authors: M. F. Shakib
Abstract: Recurrent equilibrium networks (RENs) are effective for learning the dynamics of complex dynamical systems with certified contraction and robustness properties through unconstrained learning. While this opens the door to learning large-scale RENs, deploying such large-scale RENs in real-time applications on resource-limited devices remains challenging. Since a REN consists of a feedback interconnection of linear time-invariant (LTI) dynamics and static activation functions, this article proposes a projection-based approach to reduce the state dimension of the LTI component of a trained REN. One of the two projection matrices is dedicated to preserving contraction and robustness by leveraging the already-learned REN contraction certificate. The other projection matrix is iteratively updated to improve the accuracy of the reduced-order REN based on necessary $h_2$-optimality conditions for LTI model reduction. Numerical examples validate the approach, demonstrating significant state dimension reduction with limited accuracy loss while preserving contraction and robustness.

Paper number 16:
Title: Integrating Machine Learning with Multimodal Monitoring System Utilizing Acoustic and Vision Sensing to Evaluate Geometric Variations in Laser Directed Energy Deposition
Authors: Ke Xu, Chaitanya Krishna Prasad Vallabh, Souran Manoochehri
Abstract: Laser directed energy deposition (DED) additive manufacturing struggles with consistent part quality due to complex melt pool dynamics and process variations. While much research targets defect detection, little work has validated process monitoring systems for evaluating melt pool dynamics and process quality. This study presents a novel multimodal monitoring framework, synergistically integrating contact-based acoustic emission (AE) sensing with coaxial camera vision to enable layer-wise identification and evaluation of geometric variations in DED parts. The experimental study used three part configurations: a baseline part without holes, a part with a 3mm diameter through-hole, and one with a 5mm through-hole to test the system's discerning capabilities. Raw sensor data was preprocessed: acoustic signals were filtered for time-domain and frequency-domain feature extraction, while camera data underwent melt pool segmentation and morphological feature extraction. Multiple machine learning algorithms (including SVM, random forest, and XGBoost) were evaluated to find the optimal model for classifying layer-wise geometric variations. The integrated multimodal strategy achieved a superior classification performance of 94.4%, compared to 87.8% for AE only and 86.7% for the camera only. Validation confirmed the integrated system effectively captures both structural vibration signatures and surface morphological changes tied to the geometric variations. While this study focuses on specific geometries, the demonstrated capability to discriminate between features establishes a technical foundation for future applications in characterizing part variations like geometric inaccuracies and manufacturing-induced defects.

Paper number 17:
Title: SecoustiCodec: Cross-Modal Aligned Streaming Single-Codecbook Speech Codec
Authors: Chunyu Qiang, Haoyu Wang, Cheng Gong, Tianrui Wang, Ruibo Fu, Tao Wang, Ruilong Chen, Jiangyan Yi, Zhengqi Wen, Chen Zhang, Longbiao Wang, Jianwu Dang, Jianhua Tao
Abstract: Speech codecs serve as a crucial bridge in unifying speech and text language models. Existing codec methods face several challenges in semantic encoding, such as residual paralinguistic information (e.g., timbre, emotion), insufficient semantic completeness, limited reconstruction capability, and lack of support for streaming. To address these challenges, we propose SecoustiCodec, a cross-modal aligned low-bitrate streaming speech codec that disentangles semantic and paralinguistic information in a single-codebook space. To ensure semantic completeness and reconstruction fidelity, paralinguistic encoding is introduced to bridge the information gap between semantic and acoustic encoding. A semantic-only efficient quantization method based on VAE (Variational Autoencoder) and FSQ (Finite Scalar Quantization) is proposed. This approach alleviates the long-tail distribution problem of tokens while maintaining high codebook utilization. A semantic disentanglement method based on contrastive learning is proposed, which aligns text and speech in a joint multimodal frame-level space, effectively removing paralinguistic information from semantic encoding. An acoustic-constrained multi-stage optimization strategy is proposed to ensure robust and stable convergence. Figure~\ref{fig:pesq_kbps_below_2kbps} shows SecoustiCodec achieves SOTA (state-of-the-art) reconstruction quality (PESQ) of 1.77/2.58 at 0.27/1 kbps. The code and model weights for SecoustiCodec will be open-sourced upon the completion of the peer-review process. We've open-sourced SecoustiCodec's demo, code, and model weights.

Paper number 18:
Title: Secure mmWave Beamforming with Proactive-ISAC Defense Against Beam-Stealing Attacks
Authors: Seyed Bagher Hashemi Natanzi, Hossein Mohammadi, Bo Tang, Vuk Marojevic
Abstract: Millimeter-wave (mmWave) communication systems face increasing susceptibility to advanced beam-stealing attacks, posing a significant physical layer security threat. This paper introduces a novel framework employing an advanced Deep Reinforcement Learning (DRL) agent for proactive and adaptive defense against these sophisticated attacks. A key innovation is leveraging Integrated Sensing and Communications (ISAC) capabilities for active, intelligent threat assessment. The DRL agent, built on a Proximal Policy Optimization (PPO) algorithm, dynamically controls ISAC probing actions to investigate suspicious activities. We introduce an intensive curriculum learning strategy that guarantees the agent experiences successful detection during training to overcome the complex exploration challenges inherent to such a security-critical task. Consequently, the agent learns a robust and adaptive policy that intelligently balances security and communication performance. Numerical results demonstrate that our framework achieves a mean attacker detection rate of 92.8% while maintaining an average user SINR of over 13 dB.

Paper number 19:
Title: Evaluation of 3D Counterfactual Brain MRI Generation
Authors: Pengwei Sun, Wei Peng, Lun Yu Li, Yixin Wang, Kilian M. Pohl
Abstract: Counterfactual generation offers a principled framework for simulating hypothetical changes in medical imaging, with potential applications in understanding disease mechanisms and generating physiologically plausible data. However, generating realistic structural 3D brain MRIs that respect anatomical and causal constraints remains challenging due to data scarcity, structural complexity, and the lack of standardized evaluation protocols. In this work, we convert six generative models into 3D counterfactual approaches by incorporating an anatomy-guided framework based on a causal graph, in which regional brain volumes serve as direct conditioning inputs. Each model is evaluated with respect to composition, reversibility, realism, effectiveness and minimality on T1-weighted brain MRIs (T1w MRIs) from the Alzheimer's Disease Neuroimaging Initiative (ADNI). In addition, we test the generalizability of each model with respect to T1w MRIs of the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA). Our results indicate that anatomically grounded conditioning successfully modifies the targeted anatomical regions; however, it exhibits limitations in preserving non-targeted structures. Beyond laying the groundwork for more interpretable and clinically relevant generative modeling of brain MRIs, this benchmark highlights the need for novel architectures that more accurately capture anatomical interdependencies.

Paper number 20:
Title: Optimizing Preventive and Reactive Defense Resource Allocation with Uncertain Sensor Signals
Authors: Faezeh Shojaeighadikolaei, Shouhuai Xu, Keith Paarporn
Abstract: Cyber attacks continue to be a cause of concern despite advances in cyber defense techniques. Although cyber attacks cannot be fully prevented, standard decision-making frameworks typically focus on how to prevent them from succeeding, without considering the cost of cleaning up the damages incurred by successful attacks. This motivates us to investigate a new resource allocation problem formulated in this paper: The defender must decide how to split its investment between preventive defenses, which aim to harden nodes from attacks, and reactive defenses, which aim to quickly clean up the compromised nodes. This encounters a challenge imposed by the uncertainty associated with the observation, or sensor signal, whether a node is truly compromised or not; this uncertainty is real because attack detectors are not perfect. We investigate how the quality of sensor signals impacts the defender's strategic investment in the two types of defense, and ultimately the level of security that can be achieved. In particular, we show that the optimal investment in preventive resources increases, and thus reactive resource investment decreases, with higher sensor quality. We also show that the defender's performance improvement, relative to a baseline of no sensors employed, is maximal when the attacker can only achieve low attack success probabilities.

Paper number 21:
Title: REFLECT: Rectified Flows for Efficient Brain Anomaly Correction Transport
Authors: Farzad Beizaee, Sina Hajimiri, Ismail Ben Ayed, Gregory Lodygensky, Christian Desrosiers, Jose Dolz
Abstract: Unsupervised anomaly detection (UAD) in brain imaging is crucial for identifying pathologies without the need for labeled data. However, accurately localizing anomalies remains challenging due to the intricate structure of brain anatomy and the scarcity of abnormal examples. In this work, we introduce REFLECT, a novel framework that leverages rectified flows to establish a direct, linear trajectory for correcting abnormal MR images toward a normal distribution. By learning a straight, one-step correction transport map, our method efficiently corrects brain anomalies and can precisely localize anomalies by detecting discrepancies between anomalous input and corrected counterpart. In contrast to the diffusion-based UAD models, which require iterative stochastic sampling, rectified flows provide a direct transport map, enabling single-step inference. Extensive experiments on popular UAD brain segmentation benchmarks demonstrate that REFLECT significantly outperforms state-of-the-art unsupervised anomaly detection methods. The code is available at this https URL.

Paper number 22:
Title: Modeling and Simulation of an Active Quarter Car Suspension with a Robust LQR Controller under Road Disturbance and Parameter Uncertainty
Authors: Mehmet Karahan
Abstract: Vehicle suspension is important for passengers to travel comfortably and to be less exposed to effects such as vibration and shock. A good suspension system in-creases the road holding of vehicles, allows them to take turns safely and reduces the risk of traffic accidents. Passive suspension system is the most widely used suspension system in vehicles due to its simple structure and low cost. Passive suspension systems do not have an actuator and therefore do not have a controller. Active suspension systems have an actuator and a controller. Although their structures are more complex and costly, they are safer. PID controller is widely used in active suspension systems due to its simple structure, reasonable cost and easy adjustment of coefficients. In this study, a more robust LQR controlled active suspension was designed than passive sus-pension and PID controlled active suspension. Robustness analyses were performed for passive suspension, PID controlled active suspension and LQR controlled active sus-pension. Suspension travel, sprung mass acceleration and sprung mass motion simulations were performed for all 3 suspensions under road disturbance and under simultaneous road disturbance and parameter uncertainty. A comparative analysis was performed by obtaining the suspension rise time, overshoot and settling time data. It was observed that the LQR controlled active suspension showed the least overshoot and had the shortest settling time. In this case, it was proven that the LQR controlled active suspension provided a more comfortable and safe ride compared to the other two suspension systems.

Paper number 23:
Title: Zak-OTFS for Faster-Than-Nyquist Signaling in the Presence of Mobility & Delay Spread
Authors: Sandesh Rao Mattu, Nishant Mehrotra, Robert Calderbank
Abstract: Orthogonal signaling limits the number of information symbols transmitted in bandwidth $B$ and time $T$ to be $BT$. This corresponds to the Nyquist signaling and is achieved by mounting information symbols on $BT$-dimensional basis spanning the $BT$-dimensional space spaced $\frac{1}{B}$ and $\frac{1}{T}$ apart. Faster-than-Nyquist signaling involves transmitting more than $BT$ informational symbols in a $BT$-dimensional space. This leads to loss of orthogonality. This is achieved by time and/or bandwidth expansion resulting from packing more information symbols in the same $BT$-dimensional space (spacing less than $\frac{1}{B}$ and/or $\frac{1}{T}$). In this paper, we take a different approach to faster-than-Nyquist signaling. We propose to superimpose the information symbols on one another maintaining the original spacing in the Nyquist signaling. We carry this out in the delay-Doppler (DD) domain using Zak-transform based orthogonal time frequency space (Zak-OTFS) modulation. In Zak-OTFS, the channel varies slowly. Further Zak-OTFS also allows construction of mutually unbiased bases the interference between which appear like Gaussian noise. The proposed scheme leverages the slow variation in the DD channel to construct a precoder that mitigates the effect of the doubly-spread channel. Further, in the proposed scheme we mount information symbols on two mutually unbiased bases which allows superposition of information symbols. This simplifies receiver processing to detection in Gaussian noise since each basis appears to the other as Gaussian noise. This reduction makes it possible to use trellis coded modulation to enhance bit-error performance. Numerical results demonstrate that the faster-than-Nyquist signaling scheme achieves similar uncoded performance as that of Nyquist signaling and with coding the performance is better than Nyquist signaling at high signal-to-noise ratios.

Paper number 24:
Title: AMD-Mamba: A Phenotype-Aware Multi-Modal Framework for Robust AMD Prognosis
Authors: Puzhen Wu, Mingquan Lin, Qingyu Chen, Emily Y. Chew, Zhiyong Lu, Yifan Peng, Hexin Dong
Abstract: Age-related macular degeneration (AMD) is a leading cause of irreversible vision loss, making effective prognosis crucial for timely intervention. In this work, we propose AMD-Mamba, a novel multi-modal framework for AMD prognosis, and further develop a new AMD biomarker. This framework integrates color fundus images with genetic variants and socio-demographic variables. At its core, AMD-Mamba introduces an innovative metric learning strategy that leverages AMD severity scale score as prior knowledge. This strategy allows the model to learn richer feature representations by aligning learned features with clinical phenotypes, thereby improving the capability of conventional prognosis methods in capturing disease progression patterns. In addition, unlike existing models that use traditional CNN backbones and focus primarily on local information, such as the presence of drusen, AMD-Mamba applies Vision Mamba and simultaneously fuses local and long-range global information, such as vascular changes. Furthermore, we enhance prediction performance through multi-scale fusion, combining image information with clinical variables at different resolutions. We evaluate AMD-Mamba on the AREDS dataset, which includes 45,818 color fundus photographs, 52 genetic variants, and 3 socio-demographic variables from 2,741 subjects. Our experimental results demonstrate that our proposed biomarker is one of the most significant biomarkers for the progression of AMD. Notably, combining this biomarker with other existing variables yields promising improvements in detecting high-risk AMD patients at early stages. These findings highlight the potential of our multi-modal framework to facilitate more precise and proactive management of AMD.

Paper number 25:
Title: Real-time speech enhancement in noise for throat microphone using neural audio codec as foundation model
Authors: Julien Hauret, Thomas Joubaud, Éric Bavu
Abstract: We present a real-time speech enhancement demo using speech captured with a throat microphone. This demo aims to showcase the complete pipeline, from recording to deep learning-based post-processing, for speech captured in noisy environments with a body-conducted microphone. The throat microphone records skin vibrations, which naturally attenuate external noise, but this robustness comes at the cost of reduced audio bandwidth. To address this challenge, we fine-tune Kyutai's Mimi--a neural audio codec supporting real-time inference--on Vibravox, a dataset containing paired air-conducted and throat microphone recordings. We compare this enhancement strategy against state-of-the-art models and demonstrate its superior performance. The inference runs in an interactive interface that allows users to toggle enhancement, visualize spectrograms, and monitor processing latency.

Paper number 26:
Title: Integrating Upstream Supply Chains into Generation Expansion Planning
Authors: Boyu Yao, Andrey Bernstein, Yury Dvorkin
Abstract: Rising electricity demand underscores the need for secure and reliable generation expansion planning that accounts for upstream supply chain constraints. Traditional models often overlook limitations in materials, manufacturing capacity, lead times for deployment, and field availability, which can delay availability of planned resources and thus to threaten system reliability. This paper introduces a multi-stage supply chain-constrained generation expansion planning (SC-GEP) model that optimizes long-term investments while capturing material availability, production limits, spatial and temporal constraints, and material reuse from retired assets. A decomposition algorithm efficiently solves the resulting MILP. A Maryland case study shows that supply chain constraints shift technology choices, amplify deployment delays caused by lead times, and prompt earlier investment in shorter lead-time, low-material-intensity options. In the low-demand scenario, supply chain constraints raise investment costs by $1.2 billion. Under high demand, persistent generation and reserve shortfalls emerge, underscoring the need to integrate upstream constraints into long-term planning.

Paper number 27:
Title: ClinicalFMamba: Advancing Clinical Assessment using Mamba-based Multimodal Neuroimaging Fusion
Authors: Meng Zhou, Farzad Khalvati
Abstract: Multimodal medical image fusion integrates complementary information from different imaging modalities to enhance diagnostic accuracy and treatment planning. While deep learning methods have advanced performance, existing approaches face critical limitations: Convolutional Neural Networks (CNNs) excel at local feature extraction but struggle to model global context effectively, while Transformers achieve superior long-range modeling at the cost of quadratic computational complexity, limiting clinical deployment. Recent State Space Models (SSMs) offer a promising alternative, enabling efficient long-range dependency modeling in linear time through selective scan mechanisms. Despite these advances, the extension to 3D volumetric data and the clinical validation of fused images remains underexplored. In this work, we propose ClinicalFMamba, a novel end-to-end CNN-Mamba hybrid architecture that synergistically combines local and global feature modeling for 2D and 3D images. We further design a tri-plane scanning strategy for effectively learning volumetric dependencies in 3D images. Comprehensive evaluations on three datasets demonstrate the superior fusion performance across multiple quantitative metrics while achieving real-time fusion. We further validate the clinical utility of our approach on downstream 2D/3D brain tumor classification tasks, achieving superior performance over baseline methods. Our method establishes a new paradigm for efficient multimodal medical image fusion suitable for real-time clinical deployment.

Paper number 28:
Title: Generating Light-based Fingerprints for Indoor Localization
Authors: Hsun-Yu Lee, Jie Lin, Fang-Jing Wu
Abstract: Accurate indoor localization underpins applications ranging from wayfinding and emergency response to asset tracking and smart-building services. Radio-frequency solutions (e.g. Wi-Fi, RFID, UWB) are widely adopted but remain vulnerable to multipath fading, interference, and uncontrollable coverage variation. We explore an orthogonal modality -- visible light communication (VLC) -- and demonstrate that the spectral signatures captured by a low-cost AS7341 sensor can serve as robust location fingerprints. We introduce a two-stage framework that (i) trains a multi-layer perceptron (MLP) on real spectral measurements and (ii) enlarges the training corpus with synthetic samples produced by TabGAN. The augmented dataset reduces the mean localization error from 62.9cm to 49.3cm -- a 20% improvement -- while requiring only 5% additional data-collection effort. Experimental results obtained on 42 reference points in a U-shaped laboratory confirm that GAN-based augmentation mitigates data-scarcity issues and enhances generalization.

Paper number 29:
Title: Metasurface-Enabled Extremely Large-Scale Antenna Systems: Transceiver Architecture, Physical Modeling, and Channel Estimation
Authors: Zhengyu Wang, Tiebin Mi, Gui Zhou, Robert C. Qiu
Abstract: Extremely large-scale antenna arrays (ELAAs) have emerged as a pivotal technology for addressing the unprecedented performance demands of next-generation wireless communication systems. To enhance their practicality, we propose metasurface-enabled extremely large-scale antenna (MELA) systems -- novel transceiver architectures that employ reconfigurable transmissive metasurfaces to facilitate efficient over-the-air RF-to-antenna coupling and phase control. This architecture eliminates the need for bulky switch matrices and costly phase-shifter networks typically required in conventional solutions. Physically grounded models are developed to characterize electromagnetic field propagation through individual transmissive unit cells, capturing the fundamental physics of wave transformation and transmission. Additionally, distance-dependent approximate models are introduced, exhibiting structural properties conducive to efficient parameter estimation and signal processing. Based on the channel model, a two stage channel estimation framework is proposed for the scenarios comprising users in the hybrid near- and far-fields. In the first stage, a dictionary-driven beamspace filtering technique enables rapid angular-domain scanning. In the refinement stage, the rotational symmetry of subarrays is exploited to design super-resolution estimators that jointly recover angular and range parameters. An analytical expression for the half-power beamwidth of MELA is derived, revealing its near-optimal spatial resolution relative to conventional ELAA architectures. Numerical experiments further validate the high-resolution of the proposed channel estimation algorithm and the fidelity of the electromagnetic model, positioning the MELA architecture as a highly competitive and forward-looking solution for practical ELAA deployment.

Paper number 30:
Title: A Survey of Medical Point Cloud Shape Learning: Registration, Reconstruction and Variation
Authors: Tongxu Zhang, Zhiming Liang, Bei Wang
Abstract: Point clouds have become an increasingly important representation for 3D medical imaging, offering a compact, surface-preserving alternative to traditional voxel or mesh-based approaches. Recent advances in deep learning have enabled rapid progress in extracting, modeling, and analyzing anatomical shapes directly from point cloud data. This paper provides a comprehensive and systematic survey of learning-based shape analysis for medical point clouds, focusing on three fundamental tasks: registration, reconstruction, and variation modeling. We review recent literature from 2021 to 2025, summarize representative methods, datasets, and evaluation metrics, and highlight clinical applications and unique challenges in the medical domain. Key trends include the integration of hybrid representations, large-scale self-supervised models, and generative techniques. We also discuss current limitations, such as data scarcity, inter-patient variability, and the need for interpretable and robust solutions for clinical deployment. Finally, future directions are outlined for advancing point cloud-based shape learning in medical imaging.

Paper number 31:
Title: Fast Algorithm for Moving Sound Source
Authors: Dong Yang
Abstract: Modern neural network-based speech processing systems need reverberation resistance, relying on large amounts of reverberation data for training. Existing methods simulate dynamic scenarios by sampling static systems or supplement with measured data, but struggle to simulate motion data conforming to physical laws. To address insufficient training data for speech enhancement models in moving scenarios, this paper proposes Yang's motion spatio-temporal sampling reconstruction theory, enabling efficient simulation of motion-induced continuous time-varying reverberation. It breaks through the limitations of traditional static Image-Source Method (ISM) in time-varying systems by decomposing the moving image source's impulse response into linear time-invariant modulation and discrete time-varying fractional delay, establishing a physics-compliant moving sound field model. Based on the band-limited nature of motion displacement, a hierarchical sampling strategy is adopted: high sampling rates for low-order images to retain details, and low rates for high-order ones to reduce complexity, combined with a fast synthesis architecture for real-time simulation. Experiments show that compared to open-source model GSound, the theory more accurately restores amplitude and phase changes in moving scenarios, solving the industry challenge of motion sound source data simulation. It provides high-quality dynamic training data for speech enhancement models and improves the robustness of multi-channel end-to-end voice tracking algorithms.

Paper number 32:
Title: Nexus-INR: Diverse Knowledge-guided Arbitrary-Scale Multimodal Medical Image Super-Resolution
Authors: Bo Zhang, JianFei Huo, Zheng Zhang, Wufan Wang, Hui Gao, Xiangyang Gong, Wendong Wang
Abstract: Arbitrary-resolution super-resolution (ARSR) provides crucial flexibility for medical image analysis by adapting to diverse spatial resolutions. However, traditional CNN-based methods are inherently ill-suited for ARSR, as they are typically designed for fixed upsampling factors. While INR-based methods overcome this limitation, they still struggle to effectively process and leverage multi-modal images with varying resolutions and details. In this paper, we propose Nexus-INR, a Diverse Knowledge-guided ARSR framework, which employs varied information and downstream tasks to achieve high-quality, adaptive-resolution medical image super-resolution. Specifically, Nexus-INR contains three key components. A dual-branch encoder with an auxiliary classification task to effectively disentangle shared anatomical structures and modality-specific features; a knowledge distillation module using cross-modal attention that guides low-resolution modality reconstruction with high-resolution reference, enhanced by self-supervised consistency loss; an integrated segmentation module that embeds anatomical semantics to improve both reconstruction quality and downstream segmentation performance. Experiments on the BraTS2020 dataset for both super-resolution and downstream segmentation demonstrate that Nexus-INR outperforms state-of-the-art methods across various metrics.

Paper number 33:
Title: Scenario-Agnostic Deep-Learning-Based Localization with Contrastive Self-Supervised Pre-training
Authors: Lingyan Zhang, Yuanfeng Qiu, Dachuan Li, Shaohua Wu, Tingting Zhang, Qinyu Zhang
Abstract: Wireless localization has become a promising technology for offering intelligent location-based services. Although its localization accuracy is improved under specific scenarios, the short of environmental dynamic vulnerability still hinders this approach from being fully practical applications. In this paper, we propose CSSLoc, a novel framework on contrastive self-supervised pre-training to learn generic representations for accurate localization in various scenarios. Without the location information supervision, CSSLoc attempts to learn an insightful metric on the similarity discrimination of radio data, in such a scenario-agnostic manner that the similar samples are closely clustered together and different samples are separated in the representation space. Furthermore, the trained feature encoder can be directly transferred for downstream localization tasks, and the location predictor is trained to estimate accurate locations with the robustness of environmental dynamics. With extensive experimental results, CSSLoc can outperform classical and state-of-the-art DNN-based localization schemes in typical indoor scenarios, pushing deep-learning-based localization from specificity to generality.

Paper number 34:
Title: Kernel ridge regression based sound field estimation using a rigid spherical microphone array
Authors: Ryo Matsuda, Juliano G. C. Ribeiro, Hitoshi Akiyama, Jorge Trevino
Abstract: We propose a sound field estimation method based on kernel ridge regression using a rigid spherical microphone array. Kernel ridge regression with physically constrained kernel functions, and further with kernel functions adapted to observed sound fields, have proven to be powerful tools. However, such methods generally assume an open-sphere microphone array configuration, i.e., no scatterers exist within the observation or estimation region. Alternatively, some approaches assume the presence of scatterers and attempt to eliminate their influence through a least-squares formulation. Even then, these methods typically do not incorporate the boundary conditions of the scatterers, which are not presumed to be known. In contrast, we exploit the fact the scatterer here is a rigid sphere. Meaning, both the virtual scattering source locations and the boundary conditions are well-defined. Based on this, we formulate the scattered sound field within the kernel ridge regression framework and propose a novel sound field representation incorporating a boundary constraint. The effectiveness of the proposed method is demonstrated through numerical simulations and real-world experiments using a newly developed spherical microphone array.

Paper number 35:
Title: Power System Voltage Stability Boundary: Computational Results and Applications
Authors: Zhenyao Li, Yifan Yao, Deqiang Gan
Abstract: The objective of this paper is to report some computational results for the theory of DAE stability boundary, with the aim of advancing applications in power system voltage stability studies. Firstly, a new regularization transformation for standard differential-algebraic equations (DAEs) is proposed. Then the existence of anchor points on voltage stability boundary is examined, and an optimization method for computing the controlling pseudo-saddle is suggested. Subsequently, a local representation of the stable manifold of the pseudo-saddle on the stability boundary is presented, and a voltage stability margin expression is obtained. Finally, the proposed results are verified using several examples, demonstrating the accuracy and effectiveness of the suggested methods.

Paper number 36:
Title: Can Large Language Models Identify Materials from Radar Signals?
Authors: Jiangyou Zhu, Hongyu Deng, He Chen
Abstract: Accurately identifying the material composition of objects is a critical capability for AI robots powered by large language models (LLMs) to perform context-aware manipulation. Radar technologies offer a promising sensing modality for material recognition task. When combined with deep learning, radar technologies have demonstrated strong potential in identifying the material of various objects. However, existing radar-based solutions are often constrained to closed-set object categories and typically require task-specific data collection to train deep learning models, largely limiting their practical applicability. This raises an important question: Can we leverage the powerful reasoning capabilities of pre-trained LLMs to directly infer material composition from raw radar signals? Answering this question is non-trivial due to the inherent redundancy of radar signals and the fact that pre-trained LLMs have no prior exposure to raw radar data during training. To address this, we introduce LLMaterial, the first study to investigate the feasibility of using LLM to identify materials directly from radar signals. First, we introduce a physics-informed signal processing pipeline that distills high-redundancy radar raw data into a set of compact intermediate parameters that encapsulate the material's intrinsic characteristics. Second, we adopt a retrieval-augmented generation (RAG) strategy to provide the LLM with domain-specific knowledge, enabling it to interpret and reason over the extracted intermediate parameters. Leveraging this integration, the LLM is empowered to perform step-by-step reasoning on the condensed radar features, achieving open-set material recognition directly from raw radar signals. Preliminary results show that LLMaterial can effectively distinguish among a variety of common materials, highlighting its strong potential for real-world material identification applications.

Paper number 37:
Title: Model Order Reduction for Large-scale Circuits Using Higher Order Dynamic Mode Decomposition
Authors: Na Liu, Chengliang Dai, Qiuyue Wu, Qiuqi Li, Guoxiong Cai
Abstract: Model order reduction (MOR) has long been a mainstream strategy to accelerate large-scale transient circuit simulation. Dynamic Mode Decomposition (DMD) represents a novel data-driven characterization method, extracting dominant dynamical modes directly from time-domain simulation data without requiring explicit system equations. This paper first deduces the DMD algorithm and then proposes high order dynamic mode decomposition (HODMD) incorporating delayed embedding technique, specifically targeting computational efficiency in large-scale circuit simulations. Compared with the DMD method, the HODMD method overcomes the problem that the output signal cannot be reconstructed when the spatial resolution is insufficient. The proposed HODMD algorithm is applicable to general circuits and does not impose any constraints on the topology of the pertinent circuit or type of the components. Three representative numerical test cases are presented to systematically validate both the computational efficiency and accuracy of the proposed HODMD method.

Paper number 38:
Title: Filtering and 1/3 Power Law for Optimal Time Discretisation in Numerical Integration of Stochastic Differential Equations
Authors: Igor G. Vladimirov
Abstract: This paper is concerned with the numerical integration of stochastic differential equations (SDEs) which govern diffusion processes driven by a standard Wiener process. With the latter being replaced by a sequence of increments at discrete moments of time, we revisit a filtering point of view on the approximate strong solution of the SDE as an estimate of the hidden system state whose conditional probability distribution is updated using a Bayesian approach and Brownian bridges over the intermediate time intervals. For a class of multivariable linear SDEs, where the numerical solution is organised as a Kalman filter, we investigate the fine-grid asymptotic behaviour of terminal and integral mean-square error functionals when the time discretisation is specified by a sufficiently smooth monotonic transformation of a uniform grid. This leads to constrained optimisation problems over the time discretisation profile, and their solutions reveal a 1/3 power law for the asymptotically optimal grid density functions. As a one-dimensional example, the results are illustrated for the Ornstein-Uhlenbeck process.

Paper number 39:
Title: An Event-based State Estimation Approach for Positive Systems with Positive Observers
Authors: Bhargavi Chaudhary, Krishanu Nath, Subashish Datta, Indra Narayan Kar
Abstract: This article addresses the problem of state observer design for continuous-time linear positive networked systems. Considering the bandwidth constraint in the communication network, an event-measurement-based positive observer design is proposed. The physical interpretation of a positive observer differs from that of a general observer. Its primary goal is to ensure that all state estimates remain non-negative at all times. Using output measurements, a law with weighted sampling error is used to determine the sampling sequence between the system and the observer. The observer dynamics are designed using the standard Luenberger structure with the event-based sampled output information, which is updated only when an event occurs. Assuming observability and sufficient conditions for the positivity of the system, the asymptotic stability of the observer dynamics with sampled information is established. Sufficient conditions of stability and positivity are derived using linear matrix inequalities. Moreover, the design ensures that the event-based architecture is free from Zeno behavior, ensuring a positive minimum bound on the inter-execution time. In addition, numerical simulations on a three-tank system having variable cross-sections are used to demonstrate the efficacy of the proposed event-based positive observer.

Paper number 40:
Title: PatchDSU: Uncertainty Modeling for Out of Distribution Generalization in Keyword Spotting
Authors: Bronya Roni Chernyak, Yael Segal, Yosi Shrem, Joseph Keshet
Abstract: Deep learning models excel at many tasks but rely on the assumption that training and test data follow the same distribution. This assumption often does not hold in real-world speech systems, where distribution shifts are common due to varying environments, recording conditions, and speaker diversity. The method of Domain Shifts with Uncertainty (DSU) augments the input of each neural network layer based on the input feature statistics. It addresses the problem of out-of-domain generalization by assuming feature statistics follow a multivariate Gaussian distribution and substitutes the input with sampled features from this distribution. While effective for computer vision, applying DSU to speech presents challenges due to the nature of the data. Unlike static visual data, speech is a temporal signal commonly represented by a spectrogram - the change of frequency over time. This representation cannot be treated as a simple image, and the resulting sparsity can lead to skewed feature statistics when applied to the entire input. To tackle out-of-distribution issues in keyword spotting, we propose PatchDSU, which extends DSU by splitting the input into patches and independently augmenting each patch. We evaluated PatchDSU and DSU alongside other methods on the Google Speech Commands, Librispeech, and TED-LIUM. Additionally, we evaluated performance under white Gaussian and MUSAN music noise conditions. We also explored out-of-domain generalization by analyzing model performance on datasets they were not trained on. Overall, in most cases, both PatchDSU and DSU outperform other methods. Notably, PatchDSU demonstrates more consistent improvements across the evaluated scenarios compared to other approaches.

Paper number 41:
Title: Federated Learning with Feature Reconstruction for Vector Quantization based Semantic Communication
Authors: Yoon Huh, Bumjun Kim, Wan Choi
Abstract: Recent advancements in semantic communication have primarily focused on image transmission, where neural network (NN)-based joint source-channel coding (JSCC) modules play a central role. However, such systems often experience semantic communication errors due to mismatched knowledge bases between users and performance degradation from outdated models, necessitating regular model updates. To address these challenges in vector quantization (VQ)-based image semantic communication systems, we propose FedSFR, a novel federated learning (FL) framework that incorporates semantic feature reconstruction (FR). FedSFR introduces an FR step at the parameter server (PS) and allows a subset of clients to transmit compact feature vectors in lieu of sending full local model updates, thereby improving training stability and communication efficiency. To enable effective FR learning, we design a loss function tailored for VQ-based image semantic communication and demonstrate its validity as a surrogate for image reconstruction error. Additionally, we provide a rigorous convergence analysis and present a differentially private variant of FedSFR, along with formal privacy analysis. Experimental results on two benchmark datasets validate the superiority of FedSFR over existing baselines, especially in capacity-constrained settings, confirming both its effectiveness and robustness.

Paper number 42:
Title: Investigating the Cognitive Response of Brake Lights in Initiating Braking Action Using EEG
Authors: Ramaswamy Palaniappan, Surej Mouli, Howard Bowman, Ian McLoughlin
Abstract: Half of all road accidents result from either lack of driver attention or from maintaining insufficient separation between vehicles. Collision from the rear, in particular, has been identified as the most common class of accident in the UK, and its influencing factors have been widely studied for many years. Rear-mounted stop lamps, illuminated when braking, are the primary mechanism to alert following drivers to the need to reduce speed or brake. This paper develops a novel brain response approach to measuring subject reaction to different brake light designs. A variety of off-the-shelf brake light assemblies are tested in a physical simulated driving environment to assess the cognitive reaction times of 22 subjects. Eight pairs of LED-based and two pairs of incandescent bulb-based brake light assemblies are used and electroencephalogram (EEG) data recorded. Channel Pz is utilised to extract the P3 component evoked during the decision making process that occurs in the brain when a participant decides to lift their foot from the accelerator and depress the brake. EEG analysis shows that both incandescent bulb-based lights are statistically slower to evoke cognitive responses than all tested LED-based lights. Between the LED designs, differences are evident, but not statistically significant, attributed to the significant amount of movement artifact in the EEG signal.

Paper number 43:
Title: Spiking Neural Networks for Resource Allocation in UAV-Enabled Wireless Networks
Authors: Vasileios Kouvakis, Stylianos E. Trevlakis, Ioannis Arapakis, Alexandros-Apostolos A. Boulogeorgos
Abstract: This work presents a new spiking neural network (SNN)-based approach for user equipment-base station (UE-BS) association in non-terrestrial networks (NTNs). With the introduction of UAV's in wireless networks, the system architecture becomes heterogeneous, resulting in the need for dynamic and efficient management to avoid congestion and sustain overall performance. The presented framework compares two SNN-based optimization strategies. Specifically, a top-down centralized approach with complete network visibility and a bottom-up distributed approach for individual network nodes. The SNN is based on leak integrate-and-fire neurons with temporal components, which can perform fast and efficient event-driven inference. Realistic ray-tracing simulations are conducted, which showcase that the bottom-up model attains over 90\% accuracy, while the top-down model maintains 80-100\% accuracy. Both approaches reveal a trade-off between individually optimal solutions and UE-BS association feasibility, thus revealing the effectiveness of both approaches depending on deployment scenarios.

Paper number 44:
Title: Quantum Deep Learning for Massive MIMO User Scheduling
Authors: Xingyu Huang, Ruining Fan, Mouli Chakraborty, Avishek Nag, Anshu Mukherjee
Abstract: We introduce a hybrid Quantum Neural Networks (QNN) architecture for the efficient user scheduling in 5G/Beyond 5G (B5G) massive Multiple Input Multiple Output (MIMO) systems, addressing the scalability issues of traditional methods. By leveraging statistical Channel State Information (CSI), our model reduces computational overhead and enhances spectral efficiency. It integrates classical neural networks with a variational quantum circuit kernel, outperforming classical Convolutional Neural Networks (CNNs) and maintaining robust performance in noisy channels. This demonstrates the potential of quantum-enhanced Machine Learning (ML) for wireless scheduling.

Paper number 45:
Title: GL-LCM: Global-Local Latent Consistency Models for Fast High-Resolution Bone Suppression in Chest X-Ray Images
Authors: Yifei Sun, Zhanghao Chen, Hao Zheng, Yuqing Lu, Lixin Duan, Fenglei Fan, Ahmed Elazab, Xiang Wan, Changmiao Wang, Ruiquan Ge
Abstract: Chest X-Ray (CXR) imaging for pulmonary diagnosis raises significant challenges, primarily because bone structures can obscure critical details necessary for accurate diagnosis. Recent advances in deep learning, particularly with diffusion models, offer significant promise for effectively minimizing the visibility of bone structures in CXR images, thereby improving clarity and diagnostic accuracy. Nevertheless, existing diffusion-based methods for bone suppression in CXR imaging struggle to balance the complete suppression of bones with preserving local texture details. Additionally, their high computational demand and extended processing time hinder their practical use in clinical settings. To address these limitations, we introduce a Global-Local Latent Consistency Model (GL-LCM) architecture. This model combines lung segmentation, dual-path sampling, and global-local fusion, enabling fast high-resolution bone suppression in CXR images. To tackle potential boundary artifacts and detail blurring in local-path sampling, we further propose Local-Enhanced Guidance, which addresses these issues without additional training. Comprehensive experiments on a self-collected dataset SZCH-X-Rays, and the public dataset JSRT, reveal that our GL-LCM delivers superior bone suppression and remarkable computational efficiency, significantly outperforming several competitive methods. Our code is available at this https URL.

Paper number 46:
Title: Grid-Forming Vector Current Control FRT Modes Under Symmetrical and Asymmetrical Faults
Authors: Ognjen Stanojev, Orcun Karaca, Mario Schweizer
Abstract: Recent research has shown that operating grid-connected converters using the grid-forming vector current control (GFVCC) scheme offers significant benefits, including the simplicity and modularity of the control architecture, as well as enabling a seamless transition from PLL-based grid-following control to grid-forming. An important aspect of any grid-connected converter control strategy is the handling of grid-fault scenarios such as symmetrical and asymmetrical short-circuit faults. This paper presents several fault ride-through (FRT) strategies for GFVCC that enable the converter to provide fault current and stay synchronized to the grid while respecting the converter hardware limitations and retaining grid-forming behavior. The converter control scheme is extended in a modular manner to include negative-sequence loops, and the proposed FRT strategies address both symmetrical and asymmetrical faults. The proposed FRT strategies are analyzed through case studies, including infinite-bus setups and multi-unit grids.

Paper number 47:
Title: Beam-Hopping Pattern Design for Grant-Free Random Access in LEO Satellite Communications
Authors: Seunghyeon Jeon, Seonjung Kim, Gyeongrae Im, Yo-Seb Jeon
Abstract: Increasing demand for massive device connectivity in underserved regions drives the development of advanced low Earth orbit (LEO) satellite communication systems. Beam-hopping LEO systems without connection establishment provide a promising solution for achieving both demand-aware resource allocation and low access latency. This paper investigates beam-hopping pattern design for the grant-free random access systems to dynamically allocate satellite resources according to traffic demands across serving cells. We formulate a binary optimization problem that aims to maximize the minimum successful transmission probability across cells, given limited satellite beam generation capacity. To solve this problem, we propose novel beam-hopping design algorithms that alternately enhance the collision avoidance rate and decoding success probability within an alternating optimization framework. Specifically, the algorithms employ a bisection method to optimize illumination allocation for each cell based on demand, while using the alternating direction method of multipliers (ADMM) to optimize beam-hopping patterns for maximizing decoding success probability. Furthermore, we enhance the ADMM by replacing the strict binary constraint with two equivalent continuous-valued constraints. Simulation results demonstrate the superiority of the proposed algorithms compared to other beam-hopping methods and verify robustness in managing traffic demand imbalance.

Paper number 48:
Title: A Robust Cooperative Vehicle Coordination Framework for Intersection Crossing
Authors: Haojie Bai, Jiping Luo, Huafu Li, Xiongwei Zhao, Yang Wang
Abstract: Cooperative vehicle coordination at unsignalized intersections has garnered significant interest from both academia and industry in recent years, highlighting its notable advantages in improving traffic throughput and fuel efficiency. However, most existing studies oversimplify the coordination system, assuming accurate vehicle state information and ideal state update process. The oversights pose driving risks in the presence of state uncertainty and communication constraint. To address this gap, we propose a robust and comprehensive intersection coordination framework consisting of a robust cooperative trajectory planner and a context-aware status update scheduler. The trajectory planner directly controls the evolution of the trajectory distributions during frequent vehicle interactions, thereby offering probabilistic safety guarantees. To further align with coordination safety in practical bandwidth-limited conditions, we propose a context-aware status update scheduler that dynamically prioritizes the state updating order of vehicles based on their driving urgency. Simulation results validate the robustness and effectiveness of the proposed coordination framework, showing that the collision probability can be significantly reduced while maintaining comparable coordination efficiency to state-of-theart strategies. Moreover, our proposed framework demonstrates superior effectiveness in utilizing wireless resources in practical uncertain and bandwidth-limited conditions.

Paper number 49:
Title: How to Proactively Monitor Untrusted Communications with Cell-Free Massive MIMO?
Authors: Isabella W. G. da Silva, Zahra Mobini, Hien Q. Ngo, Hyundong Shin, Michail Matthaiou
Abstract: This paper studies a cell-free massive multiple-input multiple-output (CF-mMIMO) proactive monitoring system in which multiple multi-antenna monitoring nodes (MNs) are assigned to either observe the transmissions from an untrusted transmitter (UT) or to jam the reception at the untrusted receiver (UR). We propose an effective channel state information (CSI) acquisition scheme for the monitoring system. In our approach, the MNs leverage the pilot signals transmitted during the uplink and downlink phases of the untrusted link and estimate the effective channels corresponding to the UT and UR via a minimum mean-squared error (MMSE) estimation scheme. We derive new spectral efficiency (SE) expressions for the untrusted link and the monitoring system. For the latter, the SE is derived for two CSI availability cases at the central processing unit (CPU); namely case-1: imperfect CSI knowledge at both MNs and CPU, case-2: imperfect CSI knowledge at the MNs and no CSI knowledge at the CPU. To improve the monitoring performance, we propose a novel joint mode assignment and jamming power control optimization method to maximize the monitoring success probability (MSP) based on the Bayesian optimization framework. Numerical results show that (a) our CF-mMIMO proactive monitoring system relying on the proposed CSI acquisition and optimization approach significantly outperforms the considered benchmarks; (b) the MSP performance of our CF-mMIMO proactive monitoring system is greater than 0.8, regardless of the number of antennas at the untrusted nodes or the precoding scheme for the untrusted transmission link.

Paper number 50:
Title: Joint Sensing and Bi-Directional Communication with Dynamic TDD Enabled Cell-Free MIMO
Authors: Anubhab Chowdhury, Sai Subramanyam Thoota, Erik G. Larsson
Abstract: This paper studies integrated sensing and communication (ISAC) with dynamic time division duplex (DTDD) cell-free (CF) massive multiple-input multiple-output~(mMIMO) systems. DTDD enables the CF mMIMO system to concurrently serve both uplink~(UL) and downlink~(DL) users with spatially separated \emph{half-duplex~(HD)} access points~(APs) using the same time-frequency resources. Further, to facilitate ISAC, the UL APs are utilized for both UL data and target echo reception, while the DL APs jointly transmit the precoded DL data streams and target signal. In this context, we present centralized and distributed generalized likelihood-ratio tests~(GLRTs) for target detection treating UL users' signals as sensing interference. We then quantify the optimality and complexity trade-off between distributed and centralized GLRTs and benchmark the respective estimators with the Bayesian Cramér-Rao lower bound for target radar-cross section~(RCS). Then, we present a unified framework for joint UL users' data detection and RCS estimation. Next, for communication, we derive the signal-to-noise-plus-interference~(SINR) optimal combiner accounting for the cross-link and radar interference for UL data processing. In DL, we use regularized zero-forcing for the users and propose two types of precoders for the target: one ``user-centric" that nullifies the interference caused by the target signal to the DL users and one ``target-centric" based on the dominant eigenvector of the composite channel between the target and the APs. Finally, numerical studies corroborate with our theoretical findings and reveal that the \emph{GLRT is robust to inter-AP interference, and DTDD doubles the $90\%$-likely sum UL-DL SE compared to traditional TDD-based CF-mMIMO ISAC systems}; while using HD hardware.

Paper number 51:
Title: Evaluating the Predictive Value of Preoperative MRI for Erectile Dysfunction Following Radical Prostatectomy
Authors: Gideon N. L. Rouwendaal, Daniël Boeke, Inge L. Cox, Henk G. van der Poel, Margriet C. van Dijk-de Haan, Regina G. H. Beets-Tan, Thierry N. Boellaard, Wilson Silva
Abstract: Accurate preoperative prediction of erectile dysfunction (ED) is important for counseling patients undergoing radical prostatectomy. While clinical features are established predictors, the added value of preoperative MRI remains underexplored. We investigate whether MRI provides additional predictive value for ED at 12 months post-surgery, evaluating four modeling strategies: (1) a clinical-only baseline, representing current state-of-the-art; (2) classical models using handcrafted anatomical features derived from MRI; (3) deep learning models trained directly on MRI slices; and (4) multimodal fusion of imaging and clinical inputs. Imaging-based models (maximum AUC 0.569) slightly outperformed handcrafted anatomical approaches (AUC 0.554) but fell short of the clinical baseline (AUC 0.663). Fusion models offered marginal gains (AUC 0.586) but did not exceed clinical-only performance. SHAP analysis confirmed that clinical features contributed most to predictive performance. Saliency maps from the best-performing imaging model suggested a predominant focus on anatomically plausible regions, such as the prostate and neurovascular bundles. While MRI-based models did not improve predictive performance over clinical features, our findings suggest that they try to capture patterns in relevant anatomical structures and may complement clinical predictors in future multimodal approaches.

Paper number 52:
Title: Decoding and Engineering the Phytobiome Communication for Smart Agriculture
Authors: Fatih Gulec, Hamdan Awan, Nigel Wallbridge, Andrew W. Eckford
Abstract: Smart agriculture applications, integrating technologies like the Internet of Things and machine learning/artificial intelligence (ML/AI) into agriculture, hold promise to address modern challenges of rising food demand, environmental pollution, and water scarcity. Alongside the concept of the phytobiome, which defines the area including the plant, its environment, and associated organisms, and the recent emergence of molecular communication (MC), there exists an important opportunity to advance agricultural science and practice using communication theory. In this article, we motivate to use the communication engineering perspective for developing a holistic understanding of the phytobiome communication and bridge the gap between the phytobiome communication and smart agriculture. Firstly, an overview of phytobiome communication via molecular and electrophysiological signals is presented and a multi-scale framework modeling the phytobiome as a communication network is conceptualized. Then, how this framework is used to model electrophysiological signals is demonstrated with plant experiments. Furthermore, possible smart agriculture applications, such as smart irrigation and targeted delivery of agrochemicals, through engineering the phytobiome communication are proposed. These applications merge ML/AI methods with the Internet of Bio-Nano-Things enabled by MC and pave the way towards more efficient, sustainable, and eco-friendly agricultural production. Finally, the implementation challenges, open research issues, and industrial outlook for these applications are discussed.

Paper number 53:
Title: CADD: Context aware disease deviations via restoration of brain images using normative conditional diffusion models
Authors: Ana Lawry Aguila, Ayodeji Ijishakin, Juan Eugenio Iglesias, Tomomi Takenaga, Yukihiro Nomura, Takeharu Yoshikawa, Osamu Abe, Shouhei Hanaoka
Abstract: Applying machine learning to real-world medical data, e.g. from hospital archives, has the potential to revolutionize disease detection in brain images. However, detecting pathology in such heterogeneous cohorts is a difficult challenge. Normative modeling, a form of unsupervised anomaly detection, offers a promising approach to studying such cohorts where the ``normal'' behavior is modeled and can be used at subject level to detect deviations relating to disease pathology. Diffusion models have emerged as powerful tools for anomaly detection due to their ability to capture complex data distributions and generate high-quality images. Their performance relies on image restoration; differences between the original and restored images highlight potential abnormalities. However, unlike normative models, these diffusion model approaches do not incorporate clinical information which provides important context to guide the disease detection process. Furthermore, standard approaches often poorly restore healthy regions, resulting in poor reconstructions and suboptimal detection performance. We present CADD, the first conditional diffusion model for normative modeling in 3D images. To guide the healthy restoration process, we propose a novel inference inpainting strategy which balances anomaly removal with retention of subject-specific features. Evaluated on three challenging datasets, including clinical scans, which may have lower contrast, thicker slices, and motion artifacts, CADD achieves state-of-the-art performance in detecting neurological abnormalities in heterogeneous cohorts.

Paper number 54:
Title: Improving Q-Learning for Real-World Control: A Case Study in Series Hybrid Agricultural Tractors
Authors: Hend Abououf, Sidra Ghayour Bhatti, Qadeer Ahmed
Abstract: The variable and unpredictable load demands in hybrid agricultural tractors make it difficult to design optimal rule-based energy management strategies, motivating the use of adaptive, learning-based control. However, existing approaches often rely on basic fuel-based rewards and do not leverage expert demonstrations to accelerate training. In this paper, first, the performance of Q-value-based reinforcement learning algorithms is evaluated for powertrain control in a hybrid agricultural tractor. Three algorithms, Double Q-Learning (DQL), Deep Q-Networks (DQN), and Double DQN (DDQN), are compared in terms of convergence speed and policy optimality. Second, a piecewise domain-specific reward-shaping strategy is introduced to improve learning efficiency and steer agent behavior toward engine fuel-efficient operating regions. Third, the design of the experience replay buffer is examined, with a focus on the effects of seeding the buffer with expert demonstrations and analyzing how different types of expert policies influence convergence dynamics and final performance. Experimental results demonstrate that (1) DDQN achieves 70\% faster convergence than DQN in this application domain, (2) the proposed reward shaping method effectively biases the learned policy toward fuel-efficient outcomes, and (3) initializing the replay buffer with structured expert data leads to a 33\% improvement in convergence speed.

Paper number 55:
Title: A Multi-Scale Attention-Enhanced Architecture for Gravity Wave Localization in Satellite Imagery
Authors: Seraj Al Mahmud Mostafa, Jianwu Wang
Abstract: Satellite images present unique challenges due to their high object variability and lower spatial resolution, particularly for detecting atmospheric gravity waves which exhibit significant variability in scale, shape, and pattern extent, making accurate localization highly challenging. This variability is further compounded by dominant unwanted objects such as clouds and city lights, as well as instrumental noise, all within a single image channel, while conventional detection methods struggle to capture the diverse and often subtle features of gravity waves across varying conditions. To address these issues, we introduce YOLO-DCAT incorporating Multi Dilated Residual Convolution (MDRC) and Simplified Spatial and Channel Attention (SSCA), an enhanced version of YOLOv5 specifically designed to improve gravity wave localization by effectively handling their complex and variable characteristics. MDRC captures multi-scale features through parallel dilated convolutions with varying dilation rates, while SSCA focuses on the most relevant spatial regions and channel features to enhance detection accuracy and suppress interference from background noise. In our experiments, the improved model outperformed state-of-the-art alternatives, improving mean Average Precision (mAP) by over 14% and Intersection over Union (IoU) by approximately 17%, demonstrating significantly improved localization accuracy for gravity waves in challenging satellite imagery and contributing to more precise climate research and modeling.

Paper number 56:
Title: Adaptive Knowledge Distillation for Device-Directed Speech Detection
Authors: Hyung Gun Chi, Florian Pesce, Wonil Chang, Oggi Rudovic, Arturo Argueta, Stefan Braun, Vineet Garg, Ahmed Hussen Abdelaziz
Abstract: Device-directed speech detection (DDSD) is a binary classification task that separates the user's queries to a voice assistant (VA) from background speech or side conversations. This is important for achieving naturalistic user experience. To this end, we propose knowledge distillation (KD) to enhance DDSD accuracy while ensuring efficient deployment. Specifically, we introduce a novel adaptive KD method that transfers knowledge from general representations of an ASR large pre-trained acoustic encoder (teacher). We apply task-specific adapters, on top of the (frozen) teacher encoder, trained jointly with the student model on DDSD. We demonstrate that the proposed adaptive KD outperforms the student model without distillation in the keyword and keyword-free (follow-up) invocations, with an improvement of +26% and +19% in terms of Equal Error Rate, respectively. We also show that this approach generalizes across the transformer and conformer-based model architectures.

Paper number 57:
Title: Real-World Receptivity to Adaptive Mental Health Interventions: Findings from an In-the-Wild Study
Authors: Nilesh Kumar Sahu, Aditya Sneh, Snehil Gupta, Haroon R Lone
Abstract: The rise of mobile health (mHealth) technologies has enabled real-time monitoring and intervention for mental health conditions using passively sensed smartphone data. Building on these capabilities, Just-in-Time Adaptive Interventions (JITAIs) seek to deliver personalized support at opportune moments, adapting to users' evolving contexts and needs. Although prior research has examined how context affects user responses to generic notifications and general mHealth messages, relatively little work has explored its influence on engagement with actual mental health interventions. Furthermore, while much of the existing research has focused on detecting when users might benefit from an intervention, less attention has been paid to understanding receptivity, i.e., users' willingness and ability to engage with and act upon the intervention. In this study, we investigate user receptivity through two components: acceptance(acknowledging or engaging with a prompt) and feasibility (ability to act given situational constraints). We conducted a two-week in-the-wild study with 70 students using a custom Android app, LogMe, which collected passive sensor data and active context reports to prompt mental health interventions. The adaptive intervention module was built using Thompson Sampling, a reinforcement learning algorithm. We address four research questions relating smartphone features and self-reported contexts to acceptance and feasibility, and examine whether an adaptive reinforcement learning approach can optimize intervention delivery by maximizing a combined receptivity reward. Our results show that several types of passively sensed data significantly influenced user receptivity to interventions. Our findings contribute insights into the design of context-aware, adaptive interventions that are not only timely but also actionable in real-world settings.

Paper number 58:
Title: Tunable Leg Stiffness in a Monopedal Hopper for Energy-Efficient Vertical Hopping Across Varying Ground Profiles
Authors: Rongqian Chen, Jun Kwon, Kefan Wu, Wei-Hsi Chen
Abstract: We present the design and implementation of HASTA (Hopper with Adjustable Stiffness for Terrain Adaptation), a vertical hopping robot with real-time tunable leg stiffness, aimed at optimizing energy efficiency across various ground profiles (a pair of ground stiffness and damping conditions). By adjusting leg stiffness, we aim to maximize apex hopping height, a key metric for energy-efficient vertical hopping. We hypothesize that softer legs perform better on soft, damped ground by minimizing penetration and energy loss, while stiffer legs excel on hard, less damped ground by reducing limb deformation and energy dissipation. Through experimental tests and simulations, we find the best leg stiffness within our selection for each combination of ground stiffness and damping, enabling the robot to achieve maximum steady-state hopping height with a constant energy input. These results support our hypothesis that tunable stiffness improves energy-efficient locomotion in controlled experimental conditions. In addition, the simulation provides insights that could aid in the future development of controllers for selecting leg stiffness.

Paper number 59:
Title: Physics-Embedded Neural ODEs for Sim2Real Edge Digital Twins of Hybrid Power Electronics Systems
Authors: Jialin Zheng, Haoyu Wang, Yangbin Zeng, Di Mou, Xin Zhang, Hong Li, Sergio Vazquez, Leopoldo G. Franquelo
Abstract: Edge Digital Twins (EDTs) are crucial for monitoring and control of Power Electronics Systems (PES). However, existing modeling approaches struggle to consistently capture continuously evolving hybrid dynamics that are inherent in PES, degrading Sim-to-Real generalization on resource-constrained edge devices. To address these challenges, this paper proposes a Physics-Embedded Neural ODEs (PENODE) that (i) embeds the hybrid operating mechanism as an event automaton to explicitly govern discrete switching and (ii) injects known governing ODE components directly into the neural parameterization of unmodeled dynamics. This unified design yields a differentiable end-to-end trainable architecture that preserves physical interpretability while reducing redundancy, and it supports a cloud-to-edge toolchain for efficient FPGA deployment. Experimental results demonstrate that PENODE achieves significantly higher accuracy in benchmarks in white-box, gray-box, and black-box scenarios, with a 75% reduction in neuron count, validating that the proposed PENODE maintains physical interpretability, efficient edge deployment, and real-time control enhancement.

Paper number 60:
Title: Optimal control driven functional electrical stimulation: A scoping review
Authors: Kevin Co, Mickaël Begon, François Bailly, Florent Moissenet
Abstract: Introduction: Rehabilitation after a neurological impairment can be supported by functional electrical stimulation (FES). However, FES is limited by early muscle fatigue, slowing down the recovery progress. The use of optimal control to reduce overstimulation and improve motion precision is gaining interest. This review aims to map the current literature state meanwhile clarifying the best practices, identifying persistent challenges, and outlining directions for future research. Methods: Following the PRISMA guidelines, a search was conducted up to February 2024 using the combined keywords "FES", "optimal control" or "fatigue" across five databases (Medline, Embase, CINAHL Complete, Web of Science, and ProQuest Dissertations & Theses Citation Index). Inclusion criteria included the use of optimal control with FES for healthy individuals and those with neuromuscular disorders. Results: Among the 44 included studies, half were in silico and half in vivo, involving 87 participants, predominantly healthy young men. Twelve different motor tasks were investigated, with a focus on single joint lower limb movements. These studies principally used simple FES models, modulating pulse width or intensity to track joint angle. Conclusions: Optimal control-driven FES can deliver precise motions and reduce fatigue. Yet clinical adoption is slowed down by the lack of consensus about modelling, inconvenient model identification protocol and limited validation. Additional barriers include insufficient open-science practices, computational performance reporting and the availability of customizable commercial hardware. Comparative FES model studies and longitudinal trials with large cohorts, among other efforts, are required to improve the technology readiness level. Such advances would help clinical adoption and improve patient outcomes.

Paper number 61:
Title: Global Optimality in Multi-Flyby Asteroid Trajectory Optimization: Theory and Application Techniques
Authors: Zhong Zhang, Xiang Guo, Di Wu, Hexi Baoyin, Junfeng Li, Francesco Topputo
Abstract: Designing optimal trajectories for multi-flyby asteroid missions is scientifically critical but technically challenging due to nonlinear dynamics, intermediate constraints, and numerous local optima. This paper establishes a method that approaches global optimality for multi-flyby trajectory optimization under a given sequence. The original optimal control problem with interior-point equality constraints is transformed into a multi-stage decision formulation. This reformulation enables direct application of dynamic programming in lower dimensions, and follows Bellman's principle of optimality. Moreover, the method provides a quantifiable bound on global optima errors introduced by discretization and approximation assumptions, thus ensuring a measure of confidence in the obtained solution. The method accommodates both impulsive and low-thrust maneuver schemes in rendezvous and flyby scenarios. Several computational techniques are introduced to enhance efficiency, including a specialized solution for bi-impulse cases and an adaptive step refinement strategy. The proposed method is validated through three problems: 1) an impulsive variant of the fourth Global Trajectory Optimization competition problem (GTOC4), 2) the GTOC11 problem, and 3) the original low-thrust GTOC4 problem. Each case demonstrates improvements in fuel consumption over the best-known trajectories. These results give evidence of the generality and effectiveness of the proposed method in global trajectory optimization.

Paper number 62:
Title: How Would It Sound? Material-Controlled Multimodal Acoustic Profile Generation for Indoor Scenes
Authors: Mahnoor Fatima Saad, Ziad Al-Halah
Abstract: How would the sound in a studio change with a carpeted floor and acoustic tiles on the walls? We introduce the task of material-controlled acoustic profile generation, where, given an indoor scene with specific audio-visual characteristics, the goal is to generate a target acoustic profile based on a user-defined material configuration at inference time. We address this task with a novel encoder-decoder approach that encodes the scene's key properties from an audio-visual observation and generates the target Room Impulse Response (RIR) conditioned on the material specifications provided by the user. Our model enables the generation of diverse RIRs based on various material configurations defined dynamically at inference time. To support this task, we create a new benchmark, the Acoustic Wonderland Dataset, designed for developing and evaluating material-aware RIR prediction methods under diverse and challenging settings. Our results demonstrate that the proposed model effectively encodes material information and generates high-fidelity RIRs, outperforming several baselines and state-of-the-art methods.

Paper number 63:
Title: Neural Approximators for Low-Thrust Trajectory Transfer Cost and Reachability
Authors: Zhong Zhang, Francesco Topputo
Abstract: In trajectory design, fuel consumption and trajectory reachability are two key performance indicators for low-thrust missions. This paper proposes general-purpose pretrained neural networks to predict these metrics. The contributions of this paper are as follows: Firstly, based on the confirmation of the Scaling Law applicable to low-thrust trajectory approximation, the largest dataset is constructed using the proposed homotopy ray method, which aligns with mission-design-oriented data requirements. Secondly, the data are transformed into a self-similar space, enabling the neural network to adapt to arbitrary semi-major axes, inclinations, and central bodies. This extends the applicability beyond existing studies and can generalize across diverse mission scenarios without retraining. Thirdly, to the best of our knowledge, this work presents the current most general and accurate low-thrust trajectory approximator, with implementations available in C++, Python, and MATLAB. The resulting neural network achieves a relative error of 0.78% in predicting velocity increments and 0.63% in minimum transfer time estimation. The models have also been validated on a third-party dataset, multi-flyby mission design problem, and mission analysis scenario, demonstrating their generalization capability, predictive accuracy, and computational efficiency.

Paper number 64:
Title: Engineered over Emergent Communication in MARL for Scalable and Sample-Efficient Cooperative Task Allocation in a Partially Observable Grid
Authors: Brennen A. Hill, Mant Koh En Wei, Thangavel Jishnuanandh
Abstract: We compare the efficacy of learned versus engineered communication strategies in a cooperative multi-agent reinforcement learning (MARL) environment. For the learned approach, we introduce Learned Direct Communication (LDC), where agents generate messages and actions concurrently via a neural network. Our engineered approach, Intention Communication, employs an Imagined Trajectory Generation Module (ITGM) and a Message Generation Network (MGN) to formulate messages based on predicted future states. Both strategies are evaluated on their success rates in cooperative tasks under fully and partially observable conditions. Our findings indicate that while emergent communication is viable, the engineered approach demonstrates superior performance and scalability, particularly as environmental complexity increases.

Paper number 65:
Title: A Comparative Study of Optimal Control and Neural Networks in Asteroid Rendezvous Mission Analysis
Authors: Zhong Zhang, Niccolò Michelotti, Gonçalo Oliveira Pinho, Francesco Topputo
Abstract: This paper presents a comparative study of the applicability and accuracy of optimal control methods and neural network-based estimators in the context of porkchop plots for preliminary asteroid rendezvous mission design. The scenario considered involves a deep-space CubeSat equipped with a low-thrust engine, departing from Earth and rendezvousing with a near-Earth asteroid within a three-year launch window. A low-thrust trajectory optimization model is formulated, incorporating variable specific impulse, maximum thrust, and path constraints. The optimal control problem is efficiently solved using Sequential Convex Programming (SCP) combined with a solution continuation strategy. The neural network framework consists of two models: one predicts the minimum fuel consumption ($\Delta v$), while the other estimates the minimum flight time ($\Delta t$) which is used to assess transfer feasibility. Case results demonstrate that, in simplified scenarios without path constraints, the neural network approach achieves low relative errors across most of the design space and successfully captures the main structural features of the porkchop plots. In cases where the SCP-based continuation method fails due to the presence of multiple local optima, the neural network still provides smooth and globally consistent predictions, significantly improving the efficiency of early-stage asteroid candidate screening. However, the deformation of the feasible region caused by path constraints leads to noticeable discrepancies in certain boundary regions, thereby limiting the applicability of the network in detailed mission design phases. Overall, the integration of neural networks with porkchop plot analysis offers a effective decision-making tool for mission designers and planetary scientists, with significant potential for engineering applications.

Paper number 66:
Title: Quantum Hamiltonian Descent based Augmented Lagrangian Method for Constrained Nonconvex Nonlinear Optimization
Authors: Mingze Li, Lei Fan, Zhu Han
Abstract: Nonlinear programming (NLP) plays a critical role in domains such as power energy systems, chemical engineering, communication networks, and financial engineering. However, solving large-scale, nonconvex NLP problems remains a significant challenge due to the complexity of the solution landscape and the presence of nonlinear nonconvex constraints. In this paper, we develop a Quantum Hamiltonian Descent based Augmented Lagrange Method (QHD-ALM) framework to address largescale, constrained nonconvex NLP problems. The augmented Lagrange method (ALM) can convert a constrained NLP to an unconstrained NLP, which can be solved by using Quantum Hamiltonian Descent (QHD). To run the QHD on a classical machine, we propose to use the Simulated Bifurcation algorithm as the engine to simulate the dynamic process. We apply our algorithm to a Power-to-Hydrogen System, and the simulation results verify the effectiveness of our algorithm.

Paper number 67:
Title: Neural Speech Extraction with Human Feedback
Authors: Malek Itani, Ashton Graves, Sefik Emre Eskimez, Shyamnath Gollakota
Abstract: We present the first neural target speech extraction (TSE) system that uses human feedback for iterative refinement. Our approach allows users to mark specific segments of the TSE output, generating an edit mask. The refinement system then improves the marked sections while preserving unmarked regions. Since large-scale datasets of human-marked errors are difficult to collect, we generate synthetic datasets using various automated masking functions and train models on each. Evaluations show that models trained with noise power-based masking (in dBFS) and probabilistic thresholding perform best, aligning with human annotations. In a study with 22 participants, users showed a preference for refined outputs over baseline TSE. Our findings demonstrate that human-in-the-loop refinement is a promising approach for improving the performance of neural speech extraction.

Paper number 68:
Title: Aerobatic maneuvers in insect-scale flapping-wing aerial robots via deep-learned robust tube model predictive control
Authors: Yi-Hsuan Hsiao, Andrea Tagliabue, Owen Matteson, Suhan Kim, Tong Zhao, Jonathan P. How, YuFeng Chen
Abstract: Aerial insects exhibit highly agile maneuvers such as sharp braking, saccades, and body flips under disturbance. In contrast, insect-scale aerial robots are limited to tracking non-aggressive trajectories with small body acceleration. This performance gap is contributed by a combination of low robot inertia, fast dynamics, uncertainty in flapping-wing aerodynamics, and high susceptibility to environmental disturbance. Executing highly dynamic maneuvers requires the generation of aggressive flight trajectories that push against the hardware limit and a high-rate feedback controller that accounts for model and environmental uncertainty. Here, through designing a deep-learned robust tube model predictive controller, we showcase insect-like flight agility and robustness in a 750-millgram flapping-wing robot. Our model predictive controller can track aggressive flight trajectories under disturbance. To achieve a high feedback rate in a compute-constrained real-time system, we design imitation learning methods to train a two-layer, fully connected neural network, which resembles insect flight control architecture consisting of central nervous system and motor neurons. Our robot demonstrates insect-like saccade movements with lateral speed and acceleration of 197 centimeters per second and 11.7 meters per second square, representing 447$\%$ and 255$\%$ improvement over prior results. The robot can also perform saccade maneuvers under 160 centimeters per second wind disturbance and large command-to-force mapping errors. Furthermore, it performs 10 consecutive body flips in 11 seconds - the most challenging maneuver among sub-gram flyers. These results represent a milestone in achieving insect-scale flight agility and inspire future investigations on sensing and compute autonomy.

Paper number 69:
Title: TF-MLPNet: Tiny Real-Time Neural Speech Separation
Authors: Malek Itani, Tuochao Chen, Shyamnath Gollakota
Abstract: Speech separation on hearable devices can enable transformative augmented and enhanced hearing capabilities. However, state-of-the-art speech separation networks cannot run in real-time on tiny, low-power neural accelerators designed for hearables, due to their limited compute capabilities. We present TF-MLPNet, the first speech separation network capable of running in real-time on such low-power accelerators while outperforming existing streaming models for blind speech separation and target speech extraction. Our network operates in the time-frequency domain, processing frequency sequences with stacks of fully connected layers that alternate along the channel and frequency dimensions, and independently processing the time sequence at each frequency bin using convolutional layers. Results show that our mixed-precision quantization-aware trained (QAT) model can process 6 ms audio chunks in real-time on the GAP9 processor, achieving a 3.5-4x runtime reduction compared to prior speech separation models.

Paper number 70:
Title: Fine-Tuning Text-to-Speech Diffusion Models Using Reinforcement Learning with Human Feedback
Authors: Jingyi Chen, Ju Seung Byun, Micha Elsner, Pichao Wang, Andrew Perrault
Abstract: Diffusion models produce high-fidelity speech but are inefficient for real-time use due to long denoising steps and challenges in modeling intonation and rhythm. To improve this, we propose Diffusion Loss-Guided Policy Optimization (DLPO), an RLHF framework for TTS diffusion models. DLPO integrates the original training loss into the reward function, preserving generative capabilities while reducing inefficiencies. Using naturalness scores as feedback, DLPO aligns reward optimization with the diffusion model's structure, improving speech quality. We evaluate DLPO on WaveGrad 2, a non-autoregressive diffusion-based TTS model. Results show significant improvements in objective metrics (UTMOS 3.65, NISQA 4.02) and subjective evaluations, with DLPO audio preferred 67\% of the time. These findings demonstrate DLPO's potential for efficient, high-quality diffusion TTS in real-time, resource-limited settings.

Paper number 71:
Title: MiSTR: Multi-Modal iEEG-to-Speech Synthesis with Transformer-Based Prosody Prediction and Neural Phase Reconstruction
Authors: Mohammed Salah Al-Radhi, Géza Németh, Branislav Gerazov
Abstract: Speech synthesis from intracranial EEG (iEEG) signals offers a promising avenue for restoring communication in individuals with severe speech impairments. However, achieving intelligible and natural speech remains challenging due to limitations in feature representation, prosody modeling, and phase reconstruction. We introduce MiSTR, a deep-learning framework that integrates: 1) Wavelet-based feature extraction to capture fine-grained temporal, spectral, and neurophysiological representations of iEEG signals, 2) A Transformer-based decoder for prosody-aware spectrogram prediction, and 3) A neural phase vocoder enforcing harmonic consistency via adaptive spectral correction. Evaluated on a public iEEG dataset, MiSTR achieves state-of-the-art speech intelligibility, with a mean Pearson correlation of 0.91 between reconstructed and original Mel spectrograms, improving over existing neural speech synthesis baselines.

Paper number 72:
Title: Timing is everything: How subtle timing changes in MRI echo planar imaging can significantly alter mechanical vibrations and sound level
Authors: Amir Seginer, Alexander Bratch, Shahar Goren, Edna Furman-Haran, Noam Harel, Essa Yacoub, Rita Schmidt
Abstract: Modern MRI relies on the well-established Echo-Planar-Imaging (EPI) method for fast acquisition. EPI is the workhorse of diffusion and functional MRI in neuroscience as well as of many dynamic applications for clinical body imaging. Its speed stems from rapidly switching currents through the gradient coils responsible for spatial encoding. These quick changes, within a strong static magnetic field induce Lorentz forces that generate mechanical vibrations, leading to the loud, characteristic MRI noise. This acoustic noise is already a significant concern in standard clinical scanners, requiring hearing protection and risking image degradation or even hardware strain. In ultra-high-field systems, the issue is exacerbated due to stronger Lorentz forces. In this study, we introduce a novel model that characterizes the acoustic spectrum for a given EPI scan. The spectrum results from interference between multiple identical periods of alternating currents, making the relative timing between them a key factor. We show that even subtle timing changes significantly alter the sound level. Scans of either high spatial resolution or high temporal resolution, on clinical 7T and investigational 10.5T human scanners, corroborated the model and its predicted acoustics spectra. Acoustic energy changes of up to 47-fold were reached in close to mechanical resonances and up to 5-fold in other regions. Intriguingly, under certain conditions, doubling the acquisitions per unit time actually reduced the minimal acoustic energy two-fold. Not less important, ghosting-artifacts exhibit strong dependence on the scan's acoustic characteristics and the benefit of subtle time delays of internal correction-acquisitions (navigators) is also demonstrated.

Paper number 73:
Title: Live Demonstration: Neuromorphic Radar for Gesture Recognition
Authors: Satyapreet Singh Yadav, Chandra Sekhar Seelamantula, Chetan Singh Thakur
Abstract: We present a neuromorphic radar framework for real-time, low-power hand gesture recognition (HGR) using an event-driven architecture inspired by biological sensing. Our system comprises a 24 GHz Doppler radar front-end and a custom neuromorphic sampler that converts intermediate-frequency (IF) signals into sparse spike-based representations via asynchronous sigma-delta encoding. These events are directly processed by a lightweight neural network deployed on a Cortex-M0 microcontroller, enabling low-latency inference without requiring spectrogram reconstruction. Unlike conventional radar HGR pipelines that continuously sample and process data, our architecture activates only when meaningful motion is detected, significantly reducing memory, power, and computation overhead. Evaluated on a dataset of five gestures collected from seven users, our system achieves > 85% real-time accuracy. To the best of our knowledge, this is the first work that employs bio-inspired asynchronous sigma-delta encoding and an event-driven processing framework for radar-based HGR.

Paper number 74:
Title: UniFucGrasp: Human-Hand-Inspired Unified Functional Grasp Annotation Strategy and Dataset for Diverse Dexterous Hands
Authors: Haoran Lin, Wenrui Chen, Xianchi Chen, Fan Yang, Qiang Diao, Wenxin Xie, Sijie Wu, Kailun Yang, Maojun Li, Yaonan Wang
Abstract: Dexterous grasp datasets are vital for embodied intelligence, but mostly emphasize grasp stability, ignoring functional grasps needed for tasks like opening bottle caps or holding cup handles. Most rely on bulky, costly, and hard-to-control high-DOF Shadow Hands. Inspired by the human hand's underactuated mechanism, we establish UniFucGrasp, a universal functional grasp annotation strategy and dataset for multiple dexterous hand types. Based on biomimicry, it maps natural human motions to diverse hand structures and uses geometry-based force closure to ensure functional, stable, human-like grasps. This method supports low-cost, efficient collection of diverse, high-quality functional grasps. Finally, we establish the first multi-hand functional grasp dataset and provide a synthesis model to validate its effectiveness. Experiments on the UFG dataset, IsaacSim, and complex robotic tasks show that our method improves functional manipulation accuracy and grasp stability, enables efficient generalization across diverse robotic hands, and overcomes annotation cost and generalization challenges in dexterous grasping. The project page is at this https URL.

Paper number 75:
Title: When Good Sounds Go Adversarial: Jailbreaking Audio-Language Models with Benign Inputs
Authors: Bodam Kim, Hiskias Dingeto, Taeyoun Kwon, Dasol Choi, DongGeon Lee, Haon Park, JaeHoon Lee, Jongho Shin
Abstract: As large language models become increasingly integrated into daily life, audio has emerged as a key interface for human-AI interaction. However, this convenience also introduces new vulnerabilities, making audio a potential attack surface for adversaries. Our research introduces WhisperInject, a two-stage adversarial audio attack framework that can manipulate state-of-the-art audio language models to generate harmful content. Our method uses imperceptible perturbations in audio inputs that remain benign to human listeners. The first stage uses a novel reward-based optimization method, Reinforcement Learning with Projected Gradient Descent (RL-PGD), to guide the target model to circumvent its own safety protocols and generate harmful native responses. This native harmful response then serves as the target for Stage 2, Payload Injection, where we use Projected Gradient Descent (PGD) to optimize subtle perturbations that are embedded into benign audio carriers, such as weather queries or greeting messages. Validated under the rigorous StrongREJECT, LlamaGuard, as well as Human Evaluation safety evaluation framework, our experiments demonstrate a success rate exceeding 86% across Qwen2.5-Omni-3B, Qwen2.5-Omni-7B, and Phi-4-Multimodal. Our work demonstrates a new class of practical, audio-native threats, moving beyond theoretical exploits to reveal a feasible and covert method for manipulating AI behavior.

Paper number 76:
Title: Channel Coding for Unequal Error Protection in Digital Semantic Communication
Authors: Seonjung Kim, Yongjeong Oh, Yongjune Kim, Namyoon Lee, Yo-Seb Jeon
Abstract: Semantic communication is an emerging paradigm that prioritizes transmitting task-relevant information over accurately delivering raw data bits. In this paper, we address an unequal error protection (UEP) problem in digital semantic communication, where bits of higher semantic importance require stronger protection. To quantify bit-level importance, we leverage bit-flip probabilities of semantic bits as target error protection levels, which are jointly learned with semantic encoder and decoder. We propose two novel channel coding frameworks aimed at minimizing the total blocklength while satisfying UEP constraints. First, we develop a bit-level UEP framework based on repetition coding, in which the repetition number for each bit is optimized to precisely meet its target bit-flip probability. Second, we introduce a block-level UEP framework utilizing modern channel codes, where semantic bits with similar target bit-flip probabilities are grouped to exploit coding gains. Within this framework, we propose a bit-grouping algorithm guided by finite blocklength capacity analysis. Simulation results conducted on image transmission tasks confirm that the proposed frameworks significantly outperform conventional approaches, yielding substantial improvements in both task performance and transmission efficiency.

Paper number 77:
Title: Sparsity and Total Variation Constrained Multilayer Linear Unmixing for Hyperspectral Imagery
Authors: Gang Yang
Abstract: Hyperspectral unmixing aims at estimating material signatures (known as endmembers) and the corresponding proportions (referred to abundances), which is a critical preprocessing step in various hyperspectral imagery applications. This study develops a novel approach called sparsity and total variation (TV) constrained multilayer linear unmixing (STVMLU) for hyperspectral imagery. Specifically, based on a multilayer matrix factorization model, to improve the accuracy of unmixing, a TV constraint is incorporated to consider adjacent spatial similarity. Additionally, a L1/2-norm sparse constraint is adopted to effectively characterize the sparsity of the abundance matrix. For optimizing the STVMLU model, the method of alternating direction method of multipliers (ADMM) is employed, which allows for the simultaneous extraction of endmembers and their corresponding abundance matrix. Experimental results illustrate the enhanced performance of the proposed STVMLU when compared to other algorithms.

Paper number 78:
Title: Residual Neural Terminal Constraint for MPC-based Collision Avoidance in Dynamic Environments
Authors: Bojan Derajić, Mohamed-Khalil Bouzidi, Sebastian Bernhard, Wolfgang Hönig
Abstract: In this paper, we propose a hybrid MPC local planner that uses a learning-based approximation of a time-varying safe set, derived from local observations and applied as the MPC terminal constraint. This set can be represented as a zero-superlevel set of the value function computed via Hamilton-Jacobi (HJ) reachability analysis, which is infeasible in real-time. We exploit the property that the HJ value function can be expressed as a difference of the corresponding signed distance function (SDF) and a non-negative residual function. The residual component is modeled as a neural network with non-negative output and subtracted from the computed SDF, resulting in a real-time value function estimate that is at least as safe as the SDF by design. Additionally, we parametrize the neural residual by a hypernetwork to improve real-time performance and generalization properties. The proposed method is compared with three state-of-the-art methods in simulations and hardware experiments, achieving up to 30\% higher success rates compared to the best baseline while requiring a similar computational effort and producing high-quality (low travel-time) solutions.

Paper number 79:
Title: SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering
Authors: Jan Melechovsky, Ambuj Mehrish, Dorien Herremans
Abstract: Music recordings often suffer from audio quality issues such as excessive reverberation, distortion, clipping, tonal imbalances, and a narrowed stereo image, especially when created in non-professional settings without specialized equipment or expertise. These problems are typically corrected using separate specialized tools and manual adjustments. In this paper, we introduce SonicMaster, the first unified generative model for music restoration and mastering that addresses a broad spectrum of audio artifacts with text-based control. SonicMaster is conditioned on natural language instructions to apply targeted enhancements, or can operate in an automatic mode for general restoration. To train this model, we construct the SonicMaster dataset, a large dataset of paired degraded and high-quality tracks by simulating common degradation types with nineteen degradation functions belonging to five enhancements groups: equalization, dynamics, reverb, amplitude, and stereo. Our approach leverages a flow-matching generative training paradigm to learn an audio transformation that maps degraded inputs to their cleaned, mastered versions guided by text prompts. Objective audio quality metrics demonstrate that SonicMaster significantly improves sound quality across all artifact categories. Furthermore, subjective listening tests confirm that listeners prefer SonicMaster's enhanced outputs over the original degraded audio, highlighting the effectiveness of our unified approach.

Paper number 80:
Title: CloudBreaker: Breaking the Cloud Covers of Sentinel-2 Images using Multi-Stage Trained Conditional Flow Matching on Sentinel-1
Authors: Saleh Sakib Ahmed, Sara Nowreen, M. Sohel Rahman
Abstract: Cloud cover and nighttime conditions remain significant limitations in satellite-based remote sensing, often restricting the availability and usability of multi-spectral imagery. In contrast, Sentinel-1 radar images are unaffected by cloud cover and can provide consistent data regardless of weather or lighting conditions. To address the challenges of limited satellite imagery, we propose CloudBreaker, a novel framework that generates high-quality multi-spectral Sentinel-2 signals from Sentinel-1 data. This includes the reconstruction of optical (RGB) images as well as critical vegetation and water indices such as NDVI and this http URL employed a novel multi-stage training approach based on conditional latent flow matching and, to the best of our knowledge, are the first to integrate cosine scheduling with flow matching. CloudBreaker demonstrates strong performance, achieving a Frechet Inception Distance (FID) score of 0.7432, indicating high fidelity and realism in the generated optical imagery. The model also achieved Structural Similarity Index Measure (SSIM) of 0.6156 for NDWI and 0.6874 for NDVI, indicating a high degree of structural similarity. This establishes CloudBreaker as a promising solution for a wide range of remote sensing applications where multi-spectral data is typically unavailable or unreliable

Paper number 81:
Title: Streaming Generated Gaussian Process Experts for Online Learning and Control
Authors: Zewen Yang, Dongfa Zhang, Xiaobing Dai, Fengyi Yu, Chi Zhang, Bingkun Huang, Hamid Sadeghian, Sami Haddadin
Abstract: Gaussian Processes (GPs), as a nonparametric learning method, offer flexible modeling capabilities and calibrated uncertainty quantification for function approximations. Additionally, GPs support online learning by efficiently incorporating new data with polynomial-time computation, making them well-suited for safety-critical dynamical systems that require rapid adaptation. However, the inference and online updates of exact GPs, when processing streaming data, incur cubic computation time and quadratic storage memory complexity, limiting their scalability to large datasets in real-time settings. In this paper, we propose a \underline{s}treaming \underline{k}ernel-induced progressivel\underline{y} generated expert framework of \underline{G}aussian \underline{p}rocesses (SkyGP) that addresses both computational and memory constraints by maintaining a bounded set of experts, while inheriting the learning performance guarantees from exact Gaussian processes. Furthermore, two SkyGP variants are introduced, each tailored to a specific objective, either maximizing prediction accuracy (SkyGP-Dense) or improving computational efficiency (SkyGP-Fast). The effectiveness of SkyGP is validated through extensive benchmarks and real-time control experiments demonstrating its superior performance compared to state-of-the-art approaches.

Paper number 82:
Title: What If, But Privately: Private Counterfactual Retrieval
Authors: Shreya Meel, Mohamed Nomeir, Pasan Dissanayake, Sanghamitra Dutta, Sennur Ulukus
Abstract: Transparency and explainability are two important aspects to be considered when employing black-box machine learning models in high-stake applications. Providing counterfactual explanations is one way of catering this requirement. However, this also poses a threat to the privacy of the institution that is providing the explanation, as well as the user who is requesting it. In this work, we are primarily concerned with the user's privacy who wants to retrieve a counterfactual instance, without revealing their feature vector to the institution. Our framework retrieves the exact nearest neighbor counterfactual explanation from a database of accepted points while achieving perfect, information-theoretic, privacy for the user. First, we introduce the problem of private counterfactual retrieval (PCR) and propose a baseline PCR scheme that keeps the user's feature vector information-theoretically private from the institution. Building on this, we propose two other schemes that reduce the amount of information leaked about the institution database to the user, compared to the baseline scheme. Second, we relax the assumption of mutability of all features, and consider the setting of immutable PCR (I-PCR). Here, the user retrieves the nearest counterfactual without altering a private subset of their features, which constitutes the immutable set, while keeping their feature vector and immutable set private from the institution. For this, we propose two schemes that preserve the user's privacy information-theoretically, but ensure varying degrees of database privacy. Third, we extend our PCR and I-PCR schemes to incorporate user's preference on transforming their attributes, so that a more actionable explanation can be received. Finally, we present numerical results to support our theoretical findings, and compare the database leakage of the proposed schemes.

Paper number 83:
Title: Differentially Private Distributed Nonconvex Stochastic Optimization with Quantized Communication
Authors: Jialong Chen, Jimin Wang, Ji-Feng Zhang
Abstract: This paper proposes a new distributed nonconvex stochastic optimization algorithm that can achieve privacy protection, communication efficiency and convergence simultaneously. Specifically, each node adds general privacy noises to its local state to avoid information leakage, and then quantizes its noise-perturbed state before transmitting to improve communication efficiency. By using a subsampling method controlled through the sample-size parameter, the proposed algorithm reduces cumulative differential privacy parameters {\epsilon}, {\delta}, and thus enhances the differential privacy level, which is significantly different from the existing works. By using a two-time-scale step-sizes method, the mean square convergence for nonconvex cost functions is given. Furthermore, when the global cost function satisfies the Polyak-Lojasiewicz condition, the convergence rate and the oracle complexity of the proposed algorithm are given. In addition, the proposed algorithm achieves both the mean square convergence and finite cumulative differential privacy parameters {\epsilon}, {\delta} over infinite iterations as the sample-size goes to infinity. A numerical example of the distributed training on the "MNIST" dataset is given to show the effectiveness of the algorithm.

Paper number 84:
Title: FCDM: A Physics-Guided Bidirectional Frequency Aware Convolution and Diffusion-Based Model for Sinogram Inpainting
Authors: Jiaze E, Srutarshi Banerjee, Tekin Bicer, Guannan Wang, Yanfu Zhang, Bin Ren
Abstract: Computed tomography (CT) is widely used in scientific and medical imaging, but acquiring full-view sinograms requires high radiation dose and long scan times. Sparse-view CT alleviates this burden but yields incomplete sinograms with structured signal loss, hampering accurate reconstruction. Unlike RGB images, sinograms encode overlapping features along projection paths and exhibit directional spectral patterns. Standard inpainting models overlook these properties, treating missing data as local holes and neglecting angular dependencies and physical consistency. We propose~\modelname, a diffusion-based framework tailored for sinograms, which restores global structure through bidirectional frequency reasoning and angular-aware masking, while enforcing physical plausibility via physics-guided constraints and frequency-adaptive noise control. Experiments on synthetic and real-world datasets show that~\modelname~consistently outperforms baselines, achieving SSIM over 0.93 and PSNR above 31 dB across diverse sparse-view scenarios.

Paper number 85:
Title: Robust Sensor-Limited Control with Safe Input-Output Constraints for Hydraulic In-Wheel Motor Drive Mobility Systems
Authors: Mehdi Heydari Shahna, Pauli Mustalahti, Jouni Mattila
Abstract: In-wheel drive (IWD) systems enhance the responsiveness, traction, and maintenance efficiency of vehicles by enabling each wheel to operate independently. This paper proposes a novel robust torque-observed valve-based control (RTOVC) framework to address velocity tracking in hydraulic IWDs that actuate heavy-duty wheeled mobile robots (HWMRs), considering such challenges as wheel slippages, sensor limitations, rough terrains, and modeling uncertainties. To overcome the sensor-dependent control systems associated with the closed-loop torque/pressure in hydraulic IWD-actuated HWMRs, a robust observer network based on an adaptive barrier Lyapunov function (BLF) is proposed to estimate the required in-wheel motor torque to track the velocity references. Then, another adaptive BLF for valve control signals is employed to modulate the hydraulic fluid to generate the estimated torque for each IWD. The RTOVC strategy ensures user-defined safety within the logarithmic BLF framework by constraining the valve control signal, actual velocity, velocity tracking error, and torque of each hydraulic IWD in an HWMR to avoid exceeding specified limits. Despite its safety constraints, external disturbances, and modeling uncertainties, robustness and uniformly exponential stability of the RTOVC-applied hydraulic IWD mechanism are ensured in HWMRs. Experimental investigations using a 6,500-kg HWMR, actuated by four independent IWDs under intense disturbances and safety-defined constraints, validate the performance of the RTOVC.

Paper number 86:
Title: AI-driven Wireless Positioning: Fundamentals, Standards, State-of-the-art, and Challenges
Authors: Guangjin Pan, Yuan Gao, Yilin Gao, Wenjun Yu, Zhiyong Zhong, Xiaoyu Yang, Xinyu Guo, Shugong Xu
Abstract: Wireless positioning technologies hold significant value for applications in autonomous driving, extended reality (XR), unmanned aerial vehicles (UAVs), and more. With the advancement of artificial intelligence (AI), leveraging AI to enhance positioning accuracy and robustness has emerged as a field full of potential. Driven by the requirements and functionalities defined in the 3rd Generation Partnership Project (3GPP) standards, AI/machine learning (ML)-based cellular positioning is becoming a key technology to overcome the limitations of traditional methods. This paper presents a comprehensive survey of AI-driven cellular positioning. We begin by reviewing the fundamentals of wireless positioning and AI models, analyzing their respective challenges and synergies. We provide a comprehensive review of the evolution of 3GPP positioning standards, with a focus on the integration of AI/ML in current and upcoming standard releases. Guided by the 3GPP-defined taxonomy, we categorize and summarize state-of-the-art (SOTA) research into two major classes: AI/ML-assisted positioning and direct AI/ML-based positioning. The former includes line-of-sight (LOS)/non-line-of-sight (NLOS) detection, time of arrival (TOA)/time difference of arrival (TDOA) estimation, and angle prediction; the latter encompasses fingerprinting, knowledge-assisted learning, and channel charting. Furthermore, we review representative public datasets and conduct performance evaluations of AI-based positioning algorithms using these datasets. Finally, we conclude by summarizing the challenges and opportunities of AI-driven wireless positioning.

Paper number 87:
Title: Model Reference-Based Control with Guaranteed Predefined Performance for Uncertain Strict-Feedback Systems
Authors: Mehdi Heydari Shahna, Jukka-Pekka Humaloja, Jouni Mattila
Abstract: To address the complexities posed by time- and state-varying uncertainties and the computation of analytic derivatives in strict-feedback form (SFF) systems, this study introduces a novel model reference-based control (MRBC) framework which applies locally to each subsystem (SS), to ensure output tracking performance within the specified transient and steady-state response criteria. This framework includes 1) novel homogeneous adaptive estimators (HAEs) designed to match the uncertain nonlinear SFF system to a reference model, enabling easier analysis and control design at the level, and 2) model-based homogeneous adaptive controllers enhanced by logarithmic barrier Lyapunov functions (HAC-BLFs), intended to control the reference model provided by HAEs in each SS, while ensuring the prescribed tracking responses under control amplitude saturation. The inherently robust MRBC achieves uniformly exponential stability using a generic stability connector term, which addresses dynamic interactions between the adjacent SSs. The parameter sensitivities of HAEs and HAC-BLFs in the MRBC framework are analyzed, focusing on the system's robustness and responsiveness. The proposed MRBC framework is experimentally validated through several scenarios involving an electromechanical linear actuator system with an uncertain SFF, subjected loading disturbance forces challenging 0-95% of its capacity.

Paper number 88:
Title: Millimeter-Wave Communication Testbed Using Digital Coding Dynamic Metasurface Antenna: Practical Design and Implementation
Authors: Abdul Jabbar, Mostafa Elsayed, Jalil Ur-Rehman Kazim, Zhibo Pang, Julien Le Kernec, Muhammad Imran, Hadi Larijani, Masood Ur-Rehman, Qammer Abbasi, Muhammad Usman
Abstract: Dynamic Metasurface Antennas (DMAs) are transforming reconfigurable antenna technology by enabling energy-efficient, cost-effective beamforming through programmable meta-elements, eliminating the need for traditional phase shifters and delay lines. This breakthrough technology is emerging to revolutionize beamforming for next-generation wireless communication and sensing networks. In this paper, we present the design and real-world implementation of a DMA-assisted wireless communication platform operating in the license-free 60 GHz millimeter-wave (mmWave) band. Our system employs high-speed binary-coded sequences generated via a field-programmable gate array (FPGA), enabling real-time beam steering for spatial multiplexing and independent data transmission. A proof-of-concept experiment successfully demonstrates high-definition quadrature phase-shift keying (QPSK) modulated video transmission at 62 GHz. Furthermore, leveraging the DMA's multi-beam capability, we simultaneously transmit video to two spatially separated receivers, achieving accurate demodulation. We envision the proposed mmWave testbed as a platform for enabling the seamless integration of sensing and communication by allowing video transmission to be replaced with sensing data or utilizing an auxiliary wireless channel to transmit sensing information to multiple receivers. This synergy paves the way for advancing integrated sensing and communication (ISAC) in beyond-5G and 6G networks. Additionally, our testbed demonstrates potential for real-world use cases, including mmWave backhaul links and massive multiple-input multiple-output (MIMO) mmWave base stations.

Paper number 89:
Title: Semi-Data-Driven Model Predictive Control: A Physics-Informed Data-Driven Control Approach
Authors: Sebastian Zieglmeier, Mathias Hudoba de Badyn, Narada D. Warakagoda, Thomas R. Krogstad, Paal Engelstad
Abstract: Data-enabled predictive control (DeePC) has emerged as a powerful technique to control complex systems without the need for extensive modeling efforts. However, relying solely on offline collected data trajectories to represent the system dynamics introduces certain drawbacks. Therefore, we present a novel semi-data-driven model predictive control (SD-MPC) framework that combines (limited) model information with DeePC to address a range of these drawbacks, including sensitivity to noisy data and a lack of robustness. In this work, we focus on the performance of DeePC in operating regimes not captured by the offline collected data trajectories and demonstrate how incorporating an underlying parametric model can counteract this issue. SD-MPC exhibits equivalent closed-loop performance as DeePC for deterministic linear time-invariant systems. Simulations demonstrate the general control performance of the proposed SD-MPC for both a linear time-invariant system and a nonlinear system modeled as a linear parameter-varying system. These results provide numerical evidence of the enhanced robustness of SD-MPC over classical DeePC.

Paper number 90:
Title: Pseudo-Autoregressive Neural Codec Language Models for Efficient Zero-Shot Text-to-Speech Synthesis
Authors: Yifan Yang, Shujie Liu, Jinyu Li, Yuxuan Hu, Haibin Wu, Hui Wang, Jianwei Yu, Lingwei Meng, Haiyang Sun, Yanqing Liu, Yan Lu, Kai Yu, Xie Chen
Abstract: Recent zero-shot text-to-speech (TTS) systems face a common dilemma: autoregressive (AR) models suffer from slow generation and lack duration controllability, while non-autoregressive (NAR) models lack temporal modeling and typically require complex designs. In this paper, we introduce a novel pseudo-autoregressive (PAR) codec language modeling approach that unifies AR and NAR modeling. Combining explicit temporal modeling from AR with parallel generation from NAR, PAR generates dynamic-length spans at fixed time steps. Building on PAR, we propose PALLE, a two-stage TTS system that leverages PAR for initial generation followed by NAR refinement. In the first stage, PAR progressively generates speech tokens along the time dimension, with each step predicting all positions in parallel but only retaining the left-most span. In the second stage, low-confidence tokens are iteratively refined in parallel, leveraging the global contextual information. Experiments demonstrate that PALLE, trained on LibriTTS, outperforms state-of-the-art systems trained on large-scale data, including F5-TTS, E2-TTS, and MaskGCT, on the LibriSpeech test-clean set in terms of speech quality, speaker similarity, and intelligibility, while achieving up to ten times faster inference speed. Audio samples are available at this https URL.

Paper number 91:
Title: Physical Degradation Model-Guided Interferometric Hyperspectral Reconstruction with Unfolding Transformer
Authors: Yuansheng Li, Yunhao Zou, Linwei Chen, Ying Fu
Abstract: Interferometric Hyperspectral Imaging (IHI) is a critical technique for large-scale remote sensing tasks due to its advantages in flux and spectral resolution. However, IHI is susceptible to complex errors arising from imaging steps, and its quality is limited by existing signal processing-based reconstruction algorithms. Two key challenges hinder performance enhancement: 1) the lack of training datasets. 2) the difficulty in eliminating IHI-specific degradation components through learning-based methods. To address these challenges, we propose a novel IHI reconstruction pipeline. First, based on imaging physics and radiometric calibration data, we establish a simplified yet accurate IHI degradation model and a parameter estimation method. This model enables the synthesis of realistic IHI training datasets from hyperspectral images (HSIs), bridging the gap between IHI reconstruction and deep learning. Second, we design the Interferometric Hyperspectral Reconstruction Unfolding Transformer (IHRUT), which achieves effective spectral correction and detail restoration through a stripe-pattern enhancement mechanism and a spatial-spectral transformer architecture. Experimental results demonstrate the superior performance and generalization capability of our this http URL code and are available at this https URL.

Paper number 92:
Title: Topology Optimization in Medical Image Segmentation with Fast Euler Characteristic
Authors: Liu Li, Qiang Ma, Cheng Ouyang, Johannes C. Paetzold, Daniel Rueckert, Bernhard Kainz
Abstract: Deep learning-based medical image segmentation techniques have shown promising results when evaluated based on conventional metrics such as the Dice score or Intersection-over-Union. However, these fully automatic methods often fail to meet clinically acceptable accuracy, especially when topological constraints should be observed, e.g., continuous boundaries or closed surfaces. In medical image segmentation, the correctness of a segmentation in terms of the required topological genus sometimes is even more important than the pixel-wise accuracy. Existing topology-aware approaches commonly estimate and constrain the topological structure via the concept of persistent homology (PH). However, these methods are difficult to implement for high dimensional data due to their polynomial computational complexity. To overcome this problem, we propose a novel and fast approach for topology-aware segmentation based on the Euler Characteristic ($\chi$). First, we propose a fast formulation for $\chi$ computation in both 2D and 3D. The scalar $\chi$ error between the prediction and ground-truth serves as the topological evaluation metric. Then we estimate the spatial topology correctness of any segmentation network via a so-called topological violation map, i.e., a detailed map that highlights regions with $\chi$ errors. Finally, the segmentation results from the arbitrary network are refined based on the topological violation maps by a topology-aware correction network. Our experiments are conducted on both 2D and 3D datasets and show that our method can significantly improve topological correctness while preserving pixel-wise segmentation accuracy.

Paper number 93:
Title: Predicting EGFR Mutation in LUAD from Histopathological Whole-Slide Images Using Pretrained Foundation Model and Transfer Learning: An Indian Cohort Study
Authors: Sagar Singh Gwal, Rajan, Suyash Devgan, Shraddhanjali Satapathy, Abhishek Goyal, Nuruddin Mohammad Iqbal, Vivaan Jain, Prabhat Singh Mallik, Deepali Jain, Ishaan Gupta
Abstract: Lung adenocarcinoma (LUAD) is a subtype of non-small cell lung cancer (NSCLC). LUAD with mutation in the EGFR gene accounts for approximately 46% of LUAD cases. Patients carrying EGFR mutations can be treated with specific tyrosine kinase inhibitors (TKIs). Hence, predicting EGFR mutation status can help in clinical decision making. H&E-stained whole slide imaging (WSI) is a routinely performed screening procedure for cancer staging and subtyping, especially affecting the Southeast Asian populations with significantly higher incidence of the mutation when compared to Caucasians (39-64% vs 7-22%). Recent progress in AI models has shown promising results in cancer detection and classification. In this study, we propose a deep learning (DL) framework built on vision transformers (ViT) based pathology foundation model and attention-based multiple instance learning (ABMIL) architecture to predict EGFR mutation status from H&E WSI. The developed pipeline was trained using data from an Indian cohort (170 WSI) and evaluated across two independent datasets: Internal test (30 WSI from Indian cohort) set, and an external test set from TCGA (86 WSI). The model shows consistent performance across both datasets, with AUCs of 0.933 (+/-0.010), and 0.965 (+/-0.015) for the internal and external test sets respectively. This proposed framework can be efficiently trained on small datasets, achieving superior performance as compared to several prior studies irrespective of training domain. The current study demonstrates the feasibility of accurately predicting EGFR mutation status using routine pathology slides, particularly in resource-limited settings using foundation models and attention-based multiple instance learning.

Paper number 94:
Title: Identifying actionable driver mutations in lung cancer using an efficient Asymmetric Transformer Decoder
Authors: Biagio Brattoli, Jack Shi, Jongchan Park, Taebum Lee, Donggeun Yoo, Sergio Pereira
Abstract: Identifying actionable driver mutations in non-small cell lung cancer (NSCLC) can impact treatment decisions and significantly improve patient outcomes. Despite guideline recommendations, broader adoption of genetic testing remains challenging due to limited availability and lengthy turnaround times. Machine Learning (ML) methods for Computational Pathology (CPath) offer a potential solution; however, research often focuses on only one or two common mutations, limiting the clinical value of these tools and the pool of patients who can benefit from them. This study evaluates various Multiple Instance Learning (MIL) techniques to detect six key actionable NSCLC driver mutations: ALK, BRAF, EGFR, ERBB2, KRAS, and MET ex14. Additionally, we introduce an Asymmetric Transformer Decoder model that employs queries and key-values of varying dimensions to maintain a low query dimensionality. This approach efficiently extracts information from patch embeddings and minimizes overfitting risks, proving highly adaptable to the MIL setting. Moreover, we present a method to directly utilize tissue type in the model, addressing a typical MIL limitation where either all regions or only some specific regions are analyzed, neglecting biological relevance. Our method outperforms top MIL models by an average of 3%, and over 4% when predicting rare mutations such as ERBB2 and BRAF, moving ML-based tests closer to being practical alternatives to standard genetic testing.

Paper number 95:
Title: Generalized Compressed Sensing for Image Reconstruction with Diffusion Probabilistic Models
Authors: Ling-Qi Zhang, Zahra Kadkhodaie, Eero P. Simoncelli, David H. Brainard
Abstract: We examine the problem of selecting a small set of linear measurements for reconstructing high-dimensional signals. Well-established methods for optimizing such measurements include principal component analysis (PCA), independent component analysis (ICA) and compressed sensing (CS) based on random projections, all of which rely on axis- or subspace-aligned statistical characterization of the signal source. However, many naturally occurring signals, including photographic images, contain richer statistical structure. To exploit such structure, we introduce a general method for obtaining an optimized set of linear measurements for efficient image reconstruction, where the signal statistics are expressed by the prior implicit in a neural network trained to perform denoising (known as a "diffusion model"). We demonstrate that the optimal measurements derived for two natural image datasets differ from those of PCA, ICA, or CS, and result in substantially lower mean squared reconstruction error. Interestingly, the marginal distributions of the measurement values are asymmetrical (skewed), substantially more so than those of previous methods. We also find that optimizing with respect to perceptual loss, as quantified by structural similarity (SSIM), leads to measurements different from those obtained when optimizing for MSE. Our results highlight the importance of incorporating the specific statistical regularities of natural signals when designing effective linear measurements.

Paper number 96:
Title: BrainECHO: Semantic Brain Signal Decoding through Vector-Quantized Spectrogram Reconstruction for Whisper-Enhanced Text Generation
Authors: Jilong Li, Zhenxi Song, Jiaqi Wang, Meishan Zhang, Honghai Liu, Min Zhang, Zhiguo Zhang
Abstract: Current EEG/MEG-to-text decoding systems suffer from three key limitations: (1) reliance on teacher-forcing methods, which compromises robustness during inference, (2) sensitivity to session-specific noise, hindering generalization across subjects, and (3) misalignment between brain signals and linguistic representations due to pre-trained language model over-dominance. To overcome these challenges, we propose BrainECHO (Brain signal decoding via vEctor-quantized speCtrogram reconstruction for WHisper-enhanced text generatiOn), a multi-stage framework that employs decoupled representation learning to achieve state-of-the-art performance on both EEG and MEG datasets. Specifically, BrainECHO consists of three stages: (1) Discrete autoencoding, which transforms continuous Mel spectrograms into a finite set of high-quality discrete representations for subsequent stages. (2) Frozen alignment, where brain signal embeddings are mapped to corresponding Mel spectrogram embeddings in a frozen latent space, effectively filtering session-specific noise through vector-quantized reconstruction, yielding a 3.65% improvement in BLEU-4 score. (3) Constrained decoding fine-tuning, which leverages the pre-trained Whisper model for audio-to-text translation, balancing signal adaptation with knowledge preservation, and achieving 74%-89% decoding BLEU scores without excessive reliance on teacher forcing. BrainECHO demonstrates robustness across sentence, session, and subject-independent conditions, passing Gaussian noise tests and showcasing its potential for enhancing language-based brain-computer interfaces.

Paper number 97:
Title: Individual Content and Motion Dynamics Preserved Pruning for Video Diffusion Models
Authors: Yiming Wu, Zhenghao Chen, Huan Wang, Dong Xu
Abstract: The high computational cost and slow inference time are major obstacles to deploying Video Diffusion Models (VDMs). To overcome this, we introduce a new Video Diffusion Model Compression approach using individual content and motion dynamics preserved pruning and consistency loss. First, we empirically observe that deeper VDM layers are crucial for maintaining the quality of \textbf{motion dynamics} (\textit{e.g.,} coherence of the entire video), while shallower layers are more focused on \textbf{individual content} (\textit{e.g.,} individual frames). Therefore, we prune redundant blocks from the shallower layers while preserving more of the deeper layers, resulting in a lightweight VDM variant called VDMini. Moreover, we propose an \textbf{Individual Content and Motion Dynamics (ICMD)} Consistency Loss to gain comparable generation performance as larger VDM to VDMini. In particular, we first use the Individual Content Distillation (ICD) Loss to preserve the consistency in the features of each generated frame between the teacher and student models. Next, we introduce a Multi-frame Content Adversarial (MCA) Loss to enhance the motion dynamics across the generated video as a whole. This method significantly accelerates inference time while maintaining high-quality video generation. Extensive experiments demonstrate the effectiveness of our VDMini on two important video generation tasks, Text-to-Video (T2V) and Image-to-Video (I2V), where we respectively achieve an average 2.5 $\times$, 1.4 $\times$, and 1.25 $\times$ speed up for the I2V method SF-V, the T2V method T2V-Turbo-v2, and the T2V method HunyuanVideo, while maintaining the quality of the generated videos on several benchmarks including UCF101, VBench-T2V, and VBench-I2V.

Paper number 98:
Title: IntroStyle: Training-Free Introspective Style Attribution using Diffusion Features
Authors: Anand Kumar, Jiteng Mu, Nuno Vasconcelos
Abstract: Text-to-image (T2I) models have recently gained widespread adoption. This has spurred concerns about safeguarding intellectual property rights and an increasing demand for mechanisms that prevent the generation of specific artistic styles. Existing methods for style extraction typically necessitate the collection of custom datasets and the training of specialized models. This, however, is resource-intensive, time-consuming, and often impractical for real-time applications. We present a novel, training-free framework to solve the style attribution problem, using the features produced by a diffusion model alone, without any external modules or retraining. This is denoted as Introspective Style attribution (IntroStyle) and is shown to have superior performance to state-of-the-art models for style attribution. We also introduce a synthetic dataset of Artistic Style Split (ArtSplit) to isolate artistic style and evaluate fine-grained style attribution performance. Our experimental results on WikiArt and DomainNet datasets show that \ours is robust to the dynamic nature of artistic styles, outperforming existing methods by a wide margin.

Paper number 99:
Title: A Minimax Optimal Controller for Positive Systems
Authors: Alba Gurpegui, Emma Tegling, Anders Rantzer
Abstract: We present an explicit solution to the discrete-time Bellman equation for minimax optimal control of positive systems under unconstrained disturbances. The primary contribution of our result relies on deducing a bound for the disturbance penalty, which characterizes the existence of a finite solution to the problem class. Moreover, this constraint on the disturbance penalty reveals that, in scenarios where a solution is feasible, the problem converges to its equivalent minimization problem in the absence of disturbances.

Paper number 100:
Title: 16 Ways to Gallop: Energetics and Body Dynamics of High-Speed Quadrupedal Gaits
Authors: Yasser G. Alqaham, Jing Cheng, Zhenyu Gan
Abstract: Galloping is a common high-speed gait in both animals and quadrupedal robots, yet its energetic characteristics remain insufficiently explored. This study systematically analyzes a large number of possible galloping gaits by categorizing them based on the number of flight phases per stride and the phase relationships between the front and rear legs, following Hildebrand's framework for asymmetrical gaits. Using the A1 quadrupedal robot from Unitree, we model galloping dynamics as a hybrid dynamical system and employ trajectory optimization (TO) to minimize the cost of transport (CoT) across a range of speeds. Our results reveal that rotary and transverse gallop footfall sequences exhibit no fundamental energetic difference, despite variations in body yaw and roll motion. However, the number of flight phases significantly impacts energy efficiency: galloping with no flight phases is optimal at lower speeds, whereas galloping with two flight phases minimizes energy consumption at higher speeds. We validate these findings using a quadratic programming (QP)-based controller, developed in our previous work, in Gazebo simulations. These insights advance the understanding of quadrupedal locomotion energetics and may inform future legged robot designs for adaptive, energy-efficient gait transitions.

Paper number 101:
Title: Self-sustained oscillations in discrete-time relay feedback systems
Authors: Kang Tong, Christian Grussler, Michelle S. Chong
Abstract: We study the problem of determining self-sustained oscillations in discrete-time linear time-invariant relay feedback systems. Concretely, we are interested in predicting when such a system admits unimodal oscillations, i.e., when the output has a single-peaked period. Under the assumption that the linear system is stable and has an impulse response that is strictly monotonically decreasing on its infinite support, we take a novel approach in using the framework of total positivity to address our main question. It is shown that unimodal self-oscillations can only exist if the number of positive and negative elements in a period coincides. Based on this result, we derive conditions for the existence of such oscillations, determine bounds on their periods, and address the question of uniqueness.

Paper number 102:
Title: Low-Bit Integerization of Vision Transformers using Operand Reordering for Efficient Hardware
Authors: Ching-Yi Lin, Sahil Shah
Abstract: Pre-trained vision transformers have achieved remarkable performance across various visual tasks but suffer from expensive computational and memory costs. While model quantization reduces memory usage by lowering precision, these models still incur significant computational overhead due to the dequantization before matrix operations. In this work, we analyze the computation graph and propose an integerization process based on operation reordering. Specifically, the process delays dequantization until after matrix operations. This enables integerized matrix multiplication and linear module by directly processing the quantized input. To validate our approach, we synthesize the self-attention module of ViT on a systolic array-based hardware. Experimental results show that our low-bit inference reduces per-PE power consumption for linear layer and matrix multiplication, bridging the gap between quantized models and efficient inference.

Paper number 103:
Title: Rethink Repeatable Measures of Robot Performance with Statistical Query
Authors: Bowen Weng, Linda Capito, Guillermo A. Castillo, Dylan Khor
Abstract: For a general standardized testing algorithm designed to evaluate a specific aspect of a robot's performance, several key expectations are commonly imposed. Beyond accuracy (i.e., closeness to a typically unknown ground-truth reference) and efficiency (i.e., feasibility within acceptable testing costs and equipment constraints), one particularly important attribute is repeatability. Repeatability refers to the ability to consistently obtain the same testing outcome when similar testing algorithms are executed on the same subject robot by different stakeholders, across different times or locations. However, achieving repeatable testing has become increasingly challenging as the components involved grow more complex, intelligent, diverse, and, most importantly, stochastic. While related efforts have addressed repeatability at ethical, hardware, and procedural levels, this study focuses specifically on repeatable testing at the algorithmic level. Specifically, we target the well-adopted class of testing algorithms in standardized evaluation: statistical query (SQ) algorithms (i.e., algorithms that estimate the expected value of a bounded function over a distribution using sampled data). We propose a lightweight, parameterized, and adaptive modification applicable to any SQ routine, whether based on Monte Carlo sampling, importance sampling, or adaptive importance sampling, that makes it provably repeatable, with guaranteed bounds on both accuracy and efficiency. We demonstrate the effectiveness of the proposed approach across three representative scenarios: (i) established and widely adopted standardized testing of manipulators, (ii) emerging intelligent testing algorithms for operational risk assessment in automated vehicles, and (iii) developing use cases involving command tracking performance evaluation of humanoid robots in locomotion tasks.

Paper number 104:
Title: Three Tone Networks and a Tessellation
Authors: Jeffrey R. Boland, Lane P. Hughston
Abstract: The Eulerian tonnetz, which associates three minor chords to each major chord and three major chords to each minor chord, can be represented by a bipartite graph with twelve white vertices signifying major chords and twelve black vertices signifying minor chords. This so-called Levi graph uniquely determines the combinatorial geometry of a remarkable configuration of twelve points and twelve lines in the real projective plane with the property that three points lie on each line and three lines pass through each point. Interesting features of the tonnetz, such as the existence of the four principal hexacycles and the three principal octacycles, crucial for the understanding of nineteenth-century voice leading, can be read off rather directly as properties of the configuration. We show how analogous tone networks can be constructed for pentatonic music and twelve-tone music.

Paper number 105:
Title: Enhancing AI System Resiliency: Formulation and Guarantee for LSTM Resilience Based on Control Theory
Authors: Sota Yoshihara (1), Ryosuke Yamamoto (2), Hiroyuki Kusumoto (1), Masanari Shimura (1) ((1) Graduate School of Mathematics, Nagoya University, (2) AISIN SOFTWARE Co., Ltd.)
Abstract: This paper proposes a novel theoretical framework for guaranteeing and evaluating the resilience of long short-term memory (LSTM) networks in control systems. We introduce "recovery time" as a new metric of resilience in order to quantify the time required for an LSTM to return to its normal state after anomalous inputs. By mathematically refining incremental input-to-state stability ($\delta$ISS) theory for LSTM, we derive a practical data-independent upper bound on recovery time. This upper bound gives us resilience-aware training. Experimental validation on simple models demonstrates the effectiveness of our resilience estimation and control methods, enhancing a foundation for rigorous quality assurance in safety-critical AI applications.

Paper number 106:
Title: AudioGenie: A Training-Free Multi-Agent Framework for Diverse Multimodality-to-Multiaudio Generation
Authors: Yan Rong, Jinting Wang, Guangzhi Lei, Shan Yang, Li Liu
Abstract: Multimodality-to-Multiaudio (MM2MA) generation faces significant challenges in synthesizing diverse and contextually aligned audio types (e.g., sound effects, speech, music, and songs) from multimodal inputs (e.g., video, text, images), owing to the scarcity of high-quality paired datasets and the lack of robust multi-task learning frameworks. Recently, multi-agent system shows great potential in tackling the above issues. However, directly applying it to MM2MA task presents three critical challenges: (1) inadequate fine-grained understanding of multimodal inputs (especially for video), (2) the inability of single models to handle diverse audio events, and (3) the absence of self-correction mechanisms for reliable outputs. To this end, we propose AudioGenie, a novel training-free multi-agent system featuring a dual-layer architecture with a generation team and a supervisor team. For the generation team, a fine-grained task decomposition and an adaptive Mixture-of-Experts (MoE) collaborative entity are designed for detailed comprehensive multimodal understanding and dynamic model selection, and a trial-and-error iterative refinement module is designed for self-correction. The supervisor team ensures temporal-spatial consistency and verifies outputs through feedback loops. Moreover, we build MA-Bench, the first benchmark for MM2MA tasks, comprising 198 annotated videos with multi-type audios. Experiments demonstrate that our AudioGenie achieves state-of-the-art (SOTA) or comparable performance across 9 metrics in 8 tasks. User study further validates the effectiveness of our method in terms of quality, accuracy, alignment, and aesthetic. The project website with audio samples can be found at this https URL.

Paper number 107:
Title: UniCUE: Unified Recognition and Generation Framework for Chinese Cued Speech Video-to-Speech Generation
Authors: Jinting Wang, Shan Yang, Chenxing Li, Dong Yu, Li Liu
Abstract: Cued Speech (CS) enhances lipreading via hand coding, offering visual phonemic cues that support precise speech perception for the hearing-impaired. The task of CS Video-to-Speech generation (CSV2S) aims to convert CS videos into intelligible speech signals. Most existing research focuses on CS Recognition (CSR), which transcribes video content into text. Consequently, a common solution for CSV2S is to integrate CSR with a text-to-speech (TTS) system. However, this pipeline relies on text as an intermediate medium, which may lead to error propagation and temporal misalignment between speech and CS video dynamics. In contrast, directly generating audio speech from CS video (direct CSV2S) often suffers from the inherent multimodal complexity and the limited availability of CS data. To address these challenges, we propose UniCUE, the first unified framework for CSV2S that directly generates speech from CS videos without relying on intermediate text. The core innovation of UniCUE lies in integrating an understanding task (CSR) that provides fine-grained CS visual-semantic cues to guide speech generation. Specifically, UniCUE incorporates a pose-aware visual processor, a semantic alignment pool that enables precise visual-semantic mapping, and a VisioPhonetic adapter to bridge the understanding and generation tasks within a unified architecture. To support this framework, we construct UniCUE-HI, a large-scale Mandarin CS dataset containing 11282 videos from 14 cuers, including both hearing-impaired and normal-hearing individuals. Extensive experiments on this dataset demonstrate that UniCUE achieves state-of-the-art performance across multiple evaluation metrics.

Paper number 108:
Title: What Makes a Good Speech Tokenizer for LLM-Centric Speech Generation? A Systematic Study
Authors: Xiaoran Fan, Zhichao Sun, Yangfan Gao, Jingfei Xiong, Hang Yan, Yifei Cao, Jiajun Sun, Shuo Li, Zhihao Zhang, Zhiheng Xi, Yuhao Zhou, Senjie Jin, Changhao Jiang, Junjie Ye, Ming Zhang, Rui Zheng, Zhenhua Han, Yunke Zhang, Demei Yan, Shaokang Dong, Tao Ji, Tao Gui, Qi Zhang, Xuanjing Huang
Abstract: Speech-language models (SLMs) offer a promising path toward unifying speech and text understanding and generation. However, challenges remain in achieving effective cross-modal alignment and high-quality speech generation. In this work, we systematically investigate the role of speech tokenizer designs in LLM-centric SLMs, augmented by speech heads and speaker modeling. We compare coupled, semi-decoupled, and fully decoupled speech tokenizers under a fair SLM framework and find that decoupled tokenization significantly improves alignment and synthesis quality. To address the information density mismatch between speech and text, we introduce multi-token prediction (MTP) into SLMs, enabling each hidden state to decode multiple speech tokens. This leads to up to 12$\times$ faster decoding and a substantial drop in word error rate (from 6.07 to 3.01). Furthermore, we propose a speaker-aware generation paradigm and introduce RoleTriviaQA, a large-scale role-playing knowledge QA benchmark with diverse speaker identities. Experiments demonstrate that our methods enhance both knowledge understanding and speaker consistency.

Paper number 109:
Title: Detection of Intelligent Tampering in Wireless Electrocardiogram Signals Using Hybrid Machine Learning
Authors: Siddhant Deshpande, Yalemzerf Getnet, Waltenegus Dargie
Abstract: With the proliferation of wireless electrocardiogram (ECG) systems for health monitoring and authentication, protecting signal integrity against tampering is becoming increasingly important. This paper analyzes the performance of CNN, ResNet, and hybrid Transformer-CNN models for tamper detection. It also evaluates the performance of a Siamese network for ECG based identity verification. Six tampering strategies, including structured segment substitutions and random insertions, are emulated to mimic real world attacks. The one-dimensional ECG signals are transformed into a two dimensional representation in the time frequency domain using the continuous wavelet transform (CWT). The models are trained and evaluated using ECG data from 54 subjects recorded in four sessions 2019 to 2025 outside of clinical settings while the subjects performed seven different daily activities. Experimental results show that in highly fragmented manipulation scenarios, CNN, FeatCNN-TranCNN, FeatCNN-Tran and ResNet models achieved an accuracy exceeding 99.5 percent . Similarly, for subtle manipulations (for example, 50 percent from A and 50 percent from B and, 75 percent from A and 25 percent from B substitutions) our FeatCNN-TranCNN model demonstrated consistently reliable performance, achieving an average accuracy of 98 percent . For identity verification, the pure Transformer-Siamese network achieved an average accuracy of 98.30 percent . In contrast, the hybrid CNN-Transformer Siamese model delivered perfect verification performance with 100 percent accuracy.

Paper number 110:
Title: Exogeneous PpIX model for brain tumour assessment
Authors: John Raschke, Jean Pierre Ndabakuranye, Bobbi Fleiss, Arman Ahnood
Abstract: Reliable in-vitro models are used for optoelectronic device development such as fluorescence detection devices for fluorescence-guided surgery of gliomas. A common approach is based on inducing gliomas in animal models. This is followed by a dosage of 5-ALA to induce Protoporphyrin IX (PpIX) in the glioma and which fluoresces. Although these approaches excel in capturing key biomolecular and physiological features of the tumour, they are inherently indeterministic. This limits the scope of their use for preclinical device development, where consistent and controllable tumour reproduction across multiple animals is needed. Approaches using fluorescence markers in gelatine provide a simple replication but fail to capture the complexities of in-vivo models. In this study, we introduce an exogenous brain tumour model for assessing PpIX fluorescence detection. The model was developed by injecting a PpIX solution into the cortical region of a resected adult rat brain, the injection site simulated a tumoral region with elevated PpIX concentration. The tumoral region had a gradient of concentrations, with a peak at the centre and a decrease towards the margins, akin to in-vivo gliomas. The fluorescence profile was compared to in-vivo conditions using 5-ALA and correlated well with other reported works, achieving a correlation of R2>0.93. The model's validity was tested by examining the effect of the solvent, DMSO, on the Autofluorescence (AF) of the brain sample and the short-term effect of storage on AF was analysed. Examinations confirmed the solvent did not alter AF, and the brain sample should be stored in Hanks Balanced Salt Solution and refrigerated to maintain moisture and preserve AF. The model accurately replicated surgical fluorescence conditions and offers a suitable alternative to glioma induction, benefiting the development of fluorescence detection devices across design iterations.

Paper number 111:
Title: SemiSegECG: A Multi-Dataset Benchmark for Semi-Supervised Semantic Segmentation in ECG Delineation
Authors: Minje Park, Jeonghwa Lim, Taehyung Yu, Sunghoon Joo
Abstract: Electrocardiogram (ECG) delineation, the segmentation of meaningful waveform features, is critical for clinical diagnosis. Despite recent advances using deep learning, progress has been limited by the scarcity of publicly available annotated datasets. Semi-supervised learning presents a promising solution by leveraging abundant unlabeled ECG data. In this study, we present SemiSegECG, the first systematic benchmark for semi-supervised semantic segmentation (SemiSeg) in ECG delineation. We curated and unified multiple public datasets, including previously underused sources, to support robust and diverse evaluation. We adopted five representative SemiSeg algorithms from computer vision, implemented them on two different architectures: the convolutional network and the transformer, and evaluated them in two different settings: in-domain and cross-domain. Additionally, we propose ECG-specific training configurations and augmentation strategies and introduce a standardized evaluation framework. Our results show that the transformer outperforms the convolutional network in semi-supervised ECG delineation. We anticipate that SemiSegECG will serve as a foundation for advancing semi-supervised ECG delineation methods and will facilitate further research in this domain.

Paper number 112:
Title: Residual Koopman Model Predictive Control for Enhanced Vehicle Dynamics with Small On-Track Data Input
Authors: Yonghao Fu, Cheng Hu, Haokun Xiong, Zhanpeng Bao, Wenyuan Du, Edoardo Ghignone, Michele Magno, Lei Xie, Hongye Su
Abstract: In vehicle trajectory tracking tasks, the simplest approach is the Pure Pursuit (PP) Control. However, this single-point preview tracking strategy fails to consider vehicle model constraints, compromising driving safety. Model Predictive Control (MPC) as a widely adopted control method, optimizes control actions by incorporating mechanistic models and physical constraints. While its control performance critically depends on the accuracy of vehicle modeling. Traditional vehicle modeling approaches face inherent trade-offs between capturing nonlinear dynamics and maintaining computational efficiency, often resulting in reduced control performance. To address these challenges, this paper proposes Residual Koopman Model Predictive Control (RKMPC) framework. This method uses two linear MPC architecture to calculate control inputs: a Linear Model Predictive Control (LMPC) computes the baseline control input based on the vehicle kinematic model, and a neural network-based RKMPC calculates the compensation input. The final control command is obtained by adding these two components. This design preserves the reliability and interpretability of traditional mechanistic model while achieving performance optimization through residual modeling. This method has been validated on the Carsim-Matlab joint simulation platform and a physical 1:10 scale F1TENTH racing car. Experimental results show that RKMPC requires only 20% of the training data needed by traditional Koopman Model Predictive Control (KMPC) while delivering superior tracking performance. Compared to traditional LMPC, RKMPC reduces lateral error by 11.7%-22.1%, decreases heading error by 8.9%-15.8%, and improves front-wheel steering stability by up to 27.6%. The implementation code is available at: this https URL Koopman.

Paper number 113:
Title: AudioGen-Omni: A Unified Multimodal Diffusion Transformer for Video-Synchronized Audio, Speech, and Song Generation
Authors: Le Wang, Jun Wang, Feng Deng, Chen Zhang, Di Zhang, Kun Gai
Abstract: We present AudioGen-Omni - a unified approach based on multimodal diffusion transformers (MMDit), capable of generating high-fidelity audio, speech, and songs coherently synchronized with the input video. AudioGen-Omni introduces a novel joint training paradigm that seamlessly integrates large-scale video-text-audio corpora, enabling a model capable of generating semantically rich, acoustically diverse audio conditioned on multimodal inputs and adaptable to a wide range of audio generation tasks. AudioGen-Omni employs a unified lyrics-transcription encoder that encodes graphemes and phonemes from both sung and spoken inputs into dense frame-level representations. Dense frame-level representations are fused using an AdaLN-based joint attention mechanism enhanced with phase-aligned anisotropic positional infusion (PAAPI), wherein RoPE is selectively applied to temporally structured modalities to ensure precise and robust cross-modal alignment. By unfreezing all modalities and masking missing inputs, AudioGen-Omni mitigates the semantic constraints of text-frozen paradigms, enabling effective cross-modal conditioning. This joint training approach enhances audio quality, semantic alignment, and lip-sync accuracy, while also achieving state-of-the-art results on Text-to-Audio/Speech/Song tasks. With an inference time of 1.91 seconds for 8 seconds of audio, it offers substantial improvements in both efficiency and generality.

Paper number 114:
Title: Improving Drone Racing Performance Through Iterative Learning MPC
Authors: Haocheng Zhao, Niklas Schlüter, Lukas Brunke, Angela P. Schoellig
Abstract: Autonomous drone racing presents a challenging control problem, requiring real-time decision-making and robust handling of nonlinear system dynamics. While iterative learning model predictive control (LMPC) offers a promising framework for iterative performance improvement, its direct application to drone racing faces challenges like real-time compatibility or the trade-off between time-optimal and safe traversal. In this paper, we enhance LMPC with three key innovations: (1) an adaptive cost function that dynamically weights time-optimal tracking against centerline adherence, (2) a shifted local safe set to prevent excessive shortcutting and enable more robust iterative updates, and (3) a Cartesian-based formulation that accommodates safety constraints without the singularities or integration errors associated with Frenet-frame transformations. Results from extensive simulation and real-world experiments demonstrate that our improved algorithm can optimize initial trajectories generated by a wide range of controllers with varying levels of tuning for a maximum improvement in lap time by 60.85%. Even applied to the most aggressively tuned state-of-the-art model-based controller, MPCC++, on a real drone, a 6.05% improvement is still achieved. Overall, the proposed method pushes the drone toward faster traversal and avoids collisions in simulation and real-world experiments, making it a practical solution to improve the peak performance of drone racing.

Paper number 115:
Title: Hidden in the Noise: Unveiling Backdoors in Audio LLMs Alignment through Latent Acoustic Pattern Triggers
Authors: Liang Lin, Miao Yu, Kaiwen Luo, Yibo Zhang, Lilan Peng, Dexian Wang, Xuehai Tang, Yuanhe Zhang, Xikang Yang, Zhenhong Zhou, Kun Wang, Yang Liu
Abstract: As Audio Large Language Models (ALLMs) emerge as powerful tools for speech processing, their safety implications demand urgent attention. While considerable research has explored textual and vision safety, audio's distinct characteristics present significant challenges. This paper first investigates: Is ALLM vulnerable to backdoor attacks exploiting acoustic triggers? In response to this issue, we introduce Hidden in the Noise (HIN), a novel backdoor attack framework designed to exploit subtle, audio-specific features. HIN applies acoustic modifications to raw audio waveforms, such as alterations to temporal dynamics and strategic injection of spectrally tailored noise. These changes introduce consistent patterns that an ALLM's acoustic feature encoder captures, embedding robust triggers within the audio stream. To evaluate ALLM robustness against audio-feature-based triggers, we develop the AudioSafe benchmark, assessing nine distinct risk types. Extensive experiments on AudioSafe and three established safety datasets reveal critical vulnerabilities in existing ALLMs: (I) audio features like environment noise and speech rate variations achieve over 90% average attack success rate. (II) ALLMs exhibit significant sensitivity differences across acoustic features, particularly showing minimal response to volume as a trigger, and (III) poisoned sample inclusion causes only marginal loss curve fluctuations, highlighting the attack's stealth.
    